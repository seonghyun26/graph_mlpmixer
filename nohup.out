Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 224, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 224, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 224, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 224, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Processing...
Done!
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/exp.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 224, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/exp.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/exp.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 224, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/exp.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/exp.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 224, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/exp.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/exp.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 224, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/exp.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Processing...
Done!
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'lap_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/sr25.py", line 54, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 73, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/sr25.py", line 14, in train
    batch_pos_enc = data.lap_pos_enc
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'lap_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'lap_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/sr25.py", line 54, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 73, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/sr25.py", line 14, in train
    batch_pos_enc = data.lap_pos_enc
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'lap_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'lap_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/sr25.py", line 54, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 73, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/sr25.py", line 14, in train
    batch_pos_enc = data.lap_pos_enc
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'lap_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'lap_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/sr25.py", line 54, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 73, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/sr25.py", line 14, in train
    batch_pos_enc = data.lap_pos_enc
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'lap_pos_enc'
Downloading https://www.dropbox.com/s/feo9qle74kg48gy/molecules.zip?dl=1
Extracting dataset/ZINC/molecules.zip
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 47, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 80, in create_dataset
    train_dataset = ZINC(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/zinc.py", line 100, in __init__
    super().__init__(root, transform, pre_transform, pre_filter)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py", line 55, in __init__
    super().__init__(root, transform, pre_transform, pre_filter, log)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 91, in __init__
    self._download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 185, in _download
    self.download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/zinc.py", line 123, in download
    extract_zip(path, self.root)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/extract.py", line 39, in extract_zip
    with zipfile.ZipFile(path, 'r') as f:
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/zipfile.py", line 1251, in __init__
    self.fp = io.open(file, filemode)
FileNotFoundError: [Errno 2] No such file or directory: 'dataset/ZINC/molecules.zip'
Downloading https://www.dropbox.com/s/feo9qle74kg48gy/molecules.zip?dl=1
Extracting dataset/ZINC/molecules.zip
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 47, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 80, in create_dataset
    train_dataset = ZINC(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/zinc.py", line 100, in __init__
    super().__init__(root, transform, pre_transform, pre_filter)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py", line 55, in __init__
    super().__init__(root, transform, pre_transform, pre_filter, log)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 91, in __init__
    self._download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 185, in _download
    self.download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/zinc.py", line 123, in download
    extract_zip(path, self.root)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/extract.py", line 39, in extract_zip
    with zipfile.ZipFile(path, 'r') as f:
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/zipfile.py", line 1251, in __init__
    self.fp = io.open(file, filemode)
FileNotFoundError: [Errno 2] No such file or directory: 'dataset/ZINC/molecules.zip'
Downloading https://www.dropbox.com/s/feo9qle74kg48gy/molecules.zip?dl=1
Extracting dataset/ZINC/molecules.zip
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 47, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 80, in create_dataset
    train_dataset = ZINC(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/zinc.py", line 100, in __init__
    super().__init__(root, transform, pre_transform, pre_filter)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py", line 55, in __init__
    super().__init__(root, transform, pre_transform, pre_filter, log)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 91, in __init__
    self._download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 185, in _download
    self.download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/zinc.py", line 123, in download
    extract_zip(path, self.root)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/extract.py", line 39, in extract_zip
    with zipfile.ZipFile(path, 'r') as f:
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/zipfile.py", line 1251, in __init__
    self.fp = io.open(file, filemode)
FileNotFoundError: [Errno 2] No such file or directory: 'dataset/ZINC/molecules.zip'
Downloading https://www.dropbox.com/s/feo9qle74kg48gy/molecules.zip?dl=1
Extracting dataset/ZINC/molecules.zip
Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/train.index
Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/val.index
Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/test.index
Processing...
  0%|          | 0/10000 [00:00<?, ?it/s]Processing train dataset:   0%|          | 0/10000 [00:00<?, ?it/s]Processing train dataset:   0%|          | 1/10000 [00:00<17:11,  9.70it/s]Processing train dataset:   0%|          | 12/10000 [00:00<02:41, 61.68it/s]Processing train dataset:   0%|          | 18/10000 [00:00<02:55, 56.90it/s]Processing train dataset:   0%|          | 28/10000 [00:00<02:27, 67.79it/s]Processing train dataset:   0%|          | 38/10000 [00:00<02:19, 71.28it/s]Processing train dataset:   0%|          | 46/10000 [00:00<02:33, 64.83it/s]Processing train dataset:   1%|          | 59/10000 [00:00<02:05, 79.08it/s]Processing train dataset:   1%|          | 74/10000 [00:00<01:41, 98.18it/s]Processing train dataset:   1%|          | 103/10000 [00:01<01:05, 150.91it/s]Processing train dataset:   1%|▏         | 126/10000 [00:01<00:58, 169.66it/s]Processing train dataset:   1%|▏         | 144/10000 [00:01<01:07, 144.95it/s]Processing train dataset:   2%|▏         | 173/10000 [00:01<00:55, 177.15it/s]Processing train dataset:   2%|▏         | 194/10000 [00:01<00:53, 183.90it/s]Processing train dataset:   2%|▏         | 214/10000 [00:01<00:52, 185.33it/s]Processing train dataset:   2%|▏         | 236/10000 [00:01<00:50, 193.83it/s]Processing train dataset:   3%|▎         | 280/10000 [00:01<00:36, 262.70it/s]Processing train dataset:   3%|▎         | 311/10000 [00:01<00:37, 256.78it/s]Processing train dataset:   3%|▎         | 338/10000 [00:02<00:45, 213.87it/s]Processing train dataset:   4%|▎         | 369/10000 [00:02<00:40, 236.80it/s]Processing train dataset:   4%|▍         | 401/10000 [00:02<00:40, 238.42it/s]Processing train dataset:   4%|▍         | 426/10000 [00:02<00:41, 230.44it/s]Processing train dataset:   5%|▍         | 463/10000 [00:02<00:35, 265.38it/s]Processing train dataset:   5%|▍         | 491/10000 [00:02<00:37, 252.64it/s]Processing train dataset:   5%|▌         | 518/10000 [00:02<00:51, 183.36it/s]Processing train dataset:   5%|▌         | 540/10000 [00:03<00:52, 180.06it/s]Processing train dataset:   6%|▌         | 583/10000 [00:03<00:40, 229.98it/s]Processing train dataset:   6%|▌         | 609/10000 [00:03<00:40, 234.65it/s]Processing train dataset:   7%|▋         | 678/10000 [00:03<00:26, 347.87it/s]Processing...
  0%|          | 0/10000 [00:00<?, ?it/s]Processing train dataset:   0%|          | 0/10000 [00:00<?, ?it/s]Processing...
  0%|          | 0/10000 [00:00<?, ?it/s]Processing train dataset:   0%|          | 0/10000 [00:00<?, ?it/s]Processing train dataset:   0%|          | 1/10000 [00:00<34:54,  4.77it/s]Processing train dataset:   0%|          | 1/10000 [00:00<32:59,  5.05it/s]Processing train dataset:   7%|▋         | 717/10000 [00:03<00:37, 246.96it/s]Processing...
  0%|          | 0/10000 [00:00<?, ?it/s]Processing train dataset:   0%|          | 0/10000 [00:00<?, ?it/s]Processing train dataset:   0%|          | 7/10000 [00:00<06:10, 26.94it/s]Processing train dataset:   0%|          | 9/10000 [00:00<05:07, 32.47it/s]Processing train dataset:   0%|          | 5/10000 [00:00<03:30, 47.55it/s]Processing train dataset:   0%|          | 14/10000 [00:00<03:55, 42.46it/s]Processing train dataset:   0%|          | 15/10000 [00:00<03:58, 41.88it/s]Processing train dataset:   0%|          | 13/10000 [00:00<02:43, 61.23it/s]Processing train dataset:   0%|          | 21/10000 [00:00<03:21, 49.52it/s]Processing train dataset:   0%|          | 22/10000 [00:00<03:19, 49.97it/s]Processing train dataset:   0%|          | 20/10000 [00:00<02:44, 60.53it/s]Processing train dataset:   0%|          | 28/10000 [00:00<03:03, 54.38it/s]Processing train dataset:   0%|          | 30/10000 [00:00<02:54, 57.05it/s]Processing train dataset:   0%|          | 37/10000 [00:00<02:45, 60.27it/s]Processing train dataset:   0%|          | 36/10000 [00:00<02:44, 60.40it/s]Processing train dataset:   0%|          | 27/10000 [00:00<02:45, 60.30it/s]Processing train dataset:   0%|          | 34/10000 [00:00<02:38, 62.90it/s]Processing train dataset:   0%|          | 44/10000 [00:00<02:41, 61.83it/s]Processing train dataset:   0%|          | 43/10000 [00:00<02:44, 60.66it/s]Processing train dataset:   1%|          | 51/10000 [00:00<02:38, 62.72it/s]Processing train dataset:   0%|          | 41/10000 [00:00<02:40, 61.92it/s]Processing train dataset:   0%|          | 50/10000 [00:00<02:43, 60.88it/s]Processing train dataset:   7%|▋         | 749/10000 [00:04<01:26, 107.20it/s]Processing train dataset:   1%|          | 58/10000 [00:01<02:35, 64.00it/s]Processing train dataset:   0%|          | 48/10000 [00:00<02:42, 61.36it/s]Processing train dataset:   1%|          | 57/10000 [00:01<02:41, 61.73it/s]Processing train dataset:   1%|          | 65/10000 [00:01<02:39, 62.31it/s]Processing train dataset:   1%|          | 64/10000 [00:01<02:37, 63.06it/s]Processing train dataset:   1%|          | 55/10000 [00:00<02:43, 60.88it/s]Processing train dataset:   1%|          | 72/10000 [00:01<02:36, 63.32it/s]Processing train dataset:   1%|          | 71/10000 [00:01<02:33, 64.60it/s]Processing train dataset:   1%|          | 62/10000 [00:01<02:42, 60.98it/s]Processing train dataset:   1%|          | 79/10000 [00:01<02:33, 64.71it/s]Processing train dataset:   1%|          | 78/10000 [00:01<02:31, 65.37it/s]Processing train dataset:   1%|          | 69/10000 [00:01<02:40, 61.84it/s]Processing train dataset:   1%|          | 86/10000 [00:01<02:32, 65.10it/s]Processing train dataset:   1%|          | 85/10000 [00:01<02:32, 64.94it/s]Processing train dataset:   1%|          | 76/10000 [00:01<02:39, 62.29it/s]Processing train dataset:   1%|          | 93/10000 [00:01<02:30, 65.88it/s]Processing train dataset:   1%|          | 92/10000 [00:01<02:32, 65.10it/s]Processing train dataset:   1%|          | 83/10000 [00:01<02:38, 62.61it/s]Processing train dataset:   1%|          | 100/10000 [00:01<02:29, 66.21it/s]Processing train dataset:   1%|          | 99/10000 [00:01<02:31, 65.52it/s]Processing train dataset:   1%|          | 90/10000 [00:01<02:38, 62.40it/s]Processing train dataset:   1%|          | 107/10000 [00:01<02:29, 66.25it/s]Processing train dataset:   1%|          | 106/10000 [00:01<02:29, 66.11it/s]Processing train dataset:   8%|▊         | 772/10000 [00:05<02:18, 66.77it/s] Processing train dataset:   1%|          | 97/10000 [00:01<02:41, 61.47it/s]Processing train dataset:   1%|          | 113/10000 [00:01<02:31, 65.48it/s]Processing train dataset:   1%|          | 114/10000 [00:01<02:38, 62.28it/s]Processing train dataset:   1%|          | 104/10000 [00:01<02:37, 62.86it/s]Processing train dataset:   8%|▊         | 789/10000 [00:05<02:08, 71.56it/s]Processing train dataset:   1%|          | 120/10000 [00:02<02:31, 65.16it/s]Processing train dataset:   1%|          | 121/10000 [00:02<02:35, 63.51it/s]Processing train dataset:   1%|          | 112/10000 [00:01<02:31, 65.07it/s]Processing train dataset:   1%|▏         | 127/10000 [00:02<02:31, 64.98it/s]Processing train dataset:   1%|▏         | 128/10000 [00:02<02:33, 64.44it/s]Processing train dataset:   1%|          | 119/10000 [00:01<02:29, 66.05it/s]Processing train dataset:   8%|▊         | 805/10000 [00:05<02:03, 74.19it/s]Processing train dataset:   1%|▏         | 135/10000 [00:02<02:30, 65.53it/s]Processing train dataset:   1%|▏         | 134/10000 [00:02<02:31, 64.91it/s]Processing train dataset:   1%|▏         | 127/10000 [00:02<02:26, 67.32it/s]Processing train dataset:   1%|▏         | 141/10000 [00:02<02:31, 65.03it/s]Processing train dataset:   8%|▊         | 819/10000 [00:05<02:04, 74.00it/s]Processing train dataset:   1%|▏         | 142/10000 [00:02<02:45, 59.50it/s]Processing train dataset:   1%|▏         | 134/10000 [00:02<02:26, 67.16it/s]Processing...
  0%|          | 0/10000 [00:00<?, ?it/s]Processing train dataset:   0%|          | 0/10000 [00:00<?, ?it/s]Processing train dataset:   1%|▏         | 149/10000 [00:02<02:25, 67.88it/s]Processing train dataset:   2%|▏         | 150/10000 [00:02<02:34, 63.84it/s]Processing train dataset:   1%|▏         | 141/10000 [00:02<02:28, 66.52it/s]Processing train dataset:   0%|          | 9/10000 [00:00<02:00, 82.78it/s]Processing train dataset:   2%|▏         | 158/10000 [00:02<02:17, 71.46it/s]Processing train dataset:   8%|▊         | 831/10000 [00:06<02:10, 70.05it/s]Processing train dataset:   2%|▏         | 159/10000 [00:02<02:22, 69.04it/s]Processing train dataset:   1%|▏         | 149/10000 [00:02<02:24, 68.33it/s]Processing train dataset:   0%|          | 20/10000 [00:00<01:46, 94.06it/s]Processing train dataset:   2%|▏         | 166/10000 [00:02<02:17, 71.58it/s]Processing train dataset:   2%|▏         | 167/10000 [00:02<02:19, 70.52it/s]Processing train dataset:   2%|▏         | 158/10000 [00:02<02:16, 72.15it/s]Processing train dataset:   0%|          | 32/10000 [00:00<01:37, 102.12it/s]Processing train dataset:   8%|▊         | 841/10000 [00:06<02:17, 66.40it/s]Processing train dataset:   2%|▏         | 174/10000 [00:02<02:19, 70.26it/s]Processing train dataset:   2%|▏         | 175/10000 [00:02<02:21, 69.60it/s]Processing train dataset:   2%|▏         | 167/10000 [00:02<02:11, 74.66it/s]Processing train dataset:   0%|          | 43/10000 [00:00<01:35, 104.38it/s]Processing train dataset:   8%|▊         | 850/10000 [00:06<02:12, 69.12it/s]Processing train dataset:   2%|▏         | 182/10000 [00:02<02:19, 70.30it/s]Processing train dataset:   2%|▏         | 183/10000 [00:02<02:22, 68.83it/s]Processing train dataset:   2%|▏         | 175/10000 [00:02<02:11, 74.46it/s]Processing train dataset:   1%|          | 55/10000 [00:00<01:32, 107.12it/s]Processing train dataset:   9%|▊         | 859/10000 [00:06<02:13, 68.56it/s]Processing train dataset:   2%|▏         | 190/10000 [00:03<02:19, 70.50it/s]Processing train dataset:   2%|▏         | 190/10000 [00:03<02:24, 68.03it/s]Processing train dataset:   2%|▏         | 183/10000 [00:02<02:12, 73.94it/s]Processing train dataset:   1%|          | 66/10000 [00:00<01:35, 103.87it/s]Processing train dataset:   9%|▊         | 867/10000 [00:06<02:10, 69.99it/s]Processing train dataset:   2%|▏         | 199/10000 [00:03<02:13, 73.52it/s]Processing train dataset:   2%|▏         | 198/10000 [00:03<02:19, 70.16it/s]Processing train dataset:   2%|▏         | 192/10000 [00:02<02:08, 76.29it/s]Processing train dataset:   1%|          | 78/10000 [00:00<01:33, 106.29it/s]Processing train dataset:   9%|▉         | 875/10000 [00:06<02:11, 69.36it/s]Processing train dataset:   2%|▏         | 208/10000 [00:03<02:10, 75.19it/s]Processing train dataset:   2%|▏         | 206/10000 [00:03<02:16, 71.72it/s]Processing train dataset:   2%|▏         | 200/10000 [00:03<02:10, 75.30it/s]Processing train dataset:   1%|          | 90/10000 [00:00<01:31, 107.97it/s]Processing train dataset:   2%|▏         | 216/10000 [00:03<02:11, 74.39it/s]Processing train dataset:   9%|▉         | 887/10000 [00:06<01:58, 77.22it/s]Processing train dataset:   2%|▏         | 214/10000 [00:03<02:18, 70.71it/s]Processing train dataset:   2%|▏         | 209/10000 [00:03<02:07, 77.00it/s]Processing train dataset:   2%|▏         | 224/10000 [00:03<02:10, 75.14it/s]Processing train dataset:   2%|▏         | 222/10000 [00:03<02:16, 71.49it/s]Processing train dataset:   2%|▏         | 217/10000 [00:03<02:07, 76.65it/s]Processing train dataset:   1%|          | 101/10000 [00:01<02:00, 81.87it/s]Processing train dataset:   2%|▏         | 232/10000 [00:03<02:14, 72.41it/s]Processing train dataset:   2%|▏         | 230/10000 [00:03<02:22, 68.49it/s]Processing train dataset:   2%|▏         | 225/10000 [00:03<02:13, 72.97it/s]Processing train dataset:   1%|          | 111/10000 [00:01<02:13, 74.34it/s]Processing train dataset:   2%|▏         | 240/10000 [00:03<02:12, 73.44it/s]Processing train dataset:   9%|▉         | 896/10000 [00:07<02:55, 51.77it/s]Processing train dataset:   2%|▏         | 237/10000 [00:03<02:25, 66.88it/s]Processing train dataset:   2%|▏         | 233/10000 [00:03<02:18, 70.49it/s]Processing train dataset:   1%|          | 122/10000 [00:01<02:01, 81.27it/s]Processing train dataset:   2%|▏         | 248/10000 [00:03<02:16, 71.66it/s]Processing train dataset:   9%|▉         | 903/10000 [00:07<02:54, 52.05it/s]Processing train dataset:   2%|▏         | 245/10000 [00:03<02:18, 70.26it/s]Processing train dataset:   2%|▏         | 241/10000 [00:03<02:14, 72.75it/s]Processing train dataset:   1%|▏         | 134/10000 [00:01<01:49, 90.51it/s]Processing train dataset:   3%|▎         | 256/10000 [00:03<02:12, 73.30it/s]Processing train dataset:   3%|▎         | 254/10000 [00:03<02:10, 74.45it/s]Processing train dataset:   9%|▉         | 910/10000 [00:07<02:46, 54.67it/s]Processing train dataset:   2%|▏         | 249/10000 [00:03<02:14, 72.36it/s]Processing train dataset:   1%|▏         | 144/10000 [00:01<01:46, 92.71it/s]Processing train dataset:   3%|▎         | 262/10000 [00:04<02:08, 75.53it/s]Processing train dataset:   3%|▎         | 264/10000 [00:04<02:21, 68.87it/s]Processing train dataset:   3%|▎         | 258/10000 [00:03<02:10, 74.63it/s]Processing train dataset:   9%|▉         | 917/10000 [00:07<02:51, 52.89it/s]Processing train dataset:   2%|▏         | 154/10000 [00:01<01:51, 88.49it/s]Processing train dataset:   3%|▎         | 270/10000 [00:04<02:08, 75.96it/s]Processing train dataset:   3%|▎         | 272/10000 [00:04<02:19, 69.81it/s]Processing train dataset:   3%|▎         | 266/10000 [00:03<02:12, 73.64it/s]Processing train dataset:   9%|▉         | 925/10000 [00:07<02:38, 57.09it/s]Processing train dataset:   2%|▏         | 165/10000 [00:01<01:44, 93.78it/s]Processing train dataset:   3%|▎         | 279/10000 [00:04<02:05, 77.25it/s]Processing train dataset:   3%|▎         | 274/10000 [00:04<02:10, 74.61it/s]Processing train dataset:   3%|▎         | 280/10000 [00:04<02:27, 65.92it/s]Processing train dataset:   9%|▉         | 932/10000 [00:07<02:36, 58.01it/s]Processing train dataset:   2%|▏         | 175/10000 [00:01<01:49, 89.61it/s]Processing train dataset:   3%|▎         | 288/10000 [00:04<02:04, 77.95it/s]Processing train dataset:   3%|▎         | 282/10000 [00:04<02:13, 72.79it/s]Processing train dataset:   3%|▎         | 288/10000 [00:04<02:24, 67.36it/s]Processing train dataset:   9%|▉         | 940/10000 [00:07<02:28, 61.07it/s]Processing train dataset:   3%|▎         | 296/10000 [00:04<02:03, 78.50it/s]Processing train dataset:   2%|▏         | 186/10000 [00:02<01:57, 83.59it/s]Processing train dataset:   3%|▎         | 290/10000 [00:04<02:10, 74.29it/s]Processing train dataset:   3%|▎         | 296/10000 [00:04<02:20, 69.07it/s]Processing train dataset:   9%|▉         | 947/10000 [00:08<02:31, 59.89it/s]Processing train dataset:   3%|▎         | 305/10000 [00:04<02:02, 78.83it/s]Processing train dataset:   2%|▏         | 197/10000 [00:02<01:50, 88.42it/s]Processing train dataset:   3%|▎         | 299/10000 [00:04<02:04, 77.70it/s]Processing train dataset:   3%|▎         | 305/10000 [00:04<02:13, 72.35it/s]Processing train dataset:  10%|▉         | 954/10000 [00:08<02:32, 59.21it/s]Processing train dataset:   3%|▎         | 314/10000 [00:04<02:02, 79.22it/s]Processing train dataset:   3%|▎         | 308/10000 [00:04<02:03, 78.25it/s]Processing train dataset:   3%|▎         | 313/10000 [00:04<02:13, 72.71it/s]Processing train dataset:   2%|▏         | 207/10000 [00:02<01:58, 82.85it/s]Processing train dataset:  10%|▉         | 962/10000 [00:08<02:21, 63.71it/s]Processing train dataset:   3%|▎         | 322/10000 [00:04<02:04, 77.43it/s]Processing train dataset:   3%|▎         | 316/10000 [00:04<02:06, 76.31it/s]Processing train dataset:   3%|▎         | 321/10000 [00:04<02:28, 65.25it/s]Processing train dataset:   2%|▏         | 216/10000 [00:02<02:11, 74.45it/s]Processing train dataset:   3%|▎         | 332/10000 [00:04<01:55, 83.51it/s]Processing train dataset:  10%|▉         | 969/10000 [00:08<02:30, 59.83it/s]Processing train dataset:   3%|▎         | 324/10000 [00:04<02:10, 74.42it/s]Processing train dataset:   3%|▎         | 330/10000 [00:05<02:15, 71.35it/s]Processing train dataset:   2%|▏         | 226/10000 [00:02<02:01, 80.32it/s]Processing train dataset:   3%|▎         | 341/10000 [00:05<02:00, 80.15it/s]Processing train dataset:  10%|▉         | 977/10000 [00:08<02:31, 59.72it/s]Processing train dataset:   3%|▎         | 334/10000 [00:04<02:01, 79.60it/s]Processing train dataset:   3%|▎         | 338/10000 [00:05<02:16, 71.04it/s]Processing train dataset:   2%|▏         | 235/10000 [00:02<02:10, 74.67it/s]Processing train dataset:  10%|▉         | 986/10000 [00:08<02:16, 66.20it/s]Processing train dataset:   4%|▎         | 350/10000 [00:05<02:11, 73.52it/s]Processing train dataset:   3%|▎         | 342/10000 [00:04<02:06, 76.46it/s]Processing train dataset:   3%|▎         | 346/10000 [00:05<02:15, 71.28it/s]Processing train dataset:   2%|▏         | 243/10000 [00:02<02:13, 73.19it/s]Processing train dataset:   4%|▎         | 358/10000 [00:05<02:11, 73.28it/s]Processing train dataset:   4%|▎         | 350/10000 [00:05<02:09, 74.59it/s]Processing train dataset:  10%|▉         | 993/10000 [00:08<02:26, 61.46it/s]Processing train dataset:   4%|▎         | 354/10000 [00:05<02:17, 69.96it/s]Processing train dataset:   3%|▎         | 253/10000 [00:02<02:02, 79.31it/s]Processing train dataset:   4%|▎         | 367/10000 [00:05<02:07, 75.46it/s]Processing train dataset:   4%|▎         | 358/10000 [00:05<02:11, 73.18it/s]Processing train dataset:   4%|▎         | 362/10000 [00:05<02:22, 67.79it/s]Processing train dataset:  10%|█         | 1000/10000 [00:08<02:55, 51.17it/s]Processing train dataset:   4%|▍         | 375/10000 [00:05<02:09, 74.59it/s]Processing train dataset:   4%|▎         | 366/10000 [00:05<02:10, 73.89it/s]Processing train dataset:   4%|▎         | 369/10000 [00:05<02:24, 66.60it/s]Processing train dataset:   3%|▎         | 262/10000 [00:03<02:45, 58.73it/s]Processing train dataset:   4%|▍         | 383/10000 [00:05<02:09, 74.28it/s]Processing train dataset:   4%|▎         | 374/10000 [00:05<02:12, 72.43it/s]Processing train dataset:  10%|█         | 1006/10000 [00:09<03:04, 48.72it/s]Processing train dataset:   4%|▍         | 377/10000 [00:05<02:21, 67.78it/s]Processing train dataset:   3%|▎         | 273/10000 [00:03<02:22, 68.31it/s]Processing train dataset:   4%|▍         | 392/10000 [00:05<02:06, 76.24it/s]Processing train dataset:  10%|█         | 1014/10000 [00:09<02:43, 54.89it/s]Processing train dataset:   4%|▍         | 382/10000 [00:05<02:14, 71.33it/s]Processing train dataset:   4%|▍         | 385/10000 [00:05<02:16, 70.45it/s]Processing train dataset:   3%|▎         | 283/10000 [00:03<02:09, 75.26it/s]Processing train dataset:  10%|█         | 1022/10000 [00:09<02:29, 60.10it/s]Processing train dataset:   4%|▍         | 400/10000 [00:05<02:09, 74.27it/s]Processing train dataset:   4%|▍         | 390/10000 [00:05<02:18, 69.51it/s]Processing train dataset:   4%|▍         | 393/10000 [00:05<02:16, 70.44it/s]Processing train dataset:   3%|▎         | 292/10000 [00:03<02:06, 76.83it/s]Processing train dataset:  10%|█         | 1033/10000 [00:09<02:03, 72.70it/s]Processing train dataset:   4%|▍         | 408/10000 [00:05<02:09, 73.84it/s]Processing train dataset:   4%|▍         | 398/10000 [00:05<02:14, 71.20it/s]Processing train dataset:   4%|▍         | 401/10000 [00:06<02:15, 70.96it/s]Processing train dataset:   3%|▎         | 303/10000 [00:03<01:55, 84.15it/s]Processing train dataset:  10%|█         | 1041/10000 [00:09<02:01, 73.87it/s]Processing train dataset:   4%|▍         | 416/10000 [00:06<02:09, 73.97it/s]Processing train dataset:   4%|▍         | 406/10000 [00:05<02:14, 71.55it/s]Processing train dataset:   4%|▍         | 409/10000 [00:06<02:14, 71.22it/s]Processing train dataset:   4%|▍         | 414/10000 [00:05<02:16, 70.11it/s]Processing train dataset:   4%|▍         | 424/10000 [00:06<02:25, 65.76it/s]Processing train dataset:   4%|▍         | 417/10000 [00:06<02:13, 71.69it/s]Processing train dataset:   3%|▎         | 312/10000 [00:03<02:42, 59.67it/s]Processing train dataset:   4%|▍         | 422/10000 [00:06<02:15, 70.56it/s]Processing train dataset:  10%|█         | 1049/10000 [00:09<02:55, 51.12it/s]Processing train dataset:   4%|▍         | 433/10000 [00:06<02:16, 70.24it/s]Processing train dataset:   4%|▍         | 425/10000 [00:06<02:13, 71.90it/s]Processing train dataset:   4%|▍         | 430/10000 [00:06<02:11, 72.87it/s]Processing train dataset:   3%|▎         | 320/10000 [00:03<02:35, 62.10it/s]Processing train dataset:   4%|▍         | 441/10000 [00:06<02:12, 72.02it/s]Processing train dataset:  11%|█         | 1059/10000 [00:09<02:28, 60.28it/s]Processing train dataset:   4%|▍         | 433/10000 [00:06<02:09, 74.12it/s]Processing train dataset:   3%|▎         | 328/10000 [00:04<02:28, 65.35it/s]Processing train dataset:   4%|▍         | 438/10000 [00:06<02:11, 72.54it/s]Processing train dataset:   4%|▍         | 449/10000 [00:06<02:09, 73.58it/s]Processing train dataset:  11%|█         | 1068/10000 [00:10<02:15, 65.94it/s]Processing train dataset:   4%|▍         | 441/10000 [00:06<02:10, 73.48it/s]Processing train dataset:   4%|▍         | 446/10000 [00:06<02:11, 72.84it/s]Processing train dataset:   5%|▍         | 457/10000 [00:06<02:07, 74.65it/s]Processing train dataset:  11%|█         | 1076/10000 [00:10<02:18, 64.32it/s]Processing train dataset:   4%|▍         | 449/10000 [00:06<02:15, 70.23it/s]Processing train dataset:   3%|▎         | 336/10000 [00:04<02:47, 57.76it/s]Processing train dataset:   5%|▍         | 465/10000 [00:06<02:06, 75.20it/s]Processing train dataset:   5%|▍         | 454/10000 [00:06<02:14, 71.15it/s]Processing train dataset:   5%|▍         | 457/10000 [00:06<02:21, 67.67it/s]Processing train dataset:  11%|█         | 1084/10000 [00:10<02:32, 58.50it/s]Processing train dataset:   3%|▎         | 343/10000 [00:04<02:53, 55.75it/s]Processing train dataset:   5%|▍         | 474/10000 [00:06<02:03, 77.18it/s]Processing train dataset:   5%|▍         | 462/10000 [00:06<02:25, 65.73it/s]Processing train dataset:   5%|▍         | 464/10000 [00:06<02:20, 67.79it/s]Processing train dataset:   5%|▍         | 483/10000 [00:06<02:00, 79.07it/s]Processing train dataset:   4%|▎         | 350/10000 [00:04<02:51, 56.20it/s]Processing train dataset:   5%|▍         | 470/10000 [00:06<02:21, 67.25it/s]Processing train dataset:   5%|▍         | 471/10000 [00:07<02:19, 68.12it/s]Processing train dataset:  11%|█         | 1091/10000 [00:10<02:53, 51.27it/s]Processing train dataset:   5%|▍         | 491/10000 [00:07<02:00, 79.18it/s]Processing train dataset:   4%|▎         | 358/10000 [00:04<02:37, 61.30it/s]Processing train dataset:   5%|▍         | 478/10000 [00:06<02:14, 70.61it/s]Processing train dataset:   5%|▍         | 479/10000 [00:07<02:19, 68.04it/s]Processing train dataset:  11%|█         | 1098/10000 [00:10<02:55, 50.75it/s]Processing train dataset:   5%|▌         | 500/10000 [00:07<01:58, 80.22it/s]Processing train dataset:   4%|▎         | 365/10000 [00:04<02:43, 59.08it/s]Processing train dataset:   5%|▍         | 486/10000 [00:06<02:12, 72.02it/s]Processing train dataset:   5%|▍         | 486/10000 [00:07<02:19, 68.23it/s]Processing train dataset:  11%|█         | 1106/10000 [00:10<02:37, 56.63it/s]Processing train dataset:   5%|▌         | 509/10000 [00:07<01:59, 79.61it/s]Processing train dataset:   4%|▎         | 374/10000 [00:04<02:26, 65.63it/s]Processing train dataset:   5%|▍         | 495/10000 [00:07<02:07, 74.64it/s]Processing train dataset:   5%|▍         | 495/10000 [00:07<02:11, 72.01it/s]Processing train dataset:   5%|▌         | 518/10000 [00:07<01:59, 79.50it/s]Processing train dataset:  11%|█         | 1113/10000 [00:10<02:45, 53.59it/s]Processing train dataset:   5%|▌         | 504/10000 [00:07<02:02, 77.48it/s]Processing train dataset:   4%|▍         | 381/10000 [00:05<02:41, 59.55it/s]Processing train dataset:   5%|▌         | 503/10000 [00:07<02:08, 74.19it/s]Processing train dataset:   5%|▌         | 527/10000 [00:07<01:59, 79.46it/s]Processing train dataset:  11%|█         | 1119/10000 [00:11<02:47, 52.98it/s]Processing train dataset:   5%|▌         | 513/10000 [00:07<02:00, 78.84it/s]Processing train dataset:   5%|▌         | 512/10000 [00:07<02:05, 75.70it/s]Processing train dataset:   4%|▍         | 390/10000 [00:05<02:40, 59.70it/s]Processing train dataset:   5%|▌         | 535/10000 [00:07<02:01, 77.61it/s]Processing train dataset:   5%|▌         | 522/10000 [00:07<01:57, 80.41it/s]Processing train dataset:  11%|█▏        | 1125/10000 [00:11<02:52, 51.56it/s]Processing train dataset:   5%|▌         | 521/10000 [00:07<02:01, 78.07it/s]Processing train dataset:   4%|▍         | 398/10000 [00:05<02:30, 63.69it/s]Processing train dataset:   5%|▌         | 544/10000 [00:07<02:00, 78.26it/s]Processing train dataset:   5%|▌         | 531/10000 [00:07<02:03, 76.55it/s]Processing train dataset:  11%|█▏        | 1132/10000 [00:11<02:50, 51.95it/s]Processing train dataset:   5%|▌         | 529/10000 [00:07<02:08, 73.85it/s]Processing train dataset:   4%|▍         | 405/10000 [00:05<02:30, 63.69it/s]Processing train dataset:   6%|▌         | 552/10000 [00:07<02:03, 76.36it/s]Processing train dataset:   5%|▌         | 539/10000 [00:07<02:06, 74.67it/s]Processing train dataset:  11%|█▏        | 1139/10000 [00:11<02:38, 55.76it/s]Processing train dataset:   5%|▌         | 537/10000 [00:07<02:08, 73.87it/s]Processing train dataset:   4%|▍         | 414/10000 [00:05<02:17, 69.68it/s]Processing train dataset:   6%|▌         | 560/10000 [00:07<02:05, 75.24it/s]Processing train dataset:   5%|▌         | 547/10000 [00:07<02:04, 76.01it/s]Processing train dataset:   5%|▌         | 545/10000 [00:08<02:09, 72.82it/s]Processing train dataset:   6%|▌         | 568/10000 [00:08<02:05, 75.36it/s]Processing train dataset:   6%|▌         | 555/10000 [00:07<02:06, 74.88it/s]Processing train dataset:   6%|▌         | 553/10000 [00:08<02:12, 71.08it/s]Processing train dataset:  11%|█▏        | 1145/10000 [00:11<03:35, 41.01it/s]Processing train dataset:   6%|▌         | 576/10000 [00:08<02:05, 75.30it/s]Processing train dataset:   6%|▌         | 563/10000 [00:07<02:07, 73.83it/s]Processing train dataset:   6%|▌         | 561/10000 [00:08<02:12, 71.40it/s]Processing train dataset:  12%|█▏        | 1151/10000 [00:11<03:22, 43.69it/s]Processing train dataset:   6%|▌         | 584/10000 [00:08<02:04, 75.76it/s]Processing train dataset:   4%|▍         | 422/10000 [00:05<03:43, 42.91it/s]Processing train dataset:   6%|▌         | 571/10000 [00:08<02:09, 72.80it/s]Processing train dataset:   6%|▌         | 569/10000 [00:08<02:11, 71.72it/s]Processing train dataset:  12%|█▏        | 1156/10000 [00:11<03:19, 44.23it/s]Processing train dataset:   6%|▌         | 592/10000 [00:08<02:04, 75.86it/s]Processing train dataset:   4%|▍         | 430/10000 [00:05<03:14, 49.09it/s]Processing train dataset:   6%|▌         | 579/10000 [00:08<02:10, 72.40it/s]Processing train dataset:   6%|▌         | 577/10000 [00:08<02:11, 71.63it/s]Processing train dataset:  12%|█▏        | 1165/10000 [00:11<02:42, 54.30it/s]Processing train dataset:   6%|▌         | 600/10000 [00:08<02:03, 76.26it/s]Processing train dataset:   4%|▍         | 438/10000 [00:06<02:55, 54.53it/s]Processing train dataset:   6%|▌         | 587/10000 [00:08<02:10, 71.94it/s]Processing train dataset:  12%|█▏        | 1172/10000 [00:12<02:32, 57.96it/s]Processing train dataset:   6%|▌         | 585/10000 [00:08<02:11, 71.78it/s]Processing train dataset:   6%|▌         | 608/10000 [00:08<02:03, 76.31it/s]Processing train dataset:   4%|▍         | 447/10000 [00:06<02:37, 60.65it/s]Processing train dataset:   6%|▌         | 595/10000 [00:08<02:11, 71.51it/s]Processing train dataset:  12%|█▏        | 1180/10000 [00:12<02:20, 62.97it/s]Processing train dataset:   6%|▌         | 617/10000 [00:08<01:59, 78.48it/s]Processing train dataset:   6%|▌         | 593/10000 [00:08<02:11, 71.75it/s]Processing train dataset:   5%|▍         | 457/10000 [00:06<02:17, 69.47it/s]Processing train dataset:   6%|▌         | 603/10000 [00:08<02:11, 71.73it/s]Processing train dataset:   6%|▋         | 625/10000 [00:08<02:01, 76.87it/s]Processing train dataset:   6%|▌         | 601/10000 [00:08<02:11, 71.73it/s]Processing train dataset:   5%|▍         | 468/10000 [00:06<02:01, 78.48it/s]Processing train dataset:   6%|▌         | 611/10000 [00:08<02:09, 72.38it/s]Processing train dataset:   6%|▋         | 633/10000 [00:08<02:04, 75.31it/s]Processing train dataset:   6%|▌         | 609/10000 [00:08<02:10, 71.71it/s]Processing train dataset:   5%|▍         | 479/10000 [00:06<01:50, 86.14it/s]Processing train dataset:  12%|█▏        | 1187/10000 [00:12<03:12, 45.70it/s]Processing train dataset:   6%|▌         | 620/10000 [00:08<02:04, 75.24it/s]Processing train dataset:   6%|▋         | 643/10000 [00:09<01:58, 78.97it/s]Processing train dataset:   5%|▍         | 490/10000 [00:06<01:45, 90.09it/s]Processing train dataset:   6%|▌         | 618/10000 [00:09<02:06, 74.01it/s]Processing train dataset:  12%|█▏        | 1194/10000 [00:12<03:12, 45.64it/s]Processing train dataset:   6%|▋         | 628/10000 [00:08<02:05, 74.88it/s]Processing train dataset:   7%|▋         | 651/10000 [00:09<01:58, 78.92it/s]Processing train dataset:   6%|▋         | 626/10000 [00:09<02:07, 73.33it/s]Processing train dataset:   5%|▌         | 502/10000 [00:06<01:41, 93.43it/s]Processing train dataset:   6%|▋         | 636/10000 [00:08<02:02, 76.27it/s]Processing train dataset:  12%|█▏        | 1200/10000 [00:12<03:07, 47.00it/s]Processing train dataset:   7%|▋         | 660/10000 [00:09<01:53, 82.02it/s]Processing train dataset:   6%|▋         | 635/10000 [00:09<02:05, 74.88it/s]Processing train dataset:   6%|▋         | 644/10000 [00:09<02:01, 77.03it/s]Processing train dataset:   5%|▌         | 512/10000 [00:06<02:00, 78.56it/s]Processing train dataset:   7%|▋         | 670/10000 [00:09<01:47, 86.72it/s]Processing train dataset:  12%|█▏        | 1206/10000 [00:12<03:05, 47.52it/s]Processing train dataset:   6%|▋         | 644/10000 [00:09<02:02, 76.11it/s]Processing train dataset:   7%|▋         | 652/10000 [00:09<02:04, 75.24it/s]Processing train dataset:  12%|█▏        | 1216/10000 [00:12<02:27, 59.48it/s]Processing train dataset:   7%|▋         | 679/10000 [00:09<01:51, 83.61it/s]Processing train dataset:   5%|▌         | 521/10000 [00:07<02:10, 72.82it/s]Processing train dataset:   7%|▋         | 652/10000 [00:09<02:04, 74.89it/s]Processing train dataset:   7%|▋         | 660/10000 [00:09<02:02, 76.02it/s]Processing train dataset:  12%|█▏        | 1223/10000 [00:13<02:27, 59.37it/s]Processing train dataset:   7%|▋         | 688/10000 [00:09<01:55, 80.68it/s]Processing train dataset:   7%|▋         | 661/10000 [00:09<02:02, 76.22it/s]Processing train dataset:   7%|▋         | 669/10000 [00:09<01:58, 79.00it/s]Processing train dataset:   5%|▌         | 529/10000 [00:07<02:27, 64.34it/s]Processing train dataset:  12%|█▏        | 1230/10000 [00:13<02:22, 61.73it/s]Processing train dataset:   7%|▋         | 697/10000 [00:09<01:54, 81.51it/s]Processing train dataset:   7%|▋         | 669/10000 [00:09<02:01, 77.07it/s]Processing train dataset:   7%|▋         | 677/10000 [00:09<02:02, 76.22it/s]Processing train dataset:   5%|▌         | 536/10000 [00:07<02:32, 61.98it/s]Processing train dataset:  12%|█▏        | 1237/10000 [00:13<02:21, 61.88it/s]Processing train dataset:   7%|▋         | 708/10000 [00:09<01:47, 86.65it/s]Processing train dataset:   7%|▋         | 677/10000 [00:09<02:03, 75.60it/s]Processing train dataset:   7%|▋         | 685/10000 [00:09<02:04, 74.88it/s]Processing train dataset:  12%|█▏        | 1244/10000 [00:13<02:17, 63.64it/s]Processing train dataset:   5%|▌         | 543/10000 [00:07<02:37, 59.95it/s]Processing train dataset:   7%|▋         | 717/10000 [00:09<01:52, 82.42it/s]Processing train dataset:   7%|▋         | 685/10000 [00:09<02:04, 74.66it/s]Processing train dataset:   7%|▋         | 694/10000 [00:09<02:02, 76.27it/s]Processing train dataset:  13%|█▎        | 1254/10000 [00:13<02:00, 72.88it/s]Processing train dataset:   6%|▌         | 550/10000 [00:07<02:41, 58.55it/s]Processing train dataset:   7%|▋         | 726/10000 [00:10<01:55, 80.46it/s]Processing train dataset:   7%|▋         | 694/10000 [00:10<02:02, 75.95it/s]Processing train dataset:   7%|▋         | 703/10000 [00:09<01:56, 79.73it/s]Processing train dataset:  13%|█▎        | 1265/10000 [00:13<01:46, 81.97it/s]Processing train dataset:   7%|▋         | 703/10000 [00:10<01:57, 78.81it/s]Processing train dataset:   7%|▋         | 735/10000 [00:10<01:57, 78.96it/s]Processing train dataset:   6%|▌         | 556/10000 [00:07<02:51, 55.13it/s]Processing train dataset:   7%|▋         | 712/10000 [00:09<01:55, 80.61it/s]Processing train dataset:  13%|█▎        | 1276/10000 [00:13<01:38, 88.15it/s]Processing train dataset:   7%|▋         | 711/10000 [00:10<01:57, 79.03it/s]Processing train dataset:   6%|▌         | 562/10000 [00:07<02:49, 55.61it/s]Processing train dataset:   7%|▋         | 744/10000 [00:10<01:55, 80.19it/s]Processing train dataset:  13%|█▎        | 1287/10000 [00:13<01:33, 92.82it/s]Processing train dataset:   7%|▋         | 721/10000 [00:10<01:57, 78.73it/s]Processing train dataset:   7%|▋         | 719/10000 [00:10<02:00, 77.00it/s]Processing train dataset:   8%|▊         | 753/10000 [00:10<01:59, 77.23it/s]Processing train dataset:   6%|▌         | 569/10000 [00:07<02:53, 54.46it/s]Processing train dataset:  13%|█▎        | 1301/10000 [00:13<01:23, 104.22it/s]Processing train dataset:   7%|▋         | 729/10000 [00:10<01:59, 77.63it/s]Processing train dataset:   7%|▋         | 727/10000 [00:10<02:02, 75.52it/s]Processing train dataset:   6%|▌         | 575/10000 [00:08<02:49, 55.45it/s]Processing train dataset:   8%|▊         | 761/10000 [00:10<02:03, 74.65it/s]Processing train dataset:  13%|█▎        | 1312/10000 [00:14<01:26, 100.40it/s]Processing train dataset:   7%|▋         | 737/10000 [00:10<02:03, 74.94it/s]Processing train dataset:   7%|▋         | 735/10000 [00:10<02:03, 74.76it/s]Processing train dataset:   8%|▊         | 770/10000 [00:10<01:59, 77.45it/s]Processing train dataset:   6%|▌         | 581/10000 [00:08<02:57, 53.21it/s]Processing train dataset:  13%|█▎        | 1324/10000 [00:14<01:23, 103.61it/s]Processing train dataset:   7%|▋         | 746/10000 [00:10<02:01, 76.45it/s]Processing train dataset:   7%|▋         | 743/10000 [00:10<02:01, 75.99it/s]Processing train dataset:   8%|▊         | 779/10000 [00:10<01:54, 80.83it/s]Processing train dataset:  13%|█▎        | 1335/10000 [00:14<01:22, 105.29it/s]Processing train dataset:   6%|▌         | 587/10000 [00:08<02:59, 52.30it/s]Processing train dataset:   8%|▊         | 754/10000 [00:10<02:01, 75.86it/s]Processing train dataset:   8%|▊         | 751/10000 [00:10<02:14, 68.64it/s]Processing train dataset:   8%|▊         | 788/10000 [00:10<01:53, 81.25it/s]Processing train dataset:  13%|█▎        | 1346/10000 [00:14<01:21, 105.86it/s]Processing train dataset:   6%|▌         | 593/10000 [00:08<02:56, 53.26it/s]Processing train dataset:   8%|▊         | 762/10000 [00:10<02:01, 76.07it/s]Processing train dataset:   8%|▊         | 759/10000 [00:10<02:15, 68.02it/s]Processing train dataset:  14%|█▎        | 1357/10000 [00:14<01:22, 104.64it/s]Processing train dataset:   6%|▌         | 600/10000 [00:08<02:43, 57.54it/s]Processing train dataset:   8%|▊         | 797/10000 [00:10<02:01, 75.95it/s]Processing train dataset:   8%|▊         | 771/10000 [00:10<01:58, 77.80it/s]Processing train dataset:   8%|▊         | 767/10000 [00:11<02:10, 70.52it/s]Processing train dataset:   6%|▌         | 608/10000 [00:08<02:30, 62.28it/s]Processing train dataset:   8%|▊         | 805/10000 [00:11<02:01, 75.75it/s]Processing train dataset:   8%|▊         | 782/10000 [00:10<01:49, 84.09it/s]Processing train dataset:  14%|█▎        | 1368/10000 [00:14<01:31, 94.66it/s] Processing train dataset:   8%|▊         | 776/10000 [00:11<02:02, 75.18it/s]Processing train dataset:   6%|▌         | 615/10000 [00:08<02:29, 62.68it/s]Processing train dataset:   8%|▊         | 813/10000 [00:11<02:05, 73.25it/s]Processing train dataset:   8%|▊         | 791/10000 [00:10<01:51, 82.43it/s]Processing train dataset:  14%|█▍        | 1378/10000 [00:14<01:32, 92.94it/s]Processing train dataset:   8%|▊         | 785/10000 [00:11<02:00, 76.66it/s]Processing train dataset:   6%|▌         | 622/10000 [00:08<02:33, 61.03it/s]Processing train dataset:   8%|▊         | 821/10000 [00:11<02:07, 72.17it/s]Processing train dataset:  14%|█▍        | 1388/10000 [00:14<01:32, 93.34it/s]Processing train dataset:   8%|▊         | 800/10000 [00:11<01:58, 77.83it/s]Processing train dataset:   8%|▊         | 794/10000 [00:11<01:58, 77.57it/s]Processing train dataset:   6%|▋         | 629/10000 [00:08<02:30, 62.39it/s]Processing train dataset:   8%|▊         | 829/10000 [00:11<02:08, 71.20it/s]Processing train dataset:  14%|█▍        | 1398/10000 [00:14<01:34, 91.05it/s]Processing train dataset:   8%|▊         | 809/10000 [00:11<01:55, 79.49it/s]Processing train dataset:   8%|▊         | 802/10000 [00:11<02:00, 76.12it/s]Processing train dataset:   8%|▊         | 837/10000 [00:11<02:05, 72.96it/s]Processing train dataset:   6%|▋         | 638/10000 [00:09<02:23, 65.37it/s]Processing train dataset:  14%|█▍        | 1409/10000 [00:15<01:30, 94.64it/s]Processing train dataset:   8%|▊         | 817/10000 [00:11<01:56, 79.02it/s]Processing train dataset:   8%|▊         | 810/10000 [00:11<01:59, 77.18it/s]Processing train dataset:   8%|▊         | 845/10000 [00:11<02:03, 74.33it/s]Processing train dataset:   8%|▊         | 825/10000 [00:11<01:56, 78.65it/s]Processing train dataset:  14%|█▍        | 1420/10000 [00:15<01:27, 97.74it/s]Processing train dataset:   6%|▋         | 645/10000 [00:09<02:38, 59.19it/s]Processing train dataset:   8%|▊         | 818/10000 [00:11<02:01, 75.71it/s]Processing train dataset:   9%|▊         | 853/10000 [00:11<02:02, 74.52it/s]Processing train dataset:  14%|█▍        | 1432/10000 [00:15<01:22, 103.31it/s]Processing train dataset:   8%|▊         | 834/10000 [00:11<01:54, 80.13it/s]Processing train dataset:  14%|█▍        | 1443/10000 [00:15<01:21, 105.16it/s]Processing train dataset:   9%|▊         | 861/10000 [00:11<02:04, 73.18it/s]Processing train dataset:   8%|▊         | 826/10000 [00:11<02:16, 67.18it/s]Processing train dataset:   7%|▋         | 652/10000 [00:09<03:02, 51.13it/s]Processing train dataset:   8%|▊         | 843/10000 [00:11<01:59, 76.45it/s]Processing train dataset:   9%|▊         | 869/10000 [00:11<02:01, 75.02it/s]Processing train dataset:   8%|▊         | 834/10000 [00:11<02:10, 70.46it/s]Processing train dataset:  15%|█▍        | 1454/10000 [00:15<01:26, 98.41it/s] Processing train dataset:   9%|▊         | 851/10000 [00:11<02:01, 75.28it/s]Processing train dataset:   7%|▋         | 658/10000 [00:09<03:22, 46.15it/s]Processing train dataset:   8%|▊         | 842/10000 [00:12<02:08, 71.01it/s]Processing train dataset:   9%|▉         | 879/10000 [00:12<01:55, 78.68it/s]Processing train dataset:   9%|▊         | 859/10000 [00:11<02:01, 75.37it/s]Processing train dataset:  15%|█▍        | 1464/10000 [00:15<01:34, 90.46it/s]Processing train dataset:   7%|▋         | 669/10000 [00:09<02:35, 59.90it/s]Processing train dataset:   8%|▊         | 850/10000 [00:12<02:11, 69.78it/s]Processing train dataset:   9%|▉         | 887/10000 [00:12<02:02, 74.22it/s]Processing train dataset:   9%|▊         | 868/10000 [00:11<01:57, 77.74it/s]Processing train dataset:  15%|█▍        | 1474/10000 [00:15<01:38, 86.74it/s]Processing train dataset:   7%|▋         | 676/10000 [00:09<02:32, 61.09it/s]Processing train dataset:   9%|▊         | 858/10000 [00:12<02:10, 69.98it/s]Processing train dataset:   9%|▉         | 876/10000 [00:12<02:08, 70.97it/s]Processing train dataset:   7%|▋         | 683/10000 [00:09<02:31, 61.35it/s]Processing train dataset:   9%|▉         | 895/10000 [00:12<02:22, 64.05it/s]Processing train dataset:  15%|█▍        | 1483/10000 [00:15<01:43, 82.63it/s]Processing train dataset:   9%|▊         | 866/10000 [00:12<02:07, 71.75it/s]Processing train dataset:   9%|▉         | 887/10000 [00:12<01:52, 81.14it/s]Processing train dataset:   9%|▉         | 902/10000 [00:12<02:27, 61.79it/s]Processing train dataset:   7%|▋         | 690/10000 [00:10<02:36, 59.56it/s]Processing train dataset:  15%|█▍        | 1492/10000 [00:15<01:53, 75.03it/s]Processing train dataset:   9%|▊         | 874/10000 [00:12<02:06, 72.14it/s]Processing train dataset:   9%|▉         | 896/10000 [00:12<01:50, 82.20it/s]Processing train dataset:   7%|▋         | 697/10000 [00:10<02:31, 61.31it/s]Processing train dataset:   9%|▉         | 909/10000 [00:12<02:32, 59.66it/s]Processing train dataset:   9%|▉         | 884/10000 [00:12<01:55, 78.90it/s]Processing train dataset:   9%|▉         | 905/10000 [00:12<01:54, 79.24it/s]Processing train dataset:  15%|█▌        | 1500/10000 [00:16<02:09, 65.49it/s]Processing train dataset:   7%|▋         | 705/10000 [00:10<02:23, 64.90it/s]Processing train dataset:   9%|▉         | 916/10000 [00:12<02:31, 60.10it/s]Processing train dataset:   9%|▉         | 893/10000 [00:12<01:54, 79.75it/s]Processing train dataset:   9%|▉         | 914/10000 [00:12<01:57, 77.50it/s]Processing train dataset:   7%|▋         | 712/10000 [00:10<02:25, 63.72it/s]Processing train dataset:  15%|█▌        | 1507/10000 [00:16<02:26, 58.14it/s]Processing train dataset:   9%|▉         | 923/10000 [00:12<02:29, 60.76it/s]Processing train dataset:   9%|▉         | 902/10000 [00:12<01:53, 80.19it/s]Processing train dataset:   9%|▉         | 922/10000 [00:12<02:00, 75.43it/s]Processing train dataset:   7%|▋         | 719/10000 [00:10<02:28, 62.37it/s]Processing train dataset:  15%|█▌        | 1514/10000 [00:16<02:20, 60.41it/s]Processing train dataset:   9%|▉         | 932/10000 [00:12<02:15, 66.98it/s]Processing train dataset:   9%|▉         | 911/10000 [00:12<01:56, 77.92it/s]Processing train dataset:   9%|▉         | 931/10000 [00:12<01:57, 77.09it/s]Processing train dataset:   7%|▋         | 727/10000 [00:10<02:26, 63.19it/s]Processing train dataset:   9%|▉         | 939/10000 [00:13<02:19, 64.91it/s]Processing train dataset:  15%|█▌        | 1521/10000 [00:16<02:22, 59.33it/s]Processing train dataset:   9%|▉         | 919/10000 [00:13<01:58, 76.34it/s]Processing train dataset:   9%|▉         | 939/10000 [00:12<01:58, 76.31it/s]Processing train dataset:   7%|▋         | 734/10000 [00:10<02:29, 62.19it/s]Processing train dataset:   9%|▉         | 927/10000 [00:13<01:58, 76.71it/s]Processing train dataset:  15%|█▌        | 1528/10000 [00:16<02:20, 60.20it/s]Processing train dataset:   9%|▉         | 948/10000 [00:13<02:11, 69.05it/s]Processing train dataset:   9%|▉         | 948/10000 [00:12<01:56, 77.81it/s]Processing train dataset:   9%|▉         | 936/10000 [00:13<01:54, 79.14it/s]Processing train dataset:   7%|▋         | 741/10000 [00:10<02:31, 61.26it/s]Processing train dataset:  10%|▉         | 956/10000 [00:13<02:09, 69.64it/s]Processing train dataset:  15%|█▌        | 1535/10000 [00:16<02:23, 59.01it/s]Processing train dataset:  10%|▉         | 956/10000 [00:13<01:59, 75.79it/s]Processing train dataset:   9%|▉         | 945/10000 [00:13<01:52, 80.69it/s]Processing train dataset:  10%|▉         | 965/10000 [00:13<02:01, 74.57it/s]Processing train dataset:   7%|▋         | 748/10000 [00:10<02:28, 62.11it/s]Processing train dataset:  15%|█▌        | 1542/10000 [00:16<02:20, 60.29it/s]Processing train dataset:  10%|▉         | 965/10000 [00:13<01:55, 78.56it/s]Processing train dataset:  10%|▉         | 974/10000 [00:13<01:58, 76.29it/s]Processing train dataset:  10%|▉         | 954/10000 [00:13<01:57, 77.28it/s]Processing train dataset:   8%|▊         | 755/10000 [00:11<02:31, 61.01it/s]Processing train dataset:  15%|█▌        | 1549/10000 [00:17<02:23, 58.77it/s]Processing train dataset:  10%|▉         | 973/10000 [00:13<01:54, 78.52it/s]Processing train dataset:  10%|▉         | 964/10000 [00:13<01:52, 80.58it/s]Processing train dataset:  10%|▉         | 982/10000 [00:13<02:10, 69.12it/s]Processing train dataset:  16%|█▌        | 1555/10000 [00:17<02:26, 57.45it/s]Processing train dataset:   8%|▊         | 762/10000 [00:11<02:39, 57.98it/s]Processing train dataset:  10%|▉         | 983/10000 [00:13<01:49, 82.26it/s]Processing train dataset:  10%|▉         | 973/10000 [00:13<01:51, 81.20it/s]Processing train dataset:  16%|█▌        | 1561/10000 [00:17<02:29, 56.40it/s]Processing train dataset:   8%|▊         | 769/10000 [00:11<02:35, 59.52it/s]Processing train dataset:  10%|▉         | 990/10000 [00:13<02:15, 66.28it/s]Processing train dataset:  10%|▉         | 992/10000 [00:13<01:50, 81.27it/s]Processing train dataset:  10%|▉         | 983/10000 [00:13<01:46, 84.61it/s]Processing train dataset:   8%|▊         | 777/10000 [00:11<02:27, 62.61it/s]Processing train dataset:  16%|█▌        | 1567/10000 [00:17<02:34, 54.61it/s]Processing train dataset:  10%|█         | 1001/10000 [00:13<01:51, 80.98it/s]Processing train dataset:  10%|▉         | 997/10000 [00:13<02:22, 63.17it/s]Processing train dataset:  10%|▉         | 992/10000 [00:13<01:49, 82.22it/s]Processing train dataset:   8%|▊         | 784/10000 [00:11<02:25, 63.45it/s]Processing train dataset:  16%|█▌        | 1574/10000 [00:17<02:28, 56.83it/s]Processing train dataset:  10%|█         | 1004/10000 [00:14<02:18, 64.90it/s]Processing train dataset:  10%|█         | 1010/10000 [00:13<02:00, 74.55it/s]Processing train dataset:  10%|█         | 1001/10000 [00:14<01:50, 81.29it/s]Processing train dataset:   8%|▊         | 791/10000 [00:11<02:33, 59.99it/s]Processing train dataset:  10%|█         | 1012/10000 [00:14<02:14, 66.60it/s]Processing train dataset:  16%|█▌        | 1580/10000 [00:17<02:39, 52.75it/s]Processing train dataset:  10%|█         | 1018/10000 [00:13<02:02, 73.26it/s]Processing train dataset:  10%|█         | 1010/10000 [00:14<01:52, 79.77it/s]Processing train dataset:  10%|█         | 1020/10000 [00:14<02:12, 67.78it/s]Processing train dataset:  16%|█▌        | 1588/10000 [00:17<02:23, 58.51it/s]Processing train dataset:   8%|▊         | 798/10000 [00:11<02:38, 58.22it/s]Processing train dataset:  10%|█         | 1026/10000 [00:13<02:00, 74.71it/s]Processing train dataset:  10%|█         | 1018/10000 [00:14<01:54, 78.26it/s]Processing train dataset:  10%|█         | 1031/10000 [00:14<01:56, 77.27it/s]Processing train dataset:  16%|█▌        | 1595/10000 [00:17<02:20, 59.93it/s]Processing train dataset:   8%|▊         | 804/10000 [00:11<02:45, 55.49it/s]Processing train dataset:  10%|█         | 1034/10000 [00:14<02:07, 70.52it/s]Processing train dataset:  10%|█         | 1027/10000 [00:14<01:53, 79.23it/s]Processing train dataset:   8%|▊         | 811/10000 [00:12<02:36, 58.59it/s]Processing train dataset:  10%|█         | 1039/10000 [00:14<02:04, 71.92it/s]Processing train dataset:  16%|█▌        | 1602/10000 [00:17<02:31, 55.52it/s]Processing train dataset:  10%|█         | 1037/10000 [00:14<01:47, 83.07it/s]Processing train dataset:  10%|█         | 1042/10000 [00:14<02:35, 57.78it/s]Processing train dataset:   8%|▊         | 818/10000 [00:12<02:38, 57.98it/s]Processing train dataset:  10%|█         | 1047/10000 [00:14<02:12, 67.70it/s]Processing train dataset:  16%|█▌        | 1608/10000 [00:18<02:39, 52.78it/s]Processing train dataset:  10%|█         | 1046/10000 [00:14<01:52, 79.92it/s]Processing train dataset:  10%|█         | 1049/10000 [00:14<02:30, 59.31it/s]Processing train dataset:   8%|▊         | 825/10000 [00:12<02:36, 58.57it/s]Processing train dataset:  11%|█         | 1056/10000 [00:14<02:03, 72.63it/s]Processing train dataset:  16%|█▌        | 1616/10000 [00:18<02:23, 58.56it/s]Processing train dataset:  11%|█         | 1056/10000 [00:14<01:48, 82.25it/s]Processing train dataset:  11%|█         | 1058/10000 [00:14<02:17, 64.94it/s]Processing train dataset:   8%|▊         | 832/10000 [00:12<02:36, 58.41it/s]Processing train dataset:  11%|█         | 1064/10000 [00:14<02:07, 70.26it/s]Processing train dataset:  16%|█▌        | 1623/10000 [00:18<02:26, 57.36it/s]Processing train dataset:  11%|█         | 1065/10000 [00:14<01:51, 80.46it/s]Processing train dataset:  11%|█         | 1065/10000 [00:14<02:16, 65.33it/s]Processing train dataset:  16%|█▋        | 1630/10000 [00:18<02:19, 59.88it/s]Processing train dataset:   8%|▊         | 838/10000 [00:12<02:48, 54.32it/s]Processing train dataset:  11%|█         | 1072/10000 [00:14<02:16, 65.20it/s]Processing train dataset:  11%|█         | 1074/10000 [00:14<01:53, 78.31it/s]Processing train dataset:  11%|█         | 1072/10000 [00:14<02:19, 63.82it/s]Processing train dataset:   8%|▊         | 844/10000 [00:12<02:47, 54.52it/s]Processing train dataset:  16%|█▋        | 1637/10000 [00:18<02:18, 60.47it/s]Processing train dataset:  11%|█         | 1079/10000 [00:15<02:16, 65.18it/s]Processing train dataset:  11%|█         | 1083/10000 [00:15<01:52, 79.34it/s]Processing train dataset:  11%|█         | 1080/10000 [00:14<02:13, 67.02it/s]Processing train dataset:   8%|▊         | 850/10000 [00:12<02:45, 55.33it/s]Processing train dataset:  16%|█▋        | 1644/10000 [00:18<02:13, 62.51it/s]Processing train dataset:  11%|█         | 1086/10000 [00:15<02:14, 66.10it/s]Processing train dataset:  11%|█         | 1091/10000 [00:15<01:54, 77.92it/s]Processing train dataset:  11%|█         | 1087/10000 [00:14<02:13, 66.71it/s]Processing train dataset:  17%|█▋        | 1651/10000 [00:18<02:09, 64.55it/s]Processing train dataset:   9%|▊         | 857/10000 [00:12<02:35, 58.82it/s]Processing train dataset:  11%|█         | 1093/10000 [00:15<02:14, 66.45it/s]Processing train dataset:  11%|█         | 1100/10000 [00:15<01:53, 78.64it/s]Processing train dataset:  11%|█         | 1094/10000 [00:15<02:13, 66.87it/s]Processing train dataset:   9%|▊         | 864/10000 [00:12<02:30, 60.63it/s]Processing train dataset:  17%|█▋        | 1658/10000 [00:18<02:10, 63.91it/s]Processing train dataset:  11%|█         | 1101/10000 [00:15<02:09, 68.89it/s]Processing train dataset:  11%|█         | 1108/10000 [00:15<01:55, 76.87it/s]Processing train dataset:  11%|█         | 1102/10000 [00:15<02:07, 69.63it/s]Processing train dataset:   9%|▊         | 871/10000 [00:13<02:25, 62.93it/s]Processing train dataset:  17%|█▋        | 1665/10000 [00:18<02:12, 62.79it/s]Processing train dataset:  11%|█         | 1108/10000 [00:15<02:13, 66.79it/s]Processing train dataset:  11%|█         | 1116/10000 [00:15<01:57, 75.80it/s]Processing train dataset:  11%|█         | 1110/10000 [00:15<02:08, 69.36it/s]Processing train dataset:   9%|▉         | 880/10000 [00:13<02:13, 68.14it/s]Processing train dataset:  17%|█▋        | 1672/10000 [00:19<02:15, 61.48it/s]Processing train dataset:  11%|█         | 1116/10000 [00:15<02:10, 68.06it/s]Processing train dataset:  11%|█         | 1124/10000 [00:15<01:58, 75.20it/s]Processing train dataset:  11%|█         | 1118/10000 [00:15<02:06, 69.95it/s]Processing train dataset:   9%|▉         | 889/10000 [00:13<02:03, 73.96it/s]Processing train dataset:  11%|█         | 1124/10000 [00:15<02:08, 69.07it/s]Processing train dataset:  17%|█▋        | 1679/10000 [00:19<02:21, 58.69it/s]Processing train dataset:  11%|█▏        | 1132/10000 [00:15<01:58, 75.04it/s]Processing train dataset:  11%|█▏        | 1126/10000 [00:15<02:05, 70.98it/s]Processing train dataset:   9%|▉         | 897/10000 [00:13<02:02, 74.48it/s]Processing train dataset:  17%|█▋        | 1686/10000 [00:19<02:17, 60.53it/s]Processing train dataset:  11%|█▏        | 1131/10000 [00:15<02:18, 64.09it/s]Processing train dataset:  11%|█▏        | 1140/10000 [00:15<02:00, 73.79it/s]Processing train dataset:  11%|█▏        | 1134/10000 [00:15<02:05, 70.65it/s]Processing train dataset:   9%|▉         | 905/10000 [00:13<02:05, 72.36it/s]Processing train dataset:  11%|█▏        | 1148/10000 [00:15<01:59, 74.21it/s]Processing train dataset:  11%|█▏        | 1139/10000 [00:15<02:14, 65.97it/s]Processing train dataset:  17%|█▋        | 1693/10000 [00:19<02:18, 59.99it/s]Processing train dataset:  11%|█▏        | 1142/10000 [00:15<02:02, 72.39it/s]Processing train dataset:   9%|▉         | 913/10000 [00:13<02:06, 71.67it/s]Processing train dataset:  17%|█▋        | 1700/10000 [00:19<02:14, 61.86it/s]Processing train dataset:  12%|█▏        | 1156/10000 [00:16<02:00, 73.16it/s]Processing train dataset:  11%|█▏        | 1146/10000 [00:16<02:21, 62.75it/s]Processing train dataset:  12%|█▏        | 1150/10000 [00:15<02:07, 69.41it/s]Processing train dataset:   9%|▉         | 921/10000 [00:13<02:07, 70.95it/s]Processing train dataset:  17%|█▋        | 1707/10000 [00:19<02:09, 64.06it/s]Processing train dataset:  12%|█▏        | 1164/10000 [00:16<01:59, 73.89it/s]Processing train dataset:  12%|█▏        | 1154/10000 [00:16<02:12, 66.93it/s]Processing train dataset:  12%|█▏        | 1158/10000 [00:15<02:06, 70.14it/s]Processing train dataset:   9%|▉         | 929/10000 [00:13<02:05, 72.06it/s]Processing train dataset:  12%|█▏        | 1172/10000 [00:16<01:58, 74.48it/s]Processing train dataset:  17%|█▋        | 1716/10000 [00:19<02:02, 67.66it/s]Processing train dataset:  12%|█▏        | 1162/10000 [00:16<02:08, 68.58it/s]Processing train dataset:  12%|█▏        | 1166/10000 [00:16<02:05, 70.46it/s]Processing train dataset:   9%|▉         | 937/10000 [00:13<02:14, 67.42it/s]Processing train dataset:  17%|█▋        | 1723/10000 [00:19<02:01, 68.07it/s]Processing train dataset:  12%|█▏        | 1180/10000 [00:16<02:01, 72.33it/s]Processing train dataset:  12%|█▏        | 1170/10000 [00:16<02:07, 69.49it/s]Processing train dataset:  12%|█▏        | 1174/10000 [00:16<02:12, 66.40it/s]Processing train dataset:   9%|▉         | 945/10000 [00:14<02:09, 69.88it/s]Processing train dataset:  17%|█▋        | 1730/10000 [00:20<02:07, 64.90it/s]Processing train dataset:  12%|█▏        | 1188/10000 [00:16<02:01, 72.67it/s]Processing train dataset:  12%|█▏        | 1178/10000 [00:16<02:05, 70.55it/s]Processing train dataset:  12%|█▏        | 1182/10000 [00:16<02:09, 68.14it/s]Processing train dataset:  10%|▉         | 953/10000 [00:14<02:13, 67.64it/s]Processing train dataset:  12%|█▏        | 1197/10000 [00:16<01:56, 75.26it/s]Processing train dataset:  17%|█▋        | 1737/10000 [00:20<02:22, 57.99it/s]Processing train dataset:  12%|█▏        | 1186/10000 [00:16<02:16, 64.44it/s]Processing train dataset:  12%|█▏        | 1191/10000 [00:16<02:02, 72.02it/s]Processing train dataset:  10%|▉         | 961/10000 [00:14<02:09, 69.62it/s]Processing train dataset:  12%|█▏        | 1207/10000 [00:16<01:50, 79.84it/s]Processing train dataset:  17%|█▋        | 1743/10000 [00:20<02:21, 58.27it/s]Processing train dataset:  12%|█▏        | 1193/10000 [00:16<02:19, 63.24it/s]Processing train dataset:  10%|▉         | 971/10000 [00:14<01:58, 76.30it/s]Processing train dataset:  12%|█▏        | 1199/10000 [00:16<02:12, 66.62it/s]Processing train dataset:  12%|█▏        | 1215/10000 [00:16<01:51, 78.65it/s]Processing train dataset:  18%|█▊        | 1750/10000 [00:20<02:23, 57.60it/s]Processing train dataset:  10%|▉         | 983/10000 [00:14<01:42, 88.22it/s]Processing train dataset:  12%|█▏        | 1208/10000 [00:16<02:01, 72.58it/s]Processing train dataset:  12%|█▏        | 1200/10000 [00:16<02:32, 57.74it/s]Processing train dataset:  12%|█▏        | 1223/10000 [00:16<01:53, 77.23it/s]Processing train dataset:  12%|█▏        | 1206/10000 [00:17<02:37, 55.84it/s]Processing train dataset:  12%|█▏        | 1231/10000 [00:17<01:54, 76.47it/s]Processing train dataset:  18%|█▊        | 1756/10000 [00:20<02:50, 48.29it/s]Processing train dataset:  12%|█▏        | 1216/10000 [00:16<02:08, 68.17it/s]Processing train dataset:  10%|▉         | 992/10000 [00:14<02:13, 67.39it/s]Processing train dataset:  12%|█▏        | 1213/10000 [00:17<02:35, 56.55it/s]Processing train dataset:  18%|█▊        | 1763/10000 [00:20<02:40, 51.38it/s]Processing train dataset:  12%|█▏        | 1239/10000 [00:17<02:02, 71.49it/s]Processing train dataset:  12%|█▏        | 1223/10000 [00:16<02:14, 65.36it/s]Processing train dataset:  10%|█         | 1001/10000 [00:14<02:10, 68.78it/s]Processing train dataset:  12%|█▏        | 1221/10000 [00:17<02:24, 60.70it/s]Processing train dataset:  18%|█▊        | 1771/10000 [00:20<02:22, 57.79it/s]Processing train dataset:  12%|█▏        | 1247/10000 [00:17<02:02, 71.42it/s]Processing train dataset:  12%|█▏        | 1231/10000 [00:17<02:23, 61.20it/s]Processing train dataset:  10%|█         | 1009/10000 [00:14<02:06, 70.84it/s]Processing train dataset:  18%|█▊        | 1780/10000 [00:20<02:04, 65.88it/s]Processing train dataset:  13%|█▎        | 1255/10000 [00:17<02:00, 72.56it/s]Processing train dataset:  12%|█▏        | 1228/10000 [00:17<02:27, 59.55it/s]Processing train dataset:  12%|█▏        | 1238/10000 [00:17<02:32, 57.58it/s]Processing train dataset:  18%|█▊        | 1787/10000 [00:21<02:08, 63.85it/s]Processing train dataset:  12%|█▏        | 1236/10000 [00:17<02:17, 63.56it/s]Processing train dataset:  13%|█▎        | 1263/10000 [00:17<02:07, 68.76it/s]Processing train dataset:  10%|█         | 1017/10000 [00:15<02:25, 61.57it/s]Processing train dataset:  12%|█▏        | 1246/10000 [00:17<02:22, 61.56it/s]Processing train dataset:  12%|█▏        | 1244/10000 [00:17<02:09, 67.70it/s]Processing train dataset:  18%|█▊        | 1796/10000 [00:21<02:00, 67.96it/s]Processing train dataset:  13%|█▎        | 1270/10000 [00:17<02:07, 68.66it/s]Processing train dataset:  10%|█         | 1024/10000 [00:15<02:30, 59.51it/s]Processing train dataset:  13%|█▎        | 1253/10000 [00:17<02:21, 61.83it/s]Processing train dataset:  13%|█▎        | 1252/10000 [00:17<02:03, 70.68it/s]Processing train dataset:  13%|█▎        | 1280/10000 [00:17<01:59, 72.91it/s]Processing train dataset:  10%|█         | 1031/10000 [00:15<02:33, 58.59it/s]Processing train dataset:  18%|█▊        | 1805/10000 [00:21<02:13, 61.30it/s]Processing train dataset:  13%|█▎        | 1260/10000 [00:17<02:00, 72.76it/s]Processing train dataset:  13%|█▎        | 1260/10000 [00:17<02:31, 57.70it/s]Processing train dataset:  13%|█▎        | 1288/10000 [00:17<02:00, 72.35it/s]Processing train dataset:  13%|█▎        | 1268/10000 [00:17<01:57, 74.58it/s]Processing train dataset:  18%|█▊        | 1815/10000 [00:21<02:10, 62.93it/s]Processing train dataset:  10%|█         | 1038/10000 [00:15<02:46, 53.74it/s]Processing train dataset:  13%|█▎        | 1266/10000 [00:17<02:38, 55.15it/s]Processing train dataset:  13%|█▎        | 1298/10000 [00:17<01:51, 78.29it/s]Processing train dataset:  13%|█▎        | 1277/10000 [00:18<01:50, 79.01it/s]Processing train dataset:  13%|█▎        | 1273/10000 [00:17<02:28, 58.77it/s]Processing train dataset:  13%|█▎        | 1307/10000 [00:18<01:50, 78.49it/s]Processing train dataset:  18%|█▊        | 1824/10000 [00:21<02:16, 59.97it/s]Processing train dataset:  10%|█         | 1045/10000 [00:15<03:01, 49.38it/s]Processing train dataset:  13%|█▎        | 1287/10000 [00:18<01:44, 83.71it/s]Processing train dataset:  13%|█▎        | 1280/10000 [00:17<02:22, 61.13it/s]Processing train dataset:  13%|█▎        | 1315/10000 [00:18<01:50, 78.52it/s]Processing train dataset:  18%|█▊        | 1833/10000 [00:21<02:03, 65.95it/s]Processing train dataset:  13%|█▎        | 1299/10000 [00:18<01:35, 91.19it/s]Processing train dataset:  11%|█         | 1052/10000 [00:15<03:03, 48.87it/s]Processing train dataset:  13%|█▎        | 1287/10000 [00:17<02:20, 61.94it/s]Processing train dataset:  13%|█▎        | 1323/10000 [00:18<01:53, 76.23it/s]Processing train dataset:  18%|█▊        | 1840/10000 [00:21<02:06, 64.42it/s]Processing train dataset:  13%|█▎        | 1309/10000 [00:18<01:37, 89.05it/s]Processing train dataset:  13%|█▎        | 1298/10000 [00:18<01:57, 74.27it/s]Processing train dataset:  13%|█▎        | 1331/10000 [00:18<01:56, 74.23it/s]Processing train dataset:  11%|█         | 1060/10000 [00:15<03:02, 48.92it/s]Processing train dataset:  18%|█▊        | 1847/10000 [00:21<02:08, 63.41it/s]Processing train dataset:  13%|█▎        | 1318/10000 [00:18<01:39, 87.43it/s]Processing train dataset:  13%|█▎        | 1306/10000 [00:18<02:00, 71.94it/s]Processing train dataset:  13%|█▎        | 1340/10000 [00:18<01:51, 77.40it/s]Processing train dataset:  13%|█▎        | 1328/10000 [00:18<01:38, 88.18it/s]Processing train dataset:  13%|█▎        | 1314/10000 [00:18<02:00, 72.08it/s]Processing train dataset:  19%|█▊        | 1854/10000 [00:22<02:29, 54.65it/s]Processing train dataset:  11%|█         | 1066/10000 [00:16<03:41, 40.36it/s]Processing train dataset:  13%|█▎        | 1348/10000 [00:18<02:06, 68.45it/s]Processing train dataset:  13%|█▎        | 1337/10000 [00:18<01:39, 87.20it/s]Processing train dataset:  13%|█▎        | 1323/10000 [00:18<01:53, 76.71it/s]Processing train dataset:  19%|█▊        | 1862/10000 [00:22<02:15, 60.24it/s]Processing train dataset:  11%|█         | 1074/10000 [00:16<03:08, 47.31it/s]Processing train dataset:  14%|█▎        | 1356/10000 [00:18<02:03, 70.19it/s]Processing train dataset:  13%|█▎        | 1346/10000 [00:18<01:39, 86.88it/s]Processing train dataset:  13%|█▎        | 1332/10000 [00:18<01:48, 80.17it/s]Processing train dataset:  19%|█▊        | 1871/10000 [00:22<02:01, 66.87it/s]Processing train dataset:  11%|█         | 1084/10000 [00:16<02:35, 57.36it/s]Processing train dataset:  14%|█▎        | 1364/10000 [00:18<02:01, 71.36it/s]Processing train dataset:  14%|█▎        | 1355/10000 [00:18<01:42, 84.28it/s]Processing train dataset:  13%|█▎        | 1342/10000 [00:18<01:43, 84.04it/s]Processing train dataset:  19%|█▉        | 1880/10000 [00:22<01:55, 70.61it/s]Processing train dataset:  11%|█         | 1092/10000 [00:16<02:24, 61.76it/s]Processing train dataset:  14%|█▎        | 1372/10000 [00:19<01:58, 72.53it/s]Processing train dataset:  14%|█▎        | 1364/10000 [00:19<01:43, 83.07it/s]Processing train dataset:  14%|█▎        | 1351/10000 [00:18<01:45, 82.31it/s]Processing train dataset:  19%|█▉        | 1888/10000 [00:22<01:51, 72.75it/s]Processing train dataset:  11%|█         | 1103/10000 [00:16<02:04, 71.65it/s]Processing train dataset:  14%|█▍        | 1380/10000 [00:19<01:56, 73.74it/s]Processing train dataset:  14%|█▎        | 1373/10000 [00:19<01:44, 82.60it/s]Processing train dataset:  14%|█▎        | 1360/10000 [00:18<01:47, 80.65it/s]Processing train dataset:  19%|█▉        | 1896/10000 [00:22<02:01, 66.61it/s]Processing train dataset:  14%|█▍        | 1388/10000 [00:19<01:55, 74.46it/s]Processing train dataset:  14%|█▍        | 1382/10000 [00:19<01:46, 81.30it/s]Processing train dataset:  14%|█▍        | 1397/10000 [00:19<01:51, 77.09it/s]Processing train dataset:  14%|█▎        | 1369/10000 [00:19<02:01, 71.20it/s]Processing train dataset:  11%|█         | 1111/10000 [00:16<02:42, 54.79it/s]Processing train dataset:  19%|█▉        | 1903/10000 [00:22<02:19, 58.01it/s]Processing train dataset:  14%|█▍        | 1391/10000 [00:19<01:49, 78.69it/s]Processing train dataset:  14%|█▍        | 1405/10000 [00:19<01:53, 75.79it/s]Processing train dataset:  14%|█▍        | 1377/10000 [00:19<02:03, 69.70it/s]Processing train dataset:  11%|█         | 1118/10000 [00:16<02:36, 56.65it/s]Processing train dataset:  19%|█▉        | 1912/10000 [00:22<02:04, 65.22it/s]Processing train dataset:  14%|█▍        | 1400/10000 [00:19<01:46, 80.96it/s]Processing train dataset:  14%|█▍        | 1413/10000 [00:19<01:53, 75.54it/s]Processing train dataset:  14%|█▍        | 1386/10000 [00:19<01:57, 73.03it/s]Processing train dataset:  11%|█▏        | 1126/10000 [00:17<02:26, 60.65it/s]Processing train dataset:  19%|█▉        | 1922/10000 [00:23<01:50, 72.88it/s]Processing train dataset:  14%|█▍        | 1409/10000 [00:19<01:47, 80.08it/s]Processing train dataset:  14%|█▍        | 1421/10000 [00:19<01:53, 75.30it/s]Processing train dataset:  14%|█▍        | 1395/10000 [00:19<01:51, 77.26it/s]Processing train dataset:  19%|█▉        | 1932/10000 [00:23<01:43, 77.86it/s]Processing train dataset:  11%|█▏        | 1134/10000 [00:17<02:25, 61.12it/s]Processing train dataset:  14%|█▍        | 1418/10000 [00:19<01:47, 79.61it/s]Processing train dataset:  14%|█▍        | 1429/10000 [00:19<02:03, 69.31it/s]Processing train dataset:  14%|█▍        | 1403/10000 [00:19<02:02, 70.27it/s]Processing train dataset:  14%|█▍        | 1427/10000 [00:19<01:44, 81.79it/s]Processing train dataset:  19%|█▉        | 1941/10000 [00:23<01:54, 70.31it/s]Processing train dataset:  11%|█▏        | 1141/10000 [00:17<03:01, 48.76it/s]Processing train dataset:  14%|█▍        | 1436/10000 [00:19<01:44, 81.79it/s]Processing train dataset:  14%|█▍        | 1437/10000 [00:19<02:19, 61.31it/s]Processing train dataset:  14%|█▍        | 1411/10000 [00:19<02:15, 63.54it/s]Processing train dataset:  19%|█▉        | 1949/10000 [00:23<02:06, 63.75it/s]Processing train dataset:  14%|█▍        | 1446/10000 [00:20<01:39, 86.03it/s]Processing train dataset:  11%|█▏        | 1147/10000 [00:17<03:00, 48.94it/s]Processing train dataset:  14%|█▍        | 1447/10000 [00:20<02:03, 69.05it/s]Processing train dataset:  14%|█▍        | 1420/10000 [00:19<02:10, 65.54it/s]Processing train dataset:  20%|█▉        | 1956/10000 [00:23<02:08, 62.75it/s]Processing train dataset:  15%|█▍        | 1455/10000 [00:20<01:40, 84.63it/s]Processing train dataset:  12%|█▏        | 1153/10000 [00:17<03:03, 48.09it/s]Processing train dataset:  15%|█▍        | 1455/10000 [00:20<02:07, 66.98it/s]Processing train dataset:  14%|█▍        | 1429/10000 [00:19<02:02, 70.01it/s]Processing train dataset:  20%|█▉        | 1964/10000 [00:23<02:00, 66.63it/s]Processing train dataset:  15%|█▍        | 1464/10000 [00:20<01:42, 83.25it/s]Processing train dataset:  12%|█▏        | 1159/10000 [00:17<03:01, 48.71it/s]Processing train dataset:  15%|█▍        | 1462/10000 [00:20<02:09, 65.97it/s]Processing train dataset:  14%|█▍        | 1437/10000 [00:20<02:03, 69.52it/s]Processing train dataset:  20%|█▉        | 1971/10000 [00:23<02:05, 64.10it/s]Processing train dataset:  15%|█▍        | 1474/10000 [00:20<01:38, 86.81it/s]Processing train dataset:  12%|█▏        | 1167/10000 [00:17<02:37, 55.99it/s]Processing train dataset:  14%|█▍        | 1447/10000 [00:20<01:51, 76.81it/s]Processing train dataset:  15%|█▍        | 1472/10000 [00:20<01:57, 72.65it/s]Processing train dataset:  15%|█▍        | 1483/10000 [00:20<01:37, 87.48it/s]Processing train dataset:  20%|█▉        | 1978/10000 [00:23<02:12, 60.38it/s]Processing train dataset:  12%|█▏        | 1173/10000 [00:18<02:44, 53.68it/s]Processing train dataset:  15%|█▍        | 1455/10000 [00:20<01:58, 72.38it/s]Processing train dataset:  15%|█▍        | 1480/10000 [00:20<02:04, 68.42it/s]Processing train dataset:  15%|█▍        | 1493/10000 [00:20<01:34, 89.56it/s]Processing train dataset:  20%|█▉        | 1986/10000 [00:24<02:04, 64.17it/s]Processing train dataset:  15%|█▍        | 1463/10000 [00:20<01:58, 72.16it/s]Processing train dataset:  12%|█▏        | 1181/10000 [00:18<02:44, 53.62it/s]Processing train dataset:  15%|█▍        | 1487/10000 [00:20<02:13, 64.00it/s]Processing train dataset:  15%|█▌        | 1502/10000 [00:20<01:42, 82.61it/s]Processing train dataset:  20%|█▉        | 1993/10000 [00:24<02:13, 59.98it/s]Processing train dataset:  15%|█▍        | 1473/10000 [00:20<01:47, 79.09it/s]Processing train dataset:  12%|█▏        | 1189/10000 [00:18<02:27, 59.59it/s]Processing train dataset:  15%|█▌        | 1511/10000 [00:20<01:45, 80.46it/s]Processing train dataset:  15%|█▍        | 1495/10000 [00:20<02:23, 59.34it/s]Processing train dataset:  20%|██        | 2001/10000 [00:24<02:12, 60.41it/s]Processing train dataset:  12%|█▏        | 1196/10000 [00:18<02:25, 60.62it/s]Processing train dataset:  15%|█▍        | 1482/10000 [00:20<01:52, 75.40it/s]Processing train dataset:  15%|█▌        | 1502/10000 [00:20<02:17, 61.78it/s]Processing train dataset:  15%|█▌        | 1520/10000 [00:20<01:50, 76.42it/s]Processing train dataset:  20%|██        | 2009/10000 [00:24<02:04, 64.42it/s]Processing train dataset:  15%|█▍        | 1493/10000 [00:20<01:41, 83.63it/s]Processing train dataset:  15%|█▌        | 1528/10000 [00:21<02:00, 70.18it/s]Processing train dataset:  15%|█▌        | 1509/10000 [00:21<02:32, 55.61it/s]Processing train dataset:  12%|█▏        | 1205/10000 [00:18<02:51, 51.16it/s]Processing train dataset:  15%|█▌        | 1536/10000 [00:21<01:57, 72.05it/s]Processing train dataset:  15%|█▌        | 1502/10000 [00:20<02:04, 68.43it/s]Processing train dataset:  15%|█▌        | 1518/10000 [00:21<02:18, 61.28it/s]Processing train dataset:  20%|██        | 2016/10000 [00:24<03:08, 42.45it/s]Processing train dataset:  15%|█▌        | 1510/10000 [00:20<01:59, 71.09it/s]Processing train dataset:  15%|█▌        | 1544/10000 [00:21<01:56, 72.61it/s]Processing train dataset:  15%|█▌        | 1526/10000 [00:21<02:12, 63.83it/s]Processing train dataset:  12%|█▏        | 1211/10000 [00:18<03:46, 38.82it/s]Processing train dataset:  20%|██        | 2024/10000 [00:24<02:42, 49.01it/s]Processing train dataset:  15%|█▌        | 1518/10000 [00:21<01:55, 73.32it/s]Processing train dataset:  16%|█▌        | 1552/10000 [00:21<02:05, 67.08it/s]Processing train dataset:  15%|█▌        | 1534/10000 [00:21<02:07, 66.39it/s]Processing train dataset:  15%|█▌        | 1527/10000 [00:21<01:52, 75.55it/s]Processing train dataset:  12%|█▏        | 1218/10000 [00:19<03:26, 42.50it/s]Processing train dataset:  20%|██        | 2033/10000 [00:24<02:25, 54.86it/s]Processing train dataset:  16%|█▌        | 1560/10000 [00:21<02:03, 68.29it/s]Processing train dataset:  15%|█▌        | 1542/10000 [00:21<02:04, 67.85it/s]Processing train dataset:  15%|█▌        | 1536/10000 [00:21<01:49, 77.20it/s]Processing train dataset:  20%|██        | 2040/10000 [00:25<02:22, 55.87it/s]Processing train dataset:  12%|█▏        | 1223/10000 [00:19<03:31, 41.48it/s]Processing train dataset:  16%|█▌        | 1568/10000 [00:21<02:01, 69.23it/s]Processing train dataset:  16%|█▌        | 1550/10000 [00:21<02:01, 69.44it/s]Processing train dataset:  15%|█▌        | 1544/10000 [00:21<01:49, 77.45it/s]Processing train dataset:  20%|██        | 2047/10000 [00:25<02:15, 58.72it/s]Processing train dataset:  12%|█▏        | 1231/10000 [00:19<02:57, 49.28it/s]Processing train dataset:  16%|█▌        | 1576/10000 [00:21<01:57, 71.67it/s]Processing train dataset:  16%|█▌        | 1558/10000 [00:21<02:09, 65.02it/s]Processing train dataset:  16%|█▌        | 1552/10000 [00:21<01:48, 77.82it/s]Processing train dataset:  21%|██        | 2056/10000 [00:25<02:00, 65.92it/s]Processing train dataset:  12%|█▏        | 1240/10000 [00:19<02:32, 57.46it/s]Processing train dataset:  16%|█▌        | 1584/10000 [00:21<01:54, 73.82it/s]Processing train dataset:  16%|█▌        | 1566/10000 [00:21<02:05, 67.10it/s]Processing train dataset:  16%|█▌        | 1560/10000 [00:21<01:49, 77.40it/s]Processing train dataset:  21%|██        | 2066/10000 [00:25<01:47, 73.73it/s]Processing train dataset:  16%|█▌        | 1592/10000 [00:21<01:51, 75.51it/s]Processing train dataset:  12%|█▏        | 1247/10000 [00:19<02:46, 52.54it/s]Processing train dataset:  16%|█▌        | 1574/10000 [00:21<01:59, 70.32it/s]Processing train dataset:  16%|█▌        | 1568/10000 [00:21<01:48, 77.52it/s]Processing train dataset:  21%|██        | 2075/10000 [00:25<01:41, 78.03it/s]Processing train dataset:  16%|█▌        | 1600/10000 [00:22<01:52, 74.50it/s]Processing train dataset:  13%|█▎        | 1254/10000 [00:19<02:34, 56.58it/s]Processing train dataset:  16%|█▌        | 1577/10000 [00:21<01:44, 80.77it/s]Processing train dataset:  16%|█▌        | 1583/10000 [00:22<01:55, 73.18it/s]Processing train dataset:  21%|██        | 2084/10000 [00:25<01:44, 75.67it/s]Processing train dataset:  16%|█▌        | 1608/10000 [00:22<01:53, 73.66it/s]Processing train dataset:  16%|█▌        | 1586/10000 [00:21<01:41, 82.78it/s]Processing train dataset:  16%|█▌        | 1591/10000 [00:22<01:52, 75.03it/s]Processing train dataset:  13%|█▎        | 1262/10000 [00:19<02:28, 58.78it/s]Processing train dataset:  21%|██        | 2092/10000 [00:25<01:45, 74.89it/s]Processing train dataset:  16%|█▌        | 1617/10000 [00:22<01:48, 77.00it/s]Processing train dataset:  16%|█▌        | 1595/10000 [00:22<01:40, 83.96it/s]Processing train dataset:  16%|█▌        | 1599/10000 [00:22<01:53, 74.18it/s]Processing train dataset:  13%|█▎        | 1269/10000 [00:19<02:26, 59.54it/s]Processing train dataset:  16%|█▋        | 1626/10000 [00:22<01:47, 77.87it/s]Processing train dataset:  21%|██        | 2100/10000 [00:25<01:54, 69.29it/s]Processing train dataset:  16%|█▌        | 1604/10000 [00:22<01:41, 83.01it/s]Processing train dataset:  16%|█▌        | 1607/10000 [00:22<01:53, 73.70it/s]Processing train dataset:  13%|█▎        | 1276/10000 [00:20<02:42, 53.78it/s]Processing train dataset:  16%|█▋        | 1634/10000 [00:22<01:48, 76.98it/s]Processing train dataset:  21%|██        | 2108/10000 [00:25<01:51, 71.02it/s]Processing train dataset:  16%|█▌        | 1614/10000 [00:22<01:35, 87.82it/s]Processing train dataset:  16%|█▌        | 1616/10000 [00:22<01:48, 77.58it/s]Processing train dataset:  16%|█▋        | 1642/10000 [00:22<01:49, 76.53it/s]Processing train dataset:  13%|█▎        | 1282/10000 [00:20<02:42, 53.75it/s]Processing train dataset:  16%|█▌        | 1623/10000 [00:22<01:35, 87.46it/s]Processing train dataset:  21%|██        | 2116/10000 [00:26<01:56, 67.93it/s]Processing train dataset:  16%|█▌        | 1624/10000 [00:22<01:47, 77.89it/s]Processing train dataset:  16%|█▋        | 1650/10000 [00:22<01:51, 74.97it/s]Processing train dataset:  13%|█▎        | 1288/10000 [00:20<02:47, 51.98it/s]Processing train dataset:  21%|██▏       | 2125/10000 [00:26<01:48, 72.49it/s]Processing train dataset:  16%|█▋        | 1632/10000 [00:22<01:37, 85.73it/s]Processing train dataset:  16%|█▋        | 1632/10000 [00:22<01:50, 75.96it/s]Processing train dataset:  17%|█▋        | 1658/10000 [00:22<01:49, 76.24it/s]Processing train dataset:  21%|██▏       | 2135/10000 [00:26<01:38, 79.83it/s]Processing train dataset:  16%|█▋        | 1641/10000 [00:22<01:36, 86.72it/s]Processing train dataset:  13%|█▎        | 1295/10000 [00:20<02:39, 54.70it/s]Processing train dataset:  16%|█▋        | 1641/10000 [00:22<01:47, 77.46it/s]Processing train dataset:  17%|█▋        | 1668/10000 [00:22<01:43, 80.15it/s]Processing train dataset:  21%|██▏       | 2146/10000 [00:26<01:30, 86.93it/s]Processing train dataset:  16%|█▋        | 1650/10000 [00:22<01:38, 85.00it/s]Processing train dataset:  13%|█▎        | 1302/10000 [00:20<02:33, 56.77it/s]Processing train dataset:  16%|█▋        | 1649/10000 [00:22<01:49, 76.57it/s]Processing train dataset:  22%|██▏       | 2155/10000 [00:26<01:29, 87.27it/s]Processing train dataset:  17%|█▋        | 1677/10000 [00:23<01:46, 77.90it/s]Processing train dataset:  17%|█▋        | 1659/10000 [00:22<01:36, 86.37it/s]Processing train dataset:  17%|█▋        | 1658/10000 [00:23<01:46, 78.27it/s]Processing train dataset:  13%|█▎        | 1309/10000 [00:20<02:32, 57.04it/s]Processing train dataset:  17%|█▋        | 1668/10000 [00:22<01:35, 86.95it/s]Processing train dataset:  22%|██▏       | 2165/10000 [00:26<01:28, 88.55it/s]Processing train dataset:  17%|█▋        | 1685/10000 [00:23<01:49, 76.18it/s]Processing train dataset:  17%|█▋        | 1666/10000 [00:23<01:49, 75.77it/s]Processing train dataset:  13%|█▎        | 1315/10000 [00:20<02:40, 53.97it/s]Processing train dataset:  22%|██▏       | 2176/10000 [00:26<01:23, 93.44it/s]Processing train dataset:  17%|█▋        | 1693/10000 [00:23<01:47, 77.09it/s]Processing train dataset:  17%|█▋        | 1677/10000 [00:22<01:37, 85.38it/s]Processing train dataset:  17%|█▋        | 1674/10000 [00:23<01:51, 74.36it/s]Processing train dataset:  13%|█▎        | 1321/10000 [00:20<02:50, 51.00it/s]Processing train dataset:  22%|██▏       | 2186/10000 [00:26<01:24, 92.07it/s]Processing train dataset:  17%|█▋        | 1686/10000 [00:23<01:39, 83.73it/s]Processing train dataset:  17%|█▋        | 1701/10000 [00:23<01:50, 74.79it/s]Processing train dataset:  17%|█▋        | 1682/10000 [00:23<01:54, 72.33it/s]Processing train dataset:  13%|█▎        | 1327/10000 [00:20<02:43, 53.01it/s]Processing train dataset:  22%|██▏       | 2196/10000 [00:26<01:23, 93.11it/s]Processing train dataset:  17%|█▋        | 1696/10000 [00:23<01:36, 85.77it/s]Processing train dataset:  17%|█▋        | 1709/10000 [00:23<01:52, 73.57it/s]Processing train dataset:  17%|█▋        | 1691/10000 [00:23<01:50, 75.22it/s]Processing train dataset:  13%|█▎        | 1333/10000 [00:21<02:47, 51.70it/s]Processing train dataset:  17%|█▋        | 1705/10000 [00:23<01:38, 84.55it/s]Processing train dataset:  17%|█▋        | 1719/10000 [00:23<01:45, 78.16it/s]Processing train dataset:  22%|██▏       | 2206/10000 [00:27<01:30, 85.95it/s]Processing train dataset:  17%|█▋        | 1699/10000 [00:23<01:50, 75.29it/s]Processing train dataset:  13%|█▎        | 1339/10000 [00:21<02:46, 52.13it/s]Processing train dataset:  17%|█▋        | 1714/10000 [00:23<01:36, 85.85it/s]Processing train dataset:  17%|█▋        | 1727/10000 [00:23<01:47, 77.31it/s]Processing train dataset:  22%|██▏       | 2215/10000 [00:27<01:30, 86.31it/s]Processing train dataset:  17%|█▋        | 1707/10000 [00:23<01:50, 75.29it/s]Processing train dataset:  17%|█▋        | 1723/10000 [00:23<01:35, 86.92it/s]Processing train dataset:  17%|█▋        | 1735/10000 [00:23<01:48, 76.35it/s]Processing train dataset:  22%|██▏       | 2226/10000 [00:27<01:26, 90.27it/s]Processing train dataset:  13%|█▎        | 1345/10000 [00:21<03:00, 48.04it/s]Processing train dataset:  17%|█▋        | 1716/10000 [00:23<01:47, 77.33it/s]Processing train dataset:  17%|█▋        | 1732/10000 [00:23<01:37, 85.00it/s]Processing train dataset:  17%|█▋        | 1743/10000 [00:23<01:49, 75.48it/s]Processing train dataset:  14%|█▎        | 1351/10000 [00:21<02:54, 49.56it/s]Processing train dataset:  17%|█▋        | 1725/10000 [00:23<01:45, 78.32it/s]Processing train dataset:  17%|█▋        | 1741/10000 [00:23<01:37, 84.28it/s]Processing train dataset:  22%|██▏       | 2236/10000 [00:27<01:44, 74.18it/s]Processing train dataset:  18%|█▊        | 1751/10000 [00:24<01:58, 69.63it/s]Processing train dataset:  14%|█▎        | 1357/10000 [00:21<03:00, 47.75it/s]Processing train dataset:  17%|█▋        | 1733/10000 [00:24<01:49, 75.73it/s]Processing train dataset:  18%|█▊        | 1750/10000 [00:23<01:36, 85.73it/s]Processing train dataset:  18%|█▊        | 1759/10000 [00:24<01:54, 71.90it/s]Processing train dataset:  17%|█▋        | 1741/10000 [00:24<01:50, 75.07it/s]Processing train dataset:  14%|█▎        | 1363/10000 [00:21<02:57, 48.71it/s]Processing train dataset:  22%|██▏       | 2244/10000 [00:27<02:05, 61.81it/s]Processing train dataset:  18%|█▊        | 1759/10000 [00:23<01:34, 86.85it/s]Processing train dataset:  18%|█▊        | 1767/10000 [00:24<01:57, 70.29it/s]Processing train dataset:  14%|█▎        | 1368/10000 [00:21<02:57, 48.56it/s]Processing train dataset:  18%|█▊        | 1750/10000 [00:24<01:47, 76.98it/s]Processing train dataset:  18%|█▊        | 1768/10000 [00:24<01:36, 84.91it/s]Processing train dataset:  23%|██▎       | 2251/10000 [00:27<02:11, 58.99it/s]Processing train dataset:  18%|█▊        | 1775/10000 [00:24<01:56, 70.45it/s]Processing train dataset:  14%|█▎        | 1373/10000 [00:21<02:57, 48.61it/s]Processing train dataset:  18%|█▊        | 1759/10000 [00:24<01:45, 77.95it/s]Processing train dataset:  18%|█▊        | 1777/10000 [00:24<01:45, 77.78it/s]Processing train dataset:  23%|██▎       | 2258/10000 [00:27<02:15, 57.19it/s]Processing train dataset:  18%|█▊        | 1783/10000 [00:24<01:54, 71.99it/s]Processing train dataset:  14%|█▍        | 1380/10000 [00:22<02:39, 54.14it/s]Processing train dataset:  18%|█▊        | 1767/10000 [00:24<01:50, 74.65it/s]Processing train dataset:  23%|██▎       | 2265/10000 [00:28<02:13, 58.04it/s]Processing train dataset:  18%|█▊        | 1785/10000 [00:24<01:53, 72.15it/s]Processing train dataset:  18%|█▊        | 1791/10000 [00:24<01:52, 73.27it/s]Processing train dataset:  14%|█▍        | 1386/10000 [00:22<02:41, 53.29it/s]Processing train dataset:  18%|█▊        | 1775/10000 [00:24<02:01, 67.69it/s]Processing train dataset:  18%|█▊        | 1793/10000 [00:24<01:51, 73.50it/s]Processing train dataset:  23%|██▎       | 2274/10000 [00:28<02:00, 63.99it/s]Processing train dataset:  14%|█▍        | 1392/10000 [00:22<02:43, 52.76it/s]Processing train dataset:  18%|█▊        | 1799/10000 [00:24<02:03, 66.47it/s]Processing train dataset:  18%|█▊        | 1782/10000 [00:24<02:00, 68.08it/s]Processing train dataset:  18%|█▊        | 1801/10000 [00:24<01:53, 72.16it/s]Processing train dataset:  23%|██▎       | 2281/10000 [00:28<02:12, 58.44it/s]Processing train dataset:  14%|█▍        | 1399/10000 [00:22<02:39, 54.09it/s]Processing train dataset:  18%|█▊        | 1790/10000 [00:24<01:55, 71.08it/s]Processing train dataset:  18%|█▊        | 1806/10000 [00:24<02:09, 63.35it/s]Processing train dataset:  18%|█▊        | 1809/10000 [00:24<01:58, 69.05it/s]Processing train dataset:  23%|██▎       | 2288/10000 [00:28<02:08, 59.88it/s]Processing train dataset:  14%|█▍        | 1405/10000 [00:22<02:40, 53.51it/s]Processing train dataset:  18%|█▊        | 1798/10000 [00:24<01:53, 72.53it/s]Processing train dataset:  18%|█▊        | 1813/10000 [00:25<02:18, 58.98it/s]Processing train dataset:  18%|█▊        | 1816/10000 [00:24<01:58, 68.83it/s]Processing train dataset:  23%|██▎       | 2295/10000 [00:28<02:17, 55.96it/s]Processing train dataset:  18%|█▊        | 1806/10000 [00:25<02:00, 68.28it/s]Processing train dataset:  18%|█▊        | 1820/10000 [00:25<02:14, 61.01it/s]Processing train dataset:  14%|█▍        | 1411/10000 [00:22<03:10, 45.00it/s]Processing train dataset:  18%|█▊        | 1823/10000 [00:24<02:02, 66.71it/s]Processing train dataset:  23%|██▎       | 2301/10000 [00:28<02:18, 55.43it/s]Processing train dataset:  18%|█▊        | 1815/10000 [00:25<01:53, 72.02it/s]Processing train dataset:  18%|█▊        | 1827/10000 [00:25<02:21, 57.70it/s]Processing train dataset:  14%|█▍        | 1416/10000 [00:22<03:07, 45.80it/s]Processing train dataset:  18%|█▊        | 1830/10000 [00:24<02:05, 65.07it/s]Processing train dataset:  23%|██▎       | 2307/10000 [00:28<02:21, 54.31it/s]Processing train dataset:  18%|█▊        | 1823/10000 [00:25<01:55, 71.05it/s]Processing train dataset:  14%|█▍        | 1421/10000 [00:22<03:04, 46.51it/s]Processing train dataset:  18%|█▊        | 1833/10000 [00:25<02:21, 57.58it/s]Processing train dataset:  18%|█▊        | 1837/10000 [00:25<02:08, 63.70it/s]Processing train dataset:  23%|██▎       | 2313/10000 [00:28<02:20, 54.85it/s]Processing train dataset:  18%|█▊        | 1831/10000 [00:25<01:55, 70.94it/s]Processing train dataset:  14%|█▍        | 1428/10000 [00:23<02:43, 52.52it/s]Processing train dataset:  18%|█▊        | 1839/10000 [00:25<02:26, 55.70it/s]Processing train dataset:  18%|█▊        | 1847/10000 [00:25<01:54, 70.95it/s]Processing train dataset:  23%|██▎       | 2320/10000 [00:29<02:14, 56.92it/s]Processing train dataset:  18%|█▊        | 1839/10000 [00:25<01:56, 70.28it/s]Processing train dataset:  14%|█▍        | 1434/10000 [00:23<02:39, 53.68it/s]Processing train dataset:  18%|█▊        | 1847/10000 [00:25<02:12, 61.61it/s]Processing train dataset:  19%|█▊        | 1855/10000 [00:25<02:02, 66.63it/s]Processing train dataset:  18%|█▊        | 1849/10000 [00:25<01:46, 76.78it/s]Processing train dataset:  14%|█▍        | 1441/10000 [00:23<02:34, 55.27it/s]Processing train dataset:  23%|██▎       | 2327/10000 [00:29<02:18, 55.34it/s]Processing train dataset:  19%|█▊        | 1855/10000 [00:25<02:06, 64.33it/s]Processing train dataset:  19%|█▊        | 1864/10000 [00:25<01:53, 71.91it/s]Processing train dataset:  19%|█▊        | 1858/10000 [00:25<01:45, 77.35it/s]Processing train dataset:  19%|█▊        | 1866/10000 [00:25<01:49, 73.97it/s]Processing train dataset:  23%|██▎       | 2333/10000 [00:29<02:23, 53.40it/s]Processing train dataset:  14%|█▍        | 1448/10000 [00:23<02:34, 55.45it/s]Processing train dataset:  19%|█▊        | 1873/10000 [00:25<01:47, 75.26it/s]Processing train dataset:  19%|█▊        | 1867/10000 [00:25<01:41, 79.89it/s]Processing train dataset:  23%|██▎       | 2339/10000 [00:29<02:20, 54.45it/s]Processing train dataset:  15%|█▍        | 1454/10000 [00:23<02:37, 54.17it/s]Processing train dataset:  19%|█▊        | 1874/10000 [00:25<02:01, 66.93it/s]Processing train dataset:  19%|█▉        | 1881/10000 [00:25<01:53, 71.60it/s]Processing train dataset:  19%|█▉        | 1876/10000 [00:26<01:43, 78.25it/s]Processing train dataset:  23%|██▎       | 2346/10000 [00:29<02:13, 57.29it/s]Processing train dataset:  15%|█▍        | 1460/10000 [00:23<02:41, 52.83it/s]Processing train dataset:  19%|█▉        | 1882/10000 [00:26<01:58, 68.32it/s]Processing train dataset:  19%|█▉        | 1889/10000 [00:25<01:54, 70.93it/s]Processing train dataset:  19%|█▉        | 1884/10000 [00:26<01:44, 77.36it/s]Processing train dataset:  24%|██▎       | 2352/10000 [00:29<02:16, 56.03it/s]Processing train dataset:  19%|█▉        | 1889/10000 [00:26<01:58, 68.27it/s]Processing train dataset:  15%|█▍        | 1466/10000 [00:23<02:44, 52.03it/s]Processing train dataset:  19%|█▉        | 1892/10000 [00:26<01:45, 76.89it/s]Processing train dataset:  24%|██▎       | 2358/10000 [00:29<02:16, 56.12it/s]Processing train dataset:  15%|█▍        | 1473/10000 [00:23<02:31, 56.30it/s]Processing train dataset:  19%|█▉        | 1897/10000 [00:25<02:17, 59.10it/s]Processing train dataset:  19%|█▉        | 1896/10000 [00:26<02:04, 65.03it/s]Processing train dataset:  19%|█▉        | 1901/10000 [00:26<01:43, 78.27it/s]Processing train dataset:  24%|██▎       | 2364/10000 [00:29<02:23, 53.39it/s]Processing train dataset:  15%|█▍        | 1484/10000 [00:23<02:02, 69.34it/s]Processing train dataset:  19%|█▉        | 1903/10000 [00:26<02:06, 63.77it/s]Processing train dataset:  19%|█▉        | 1904/10000 [00:26<02:24, 56.13it/s]Processing train dataset:  19%|█▉        | 1909/10000 [00:26<01:47, 75.50it/s]Processing train dataset:  15%|█▍        | 1493/10000 [00:24<01:53, 74.82it/s]Processing train dataset:  24%|██▎       | 2371/10000 [00:29<02:19, 54.59it/s]Processing train dataset:  19%|█▉        | 1910/10000 [00:26<02:04, 64.91it/s]Processing train dataset:  19%|█▉        | 1910/10000 [00:26<02:26, 55.31it/s]Processing train dataset:  19%|█▉        | 1917/10000 [00:26<01:45, 76.38it/s]Processing train dataset:  15%|█▌        | 1503/10000 [00:24<01:46, 79.72it/s]Processing train dataset:  19%|█▉        | 1917/10000 [00:26<02:02, 66.17it/s]Processing train dataset:  24%|██▍       | 2377/10000 [00:30<02:25, 52.24it/s]Processing train dataset:  19%|█▉        | 1925/10000 [00:26<01:44, 77.36it/s]Processing train dataset:  19%|█▉        | 1916/10000 [00:26<02:42, 49.86it/s]Processing train dataset:  15%|█▌        | 1512/10000 [00:24<01:50, 76.58it/s]Processing train dataset:  24%|██▍       | 2383/10000 [00:30<02:21, 53.72it/s]Processing train dataset:  19%|█▉        | 1924/10000 [00:26<02:04, 64.62it/s]Processing train dataset:  19%|█▉        | 1933/10000 [00:26<01:46, 75.41it/s]Processing train dataset:  24%|██▍       | 2392/10000 [00:30<02:00, 63.02it/s]Processing train dataset:  19%|█▉        | 1923/10000 [00:26<02:42, 49.85it/s]Processing train dataset:  19%|█▉        | 1931/10000 [00:26<02:17, 58.86it/s]Processing train dataset:  19%|█▉        | 1942/10000 [00:26<01:45, 76.48it/s]Processing train dataset:  15%|█▌        | 1520/10000 [00:24<02:07, 66.67it/s]Processing train dataset:  24%|██▍       | 2401/10000 [00:30<01:50, 68.47it/s]Processing train dataset:  19%|█▉        | 1930/10000 [00:26<02:31, 53.28it/s]Processing train dataset:  20%|█▉        | 1951/10000 [00:26<01:44, 77.26it/s]Processing train dataset:  19%|█▉        | 1938/10000 [00:27<02:21, 56.91it/s]Processing train dataset:  15%|█▌        | 1527/10000 [00:24<02:18, 61.02it/s]Processing train dataset:  24%|██▍       | 2409/10000 [00:30<01:46, 71.09it/s]Processing train dataset:  19%|█▉        | 1938/10000 [00:26<02:18, 58.28it/s]Processing train dataset:  19%|█▉        | 1944/10000 [00:27<02:21, 57.07it/s]Processing train dataset:  20%|█▉        | 1959/10000 [00:27<01:47, 74.64it/s]Processing train dataset:  24%|██▍       | 2417/10000 [00:30<01:43, 73.32it/s]Processing train dataset:  19%|█▉        | 1944/10000 [00:26<02:22, 56.40it/s]Processing train dataset:  15%|█▌        | 1534/10000 [00:24<02:30, 56.27it/s]Processing train dataset:  20%|█▉        | 1967/10000 [00:27<01:45, 75.82it/s]Processing train dataset:  20%|█▉        | 1950/10000 [00:27<02:28, 54.06it/s]Processing train dataset:  24%|██▍       | 2427/10000 [00:30<01:35, 79.48it/s]Processing train dataset:  20%|█▉        | 1953/10000 [00:26<02:05, 63.93it/s]Processing train dataset:  15%|█▌        | 1540/10000 [00:24<02:36, 54.14it/s]Processing train dataset:  20%|█▉        | 1975/10000 [00:27<01:44, 76.53it/s]Processing train dataset:  24%|██▍       | 2438/10000 [00:30<01:25, 88.08it/s]Processing train dataset:  20%|█▉        | 1956/10000 [00:27<02:32, 52.83it/s]Processing train dataset:  20%|█▉        | 1960/10000 [00:27<02:08, 62.74it/s]Processing train dataset:  20%|█▉        | 1983/10000 [00:27<01:43, 77.25it/s]Processing train dataset:  15%|█▌        | 1546/10000 [00:24<02:47, 50.61it/s]Processing train dataset:  24%|██▍       | 2449/10000 [00:30<01:20, 94.24it/s]Processing train dataset:  20%|█▉        | 1962/10000 [00:27<02:44, 48.73it/s]Processing train dataset:  20%|█▉        | 1969/10000 [00:27<02:02, 65.76it/s]Processing train dataset:  20%|█▉        | 1991/10000 [00:27<01:47, 74.75it/s]Processing train dataset:  16%|█▌        | 1553/10000 [00:25<02:43, 51.67it/s]Processing train dataset:  25%|██▍       | 2459/10000 [00:31<01:22, 91.40it/s]Processing train dataset:  20%|█▉        | 1969/10000 [00:27<02:37, 50.89it/s]Processing train dataset:  20%|█▉        | 1976/10000 [00:27<02:06, 63.51it/s]Processing train dataset:  20%|█▉        | 1999/10000 [00:27<01:48, 73.63it/s]Processing train dataset:  25%|██▍       | 2469/10000 [00:31<01:20, 93.20it/s]Processing train dataset:  16%|█▌        | 1560/10000 [00:25<02:32, 55.49it/s]Processing train dataset:  20%|█▉        | 1978/10000 [00:27<02:14, 59.62it/s]Processing train dataset:  20%|██        | 2007/10000 [00:27<01:48, 73.65it/s]Processing train dataset:  20%|█▉        | 1983/10000 [00:27<02:09, 61.82it/s]Processing train dataset:  25%|██▍       | 2479/10000 [00:31<01:25, 87.69it/s]Processing train dataset:  16%|█▌        | 1566/10000 [00:25<02:39, 52.88it/s]Processing train dataset:  20%|█▉        | 1985/10000 [00:27<02:09, 62.03it/s]Processing train dataset:  20%|██        | 2015/10000 [00:27<01:47, 74.02it/s]Processing train dataset:  20%|█▉        | 1990/10000 [00:27<02:07, 62.60it/s]Processing train dataset:  16%|█▌        | 1572/10000 [00:25<02:37, 53.43it/s]Processing train dataset:  20%|█▉        | 1993/10000 [00:27<02:01, 65.81it/s]Processing train dataset:  25%|██▍       | 2488/10000 [00:31<01:35, 78.36it/s]Processing train dataset:  20%|██        | 2024/10000 [00:27<01:41, 78.28it/s]Processing train dataset:  20%|█▉        | 1997/10000 [00:27<02:10, 61.47it/s]Processing train dataset:  16%|█▌        | 1578/10000 [00:25<02:42, 51.96it/s]Processing train dataset:  20%|██        | 2032/10000 [00:28<01:42, 78.09it/s]Processing train dataset:  20%|██        | 2000/10000 [00:28<02:12, 60.32it/s]Processing train dataset:  20%|██        | 2004/10000 [00:27<02:07, 62.53it/s]Processing train dataset:  25%|██▍       | 2497/10000 [00:31<01:48, 68.98it/s]Processing train dataset:  16%|█▌        | 1585/10000 [00:25<02:33, 54.92it/s]Processing train dataset:  20%|██        | 2040/10000 [00:28<01:44, 76.13it/s]Processing train dataset:  20%|██        | 2007/10000 [00:28<02:13, 59.85it/s]Processing train dataset:  20%|██        | 2012/10000 [00:27<02:02, 65.03it/s]Processing train dataset:  25%|██▌       | 2505/10000 [00:31<01:47, 69.98it/s]Processing train dataset:  16%|█▌        | 1592/10000 [00:25<02:22, 58.84it/s]Processing train dataset:  20%|██        | 2049/10000 [00:28<01:42, 77.44it/s]Processing train dataset:  20%|██        | 2015/10000 [00:28<02:04, 64.34it/s]Processing train dataset:  20%|██        | 2020/10000 [00:28<01:59, 66.95it/s]Processing train dataset:  16%|█▌        | 1598/10000 [00:25<02:28, 56.60it/s]Processing train dataset:  25%|██▌       | 2513/10000 [00:31<01:55, 64.94it/s]Processing train dataset:  21%|██        | 2059/10000 [00:28<01:38, 81.02it/s]Processing train dataset:  20%|██        | 2023/10000 [00:28<02:00, 66.40it/s]Processing train dataset:  20%|██        | 2030/10000 [00:28<01:47, 74.36it/s]Processing train dataset:  16%|█▌        | 1607/10000 [00:26<02:14, 62.59it/s]Processing train dataset:  25%|██▌       | 2520/10000 [00:31<01:56, 64.18it/s]Processing train dataset:  21%|██        | 2068/10000 [00:28<01:40, 79.28it/s]Processing train dataset:  20%|██        | 2031/10000 [00:28<01:55, 69.01it/s]Processing train dataset:  20%|██        | 2039/10000 [00:28<01:42, 77.77it/s]Processing train dataset:  16%|█▌        | 1617/10000 [00:26<01:59, 70.31it/s]Processing train dataset:  25%|██▌       | 2528/10000 [00:32<01:52, 66.17it/s]Processing train dataset:  20%|██        | 2040/10000 [00:28<01:48, 73.67it/s]Processing train dataset:  21%|██        | 2076/10000 [00:28<01:42, 77.23it/s]Processing train dataset:  20%|██        | 2047/10000 [00:28<01:42, 77.44it/s]Processing train dataset:  25%|██▌       | 2537/10000 [00:32<01:45, 70.78it/s]Processing train dataset:  16%|█▋        | 1626/10000 [00:26<01:56, 71.74it/s]Processing train dataset:  21%|██        | 2084/10000 [00:28<01:41, 77.68it/s]Processing train dataset:  20%|██        | 2049/10000 [00:28<01:43, 76.66it/s]Processing train dataset:  21%|██        | 2056/10000 [00:28<01:45, 75.01it/s]Processing train dataset:  25%|██▌       | 2545/10000 [00:32<01:47, 69.36it/s]Processing train dataset:  16%|█▋        | 1634/10000 [00:26<01:58, 70.38it/s]Processing train dataset:  21%|██        | 2093/10000 [00:28<01:41, 78.14it/s]Processing train dataset:  21%|██        | 2057/10000 [00:28<01:48, 73.52it/s]Processing train dataset:  21%|██        | 2064/10000 [00:28<01:45, 75.32it/s]Processing train dataset:  16%|█▋        | 1642/10000 [00:26<01:57, 71.19it/s]Processing train dataset:  26%|██▌       | 2554/10000 [00:32<01:44, 71.36it/s]Processing train dataset:  21%|██        | 2065/10000 [00:28<01:46, 74.48it/s]Processing train dataset:  21%|██        | 2101/10000 [00:28<01:44, 75.28it/s]Processing train dataset:  21%|██        | 2072/10000 [00:28<01:45, 74.85it/s]Processing train dataset:  26%|██▌       | 2562/10000 [00:32<01:44, 71.32it/s]Processing train dataset:  21%|██        | 2073/10000 [00:29<01:45, 74.82it/s]Processing train dataset:  16%|█▋        | 1650/10000 [00:26<02:00, 69.16it/s]Processing train dataset:  21%|██        | 2110/10000 [00:29<01:43, 76.44it/s]Processing train dataset:  21%|██        | 2081/10000 [00:28<01:42, 77.49it/s]Processing train dataset:  17%|█▋        | 1658/10000 [00:26<01:57, 71.14it/s]Processing train dataset:  21%|██        | 2082/10000 [00:29<01:41, 77.88it/s]Processing train dataset:  21%|██        | 2118/10000 [00:29<01:45, 74.76it/s]Processing train dataset:  21%|██        | 2090/10000 [00:28<01:37, 80.93it/s]Processing train dataset:  26%|██▌       | 2570/10000 [00:32<01:51, 66.71it/s]Processing train dataset:  21%|██        | 2092/10000 [00:29<01:36, 81.69it/s]Processing train dataset:  17%|█▋        | 1667/10000 [00:26<01:55, 72.02it/s]Processing train dataset:  26%|██▌       | 2577/10000 [00:32<01:50, 67.45it/s]Processing train dataset:  21%|██▏       | 2126/10000 [00:29<01:46, 73.84it/s]Processing train dataset:  21%|██        | 2099/10000 [00:29<01:38, 80.11it/s]Processing train dataset:  21%|██        | 2101/10000 [00:29<01:38, 80.18it/s]Processing train dataset:  21%|██▏       | 2134/10000 [00:29<01:44, 75.39it/s]Processing train dataset:  26%|██▌       | 2584/10000 [00:32<01:51, 66.66it/s]Processing train dataset:  17%|█▋        | 1675/10000 [00:26<02:00, 69.34it/s]Processing train dataset:  21%|██        | 2108/10000 [00:29<01:39, 79.50it/s]Processing train dataset:  21%|██▏       | 2142/10000 [00:29<01:42, 76.43it/s]Processing train dataset:  21%|██        | 2110/10000 [00:29<01:36, 81.55it/s]Processing train dataset:  17%|█▋        | 1682/10000 [00:27<02:03, 67.54it/s]Processing train dataset:  21%|██        | 2116/10000 [00:29<01:42, 77.09it/s]Processing train dataset:  26%|██▌       | 2592/10000 [00:33<01:52, 65.77it/s]Processing train dataset:  22%|██▏       | 2150/10000 [00:29<01:41, 77.38it/s]Processing train dataset:  21%|██        | 2119/10000 [00:29<01:39, 79.57it/s]Processing train dataset:  21%|██        | 2124/10000 [00:29<01:43, 75.80it/s]Processing train dataset:  26%|██▌       | 2599/10000 [00:33<01:54, 64.74it/s]Processing train dataset:  17%|█▋        | 1691/10000 [00:27<01:58, 70.30it/s]Processing train dataset:  22%|██▏       | 2158/10000 [00:29<01:43, 75.73it/s]Processing train dataset:  21%|██▏       | 2132/10000 [00:29<01:42, 76.52it/s]Processing train dataset:  26%|██▌       | 2607/10000 [00:33<01:49, 67.39it/s]Processing train dataset:  17%|█▋        | 1699/10000 [00:27<02:00, 69.01it/s]Processing train dataset:  21%|██▏       | 2127/10000 [00:29<01:53, 69.58it/s]Processing train dataset:  22%|██▏       | 2166/10000 [00:29<01:46, 73.44it/s]Processing train dataset:  21%|██▏       | 2140/10000 [00:29<01:44, 75.12it/s]Processing train dataset:  26%|██▌       | 2614/10000 [00:33<01:59, 62.01it/s]Processing train dataset:  21%|██▏       | 2135/10000 [00:29<01:53, 69.57it/s]Processing train dataset:  17%|█▋        | 1706/10000 [00:27<02:09, 63.95it/s]Processing train dataset:  22%|██▏       | 2175/10000 [00:29<01:41, 77.06it/s]Processing train dataset:  21%|██▏       | 2148/10000 [00:29<01:45, 74.62it/s]Processing train dataset:  21%|██▏       | 2143/10000 [00:30<01:49, 71.93it/s]Processing train dataset:  17%|█▋        | 1714/10000 [00:27<02:02, 67.69it/s]Processing train dataset:  26%|██▌       | 2622/10000 [00:33<01:54, 64.28it/s]Processing train dataset:  22%|██▏       | 2183/10000 [00:30<01:44, 74.79it/s]Processing train dataset:  22%|██▏       | 2156/10000 [00:29<01:47, 72.95it/s]Processing train dataset:  22%|██▏       | 2151/10000 [00:30<01:47, 73.27it/s]Processing train dataset:  26%|██▋       | 2630/10000 [00:33<01:47, 68.31it/s]Processing train dataset:  17%|█▋        | 1724/10000 [00:27<01:55, 71.68it/s]Processing train dataset:  22%|██▏       | 2191/10000 [00:30<01:46, 73.33it/s]Processing train dataset:  22%|██▏       | 2164/10000 [00:29<01:51, 70.32it/s]Processing train dataset:  26%|██▋       | 2637/10000 [00:33<01:48, 67.57it/s]Processing train dataset:  17%|█▋        | 1732/10000 [00:27<01:56, 70.95it/s]Processing train dataset:  22%|██▏       | 2159/10000 [00:30<02:00, 65.25it/s]Processing train dataset:  22%|██▏       | 2200/10000 [00:30<01:43, 75.33it/s]Processing train dataset:  22%|██▏       | 2174/10000 [00:30<01:43, 75.67it/s]Processing train dataset:  26%|██▋       | 2645/10000 [00:33<01:46, 68.87it/s]Processing train dataset:  17%|█▋        | 1740/10000 [00:27<01:55, 71.28it/s]Processing train dataset:  22%|██▏       | 2166/10000 [00:30<02:02, 63.72it/s]Processing train dataset:  22%|██▏       | 2208/10000 [00:30<01:44, 74.30it/s]Processing train dataset:  22%|██▏       | 2182/10000 [00:30<01:52, 69.33it/s]Processing train dataset:  22%|██▏       | 2175/10000 [00:30<01:52, 69.43it/s]Processing train dataset:  22%|██▏       | 2216/10000 [00:30<01:45, 73.90it/s]Processing train dataset:  27%|██▋       | 2652/10000 [00:34<02:28, 49.42it/s]Processing train dataset:  22%|██▏       | 2183/10000 [00:30<01:53, 68.80it/s]Processing train dataset:  22%|██▏       | 2225/10000 [00:30<01:41, 76.57it/s]Processing train dataset:  22%|██▏       | 2190/10000 [00:30<02:03, 63.00it/s]Processing train dataset:  17%|█▋        | 1748/10000 [00:28<02:55, 47.03it/s]Processing train dataset:  27%|██▋       | 2658/10000 [00:34<02:27, 49.91it/s]Processing train dataset:  22%|██▏       | 2190/10000 [00:30<01:53, 68.54it/s]Processing train dataset:  22%|██▏       | 2233/10000 [00:30<01:41, 76.78it/s]Processing train dataset:  22%|██▏       | 2198/10000 [00:30<01:58, 65.84it/s]Processing train dataset:  18%|█▊        | 1756/10000 [00:28<02:36, 52.77it/s]Processing train dataset:  27%|██▋       | 2665/10000 [00:34<02:18, 52.85it/s]Processing train dataset:  22%|██▏       | 2198/10000 [00:30<01:49, 71.39it/s]Processing train dataset:  22%|██▏       | 2241/10000 [00:30<01:40, 77.22it/s]Processing train dataset:  22%|██▏       | 2206/10000 [00:30<01:55, 67.65it/s]Processing train dataset:  18%|█▊        | 1765/10000 [00:28<02:19, 59.22it/s]Processing train dataset:  22%|██▏       | 2249/10000 [00:30<01:47, 71.97it/s]Processing train dataset:  27%|██▋       | 2672/10000 [00:34<02:23, 51.14it/s]Processing train dataset:  22%|██▏       | 2206/10000 [00:30<01:58, 65.86it/s]Processing train dataset:  22%|██▏       | 2213/10000 [00:30<02:03, 63.13it/s]Processing train dataset:  18%|█▊        | 1772/10000 [00:28<02:28, 55.27it/s]Processing train dataset:  27%|██▋       | 2681/10000 [00:34<02:01, 60.13it/s]Processing train dataset:  23%|██▎       | 2257/10000 [00:31<01:46, 72.88it/s]Processing train dataset:  22%|██▏       | 2213/10000 [00:31<01:58, 65.75it/s]Processing train dataset:  22%|██▏       | 2222/10000 [00:30<02:08, 60.59it/s]Processing train dataset:  23%|██▎       | 2265/10000 [00:31<01:47, 72.22it/s]Processing train dataset:  18%|█▊        | 1779/10000 [00:28<02:35, 52.79it/s]Processing train dataset:  22%|██▏       | 2220/10000 [00:31<02:06, 61.66it/s]Processing train dataset:  27%|██▋       | 2688/10000 [00:34<02:07, 57.16it/s]Processing train dataset:  22%|██▏       | 2230/10000 [00:30<02:02, 63.63it/s]Processing train dataset:  23%|██▎       | 2274/10000 [00:31<01:46, 72.61it/s]Processing train dataset:  22%|██▏       | 2227/10000 [00:31<02:13, 58.04it/s]Processing train dataset:  27%|██▋       | 2695/10000 [00:34<02:15, 53.94it/s]Processing train dataset:  18%|█▊        | 1785/10000 [00:28<02:48, 48.85it/s]Processing train dataset:  22%|██▏       | 2237/10000 [00:31<02:10, 59.71it/s]Processing train dataset:  23%|██▎       | 2282/10000 [00:31<01:46, 72.14it/s]Processing train dataset:  22%|██▏       | 2234/10000 [00:31<02:07, 61.01it/s]Processing train dataset:  18%|█▊        | 1794/10000 [00:29<02:34, 52.99it/s]Processing train dataset:  27%|██▋       | 2705/10000 [00:34<02:04, 58.38it/s]Processing train dataset:  22%|██▏       | 2244/10000 [00:31<02:11, 58.94it/s]Processing train dataset:  23%|██▎       | 2290/10000 [00:31<01:47, 71.84it/s]Processing train dataset:  22%|██▏       | 2241/10000 [00:31<02:09, 60.11it/s]Processing train dataset:  18%|█▊        | 1801/10000 [00:29<02:24, 56.69it/s]Processing train dataset:  27%|██▋       | 2713/10000 [00:35<01:58, 61.32it/s]Processing train dataset:  23%|██▎       | 2253/10000 [00:31<01:59, 64.69it/s]Processing train dataset:  23%|██▎       | 2298/10000 [00:31<01:45, 72.78it/s]Processing train dataset:  22%|██▏       | 2248/10000 [00:31<02:15, 57.02it/s]Processing train dataset:  18%|█▊        | 1807/10000 [00:29<02:29, 54.87it/s]Processing train dataset:  23%|██▎       | 2262/10000 [00:31<01:51, 69.21it/s]Processing train dataset:  27%|██▋       | 2720/10000 [00:35<02:01, 60.07it/s]Processing train dataset:  23%|██▎       | 2307/10000 [00:31<01:41, 75.95it/s]Processing train dataset:  23%|██▎       | 2256/10000 [00:31<02:05, 61.54it/s]Processing train dataset:  18%|█▊        | 1815/10000 [00:29<02:15, 60.31it/s]Processing train dataset:  27%|██▋       | 2727/10000 [00:35<01:57, 61.81it/s]Processing train dataset:  23%|██▎       | 2272/10000 [00:31<01:42, 75.55it/s]Processing train dataset:  23%|██▎       | 2315/10000 [00:31<01:41, 75.56it/s]Processing train dataset:  23%|██▎       | 2263/10000 [00:31<02:04, 62.34it/s]Processing train dataset:  23%|██▎       | 2323/10000 [00:31<01:51, 68.71it/s]Processing train dataset:  23%|██▎       | 2270/10000 [00:32<02:00, 64.28it/s]Processing train dataset:  18%|█▊        | 1822/10000 [00:29<02:43, 49.95it/s]Processing train dataset:  23%|██▎       | 2280/10000 [00:31<02:02, 62.88it/s]Processing train dataset:  27%|██▋       | 2734/10000 [00:35<02:19, 52.11it/s]Processing train dataset:  23%|██▎       | 2330/10000 [00:32<01:54, 66.77it/s]Processing train dataset:  23%|██▎       | 2277/10000 [00:32<02:00, 64.10it/s]Processing train dataset:  27%|██▋       | 2740/10000 [00:35<02:21, 51.36it/s]Processing train dataset:  23%|██▎       | 2287/10000 [00:31<02:09, 59.53it/s]Processing train dataset:  18%|█▊        | 1828/10000 [00:29<02:52, 47.40it/s]Processing train dataset:  23%|██▎       | 2338/10000 [00:32<01:50, 69.24it/s]Processing train dataset:  23%|██▎       | 2285/10000 [00:32<02:07, 60.49it/s]Processing train dataset:  23%|██▎       | 2345/10000 [00:32<01:53, 67.46it/s]Processing train dataset:  23%|██▎       | 2294/10000 [00:32<02:22, 54.12it/s]Processing train dataset:  27%|██▋       | 2746/10000 [00:35<02:55, 41.24it/s]Processing train dataset:  18%|█▊        | 1834/10000 [00:29<03:24, 39.97it/s]Processing train dataset:  23%|██▎       | 2292/10000 [00:32<02:08, 59.90it/s]Processing train dataset:  24%|██▎       | 2353/10000 [00:32<01:50, 69.48it/s]Processing train dataset:  23%|██▎       | 2302/10000 [00:32<02:10, 58.79it/s]Processing train dataset:  28%|██▊       | 2755/10000 [00:35<02:21, 51.17it/s]Processing train dataset:  18%|█▊        | 1842/10000 [00:30<02:51, 47.56it/s]Processing train dataset:  23%|██▎       | 2301/10000 [00:32<01:56, 65.96it/s]Processing train dataset:  23%|██▎       | 2310/10000 [00:32<02:00, 63.65it/s]Processing train dataset:  24%|██▎       | 2361/10000 [00:32<01:47, 70.94it/s]Processing train dataset:  28%|██▊       | 2765/10000 [00:36<01:57, 61.48it/s]Processing train dataset:  19%|█▊        | 1851/10000 [00:30<02:24, 56.59it/s]Processing train dataset:  23%|██▎       | 2310/10000 [00:32<01:48, 70.59it/s]Processing train dataset:  23%|██▎       | 2318/10000 [00:32<01:55, 66.52it/s]Processing train dataset:  24%|██▎       | 2370/10000 [00:32<01:43, 73.98it/s]Processing train dataset:  28%|██▊       | 2775/10000 [00:36<01:43, 69.96it/s]Processing train dataset:  19%|█▊        | 1859/10000 [00:30<02:10, 62.16it/s]Processing train dataset:  23%|██▎       | 2318/10000 [00:32<01:46, 72.19it/s]Processing train dataset:  23%|██▎       | 2326/10000 [00:32<01:51, 68.57it/s]Processing train dataset:  24%|██▍       | 2378/10000 [00:32<01:42, 74.46it/s]Processing train dataset:  28%|██▊       | 2786/10000 [00:36<01:30, 79.28it/s]Processing train dataset:  19%|█▊        | 1869/10000 [00:30<01:55, 70.61it/s]Processing train dataset:  23%|██▎       | 2326/10000 [00:32<01:45, 72.85it/s]Processing train dataset:  23%|██▎       | 2334/10000 [00:32<01:48, 70.62it/s]Processing train dataset:  24%|██▍       | 2386/10000 [00:32<01:42, 74.28it/s]Processing train dataset:  23%|██▎       | 2334/10000 [00:32<01:48, 70.70it/s]Processing train dataset:  24%|██▍       | 2394/10000 [00:32<01:41, 74.69it/s]Processing train dataset:  19%|█▉        | 1877/10000 [00:30<02:15, 60.14it/s]Processing train dataset:  23%|██▎       | 2342/10000 [00:32<01:53, 67.72it/s]Processing train dataset:  28%|██▊       | 2795/10000 [00:36<01:59, 60.29it/s]Processing train dataset:  23%|██▎       | 2342/10000 [00:33<01:51, 68.40it/s]Processing train dataset:  24%|██▍       | 2403/10000 [00:33<01:39, 76.44it/s]Processing train dataset:  23%|██▎       | 2349/10000 [00:32<01:55, 66.26it/s]Processing train dataset:  19%|█▉        | 1884/10000 [00:30<02:36, 52.02it/s]Processing train dataset:  23%|██▎       | 2349/10000 [00:33<01:51, 68.51it/s]Processing train dataset:  24%|██▍       | 2412/10000 [00:33<01:37, 77.65it/s]Processing train dataset:  24%|██▎       | 2356/10000 [00:32<01:54, 66.79it/s]Processing train dataset:  28%|██▊       | 2803/10000 [00:36<02:11, 54.65it/s]Processing train dataset:  19%|█▉        | 1892/10000 [00:30<02:22, 56.90it/s]Processing train dataset:  24%|██▎       | 2357/10000 [00:33<01:49, 70.03it/s]Processing train dataset:  24%|██▍       | 2421/10000 [00:33<01:33, 81.10it/s]Processing train dataset:  24%|██▎       | 2364/10000 [00:32<01:50, 69.32it/s]Processing train dataset:  28%|██▊       | 2813/10000 [00:36<01:55, 61.99it/s]Processing train dataset:  19%|█▉        | 1899/10000 [00:30<02:17, 59.07it/s]Processing train dataset:  24%|██▎       | 2365/10000 [00:33<01:46, 71.47it/s]Processing train dataset:  24%|██▍       | 2430/10000 [00:33<01:36, 78.50it/s]Processing train dataset:  24%|██▎       | 2373/10000 [00:33<01:44, 73.28it/s]Processing train dataset:  28%|██▊       | 2822/10000 [00:36<01:47, 66.53it/s]Processing train dataset:  19%|█▉        | 1906/10000 [00:31<02:11, 61.61it/s]Processing train dataset:  24%|██▎       | 2373/10000 [00:33<01:57, 65.08it/s]Processing train dataset:  24%|██▍       | 2438/10000 [00:33<01:43, 73.16it/s]Processing train dataset:  24%|██▍       | 2381/10000 [00:33<01:53, 67.13it/s]Processing train dataset:  28%|██▊       | 2830/10000 [00:37<01:57, 61.22it/s]Processing train dataset:  19%|█▉        | 1913/10000 [00:31<02:20, 57.37it/s]Processing train dataset:  24%|██▍       | 2380/10000 [00:33<01:55, 65.96it/s]Processing train dataset:  24%|██▍       | 2446/10000 [00:33<01:40, 74.94it/s]Processing train dataset:  24%|██▍       | 2390/10000 [00:33<01:46, 71.32it/s]Processing train dataset:  28%|██▊       | 2838/10000 [00:37<02:01, 59.15it/s]Processing train dataset:  24%|██▍       | 2388/10000 [00:33<01:53, 66.98it/s]Processing train dataset:  19%|█▉        | 1920/10000 [00:31<02:26, 55.09it/s]Processing train dataset:  25%|██▍       | 2454/10000 [00:33<01:45, 71.34it/s]Processing train dataset:  24%|██▍       | 2398/10000 [00:33<01:48, 70.17it/s]Processing train dataset:  28%|██▊       | 2847/10000 [00:37<01:51, 64.24it/s]Processing train dataset:  19%|█▉        | 1927/10000 [00:31<02:18, 58.15it/s]Processing train dataset:  24%|██▍       | 2397/10000 [00:33<01:47, 70.97it/s]Processing train dataset:  24%|██▍       | 2406/10000 [00:33<01:44, 72.64it/s]Processing train dataset:  25%|██▍       | 2462/10000 [00:33<01:49, 69.10it/s]Processing train dataset:  24%|██▍       | 2405/10000 [00:33<01:51, 68.39it/s]Processing train dataset:  29%|██▊       | 2854/10000 [00:37<01:59, 60.04it/s]Processing train dataset:  24%|██▍       | 2414/10000 [00:33<01:47, 70.24it/s]Processing train dataset:  19%|█▉        | 1934/10000 [00:31<02:26, 54.95it/s]Processing train dataset:  25%|██▍       | 2469/10000 [00:34<02:00, 62.42it/s]Processing train dataset:  24%|██▍       | 2413/10000 [00:34<01:47, 70.87it/s]Processing train dataset:  24%|██▍       | 2422/10000 [00:33<01:44, 72.19it/s]Processing train dataset:  29%|██▊       | 2861/10000 [00:37<01:59, 59.98it/s]Processing train dataset:  19%|█▉        | 1940/10000 [00:31<02:36, 51.64it/s]Processing train dataset:  25%|██▍       | 2476/10000 [00:34<02:02, 61.58it/s]Processing train dataset:  24%|██▍       | 2423/10000 [00:34<01:39, 76.49it/s]Processing train dataset:  29%|██▊       | 2868/10000 [00:37<01:54, 62.34it/s]Processing train dataset:  24%|██▍       | 2430/10000 [00:33<01:43, 72.88it/s]Processing train dataset:  19%|█▉        | 1949/10000 [00:31<02:13, 60.13it/s]Processing train dataset:  25%|██▍       | 2485/10000 [00:34<01:52, 66.94it/s]Processing train dataset:  24%|██▍       | 2431/10000 [00:34<01:42, 73.79it/s]Processing train dataset:  29%|██▉       | 2875/10000 [00:37<02:00, 59.36it/s]Processing train dataset:  24%|██▍       | 2438/10000 [00:34<01:50, 68.22it/s]Processing train dataset:  25%|██▍       | 2492/10000 [00:34<01:55, 64.79it/s]Processing train dataset:  20%|█▉        | 1956/10000 [00:31<02:24, 55.49it/s]Processing train dataset:  24%|██▍       | 2439/10000 [00:34<01:46, 71.33it/s]Processing train dataset:  29%|██▉       | 2882/10000 [00:37<01:55, 61.38it/s]Processing train dataset:  24%|██▍       | 2447/10000 [00:34<01:43, 73.11it/s]Processing train dataset:  25%|██▍       | 2499/10000 [00:34<01:54, 65.23it/s]Processing train dataset:  20%|█▉        | 1962/10000 [00:32<02:41, 49.76it/s]Processing train dataset:  24%|██▍       | 2447/10000 [00:34<01:46, 70.92it/s]Processing train dataset:  25%|██▌       | 2508/10000 [00:34<01:48, 69.23it/s]Processing train dataset:  25%|██▍       | 2455/10000 [00:34<01:56, 64.74it/s]Processing train dataset:  29%|██▉       | 2889/10000 [00:38<02:12, 53.70it/s]Processing train dataset:  25%|██▍       | 2455/10000 [00:34<01:43, 72.90it/s]Processing train dataset:  25%|██▌       | 2515/10000 [00:34<01:51, 66.86it/s]Processing train dataset:  20%|█▉        | 1970/10000 [00:32<02:40, 50.16it/s]Processing train dataset:  25%|██▍       | 2462/10000 [00:34<01:56, 64.78it/s]Processing train dataset:  29%|██▉       | 2895/10000 [00:38<02:19, 50.87it/s]Processing train dataset:  25%|██▍       | 2463/10000 [00:34<01:42, 73.23it/s]Processing train dataset:  25%|██▌       | 2523/10000 [00:34<01:46, 70.04it/s]Processing train dataset:  20%|█▉        | 1978/10000 [00:32<02:22, 56.13it/s]Processing train dataset:  25%|██▍       | 2471/10000 [00:34<01:48, 69.46it/s]Processing train dataset:  25%|██▍       | 2471/10000 [00:34<01:49, 68.60it/s]Processing train dataset:  29%|██▉       | 2904/10000 [00:38<02:13, 53.01it/s]Processing train dataset:  25%|██▌       | 2531/10000 [00:34<01:44, 71.26it/s]Processing train dataset:  25%|██▍       | 2479/10000 [00:34<01:49, 68.72it/s]Processing train dataset:  25%|██▍       | 2480/10000 [00:35<01:41, 73.74it/s]Processing train dataset:  25%|██▌       | 2540/10000 [00:35<01:39, 74.66it/s]Processing train dataset:  25%|██▍       | 2488/10000 [00:35<01:39, 75.41it/s]Processing train dataset:  25%|██▍       | 2486/10000 [00:34<02:10, 57.46it/s]Processing train dataset:  25%|██▌       | 2548/10000 [00:35<01:39, 74.82it/s]Processing train dataset:  29%|██▉       | 2910/10000 [00:38<02:55, 40.32it/s]Processing train dataset:  25%|██▍       | 2496/10000 [00:35<01:38, 76.53it/s]Processing train dataset:  20%|█▉        | 1984/10000 [00:32<04:05, 32.66it/s]Processing train dataset:  26%|██▌       | 2558/10000 [00:35<01:33, 79.56it/s]Processing train dataset:  25%|██▍       | 2493/10000 [00:34<02:10, 57.54it/s]Processing train dataset:  29%|██▉       | 2915/10000 [00:38<02:57, 39.85it/s]Processing train dataset:  25%|██▌       | 2504/10000 [00:35<01:37, 76.85it/s]Processing train dataset:  20%|█▉        | 1991/10000 [00:32<03:26, 38.71it/s]Processing train dataset:  25%|██▍       | 2499/10000 [00:35<02:11, 56.98it/s]Processing train dataset:  26%|██▌       | 2567/10000 [00:35<01:32, 80.09it/s]Processing train dataset:  29%|██▉       | 2922/10000 [00:38<02:40, 44.19it/s]Processing train dataset:  25%|██▌       | 2513/10000 [00:35<01:36, 77.87it/s]Processing train dataset:  20%|█▉        | 1997/10000 [00:32<03:16, 40.67it/s]Processing train dataset:  25%|██▌       | 2506/10000 [00:35<02:04, 60.15it/s]Processing train dataset:  26%|██▌       | 2576/10000 [00:35<01:32, 80.69it/s]Processing train dataset:  29%|██▉       | 2930/10000 [00:39<02:17, 51.55it/s]Processing train dataset:  25%|██▌       | 2521/10000 [00:35<01:39, 75.11it/s]Processing train dataset:  25%|██▌       | 2513/10000 [00:35<02:02, 61.35it/s]Processing train dataset:  20%|██        | 2003/10000 [00:33<03:09, 42.12it/s]Processing train dataset:  26%|██▌       | 2585/10000 [00:35<01:34, 78.38it/s]Processing train dataset:  29%|██▉       | 2938/10000 [00:39<02:06, 55.99it/s]Processing train dataset:  25%|██▌       | 2531/10000 [00:35<01:34, 78.82it/s]Processing train dataset:  26%|██▌       | 2594/10000 [00:35<01:32, 80.46it/s]Processing train dataset:  25%|██▌       | 2522/10000 [00:35<01:57, 63.49it/s]Processing train dataset:  20%|██        | 2009/10000 [00:33<03:00, 44.32it/s]Processing train dataset:  29%|██▉       | 2946/10000 [00:39<01:55, 61.09it/s]Processing train dataset:  25%|██▌       | 2539/10000 [00:35<01:40, 74.57it/s]Processing train dataset:  26%|██▌       | 2603/10000 [00:35<01:29, 82.44it/s]Processing train dataset:  25%|██▌       | 2531/10000 [00:35<01:49, 68.46it/s]Processing train dataset:  20%|██        | 2016/10000 [00:33<02:42, 49.09it/s]Processing train dataset:  30%|██▉       | 2954/10000 [00:39<01:48, 64.69it/s]Processing train dataset:  25%|██▌       | 2547/10000 [00:35<01:42, 72.93it/s]Processing train dataset:  26%|██▌       | 2612/10000 [00:35<01:31, 80.73it/s]Processing train dataset:  25%|██▌       | 2538/10000 [00:35<01:51, 67.03it/s]Processing train dataset:  20%|██        | 2023/10000 [00:33<02:31, 52.64it/s]Processing train dataset:  30%|██▉       | 2962/10000 [00:39<01:44, 67.42it/s]Processing train dataset:  26%|██▌       | 2557/10000 [00:36<01:35, 77.55it/s]Processing train dataset:  26%|██▌       | 2622/10000 [00:36<01:28, 83.00it/s]Processing train dataset:  20%|██        | 2030/10000 [00:33<02:23, 55.60it/s]Processing train dataset:  25%|██▌       | 2545/10000 [00:35<01:55, 64.33it/s]Processing train dataset:  30%|██▉       | 2970/10000 [00:39<01:40, 69.67it/s]Processing train dataset:  26%|██▌       | 2566/10000 [00:36<01:34, 78.29it/s]Processing train dataset:  20%|██        | 2038/10000 [00:33<02:11, 60.37it/s]Processing train dataset:  26%|██▋       | 2631/10000 [00:36<01:31, 80.25it/s]Processing train dataset:  26%|██▌       | 2554/10000 [00:35<01:47, 69.52it/s]Processing train dataset:  30%|██▉       | 2978/10000 [00:39<01:46, 65.78it/s]Processing train dataset:  26%|██▌       | 2574/10000 [00:36<01:37, 75.98it/s]Processing train dataset:  20%|██        | 2045/10000 [00:33<02:13, 59.44it/s]Processing train dataset:  26%|██▋       | 2640/10000 [00:36<01:37, 75.72it/s]Processing train dataset:  26%|██▌       | 2562/10000 [00:35<01:58, 62.81it/s]Processing train dataset:  30%|██▉       | 2985/10000 [00:39<01:47, 65.21it/s]Processing train dataset:  26%|██▌       | 2582/10000 [00:36<01:37, 76.35it/s]Processing train dataset:  26%|██▋       | 2649/10000 [00:36<01:35, 76.93it/s]Processing train dataset:  21%|██        | 2053/10000 [00:33<02:12, 59.97it/s]Processing train dataset:  26%|██▌       | 2569/10000 [00:36<02:02, 60.55it/s]Processing train dataset:  26%|██▌       | 2590/10000 [00:36<01:36, 76.60it/s]Processing train dataset:  30%|██▉       | 2992/10000 [00:39<01:59, 58.76it/s]Processing train dataset:  21%|██        | 2060/10000 [00:34<02:11, 60.38it/s]Processing train dataset:  26%|██▌       | 2576/10000 [00:36<01:59, 62.22it/s]Processing train dataset:  27%|██▋       | 2657/10000 [00:36<01:46, 69.21it/s]Processing train dataset:  26%|██▌       | 2598/10000 [00:36<01:37, 76.28it/s]Processing train dataset:  30%|██▉       | 2999/10000 [00:40<02:04, 56.03it/s]Processing train dataset:  21%|██        | 2067/10000 [00:34<02:17, 57.62it/s]Processing train dataset:  27%|██▋       | 2665/10000 [00:36<01:44, 70.15it/s]Processing train dataset:  26%|██▌       | 2608/10000 [00:36<01:32, 80.14it/s]Processing train dataset:  26%|██▌       | 2583/10000 [00:36<02:03, 60.13it/s]Processing train dataset:  30%|███       | 3005/10000 [00:40<02:14, 52.20it/s]Processing train dataset:  21%|██        | 2073/10000 [00:34<02:18, 57.09it/s]Processing train dataset:  26%|██▌       | 2592/10000 [00:36<01:49, 67.48it/s]Processing train dataset:  26%|██▌       | 2618/10000 [00:36<01:29, 82.79it/s]Processing train dataset:  27%|██▋       | 2673/10000 [00:36<01:49, 66.66it/s]Processing train dataset:  30%|███       | 3011/10000 [00:40<02:13, 52.33it/s]Processing train dataset:  21%|██        | 2079/10000 [00:34<02:22, 55.51it/s]Processing train dataset:  26%|██▋       | 2627/10000 [00:36<01:30, 81.67it/s]Processing train dataset:  26%|██▌       | 2599/10000 [00:36<01:54, 64.77it/s]Processing train dataset:  27%|██▋       | 2682/10000 [00:36<01:41, 71.81it/s]Processing train dataset:  30%|███       | 3017/10000 [00:40<02:14, 52.05it/s]Processing train dataset:  26%|██▌       | 2606/10000 [00:36<01:52, 65.55it/s]Processing train dataset:  21%|██        | 2085/10000 [00:34<02:27, 53.84it/s]Processing train dataset:  27%|██▋       | 2690/10000 [00:36<01:38, 73.92it/s]Processing train dataset:  26%|██▋       | 2636/10000 [00:37<01:38, 74.97it/s]Processing train dataset:  30%|███       | 3024/10000 [00:40<02:07, 54.77it/s]Processing train dataset:  26%|██▌       | 2615/10000 [00:36<01:42, 72.16it/s]Processing train dataset:  21%|██        | 2091/10000 [00:34<02:23, 55.25it/s]Processing train dataset:  27%|██▋       | 2699/10000 [00:37<01:36, 75.53it/s]Processing train dataset:  26%|██▋       | 2644/10000 [00:37<01:37, 75.80it/s]Processing train dataset:  26%|██▌       | 2624/10000 [00:36<01:38, 74.94it/s]Processing train dataset:  30%|███       | 3030/10000 [00:40<02:10, 53.41it/s]Processing train dataset:  21%|██        | 2097/10000 [00:34<02:27, 53.53it/s]Processing train dataset:  27%|██▋       | 2708/10000 [00:37<01:34, 77.47it/s]Processing train dataset:  27%|██▋       | 2652/10000 [00:37<01:37, 75.13it/s]Processing train dataset:  26%|██▋       | 2632/10000 [00:37<01:38, 74.69it/s]Processing train dataset:  27%|██▋       | 2716/10000 [00:37<01:35, 76.41it/s]Processing train dataset:  30%|███       | 3036/10000 [00:40<02:16, 50.84it/s]Processing train dataset:  21%|██        | 2103/10000 [00:34<02:31, 52.15it/s]Processing train dataset:  27%|██▋       | 2660/10000 [00:37<01:39, 74.04it/s]Processing train dataset:  26%|██▋       | 2642/10000 [00:37<01:33, 78.47it/s]Processing train dataset:  27%|██▋       | 2724/10000 [00:37<01:34, 77.18it/s]Processing train dataset:  30%|███       | 3043/10000 [00:40<02:06, 54.83it/s]Processing train dataset:  21%|██        | 2111/10000 [00:34<02:14, 58.67it/s]Processing train dataset:  27%|██▋       | 2668/10000 [00:37<01:40, 73.24it/s]Processing train dataset:  26%|██▋       | 2650/10000 [00:37<01:35, 76.93it/s]Processing train dataset:  27%|██▋       | 2732/10000 [00:37<01:36, 75.22it/s]Processing train dataset:  21%|██        | 2117/10000 [00:35<02:18, 56.83it/s]Processing train dataset:  31%|███       | 3051/10000 [00:41<01:58, 58.44it/s]Processing train dataset:  27%|██▋       | 2677/10000 [00:37<01:37, 74.82it/s]Processing train dataset:  27%|██▋       | 2740/10000 [00:37<01:38, 73.92it/s]Processing train dataset:  31%|███       | 3059/10000 [00:41<01:48, 63.88it/s]Processing train dataset:  21%|██        | 2124/10000 [00:35<02:12, 59.22it/s]Processing train dataset:  27%|██▋       | 2658/10000 [00:37<01:44, 70.09it/s]Processing train dataset:  27%|██▋       | 2685/10000 [00:37<01:37, 75.26it/s]Processing train dataset:  27%|██▋       | 2748/10000 [00:37<01:38, 73.47it/s]Processing train dataset:  21%|██▏       | 2132/10000 [00:35<02:07, 61.86it/s]Processing train dataset:  27%|██▋       | 2693/10000 [00:37<01:35, 76.49it/s]Processing train dataset:  27%|██▋       | 2666/10000 [00:37<01:44, 70.28it/s]Processing train dataset:  31%|███       | 3067/10000 [00:41<01:49, 63.07it/s]Processing train dataset:  28%|██▊       | 2757/10000 [00:37<01:36, 75.31it/s]Processing train dataset:  27%|██▋       | 2702/10000 [00:37<01:31, 79.67it/s]Processing train dataset:  21%|██▏       | 2139/10000 [00:35<02:06, 62.01it/s]Processing train dataset:  27%|██▋       | 2674/10000 [00:37<01:43, 70.81it/s]Processing train dataset:  31%|███       | 3074/10000 [00:41<01:51, 62.05it/s]Processing train dataset:  28%|██▊       | 2767/10000 [00:37<01:31, 79.42it/s]Processing train dataset:  27%|██▋       | 2710/10000 [00:37<01:34, 76.95it/s]Processing train dataset:  27%|██▋       | 2682/10000 [00:37<01:44, 70.21it/s]Processing train dataset:  21%|██▏       | 2146/10000 [00:35<02:09, 60.45it/s]Processing train dataset:  31%|███       | 3081/10000 [00:41<01:57, 58.89it/s]Processing train dataset:  28%|██▊       | 2776/10000 [00:38<01:30, 79.43it/s]Processing train dataset:  27%|██▋       | 2718/10000 [00:38<01:35, 76.01it/s]Processing train dataset:  27%|██▋       | 2690/10000 [00:37<01:41, 71.73it/s]Processing train dataset:  22%|██▏       | 2153/10000 [00:35<02:11, 59.88it/s]Processing train dataset:  31%|███       | 3087/10000 [00:41<02:02, 56.33it/s]Processing train dataset:  28%|██▊       | 2785/10000 [00:38<01:27, 82.24it/s]Processing train dataset:  27%|██▋       | 2727/10000 [00:38<01:33, 77.57it/s]Processing train dataset:  27%|██▋       | 2698/10000 [00:37<01:38, 73.85it/s]Processing train dataset:  31%|███       | 3093/10000 [00:41<02:03, 56.11it/s]Processing train dataset:  22%|██▏       | 2160/10000 [00:35<02:17, 56.99it/s]Processing train dataset:  27%|██▋       | 2706/10000 [00:38<01:36, 75.24it/s]Processing train dataset:  27%|██▋       | 2735/10000 [00:38<01:35, 76.19it/s]Processing train dataset:  28%|██▊       | 2794/10000 [00:38<01:31, 78.71it/s]Processing train dataset:  22%|██▏       | 2166/10000 [00:35<02:21, 55.25it/s]Processing train dataset:  31%|███       | 3099/10000 [00:41<02:11, 52.61it/s]Processing train dataset:  27%|██▋       | 2714/10000 [00:38<01:37, 74.56it/s]Processing train dataset:  27%|██▋       | 2743/10000 [00:38<01:36, 74.86it/s]Processing train dataset:  28%|██▊       | 2802/10000 [00:38<01:34, 76.53it/s]Processing train dataset:  22%|██▏       | 2175/10000 [00:36<02:02, 63.79it/s]Processing train dataset:  31%|███       | 3105/10000 [00:41<02:07, 54.26it/s]Processing train dataset:  27%|██▋       | 2722/10000 [00:38<01:35, 76.04it/s]Processing train dataset:  28%|██▊       | 2810/10000 [00:38<01:32, 77.41it/s]Processing train dataset:  28%|██▊       | 2751/10000 [00:38<01:38, 73.27it/s]Processing train dataset:  22%|██▏       | 2182/10000 [00:36<02:05, 62.39it/s]Processing train dataset:  31%|███       | 3113/10000 [00:42<01:55, 59.64it/s]Processing train dataset:  27%|██▋       | 2730/10000 [00:38<01:37, 74.55it/s]Processing train dataset:  28%|██▊       | 2819/10000 [00:38<01:31, 78.54it/s]Processing train dataset:  28%|██▊       | 2759/10000 [00:38<01:46, 67.86it/s]Processing train dataset:  31%|███       | 3121/10000 [00:42<01:52, 61.25it/s]Processing train dataset:  27%|██▋       | 2738/10000 [00:38<01:38, 73.45it/s]Processing train dataset:  28%|██▊       | 2827/10000 [00:38<01:33, 76.93it/s]Processing train dataset:  28%|██▊       | 2768/10000 [00:38<01:38, 73.30it/s]Processing train dataset:  22%|██▏       | 2189/10000 [00:36<02:30, 52.02it/s]Processing train dataset:  31%|███▏      | 3128/10000 [00:42<01:49, 62.69it/s]Processing train dataset:  27%|██▋       | 2746/10000 [00:38<01:40, 72.30it/s]Processing train dataset:  28%|██▊       | 2836/10000 [00:38<01:32, 77.61it/s]Processing train dataset:  28%|██▊       | 2777/10000 [00:38<01:36, 75.20it/s]Processing train dataset:  22%|██▏       | 2195/10000 [00:36<02:30, 51.84it/s]Processing train dataset:  31%|███▏      | 3135/10000 [00:42<01:50, 62.38it/s]Processing train dataset:  28%|██▊       | 2844/10000 [00:38<01:31, 78.15it/s]Processing train dataset:  28%|██▊       | 2754/10000 [00:38<01:40, 71.76it/s]Processing train dataset:  28%|██▊       | 2786/10000 [00:39<01:31, 79.10it/s]Processing train dataset:  22%|██▏       | 2201/10000 [00:36<02:29, 52.04it/s]Processing train dataset:  31%|███▏      | 3142/10000 [00:42<01:47, 63.69it/s]Processing train dataset:  29%|██▊       | 2852/10000 [00:39<01:33, 76.06it/s]Processing train dataset:  28%|██▊       | 2764/10000 [00:38<01:34, 76.89it/s]Processing train dataset:  28%|██▊       | 2795/10000 [00:39<01:33, 76.99it/s]Processing train dataset:  22%|██▏       | 2207/10000 [00:36<02:36, 49.66it/s]Processing train dataset:  31%|███▏      | 3149/10000 [00:42<01:48, 63.38it/s]Processing train dataset:  29%|██▊       | 2861/10000 [00:39<01:30, 79.17it/s]Processing train dataset:  28%|██▊       | 2772/10000 [00:38<01:35, 76.02it/s]Processing train dataset:  28%|██▊       | 2803/10000 [00:39<01:35, 75.55it/s]Processing train dataset:  22%|██▏       | 2213/10000 [00:36<02:39, 48.88it/s]Processing train dataset:  29%|██▊       | 2869/10000 [00:39<01:32, 76.90it/s]Processing train dataset:  28%|██▊       | 2781/10000 [00:39<01:31, 79.16it/s]Processing train dataset:  32%|███▏      | 3156/10000 [00:42<01:55, 59.02it/s]Processing train dataset:  28%|██▊       | 2811/10000 [00:39<01:33, 76.74it/s]Processing train dataset:  22%|██▏       | 2219/10000 [00:36<02:31, 51.41it/s]Processing train dataset:  29%|██▉       | 2877/10000 [00:39<01:32, 77.26it/s]Processing train dataset:  28%|██▊       | 2790/10000 [00:39<01:29, 80.23it/s]Processing train dataset:  32%|███▏      | 3164/10000 [00:42<01:50, 61.73it/s]Processing train dataset:  28%|██▊       | 2820/10000 [00:39<01:32, 77.67it/s]Processing train dataset:  22%|██▏       | 2227/10000 [00:37<02:16, 57.03it/s]Processing train dataset:  29%|██▉       | 2885/10000 [00:39<01:34, 75.23it/s]Processing train dataset:  32%|███▏      | 3173/10000 [00:43<01:41, 67.11it/s]Processing train dataset:  28%|██▊       | 2799/10000 [00:39<01:33, 77.05it/s]Processing train dataset:  28%|██▊       | 2828/10000 [00:39<01:34, 76.12it/s]Processing train dataset:  22%|██▏       | 2234/10000 [00:37<02:10, 59.67it/s]Processing train dataset:  29%|██▉       | 2893/10000 [00:39<01:35, 74.05it/s]Processing train dataset:  32%|███▏      | 3181/10000 [00:43<01:38, 69.19it/s]Processing train dataset:  28%|██▊       | 2808/10000 [00:39<01:31, 78.62it/s]Processing train dataset:  28%|██▊       | 2837/10000 [00:39<01:31, 77.91it/s]Processing train dataset:  29%|██▉       | 2901/10000 [00:39<01:34, 75.48it/s]Processing train dataset:  32%|███▏      | 3190/10000 [00:43<01:33, 73.14it/s]Processing train dataset:  28%|██▊       | 2817/10000 [00:39<01:29, 79.86it/s]Processing train dataset:  22%|██▏       | 2241/10000 [00:37<02:22, 54.64it/s]Processing train dataset:  28%|██▊       | 2845/10000 [00:39<01:38, 72.45it/s]Processing train dataset:  29%|██▉       | 2909/10000 [00:39<01:38, 72.06it/s]Processing train dataset:  32%|███▏      | 3200/10000 [00:43<01:31, 74.42it/s]Processing train dataset:  22%|██▏       | 2247/10000 [00:37<02:27, 52.41it/s]Processing train dataset:  29%|██▊       | 2853/10000 [00:39<01:39, 72.15it/s]Processing train dataset:  28%|██▊       | 2826/10000 [00:39<01:43, 69.01it/s]Processing train dataset:  29%|██▉       | 2917/10000 [00:39<01:38, 71.95it/s]Processing train dataset:  32%|███▏      | 3208/10000 [00:43<01:34, 71.96it/s]Processing train dataset:  23%|██▎       | 2253/10000 [00:37<02:34, 50.07it/s]Processing train dataset:  29%|██▊       | 2861/10000 [00:40<01:40, 70.91it/s]Processing train dataset:  28%|██▊       | 2834/10000 [00:39<01:47, 66.47it/s]Processing train dataset:  29%|██▉       | 2925/10000 [00:40<01:39, 71.00it/s]Processing train dataset:  32%|███▏      | 3216/10000 [00:43<01:35, 71.31it/s]Processing train dataset:  29%|██▊       | 2869/10000 [00:40<01:40, 71.05it/s]Processing train dataset:  23%|██▎       | 2259/10000 [00:37<02:35, 49.68it/s]Processing train dataset:  28%|██▊       | 2843/10000 [00:39<01:41, 70.41it/s]Processing train dataset:  29%|██▉       | 2933/10000 [00:40<01:39, 71.30it/s]Processing train dataset:  32%|███▏      | 3224/10000 [00:43<01:38, 68.84it/s]Processing train dataset:  29%|██▉       | 2877/10000 [00:40<01:38, 72.59it/s]Processing train dataset:  23%|██▎       | 2268/10000 [00:37<02:17, 56.08it/s]Processing train dataset:  29%|██▉       | 2942/10000 [00:40<01:35, 73.95it/s]Processing train dataset:  29%|██▊       | 2851/10000 [00:40<01:52, 63.79it/s]Processing train dataset:  32%|███▏      | 3232/10000 [00:43<01:37, 69.44it/s]Processing train dataset:  29%|██▉       | 2885/10000 [00:40<01:45, 67.51it/s]Processing train dataset:  23%|██▎       | 2274/10000 [00:37<02:19, 55.33it/s]Processing train dataset:  30%|██▉       | 2951/10000 [00:40<01:32, 75.99it/s]Processing train dataset:  29%|██▊       | 2859/10000 [00:40<01:48, 65.57it/s]Processing train dataset:  32%|███▏      | 3241/10000 [00:43<01:30, 74.38it/s]Processing train dataset:  29%|██▉       | 2893/10000 [00:40<01:42, 69.59it/s]Processing train dataset:  30%|██▉       | 2959/10000 [00:40<01:34, 74.61it/s]Processing train dataset:  23%|██▎       | 2280/10000 [00:38<02:33, 50.34it/s]Processing train dataset:  29%|██▊       | 2867/10000 [00:40<01:46, 67.25it/s]Processing train dataset:  32%|███▎      | 3250/10000 [00:44<01:26, 78.29it/s]Processing train dataset:  29%|██▉       | 2902/10000 [00:40<01:37, 72.75it/s]Processing train dataset:  30%|██▉       | 2967/10000 [00:40<01:35, 73.62it/s]Processing train dataset:  23%|██▎       | 2286/10000 [00:38<02:31, 50.80it/s]Processing train dataset:  33%|███▎      | 3260/10000 [00:44<01:20, 83.88it/s]Processing train dataset:  29%|██▉       | 2876/10000 [00:40<01:40, 70.87it/s]Processing train dataset:  29%|██▉       | 2910/10000 [00:40<01:37, 72.48it/s]Processing train dataset:  30%|██▉       | 2975/10000 [00:40<01:35, 73.24it/s]Processing train dataset:  23%|██▎       | 2293/10000 [00:38<02:19, 55.30it/s]Processing train dataset:  33%|███▎      | 3269/10000 [00:44<01:23, 81.07it/s]Processing train dataset:  29%|██▉       | 2884/10000 [00:40<01:44, 67.79it/s]Processing train dataset:  29%|██▉       | 2918/10000 [00:40<01:37, 72.39it/s]Processing train dataset:  30%|██▉       | 2983/10000 [00:40<01:35, 73.16it/s]Processing train dataset:  23%|██▎       | 2299/10000 [00:38<02:19, 55.26it/s]Processing train dataset:  33%|███▎      | 3279/10000 [00:44<01:18, 85.95it/s]Processing train dataset:  29%|██▉       | 2892/10000 [00:40<01:43, 68.94it/s]Processing train dataset:  29%|██▉       | 2926/10000 [00:40<01:38, 71.99it/s]Processing train dataset:  30%|██▉       | 2991/10000 [00:40<01:33, 74.65it/s]Processing train dataset:  23%|██▎       | 2307/10000 [00:38<02:07, 60.14it/s]Processing train dataset:  33%|███▎      | 3291/10000 [00:44<01:12, 92.83it/s]Processing train dataset:  29%|██▉       | 2901/10000 [00:40<01:37, 72.94it/s]Processing train dataset:  29%|██▉       | 2934/10000 [00:41<01:38, 71.90it/s]Processing train dataset:  30%|██▉       | 2999/10000 [00:41<01:35, 73.22it/s]Processing train dataset:  23%|██▎       | 2314/10000 [00:38<02:04, 61.58it/s]Processing train dataset:  33%|███▎      | 3301/10000 [00:44<01:11, 93.94it/s]Processing train dataset:  29%|██▉       | 2909/10000 [00:40<01:36, 73.12it/s]Processing train dataset:  29%|██▉       | 2943/10000 [00:41<01:35, 74.21it/s]Processing train dataset:  30%|███       | 3007/10000 [00:41<01:37, 72.03it/s]Processing train dataset:  23%|██▎       | 2321/10000 [00:38<02:05, 61.39it/s]Processing train dataset:  33%|███▎      | 3312/10000 [00:44<01:08, 97.31it/s]Processing train dataset:  29%|██▉       | 2917/10000 [00:40<01:36, 73.42it/s]Processing train dataset:  30%|██▉       | 2951/10000 [00:41<01:34, 74.74it/s]Processing train dataset:  30%|███       | 3015/10000 [00:41<01:37, 71.77it/s]Processing train dataset:  33%|███▎      | 3322/10000 [00:44<01:10, 95.37it/s]Processing train dataset:  23%|██▎       | 2329/10000 [00:38<02:02, 62.66it/s]Processing train dataset:  29%|██▉       | 2925/10000 [00:41<01:43, 68.14it/s]Processing train dataset:  30%|██▉       | 2959/10000 [00:41<01:37, 72.05it/s]Processing train dataset:  30%|███       | 3024/10000 [00:41<01:34, 74.02it/s]Processing train dataset:  23%|██▎       | 2336/10000 [00:38<01:59, 64.38it/s]Processing train dataset:  33%|███▎      | 3332/10000 [00:44<01:11, 93.49it/s]Processing train dataset:  29%|██▉       | 2932/10000 [00:41<01:48, 65.22it/s]Processing train dataset:  30%|██▉       | 2967/10000 [00:41<01:37, 72.20it/s]Processing train dataset:  23%|██▎       | 2343/10000 [00:39<01:58, 64.79it/s]Processing train dataset:  30%|███       | 3032/10000 [00:41<01:35, 73.25it/s]Processing train dataset:  33%|███▎      | 3342/10000 [00:45<01:12, 91.58it/s]Processing train dataset:  29%|██▉       | 2940/10000 [00:41<01:42, 68.94it/s]Processing train dataset:  30%|██▉       | 2975/10000 [00:41<01:37, 72.26it/s]Processing train dataset:  30%|███       | 3040/10000 [00:41<01:35, 72.88it/s]Processing train dataset:  34%|███▎      | 3352/10000 [00:45<01:12, 91.99it/s]Processing train dataset:  24%|██▎       | 2350/10000 [00:39<02:07, 60.20it/s]Processing train dataset:  29%|██▉       | 2949/10000 [00:41<01:37, 72.32it/s]Processing train dataset:  30%|██▉       | 2983/10000 [00:41<01:37, 72.30it/s]Processing train dataset:  30%|███       | 3049/10000 [00:41<01:32, 75.25it/s]Processing train dataset:  34%|███▎      | 3362/10000 [00:45<01:12, 91.93it/s]Processing train dataset:  24%|██▎       | 2357/10000 [00:39<02:10, 58.38it/s]Processing train dataset:  30%|██▉       | 2957/10000 [00:41<01:36, 72.71it/s]Processing train dataset:  30%|██▉       | 2992/10000 [00:41<01:33, 74.79it/s]Processing train dataset:  31%|███       | 3058/10000 [00:41<01:30, 76.52it/s]Processing train dataset:  34%|███▎      | 3372/10000 [00:45<01:12, 91.25it/s]Processing train dataset:  24%|██▎       | 2364/10000 [00:39<02:12, 57.58it/s]Processing train dataset:  30%|███       | 3000/10000 [00:41<01:33, 74.54it/s]Processing train dataset:  30%|██▉       | 2965/10000 [00:41<01:42, 68.57it/s]Processing train dataset:  31%|███       | 3067/10000 [00:41<01:28, 77.91it/s]Processing train dataset:  34%|███▍      | 3382/10000 [00:45<01:13, 89.73it/s]Processing train dataset:  24%|██▎       | 2371/10000 [00:39<02:11, 58.00it/s]Processing train dataset:  30%|███       | 3008/10000 [00:42<01:34, 74.20it/s]Processing train dataset:  30%|██▉       | 2973/10000 [00:41<01:40, 70.08it/s]Processing train dataset:  31%|███       | 3075/10000 [00:42<01:30, 76.28it/s]Processing train dataset:  34%|███▍      | 3391/10000 [00:45<01:16, 86.21it/s]Processing train dataset:  24%|██▍       | 2377/10000 [00:39<02:11, 58.09it/s]Processing train dataset:  30%|███       | 3016/10000 [00:42<01:34, 73.58it/s]Processing train dataset:  30%|██▉       | 2981/10000 [00:41<01:39, 70.39it/s]Processing train dataset:  31%|███       | 3083/10000 [00:42<01:32, 75.04it/s]Processing train dataset:  34%|███▍      | 3400/10000 [00:45<01:17, 84.67it/s]Processing train dataset:  24%|██▍       | 2383/10000 [00:39<02:12, 57.34it/s]Processing train dataset:  30%|███       | 3024/10000 [00:42<01:32, 75.10it/s]Processing train dataset:  30%|██▉       | 2990/10000 [00:41<01:35, 73.11it/s]Processing train dataset:  31%|███       | 3092/10000 [00:42<01:30, 76.70it/s]Processing train dataset:  34%|███▍      | 3409/10000 [00:45<01:17, 84.90it/s]Processing train dataset:  24%|██▍       | 2390/10000 [00:39<02:07, 59.48it/s]Processing train dataset:  30%|██▉       | 2998/10000 [00:42<01:41, 69.00it/s]Processing train dataset:  30%|███       | 3032/10000 [00:42<01:44, 66.77it/s]Processing train dataset:  31%|███       | 3100/10000 [00:42<01:31, 75.42it/s]Processing train dataset:  34%|███▍      | 3418/10000 [00:45<01:20, 81.92it/s]Processing train dataset:  24%|██▍       | 2396/10000 [00:39<02:10, 58.36it/s]Processing train dataset:  31%|███       | 3108/10000 [00:42<01:34, 72.85it/s]Processing train dataset:  34%|███▍      | 3430/10000 [00:46<01:11, 91.81it/s]Processing train dataset:  30%|███       | 3005/10000 [00:42<01:49, 63.89it/s]Processing train dataset:  30%|███       | 3039/10000 [00:42<01:52, 62.07it/s]Processing train dataset:  24%|██▍       | 2402/10000 [00:40<02:14, 56.36it/s]Processing train dataset:  31%|███       | 3116/10000 [00:42<01:32, 74.76it/s]Processing train dataset:  34%|███▍      | 3440/10000 [00:46<01:10, 92.85it/s]Processing train dataset:  30%|███       | 3013/10000 [00:42<01:46, 65.70it/s]Processing train dataset:  30%|███       | 3048/10000 [00:42<01:44, 66.54it/s]Processing train dataset:  24%|██▍       | 2409/10000 [00:40<02:09, 58.70it/s]Processing train dataset:  31%|███       | 3124/10000 [00:42<01:30, 75.73it/s]Processing train dataset:  30%|███       | 3021/10000 [00:42<01:40, 69.44it/s]Processing train dataset:  34%|███▍      | 3450/10000 [00:46<01:12, 90.88it/s]Processing train dataset:  31%|███       | 3056/10000 [00:42<01:39, 69.88it/s]Processing train dataset:  24%|██▍       | 2417/10000 [00:40<02:02, 61.94it/s]Processing train dataset:  31%|███▏      | 3132/10000 [00:42<01:31, 75.32it/s]Processing train dataset:  31%|███       | 3064/10000 [00:42<01:35, 72.49it/s]Processing train dataset:  30%|███       | 3029/10000 [00:42<01:39, 70.30it/s]Processing train dataset:  35%|███▍      | 3460/10000 [00:46<01:13, 89.26it/s]Processing train dataset:  24%|██▍       | 2424/10000 [00:40<02:01, 62.11it/s]Processing train dataset:  31%|███▏      | 3140/10000 [00:42<01:32, 74.15it/s]Processing train dataset:  31%|███       | 3072/10000 [00:42<01:35, 72.20it/s]Processing train dataset:  35%|███▍      | 3469/10000 [00:46<01:17, 84.47it/s]Processing train dataset:  30%|███       | 3037/10000 [00:42<01:44, 66.77it/s]Processing train dataset:  24%|██▍       | 2431/10000 [00:40<02:03, 61.37it/s]Processing train dataset:  31%|███▏      | 3148/10000 [00:43<01:32, 73.68it/s]Processing train dataset:  31%|███       | 3080/10000 [00:43<01:37, 71.30it/s]Processing train dataset:  35%|███▍      | 3479/10000 [00:46<01:14, 87.59it/s]Processing train dataset:  30%|███       | 3045/10000 [00:42<01:42, 67.90it/s]Processing train dataset:  24%|██▍       | 2438/10000 [00:40<02:02, 61.78it/s]Processing train dataset:  32%|███▏      | 3156/10000 [00:43<01:33, 73.16it/s]Processing train dataset:  31%|███       | 3088/10000 [00:43<01:34, 72.84it/s]Processing train dataset:  35%|███▍      | 3489/10000 [00:46<01:13, 88.28it/s]Processing train dataset:  31%|███       | 3053/10000 [00:42<01:38, 70.85it/s]Processing train dataset:  24%|██▍       | 2445/10000 [00:40<01:59, 63.38it/s]Processing train dataset:  32%|███▏      | 3164/10000 [00:43<01:34, 72.44it/s]Processing train dataset:  31%|███       | 3096/10000 [00:43<01:36, 71.67it/s]Processing train dataset:  31%|███       | 3061/10000 [00:43<01:35, 72.48it/s]Processing train dataset:  25%|██▍       | 2452/10000 [00:40<01:58, 63.77it/s]Processing train dataset:  35%|███▍      | 3498/10000 [00:46<01:25, 75.93it/s]Processing train dataset:  32%|███▏      | 3172/10000 [00:43<01:35, 71.31it/s]Processing train dataset:  31%|███       | 3069/10000 [00:43<01:34, 73.46it/s]Processing train dataset:  31%|███       | 3104/10000 [00:43<01:38, 70.13it/s]Processing train dataset:  25%|██▍       | 2459/10000 [00:41<02:00, 62.49it/s]Processing train dataset:  32%|███▏      | 3180/10000 [00:43<01:36, 70.61it/s]Processing train dataset:  35%|███▌      | 3506/10000 [00:47<01:35, 67.99it/s]Processing train dataset:  31%|███       | 3112/10000 [00:43<01:34, 72.52it/s]Processing train dataset:  31%|███       | 3077/10000 [00:43<01:34, 73.27it/s]Processing train dataset:  25%|██▍       | 2467/10000 [00:41<01:54, 65.70it/s]Processing train dataset:  35%|███▌      | 3517/10000 [00:47<01:23, 77.30it/s]Processing train dataset:  31%|███       | 3120/10000 [00:43<01:32, 74.30it/s]Processing train dataset:  32%|███▏      | 3188/10000 [00:43<01:37, 70.21it/s]Processing train dataset:  31%|███       | 3086/10000 [00:43<01:30, 76.57it/s]Processing train dataset:  25%|██▍       | 2474/10000 [00:41<01:54, 65.74it/s]Processing train dataset:  35%|███▌      | 3529/10000 [00:47<01:14, 86.41it/s]Processing train dataset:  32%|███▏      | 3196/10000 [00:43<01:35, 71.08it/s]Processing train dataset:  31%|███       | 3094/10000 [00:43<01:31, 75.49it/s]Processing train dataset:  31%|███▏      | 3128/10000 [00:43<01:38, 69.44it/s]Processing train dataset:  25%|██▍       | 2482/10000 [00:41<01:49, 68.93it/s]Processing train dataset:  35%|███▌      | 3539/10000 [00:47<01:13, 88.39it/s]Processing train dataset:  31%|███       | 3102/10000 [00:43<01:31, 75.02it/s]Processing train dataset:  32%|███▏      | 3204/10000 [00:43<01:37, 69.54it/s]Processing train dataset:  31%|███▏      | 3137/10000 [00:43<01:34, 72.72it/s]Processing train dataset:  25%|██▍       | 2489/10000 [00:41<01:50, 67.79it/s]Processing train dataset:  35%|███▌      | 3549/10000 [00:47<01:11, 89.99it/s]Processing train dataset:  31%|███       | 3110/10000 [00:43<01:31, 75.52it/s]Processing train dataset:  32%|███▏      | 3211/10000 [00:43<01:37, 69.43it/s]Processing train dataset:  31%|███▏      | 3145/10000 [00:43<01:33, 73.03it/s]Processing train dataset:  25%|██▍       | 2497/10000 [00:41<01:47, 69.64it/s]Processing train dataset:  36%|███▌      | 3560/10000 [00:47<01:08, 93.85it/s]Processing train dataset:  31%|███       | 3119/10000 [00:43<01:27, 78.66it/s]Processing train dataset:  32%|███▏      | 3219/10000 [00:44<01:36, 70.54it/s]Processing train dataset:  32%|███▏      | 3153/10000 [00:44<01:34, 72.76it/s]Processing train dataset:  25%|██▌       | 2505/10000 [00:41<01:45, 71.29it/s]Processing train dataset:  36%|███▌      | 3572/10000 [00:47<01:05, 98.54it/s]Processing train dataset:  32%|███▏      | 3227/10000 [00:44<01:34, 71.36it/s]Processing train dataset:  31%|███▏      | 3127/10000 [00:43<01:33, 73.81it/s]Processing train dataset:  32%|███▏      | 3161/10000 [00:44<01:34, 72.20it/s]Processing train dataset:  25%|██▌       | 2515/10000 [00:41<01:39, 74.90it/s]Processing train dataset:  36%|███▌      | 3582/10000 [00:47<01:06, 96.75it/s]Processing train dataset:  32%|███▏      | 3235/10000 [00:44<01:35, 70.89it/s]Processing train dataset:  31%|███▏      | 3136/10000 [00:44<01:30, 75.59it/s]Processing train dataset:  32%|███▏      | 3169/10000 [00:44<01:35, 71.28it/s]Processing train dataset:  25%|██▌       | 2525/10000 [00:41<01:35, 78.26it/s]Processing train dataset:  36%|███▌      | 3592/10000 [00:47<01:07, 95.24it/s]Processing train dataset:  31%|███▏      | 3144/10000 [00:44<01:31, 75.15it/s]Processing train dataset:  32%|███▏      | 3243/10000 [00:44<01:36, 70.31it/s]Processing train dataset:  32%|███▏      | 3177/10000 [00:44<01:36, 70.75it/s]Processing train dataset:  25%|██▌       | 2536/10000 [00:42<01:30, 82.16it/s]Processing train dataset:  36%|███▌      | 3602/10000 [00:47<01:07, 95.16it/s]Processing train dataset:  32%|███▏      | 3152/10000 [00:44<01:32, 74.00it/s]Processing train dataset:  33%|███▎      | 3251/10000 [00:44<01:36, 70.12it/s]Processing train dataset:  32%|███▏      | 3185/10000 [00:44<01:37, 70.23it/s]Processing train dataset:  25%|██▌       | 2545/10000 [00:42<01:35, 78.06it/s]Processing train dataset:  36%|███▌      | 3612/10000 [00:48<01:08, 93.01it/s]Processing train dataset:  33%|███▎      | 3259/10000 [00:44<01:32, 72.67it/s]Processing train dataset:  32%|███▏      | 3160/10000 [00:44<01:33, 73.23it/s]Processing train dataset:  32%|███▏      | 3193/10000 [00:44<01:35, 71.01it/s]Processing train dataset:  26%|██▌       | 2555/10000 [00:42<01:37, 76.75it/s]Processing train dataset:  32%|███▏      | 3168/10000 [00:44<01:32, 73.82it/s]Processing train dataset:  33%|███▎      | 3267/10000 [00:44<01:33, 72.22it/s]Processing train dataset:  36%|███▌      | 3622/10000 [00:48<01:16, 82.95it/s]Processing train dataset:  32%|███▏      | 3202/10000 [00:44<01:31, 74.26it/s]Processing train dataset:  26%|██▌       | 2564/10000 [00:42<01:34, 78.70it/s]Processing train dataset:  32%|███▏      | 3176/10000 [00:44<01:32, 73.54it/s]Processing train dataset:  33%|███▎      | 3276/10000 [00:44<01:30, 74.67it/s]Processing train dataset:  32%|███▏      | 3210/10000 [00:44<01:31, 73.94it/s]Processing train dataset:  36%|███▋      | 3631/10000 [00:48<01:21, 77.67it/s]Processing train dataset:  33%|███▎      | 3286/10000 [00:44<01:24, 79.26it/s]Processing train dataset:  32%|███▏      | 3218/10000 [00:45<01:36, 70.35it/s]Processing train dataset:  32%|███▏      | 3184/10000 [00:44<01:49, 62.26it/s]Processing train dataset:  33%|███▎      | 3296/10000 [00:45<01:21, 82.17it/s]Processing train dataset:  36%|███▋      | 3639/10000 [00:48<01:46, 59.60it/s]Processing train dataset:  26%|██▌       | 2572/10000 [00:42<02:22, 52.14it/s]Processing train dataset:  32%|███▏      | 3226/10000 [00:45<01:39, 68.32it/s]Processing train dataset:  32%|███▏      | 3191/10000 [00:44<01:50, 61.67it/s]Processing train dataset:  33%|███▎      | 3305/10000 [00:45<01:23, 79.90it/s]Processing train dataset:  36%|███▋      | 3646/10000 [00:48<01:48, 58.62it/s]Processing train dataset:  26%|██▌       | 2582/10000 [00:42<02:01, 60.90it/s]Processing train dataset:  32%|███▏      | 3199/10000 [00:44<01:42, 66.33it/s]Processing train dataset:  32%|███▏      | 3233/10000 [00:45<01:40, 67.25it/s]Processing train dataset:  33%|███▎      | 3314/10000 [00:45<01:23, 80.12it/s]Processing train dataset:  32%|███▏      | 3207/10000 [00:45<01:38, 68.79it/s]Processing train dataset:  37%|███▋      | 3653/10000 [00:48<01:47, 59.25it/s]Processing train dataset:  26%|██▌       | 2594/10000 [00:42<01:42, 72.49it/s]Processing train dataset:  32%|███▏      | 3241/10000 [00:45<01:37, 69.43it/s]Processing train dataset:  33%|███▎      | 3323/10000 [00:45<01:26, 77.38it/s]Processing train dataset:  32%|███▏      | 3248/10000 [00:45<01:38, 68.21it/s]Processing train dataset:  26%|██▌       | 2603/10000 [00:43<01:41, 72.55it/s]Processing train dataset:  37%|███▋      | 3660/10000 [00:48<01:49, 57.81it/s]Processing train dataset:  32%|███▏      | 3215/10000 [00:45<01:44, 64.75it/s]Processing train dataset:  33%|███▎      | 3256/10000 [00:45<01:38, 68.52it/s]Processing train dataset:  33%|███▎      | 3331/10000 [00:45<01:35, 69.52it/s]Processing train dataset:  26%|██▌       | 2612/10000 [00:43<01:46, 69.69it/s]Processing train dataset:  32%|███▏      | 3222/10000 [00:45<01:50, 61.32it/s]Processing train dataset:  37%|███▋      | 3667/10000 [00:49<01:54, 55.17it/s]Processing train dataset:  33%|███▎      | 3264/10000 [00:45<01:36, 70.08it/s]Processing train dataset:  33%|███▎      | 3339/10000 [00:45<01:34, 70.41it/s]Processing train dataset:  26%|██▌       | 2622/10000 [00:43<01:36, 76.62it/s]Processing train dataset:  32%|███▏      | 3230/10000 [00:45<01:43, 65.26it/s]Processing train dataset:  37%|███▋      | 3676/10000 [00:49<01:43, 60.93it/s]Processing train dataset:  33%|███▎      | 3272/10000 [00:45<01:38, 68.39it/s]Processing train dataset:  33%|███▎      | 3347/10000 [00:45<01:36, 68.75it/s]Processing train dataset:  32%|███▏      | 3237/10000 [00:45<01:47, 63.15it/s]Processing train dataset:  26%|██▋       | 2631/10000 [00:43<01:42, 71.64it/s]Processing train dataset:  37%|███▋      | 3683/10000 [00:49<01:46, 59.30it/s]Processing train dataset:  33%|███▎      | 3281/10000 [00:45<01:33, 71.59it/s]Processing train dataset:  34%|███▎      | 3356/10000 [00:45<01:32, 71.81it/s]Processing train dataset:  32%|███▏      | 3245/10000 [00:45<01:40, 67.40it/s]Processing train dataset:  37%|███▋      | 3691/10000 [00:49<01:41, 62.34it/s]Processing train dataset:  26%|██▋       | 2639/10000 [00:43<01:45, 70.04it/s]Processing train dataset:  33%|███▎      | 3289/10000 [00:46<01:33, 72.10it/s]Processing train dataset:  34%|███▎      | 3364/10000 [00:46<01:35, 69.51it/s]Processing train dataset:  33%|███▎      | 3252/10000 [00:45<01:51, 60.45it/s]Processing train dataset:  26%|██▋       | 2647/10000 [00:43<01:45, 69.72it/s]Processing train dataset:  37%|███▋      | 3698/10000 [00:49<01:48, 58.21it/s]Processing train dataset:  33%|███▎      | 3297/10000 [00:46<01:32, 72.36it/s]Processing train dataset:  34%|███▎      | 3372/10000 [00:46<01:41, 65.14it/s]Processing train dataset:  33%|███▎      | 3260/10000 [00:45<01:45, 63.71it/s]Processing train dataset:  37%|███▋      | 3704/10000 [00:49<01:57, 53.74it/s]Processing train dataset:  27%|██▋       | 2655/10000 [00:43<01:56, 63.17it/s]Processing train dataset:  33%|███▎      | 3305/10000 [00:46<01:43, 64.95it/s]Processing train dataset:  34%|███▍      | 3380/10000 [00:46<01:37, 68.02it/s]Processing train dataset:  33%|███▎      | 3267/10000 [00:46<01:49, 61.40it/s]Processing train dataset:  27%|██▋       | 2664/10000 [00:43<01:46, 68.77it/s]Processing train dataset:  37%|███▋      | 3710/10000 [00:49<01:55, 54.22it/s]Processing train dataset:  33%|███▎      | 3313/10000 [00:46<01:38, 68.17it/s]Processing train dataset:  34%|███▍      | 3388/10000 [00:46<01:38, 67.34it/s]Processing train dataset:  33%|███▎      | 3274/10000 [00:46<01:51, 60.14it/s]Processing train dataset:  37%|███▋      | 3716/10000 [00:49<02:02, 51.25it/s]Processing train dataset:  27%|██▋       | 2672/10000 [00:44<01:55, 63.44it/s]Processing train dataset:  33%|███▎      | 3320/10000 [00:46<01:42, 65.00it/s]Processing train dataset:  34%|███▍      | 3395/10000 [00:46<01:37, 67.91it/s]Processing train dataset:  33%|███▎      | 3282/10000 [00:46<01:43, 65.04it/s]Processing train dataset:  37%|███▋      | 3724/10000 [00:50<01:51, 56.33it/s]Processing train dataset:  33%|███▎      | 3327/10000 [00:46<01:41, 65.95it/s]Processing train dataset:  34%|███▍      | 3402/10000 [00:46<01:37, 67.72it/s]Processing train dataset:  27%|██▋       | 2682/10000 [00:44<01:46, 68.56it/s]Processing train dataset:  33%|███▎      | 3292/10000 [00:46<01:33, 71.97it/s]Processing train dataset:  34%|███▍      | 3410/10000 [00:46<01:33, 70.45it/s]Processing train dataset:  33%|███▎      | 3334/10000 [00:46<01:48, 61.58it/s]Processing train dataset:  37%|███▋      | 3730/10000 [00:50<02:16, 45.97it/s]Processing train dataset:  33%|███▎      | 3300/10000 [00:46<01:42, 65.38it/s]Processing train dataset:  34%|███▍      | 3418/10000 [00:46<01:38, 66.83it/s]Processing train dataset:  33%|███▎      | 3341/10000 [00:46<01:52, 59.07it/s]Processing train dataset:  27%|██▋       | 2690/10000 [00:44<02:22, 51.22it/s]Processing train dataset:  33%|███▎      | 3307/10000 [00:46<01:49, 60.98it/s]Processing train dataset:  37%|███▋      | 3735/10000 [00:50<02:29, 41.78it/s]Processing train dataset:  34%|███▍      | 3428/10000 [00:46<01:28, 74.16it/s]Processing train dataset:  33%|███▎      | 3349/10000 [00:46<01:43, 64.04it/s]Processing train dataset:  27%|██▋       | 2697/10000 [00:44<02:16, 53.63it/s]Processing train dataset:  33%|███▎      | 3316/10000 [00:46<01:39, 67.07it/s]Processing train dataset:  37%|███▋      | 3744/10000 [00:50<02:00, 52.01it/s]Processing train dataset:  34%|███▍      | 3437/10000 [00:47<01:26, 76.14it/s]Processing train dataset:  34%|███▎      | 3357/10000 [00:47<01:40, 65.97it/s]Processing train dataset:  27%|██▋       | 2707/10000 [00:44<01:54, 63.65it/s]Processing train dataset:  33%|███▎      | 3324/10000 [00:46<01:35, 69.60it/s]Processing train dataset:  38%|███▊      | 3753/10000 [00:50<01:43, 60.49it/s]Processing train dataset:  34%|███▍      | 3445/10000 [00:47<01:28, 74.15it/s]Processing train dataset:  34%|███▎      | 3366/10000 [00:47<01:34, 69.84it/s]Processing train dataset:  27%|██▋       | 2715/10000 [00:44<01:50, 66.12it/s]Processing train dataset:  33%|███▎      | 3332/10000 [00:46<01:33, 71.66it/s]Processing train dataset:  38%|███▊      | 3761/10000 [00:50<01:35, 65.26it/s]Processing train dataset:  34%|███▍      | 3375/10000 [00:47<01:28, 75.26it/s]Processing train dataset:  35%|███▍      | 3453/10000 [00:47<01:30, 72.29it/s]Processing train dataset:  27%|██▋       | 2724/10000 [00:44<01:41, 71.81it/s]Processing train dataset:  33%|███▎      | 3340/10000 [00:47<01:30, 73.40it/s]Processing train dataset:  38%|███▊      | 3770/10000 [00:50<01:30, 68.71it/s]Processing train dataset:  34%|███▍      | 3383/10000 [00:47<01:28, 75.04it/s]Processing train dataset:  27%|██▋       | 2732/10000 [00:44<01:39, 73.34it/s]Processing train dataset:  35%|███▍      | 3461/10000 [00:47<01:35, 68.48it/s]Processing train dataset:  33%|███▎      | 3349/10000 [00:47<01:26, 77.23it/s]Processing train dataset:  35%|███▍      | 3469/10000 [00:47<01:31, 71.39it/s]Processing train dataset:  34%|███▍      | 3391/10000 [00:47<01:39, 66.33it/s]Processing train dataset:  34%|███▎      | 3357/10000 [00:47<01:38, 67.53it/s]Processing train dataset:  38%|███▊      | 3778/10000 [00:51<02:04, 49.89it/s]Processing train dataset:  35%|███▍      | 3478/10000 [00:47<01:28, 74.08it/s]Processing train dataset:  34%|███▍      | 3399/10000 [00:47<01:37, 67.96it/s]Processing train dataset:  34%|███▎      | 3365/10000 [00:47<01:33, 70.63it/s]Processing train dataset:  27%|██▋       | 2740/10000 [00:45<02:29, 48.44it/s]Processing train dataset:  38%|███▊      | 3784/10000 [00:51<02:00, 51.73it/s]Processing train dataset:  35%|███▍      | 3486/10000 [00:47<01:32, 70.37it/s]Processing train dataset:  34%|███▍      | 3408/10000 [00:47<01:32, 71.61it/s]Processing train dataset:  27%|██▋       | 2747/10000 [00:45<02:17, 52.69it/s]Processing train dataset:  34%|███▎      | 3373/10000 [00:47<01:35, 69.40it/s]Processing train dataset:  38%|███▊      | 3792/10000 [00:51<01:47, 57.85it/s]Processing train dataset:  35%|███▍      | 3494/10000 [00:47<01:33, 69.75it/s]Processing train dataset:  34%|███▍      | 3416/10000 [00:47<01:31, 71.71it/s]Processing train dataset:  28%|██▊       | 2756/10000 [00:45<02:07, 56.69it/s]Processing train dataset:  38%|███▊      | 3799/10000 [00:51<01:43, 59.75it/s]Processing train dataset:  34%|███▍      | 3381/10000 [00:47<01:37, 68.07it/s]Processing train dataset:  34%|███▍      | 3424/10000 [00:48<01:31, 71.95it/s]Processing train dataset:  35%|███▌      | 3502/10000 [00:48<01:34, 68.68it/s]Processing train dataset:  28%|██▊       | 2764/10000 [00:45<02:03, 58.43it/s]Processing train dataset:  34%|███▍      | 3388/10000 [00:47<01:43, 64.05it/s]Processing train dataset:  38%|███▊      | 3806/10000 [00:51<01:48, 57.09it/s]Processing train dataset:  34%|███▍      | 3433/10000 [00:48<01:26, 75.92it/s]Processing train dataset:  35%|███▌      | 3510/10000 [00:48<01:33, 69.45it/s]Processing train dataset:  28%|██▊       | 2772/10000 [00:45<01:56, 62.24it/s]Processing train dataset:  34%|███▍      | 3396/10000 [00:47<01:37, 67.97it/s]Processing train dataset:  38%|███▊      | 3814/10000 [00:51<01:39, 62.22it/s]Processing train dataset:  34%|███▍      | 3441/10000 [00:48<01:26, 76.09it/s]Processing train dataset:  35%|███▌      | 3520/10000 [00:48<01:24, 76.77it/s]Processing train dataset:  34%|███▍      | 3403/10000 [00:48<01:48, 60.97it/s]Processing train dataset:  28%|██▊       | 2779/10000 [00:45<02:05, 57.32it/s]Processing train dataset:  38%|███▊      | 3821/10000 [00:51<01:48, 56.92it/s]Processing train dataset:  34%|███▍      | 3449/10000 [00:48<01:32, 70.90it/s]Processing train dataset:  35%|███▌      | 3528/10000 [00:48<01:27, 73.75it/s]Processing train dataset:  28%|██▊       | 2787/10000 [00:45<01:55, 62.52it/s]Processing train dataset:  34%|███▍      | 3412/10000 [00:48<01:38, 67.05it/s]Processing train dataset:  38%|███▊      | 3830/10000 [00:51<01:35, 64.90it/s]Processing train dataset:  35%|███▍      | 3457/10000 [00:48<01:31, 71.36it/s]Processing train dataset:  35%|███▌      | 3536/10000 [00:48<01:27, 73.90it/s]Processing train dataset:  28%|██▊       | 2794/10000 [00:46<01:59, 60.10it/s]Processing train dataset:  38%|███▊      | 3837/10000 [00:52<01:37, 63.39it/s]Processing train dataset:  34%|███▍      | 3419/10000 [00:48<01:43, 63.65it/s]Processing train dataset:  35%|███▌      | 3544/10000 [00:48<01:30, 71.30it/s]Processing train dataset:  35%|███▍      | 3465/10000 [00:48<01:34, 69.06it/s]Processing train dataset:  38%|███▊      | 3845/10000 [00:52<01:31, 67.57it/s]Processing train dataset:  28%|██▊       | 2802/10000 [00:46<01:53, 63.42it/s]Processing train dataset:  34%|███▍      | 3431/10000 [00:48<01:27, 74.78it/s]Processing train dataset:  35%|███▍      | 3474/10000 [00:48<01:29, 73.23it/s]Processing train dataset:  36%|███▌      | 3552/10000 [00:48<01:39, 64.69it/s]Processing train dataset:  39%|███▊      | 3852/10000 [00:52<01:36, 63.65it/s]Processing train dataset:  35%|███▍      | 3482/10000 [00:48<01:28, 73.27it/s]Processing train dataset:  28%|██▊       | 2809/10000 [00:46<01:57, 61.02it/s]Processing train dataset:  34%|███▍      | 3439/10000 [00:48<01:30, 72.66it/s]Processing train dataset:  36%|███▌      | 3560/10000 [00:48<01:34, 68.17it/s]Processing train dataset:  35%|███▍      | 3490/10000 [00:48<01:26, 75.01it/s]Processing train dataset:  28%|██▊       | 2817/10000 [00:46<01:48, 65.92it/s]Processing train dataset:  39%|███▊      | 3861/10000 [00:52<01:30, 68.13it/s]Processing train dataset:  36%|███▌      | 3569/10000 [00:48<01:29, 71.77it/s]Processing train dataset:  34%|███▍      | 3447/10000 [00:48<01:39, 66.05it/s]Processing train dataset:  39%|███▊      | 3868/10000 [00:52<01:30, 67.98it/s]Processing train dataset:  35%|███▍      | 3498/10000 [00:49<01:32, 70.08it/s]Processing train dataset:  28%|██▊       | 2824/10000 [00:46<01:57, 61.15it/s]Processing train dataset:  36%|███▌      | 3577/10000 [00:49<01:30, 71.00it/s]Processing train dataset:  35%|███▍      | 3454/10000 [00:48<01:45, 61.85it/s]Processing train dataset:  39%|███▉      | 3876/10000 [00:52<01:35, 64.28it/s]Processing train dataset:  36%|███▌      | 3585/10000 [00:49<01:27, 73.25it/s]Processing train dataset:  28%|██▊       | 2831/10000 [00:46<02:04, 57.38it/s]Processing train dataset:  35%|███▌      | 3506/10000 [00:49<01:41, 63.75it/s]Processing train dataset:  35%|███▍      | 3461/10000 [00:48<01:50, 59.15it/s]Processing train dataset:  39%|███▉      | 3883/10000 [00:52<01:33, 65.27it/s]Processing train dataset:  36%|███▌      | 3593/10000 [00:49<01:28, 72.05it/s]Processing train dataset:  28%|██▊       | 2839/10000 [00:46<01:57, 60.79it/s]Processing train dataset:  35%|███▌      | 3513/10000 [00:49<01:42, 63.51it/s]Processing train dataset:  35%|███▍      | 3469/10000 [00:49<01:54, 57.28it/s]Processing train dataset:  36%|███▌      | 3601/10000 [00:49<01:26, 73.97it/s]Processing train dataset:  39%|███▉      | 3890/10000 [00:52<01:45, 57.95it/s]Processing train dataset:  35%|███▌      | 3520/10000 [00:49<01:48, 59.89it/s]Processing train dataset:  28%|██▊       | 2846/10000 [00:46<02:04, 57.29it/s]Processing train dataset:  35%|███▍      | 3475/10000 [00:49<01:52, 57.91it/s]Processing train dataset:  36%|███▌      | 3609/10000 [00:49<01:28, 71.95it/s]Processing train dataset:  39%|███▉      | 3896/10000 [00:53<01:58, 51.40it/s]Processing train dataset:  35%|███▌      | 3527/10000 [00:49<01:57, 55.19it/s]Processing train dataset:  36%|███▌      | 3617/10000 [00:49<01:33, 68.41it/s]Processing train dataset:  35%|███▌      | 3533/10000 [00:49<02:02, 52.77it/s]Processing train dataset:  39%|███▉      | 3902/10000 [00:53<02:09, 47.18it/s]Processing train dataset:  35%|███▍      | 3481/10000 [00:49<02:37, 41.26it/s]Processing train dataset:  36%|███▋      | 3626/10000 [00:49<01:29, 71.38it/s]Processing train dataset:  29%|██▊       | 2852/10000 [00:47<03:16, 36.46it/s]Processing train dataset:  35%|███▌      | 3540/10000 [00:49<01:56, 55.56it/s]Processing train dataset:  35%|███▍      | 3489/10000 [00:49<02:16, 47.76it/s]Processing train dataset:  36%|███▋      | 3635/10000 [00:49<01:26, 73.53it/s]Processing train dataset:  39%|███▉      | 3907/10000 [00:53<02:20, 43.44it/s]Processing train dataset:  29%|██▊       | 2857/10000 [00:47<03:10, 37.50it/s]Processing train dataset:  35%|███▌      | 3547/10000 [00:49<01:52, 57.38it/s]Processing train dataset:  35%|███▍      | 3496/10000 [00:49<02:06, 51.46it/s]Processing train dataset:  36%|███▋      | 3643/10000 [00:49<01:26, 73.41it/s]Processing train dataset:  39%|███▉      | 3914/10000 [00:53<02:06, 48.11it/s]Processing train dataset:  29%|██▊       | 2863/10000 [00:47<02:50, 41.78it/s]Processing train dataset:  36%|███▌      | 3554/10000 [00:50<01:49, 58.96it/s]Processing train dataset:  35%|███▌      | 3502/10000 [00:49<02:03, 52.70it/s]Processing train dataset:  37%|███▋      | 3651/10000 [00:50<01:26, 73.27it/s]Processing train dataset:  39%|███▉      | 3921/10000 [00:53<01:55, 52.47it/s]Processing train dataset:  29%|██▊       | 2870/10000 [00:47<02:32, 46.88it/s]Processing train dataset:  36%|███▌      | 3564/10000 [00:50<01:34, 68.29it/s]Processing train dataset:  35%|███▌      | 3510/10000 [00:49<01:52, 57.92it/s]Processing train dataset:  39%|███▉      | 3928/10000 [00:53<01:49, 55.68it/s]Processing train dataset:  37%|███▋      | 3659/10000 [00:50<01:28, 72.00it/s]Processing train dataset:  29%|██▉       | 2876/10000 [00:47<02:30, 47.49it/s]Processing train dataset:  36%|███▌      | 3571/10000 [00:50<01:35, 67.05it/s]Processing train dataset:  35%|███▌      | 3520/10000 [00:49<01:36, 66.95it/s]Processing train dataset:  39%|███▉      | 3937/10000 [00:53<01:36, 63.10it/s]Processing train dataset:  37%|███▋      | 3667/10000 [00:50<01:28, 71.23it/s]Processing train dataset:  29%|██▉       | 2884/10000 [00:47<02:08, 55.24it/s]Processing train dataset:  36%|███▌      | 3579/10000 [00:50<01:33, 68.31it/s]Processing train dataset:  35%|███▌      | 3528/10000 [00:50<01:34, 68.64it/s]Processing train dataset:  39%|███▉      | 3945/10000 [00:53<01:31, 66.08it/s]Processing train dataset:  37%|███▋      | 3675/10000 [00:50<01:26, 73.29it/s]Processing train dataset:  29%|██▉       | 2891/10000 [00:48<02:11, 53.89it/s]Processing train dataset:  36%|███▌      | 3586/10000 [00:50<01:40, 63.76it/s]Processing train dataset:  40%|███▉      | 3953/10000 [00:54<01:27, 69.14it/s]Processing train dataset:  35%|███▌      | 3536/10000 [00:50<01:36, 67.00it/s]Processing train dataset:  37%|███▋      | 3683/10000 [00:50<01:27, 72.40it/s]Processing train dataset:  29%|██▉       | 2897/10000 [00:48<02:17, 51.72it/s]Processing train dataset:  40%|███▉      | 3962/10000 [00:54<01:22, 73.61it/s]Processing train dataset:  35%|███▌      | 3544/10000 [00:50<01:32, 69.43it/s]Processing train dataset:  37%|███▋      | 3693/10000 [00:50<01:21, 77.60it/s]Processing train dataset:  36%|███▌      | 3593/10000 [00:50<01:48, 58.79it/s]Processing train dataset:  29%|██▉       | 2903/10000 [00:48<02:13, 53.13it/s]Processing train dataset:  37%|███▋      | 3701/10000 [00:50<01:22, 76.44it/s]Processing train dataset:  36%|███▌      | 3552/10000 [00:50<01:34, 67.98it/s]Processing train dataset:  40%|███▉      | 3970/10000 [00:54<01:28, 68.27it/s]Processing train dataset:  36%|███▌      | 3599/10000 [00:50<01:55, 55.21it/s]Processing train dataset:  36%|███▌      | 3560/10000 [00:50<01:32, 69.91it/s]Processing train dataset:  37%|███▋      | 3709/10000 [00:50<01:24, 74.51it/s]Processing train dataset:  40%|███▉      | 3978/10000 [00:54<01:24, 71.20it/s]Processing train dataset:  29%|██▉       | 2909/10000 [00:48<02:29, 47.33it/s]Processing train dataset:  36%|███▌      | 3605/10000 [00:50<02:01, 52.67it/s]Processing train dataset:  29%|██▉       | 2916/10000 [00:48<02:17, 51.67it/s]Processing train dataset:  36%|███▌      | 3568/10000 [00:50<01:31, 70.09it/s]Processing train dataset:  40%|███▉      | 3986/10000 [00:54<01:24, 71.45it/s]Processing train dataset:  37%|███▋      | 3717/10000 [00:50<01:26, 73.04it/s]Processing train dataset:  36%|███▌      | 3612/10000 [00:51<01:54, 55.97it/s]Processing train dataset:  40%|███▉      | 3994/10000 [00:54<01:22, 72.74it/s]Processing train dataset:  37%|███▋      | 3725/10000 [00:51<01:25, 73.10it/s]Processing train dataset:  36%|███▌      | 3576/10000 [00:50<01:38, 65.55it/s]Processing train dataset:  36%|███▌      | 3619/10000 [00:51<01:49, 58.18it/s]Processing train dataset:  29%|██▉       | 2922/10000 [00:48<02:31, 46.70it/s]Processing train dataset:  40%|████      | 4002/10000 [00:54<01:21, 73.41it/s]Processing train dataset:  37%|███▋      | 3733/10000 [00:51<01:24, 74.33it/s]Processing train dataset:  36%|███▌      | 3583/10000 [00:50<01:38, 65.32it/s]Processing train dataset:  36%|███▋      | 3627/10000 [00:51<01:41, 62.74it/s]Processing train dataset:  29%|██▉       | 2928/10000 [00:48<02:28, 47.53it/s]Processing train dataset:  37%|███▋      | 3741/10000 [00:51<01:22, 75.75it/s]Processing train dataset:  40%|████      | 4010/10000 [00:54<01:24, 70.98it/s]Processing train dataset:  36%|███▌      | 3591/10000 [00:51<01:35, 67.30it/s]Processing train dataset:  36%|███▋      | 3635/10000 [00:51<01:35, 66.85it/s]Processing train dataset:  29%|██▉       | 2933/10000 [00:48<02:33, 45.91it/s]Processing train dataset:  37%|███▋      | 3749/10000 [00:51<01:22, 75.85it/s]Processing train dataset:  40%|████      | 4019/10000 [00:54<01:18, 76.14it/s]Processing train dataset:  36%|███▌      | 3599/10000 [00:51<01:30, 70.42it/s]Processing train dataset:  36%|███▋      | 3643/10000 [00:51<01:33, 67.98it/s]Processing train dataset:  29%|██▉       | 2940/10000 [00:49<02:17, 51.24it/s]Processing train dataset:  38%|███▊      | 3759/10000 [00:51<01:18, 79.83it/s]Processing train dataset:  40%|████      | 4027/10000 [00:55<01:18, 76.21it/s]Processing train dataset:  36%|███▌      | 3607/10000 [00:51<01:28, 72.45it/s]Processing train dataset:  37%|███▋      | 3651/10000 [00:51<01:31, 69.24it/s]Processing train dataset:  29%|██▉       | 2946/10000 [00:49<02:14, 52.46it/s]Processing train dataset:  40%|████      | 4037/10000 [00:55<01:13, 81.44it/s]Processing train dataset:  38%|███▊      | 3768/10000 [00:51<01:18, 79.82it/s]Processing train dataset:  37%|███▋      | 3659/10000 [00:51<01:30, 69.83it/s]Processing train dataset:  36%|███▌      | 3615/10000 [00:51<01:36, 66.47it/s]Processing train dataset:  30%|██▉       | 2952/10000 [00:49<02:14, 52.49it/s]Processing train dataset:  40%|████      | 4049/10000 [00:55<01:05, 90.39it/s]Processing train dataset:  38%|███▊      | 3776/10000 [00:51<01:20, 77.73it/s]Processing train dataset:  37%|███▋      | 3667/10000 [00:51<01:29, 70.43it/s]Processing train dataset:  36%|███▌      | 3623/10000 [00:51<01:32, 69.03it/s]Processing train dataset:  30%|██▉       | 2958/10000 [00:49<02:12, 53.24it/s]Processing train dataset:  41%|████      | 4059/10000 [00:55<01:04, 92.61it/s]Processing train dataset:  38%|███▊      | 3784/10000 [00:51<01:22, 75.42it/s]Processing train dataset:  37%|███▋      | 3675/10000 [00:51<01:27, 72.57it/s]Processing train dataset:  36%|███▋      | 3631/10000 [00:51<01:31, 69.61it/s]Processing train dataset:  30%|██▉       | 2964/10000 [00:49<02:11, 53.69it/s]Processing train dataset:  41%|████      | 4069/10000 [00:55<01:08, 86.05it/s]Processing train dataset:  38%|███▊      | 3792/10000 [00:51<01:28, 70.24it/s]Processing train dataset:  37%|███▋      | 3683/10000 [00:52<01:27, 72.05it/s]Processing train dataset:  36%|███▋      | 3639/10000 [00:51<01:33, 67.84it/s]Processing train dataset:  30%|██▉       | 2970/10000 [00:49<02:14, 52.11it/s]Processing train dataset:  41%|████      | 4078/10000 [00:55<01:08, 85.98it/s]Processing train dataset:  38%|███▊      | 3800/10000 [00:52<01:28, 70.18it/s]Processing train dataset:  37%|███▋      | 3692/10000 [00:52<01:22, 76.65it/s]Processing train dataset:  30%|██▉       | 2976/10000 [00:49<02:09, 54.16it/s]Processing train dataset:  36%|███▋      | 3647/10000 [00:51<01:35, 66.64it/s]Processing train dataset:  41%|████      | 4088/10000 [00:55<01:08, 86.73it/s]Processing train dataset:  38%|███▊      | 3808/10000 [00:52<01:26, 71.23it/s]Processing train dataset:  37%|███▋      | 3700/10000 [00:52<01:23, 75.38it/s]Processing train dataset:  37%|███▋      | 3655/10000 [00:51<01:33, 68.18it/s]Processing train dataset:  30%|██▉       | 2983/10000 [00:49<02:08, 54.63it/s]Processing train dataset:  41%|████      | 4097/10000 [00:55<01:10, 84.06it/s]Processing train dataset:  38%|███▊      | 3816/10000 [00:52<01:25, 71.95it/s]Processing train dataset:  37%|███▋      | 3708/10000 [00:52<01:23, 74.92it/s]Processing train dataset:  37%|███▋      | 3663/10000 [00:52<01:30, 70.22it/s]Processing train dataset:  30%|██▉       | 2990/10000 [00:49<02:05, 56.06it/s]Processing train dataset:  41%|████      | 4107/10000 [00:55<01:07, 87.00it/s]Processing train dataset:  38%|███▊      | 3825/10000 [00:52<01:22, 74.89it/s]Processing train dataset:  37%|███▋      | 3716/10000 [00:52<01:24, 74.13it/s]Processing train dataset:  37%|███▋      | 3671/10000 [00:52<01:26, 72.87it/s]Processing train dataset:  30%|██▉       | 2996/10000 [00:50<02:11, 53.30it/s]Processing train dataset:  41%|████      | 4116/10000 [00:56<01:10, 83.28it/s]Processing train dataset:  38%|███▊      | 3833/10000 [00:52<01:22, 74.78it/s]Processing train dataset:  37%|███▋      | 3724/10000 [00:52<01:25, 73.82it/s]Processing train dataset:  37%|███▋      | 3679/10000 [00:52<01:25, 74.03it/s]Processing train dataset:  41%|████▏     | 4127/10000 [00:56<01:05, 89.76it/s]Processing train dataset:  38%|███▊      | 3841/10000 [00:52<01:22, 74.70it/s]Processing train dataset:  37%|███▋      | 3732/10000 [00:52<01:23, 75.21it/s]Processing train dataset:  30%|███       | 3002/10000 [00:50<02:21, 49.35it/s]Processing train dataset:  37%|███▋      | 3689/10000 [00:52<01:19, 79.73it/s]Processing train dataset:  41%|████▏     | 4137/10000 [00:56<01:04, 90.92it/s]Processing train dataset:  38%|███▊      | 3849/10000 [00:52<01:23, 74.00it/s]Processing train dataset:  37%|███▋      | 3740/10000 [00:52<01:25, 73.43it/s]Processing train dataset:  30%|███       | 3008/10000 [00:50<02:20, 49.89it/s]Processing train dataset:  37%|███▋      | 3698/10000 [00:52<01:19, 79.15it/s]Processing train dataset:  41%|████▏     | 4148/10000 [00:56<01:01, 95.52it/s]Processing train dataset:  39%|███▊      | 3858/10000 [00:52<01:21, 75.71it/s]Processing train dataset:  37%|███▋      | 3749/10000 [00:52<01:21, 76.83it/s]Processing train dataset:  30%|███       | 3015/10000 [00:50<02:07, 54.74it/s]Processing train dataset:  37%|███▋      | 3706/10000 [00:52<01:20, 78.51it/s]Processing train dataset:  42%|████▏     | 4158/10000 [00:56<01:03, 91.95it/s]Processing train dataset:  39%|███▊      | 3867/10000 [00:52<01:17, 79.24it/s]Processing train dataset:  38%|███▊      | 3757/10000 [00:52<01:21, 76.81it/s]Processing train dataset:  30%|███       | 3023/10000 [00:50<01:58, 59.09it/s]Processing train dataset:  37%|███▋      | 3714/10000 [00:52<01:26, 72.88it/s]Processing train dataset:  39%|███▉      | 3876/10000 [00:53<01:17, 79.47it/s]Processing train dataset:  42%|████▏     | 4168/10000 [00:56<01:07, 85.93it/s]Processing train dataset:  30%|███       | 3030/10000 [00:50<02:00, 57.93it/s]Processing train dataset:  38%|███▊      | 3765/10000 [00:53<01:34, 66.04it/s]Processing train dataset:  37%|███▋      | 3722/10000 [00:52<01:25, 73.73it/s]Processing train dataset:  39%|███▉      | 3884/10000 [00:53<01:19, 77.14it/s]Processing train dataset:  30%|███       | 3036/10000 [00:50<02:04, 55.94it/s]Processing train dataset:  38%|███▊      | 3772/10000 [00:53<01:36, 64.32it/s]Processing train dataset:  37%|███▋      | 3730/10000 [00:52<01:27, 71.69it/s]Processing train dataset:  42%|████▏     | 4177/10000 [00:56<01:19, 73.23it/s]Processing train dataset:  39%|███▉      | 3893/10000 [00:53<01:18, 78.12it/s]Processing train dataset:  30%|███       | 3043/10000 [00:50<02:02, 56.90it/s]Processing train dataset:  37%|███▋      | 3738/10000 [00:53<01:25, 73.31it/s]Processing train dataset:  38%|███▊      | 3779/10000 [00:53<01:41, 61.15it/s]Processing train dataset:  42%|████▏     | 4185/10000 [00:56<01:20, 71.85it/s]Processing train dataset:  39%|███▉      | 3901/10000 [00:53<01:17, 78.21it/s]Processing train dataset:  37%|███▋      | 3748/10000 [00:53<01:18, 79.19it/s]Processing train dataset:  30%|███       | 3050/10000 [00:51<01:57, 59.23it/s]Processing train dataset:  42%|████▏     | 4193/10000 [00:56<01:21, 70.91it/s]Processing train dataset:  39%|███▉      | 3909/10000 [00:53<01:20, 76.02it/s]Processing train dataset:  38%|███▊      | 3786/10000 [00:53<01:48, 57.23it/s]Processing train dataset:  38%|███▊      | 3756/10000 [00:53<01:19, 78.41it/s]Processing train dataset:  31%|███       | 3056/10000 [00:51<01:58, 58.62it/s]Processing train dataset:  39%|███▉      | 3917/10000 [00:53<01:19, 76.74it/s]Processing train dataset:  38%|███▊      | 3792/10000 [00:53<01:54, 54.06it/s]Processing train dataset:  42%|████▏     | 4201/10000 [00:57<01:30, 64.11it/s]Processing train dataset:  38%|███▊      | 3764/10000 [00:53<01:21, 76.31it/s]Processing train dataset:  31%|███       | 3062/10000 [00:51<02:02, 56.49it/s]Processing train dataset:  39%|███▉      | 3925/10000 [00:53<01:20, 75.46it/s]Processing train dataset:  38%|███▊      | 3798/10000 [00:53<01:54, 53.96it/s]Processing train dataset:  42%|████▏     | 4208/10000 [00:57<01:29, 64.70it/s]Processing train dataset:  38%|███▊      | 3773/10000 [00:53<01:19, 78.68it/s]Processing train dataset:  31%|███       | 3069/10000 [00:51<02:01, 56.93it/s]Processing train dataset:  39%|███▉      | 3933/10000 [00:53<01:21, 74.71it/s]Processing train dataset:  42%|████▏     | 4218/10000 [00:57<01:20, 71.83it/s]Processing train dataset:  38%|███▊      | 3804/10000 [00:53<01:55, 53.87it/s]Processing train dataset:  38%|███▊      | 3781/10000 [00:53<01:19, 78.33it/s]Processing train dataset:  31%|███       | 3075/10000 [00:51<02:03, 55.95it/s]Processing train dataset:  39%|███▉      | 3942/10000 [00:53<01:19, 75.94it/s]Processing train dataset:  38%|███▊      | 3810/10000 [00:53<01:56, 53.10it/s]Processing train dataset:  42%|████▏     | 4226/10000 [00:57<01:21, 70.50it/s]Processing train dataset:  38%|███▊      | 3789/10000 [00:53<01:22, 74.98it/s]Processing train dataset:  31%|███       | 3081/10000 [00:51<02:03, 56.10it/s]Processing train dataset:  40%|███▉      | 3951/10000 [00:54<01:18, 77.30it/s]Processing train dataset:  38%|███▊      | 3816/10000 [00:54<01:56, 53.02it/s]Processing train dataset:  42%|████▏     | 4236/10000 [00:57<01:16, 75.56it/s]Processing train dataset:  38%|███▊      | 3797/10000 [00:53<01:23, 74.27it/s]Processing train dataset:  31%|███       | 3088/10000 [00:51<01:55, 59.61it/s]Processing train dataset:  40%|███▉      | 3959/10000 [00:54<01:20, 75.49it/s]Processing train dataset:  42%|████▏     | 4245/10000 [00:57<01:13, 77.91it/s]Processing train dataset:  38%|███▊      | 3823/10000 [00:54<01:52, 54.94it/s]Processing train dataset:  31%|███       | 3094/10000 [00:51<01:58, 58.04it/s]Processing train dataset:  38%|███▊      | 3805/10000 [00:53<01:27, 71.02it/s]Processing train dataset:  40%|███▉      | 3967/10000 [00:54<01:22, 73.54it/s]Processing train dataset:  43%|████▎     | 4255/10000 [00:57<01:09, 82.85it/s]Processing train dataset:  38%|███▊      | 3829/10000 [00:54<01:55, 53.62it/s]Processing train dataset:  31%|███       | 3100/10000 [00:51<02:00, 57.44it/s]Processing train dataset:  38%|███▊      | 3813/10000 [00:54<01:26, 71.92it/s]Processing train dataset:  40%|███▉      | 3975/10000 [00:54<01:23, 72.45it/s]Processing train dataset:  43%|████▎     | 4264/10000 [00:57<01:10, 81.39it/s]Processing train dataset:  38%|███▊      | 3835/10000 [00:54<01:55, 53.43it/s]Processing train dataset:  38%|███▊      | 3821/10000 [00:54<01:24, 72.71it/s]Processing train dataset:  31%|███       | 3107/10000 [00:52<01:57, 58.51it/s]Processing train dataset:  40%|███▉      | 3983/10000 [00:54<01:21, 73.92it/s]Processing train dataset:  43%|████▎     | 4273/10000 [00:58<01:09, 82.36it/s]Processing train dataset:  38%|███▊      | 3841/10000 [00:54<01:51, 55.00it/s]Processing train dataset:  38%|███▊      | 3829/10000 [00:54<01:26, 71.28it/s]Processing train dataset:  31%|███       | 3116/10000 [00:52<01:49, 62.77it/s]Processing train dataset:  40%|███▉      | 3991/10000 [00:54<01:21, 73.73it/s]Processing train dataset:  43%|████▎     | 4282/10000 [00:58<01:09, 81.77it/s]Processing train dataset:  38%|███▊      | 3849/10000 [00:54<01:41, 60.90it/s]Processing train dataset:  38%|███▊      | 3837/10000 [00:54<01:23, 73.45it/s]Processing train dataset:  31%|███       | 3123/10000 [00:52<01:53, 60.82it/s]Processing train dataset:  40%|████      | 4000/10000 [00:54<01:18, 76.61it/s]Processing train dataset:  43%|████▎     | 4292/10000 [00:58<01:05, 86.71it/s]Processing train dataset:  39%|███▊      | 3858/10000 [00:54<01:30, 68.00it/s]Processing train dataset:  38%|███▊      | 3845/10000 [00:54<01:22, 74.63it/s]Processing train dataset:  40%|████      | 4008/10000 [00:54<01:19, 75.84it/s]Processing train dataset:  43%|████▎     | 4301/10000 [00:58<01:08, 82.60it/s]Processing train dataset:  31%|███▏      | 3130/10000 [00:52<02:05, 54.62it/s]Processing train dataset:  39%|███▊      | 3867/10000 [00:54<01:24, 72.22it/s]Processing train dataset:  39%|███▊      | 3853/10000 [00:54<01:25, 71.77it/s]Processing train dataset:  40%|████      | 4016/10000 [00:54<01:20, 74.45it/s]Processing train dataset:  43%|████▎     | 4311/10000 [00:58<01:06, 86.19it/s]Processing train dataset:  39%|███▉      | 3875/10000 [00:54<01:24, 72.30it/s]Processing train dataset:  31%|███▏      | 3137/10000 [00:52<02:03, 55.48it/s]Processing train dataset:  39%|███▊      | 3864/10000 [00:54<01:16, 79.94it/s]Processing train dataset:  40%|████      | 4024/10000 [00:55<01:18, 75.94it/s]Processing train dataset:  43%|████▎     | 4320/10000 [00:58<01:05, 87.25it/s]Processing train dataset:  39%|███▉      | 3883/10000 [00:55<01:27, 69.70it/s]Processing train dataset:  39%|███▊      | 3873/10000 [00:54<01:16, 80.46it/s]Processing train dataset:  31%|███▏      | 3143/10000 [00:52<02:12, 51.90it/s]Processing train dataset:  40%|████      | 4032/10000 [00:55<01:20, 73.83it/s]Processing train dataset:  43%|████▎     | 4329/10000 [00:58<01:07, 84.48it/s]Processing train dataset:  39%|███▉      | 3891/10000 [00:55<01:25, 71.72it/s]Processing train dataset:  31%|███▏      | 3149/10000 [00:52<02:08, 53.48it/s]Processing train dataset:  39%|███▉      | 3882/10000 [00:54<01:18, 77.55it/s]Processing train dataset:  40%|████      | 4040/10000 [00:55<01:19, 75.43it/s]Processing train dataset:  43%|████▎     | 4339/10000 [00:58<01:05, 87.08it/s]Processing train dataset:  39%|███▉      | 3900/10000 [00:55<01:21, 74.46it/s]Processing train dataset:  32%|███▏      | 3155/10000 [00:52<02:11, 52.22it/s]Processing train dataset:  40%|████      | 4049/10000 [00:55<01:15, 79.17it/s]Processing train dataset:  39%|███▉      | 3890/10000 [00:55<01:21, 75.04it/s]Processing train dataset:  43%|████▎     | 4348/10000 [00:58<01:07, 84.28it/s]Processing train dataset:  39%|███▉      | 3908/10000 [00:55<01:21, 74.68it/s]Processing train dataset:  32%|███▏      | 3161/10000 [00:52<02:06, 54.02it/s]Processing train dataset:  39%|███▉      | 3898/10000 [00:55<01:20, 75.47it/s]Processing train dataset:  41%|████      | 4057/10000 [00:55<01:16, 77.19it/s]Processing train dataset:  44%|████▎     | 4357/10000 [00:59<01:07, 84.19it/s]Processing train dataset:  39%|███▉      | 3916/10000 [00:55<01:20, 75.21it/s]Processing train dataset:  32%|███▏      | 3168/10000 [00:53<01:57, 58.12it/s]Processing train dataset:  41%|████      | 4065/10000 [00:55<01:17, 76.53it/s]Processing train dataset:  39%|███▉      | 3906/10000 [00:55<01:23, 73.10it/s]Processing train dataset:  44%|████▎     | 4366/10000 [00:59<01:09, 80.93it/s]Processing train dataset:  39%|███▉      | 3924/10000 [00:55<01:24, 71.56it/s]Processing train dataset:  32%|███▏      | 3176/10000 [00:53<01:50, 61.72it/s]Processing train dataset:  41%|████      | 4073/10000 [00:55<01:17, 76.11it/s]Processing train dataset:  39%|███▉      | 3914/10000 [00:55<01:23, 72.55it/s]Processing train dataset:  44%|████▍     | 4375/10000 [00:59<01:10, 80.04it/s]Processing train dataset:  39%|███▉      | 3932/10000 [00:55<01:24, 72.23it/s]Processing train dataset:  32%|███▏      | 3183/10000 [00:53<01:48, 62.69it/s]Processing train dataset:  41%|████      | 4082/10000 [00:55<01:15, 78.21it/s]Processing train dataset:  39%|███▉      | 3922/10000 [00:55<01:26, 70.38it/s]Processing train dataset:  44%|████▍     | 4384/10000 [00:59<01:10, 79.16it/s]Processing train dataset:  39%|███▉      | 3941/10000 [00:55<01:20, 75.00it/s]Processing train dataset:  32%|███▏      | 3190/10000 [00:53<01:52, 60.72it/s]Processing train dataset:  41%|████      | 4091/10000 [00:55<01:13, 80.03it/s]Processing train dataset:  39%|███▉      | 3930/10000 [00:55<01:26, 70.38it/s]Processing train dataset:  44%|████▍     | 4395/10000 [00:59<01:05, 85.59it/s]Processing train dataset:  40%|███▉      | 3950/10000 [00:55<01:18, 76.84it/s]Processing train dataset:  32%|███▏      | 3197/10000 [00:53<01:49, 62.25it/s]Processing train dataset:  41%|████      | 4100/10000 [00:56<01:13, 80.63it/s]Processing train dataset:  39%|███▉      | 3938/10000 [00:55<01:24, 71.41it/s]Processing train dataset:  44%|████▍     | 4404/10000 [00:59<01:04, 86.30it/s]Processing train dataset:  40%|███▉      | 3958/10000 [00:56<01:20, 75.42it/s]Processing train dataset:  32%|███▏      | 3204/10000 [00:53<01:51, 60.97it/s]Processing train dataset:  41%|████      | 4109/10000 [00:56<01:15, 77.90it/s]Processing train dataset:  39%|███▉      | 3948/10000 [00:55<01:18, 77.30it/s]Processing train dataset:  44%|████▍     | 4413/10000 [00:59<01:06, 84.02it/s]Processing train dataset:  40%|███▉      | 3966/10000 [00:56<01:22, 73.43it/s]Processing train dataset:  32%|███▏      | 3212/10000 [00:53<01:49, 62.15it/s]Processing train dataset:  41%|████      | 4117/10000 [00:56<01:18, 75.06it/s]Processing train dataset:  40%|███▉      | 3956/10000 [00:55<01:19, 75.79it/s]Processing train dataset:  44%|████▍     | 4422/10000 [00:59<01:08, 81.05it/s]Processing train dataset:  40%|███▉      | 3974/10000 [00:56<01:23, 72.19it/s]Processing train dataset:  32%|███▏      | 3219/10000 [00:53<01:46, 63.93it/s]Processing train dataset:  41%|████▏     | 4125/10000 [00:56<01:17, 75.96it/s]Processing train dataset:  40%|███▉      | 3964/10000 [00:56<01:19, 76.28it/s]Processing train dataset:  44%|████▍     | 4431/10000 [00:59<01:07, 82.87it/s]Processing train dataset:  40%|███▉      | 3982/10000 [00:56<01:21, 73.84it/s]Processing train dataset:  41%|████▏     | 4134/10000 [00:56<01:16, 76.91it/s]Processing train dataset:  40%|███▉      | 3972/10000 [00:56<01:19, 76.17it/s]Processing train dataset:  32%|███▏      | 3226/10000 [00:54<01:51, 60.79it/s]Processing train dataset:  40%|███▉      | 3990/10000 [00:56<01:21, 73.91it/s]Processing train dataset:  44%|████▍     | 4440/10000 [01:00<01:11, 77.58it/s]Processing train dataset:  41%|████▏     | 4142/10000 [00:56<01:17, 75.94it/s]Processing train dataset:  40%|███▉      | 3981/10000 [00:56<01:17, 77.51it/s]Processing train dataset:  40%|███▉      | 3999/10000 [00:56<01:17, 77.69it/s]Processing train dataset:  32%|███▏      | 3233/10000 [00:54<02:08, 52.86it/s]Processing train dataset:  44%|████▍     | 4448/10000 [01:00<01:13, 75.62it/s]Processing train dataset:  42%|████▏     | 4151/10000 [00:56<01:15, 77.59it/s]Processing train dataset:  40%|███▉      | 3989/10000 [00:56<01:18, 76.82it/s]Processing train dataset:  40%|████      | 4007/10000 [00:56<01:18, 76.81it/s]Processing train dataset:  32%|███▏      | 3239/10000 [00:54<02:15, 49.96it/s]Processing train dataset:  40%|███▉      | 3997/10000 [00:56<01:17, 77.12it/s]Processing train dataset:  42%|████▏     | 4160/10000 [00:56<01:13, 79.36it/s]Processing train dataset:  45%|████▍     | 4456/10000 [01:00<01:26, 64.12it/s]Processing train dataset:  40%|████      | 4015/10000 [00:56<01:17, 77.46it/s]Processing train dataset:  40%|████      | 4006/10000 [00:56<01:14, 80.09it/s]Processing train dataset:  42%|████▏     | 4168/10000 [00:56<01:15, 77.13it/s]Processing train dataset:  32%|███▏      | 3245/10000 [00:54<02:19, 48.53it/s]Processing train dataset:  45%|████▍     | 4463/10000 [01:00<01:24, 65.51it/s]Processing train dataset:  40%|████      | 4024/10000 [00:56<01:14, 80.33it/s]Processing train dataset:  40%|████      | 4015/10000 [00:56<01:14, 80.01it/s]Processing train dataset:  42%|████▏     | 4176/10000 [00:57<01:16, 75.65it/s]Processing train dataset:  32%|███▎      | 3250/10000 [00:54<02:25, 46.44it/s]Processing train dataset:  40%|████      | 4033/10000 [00:57<01:16, 77.93it/s]Processing train dataset:  45%|████▍     | 4470/10000 [01:00<01:31, 60.11it/s]Processing train dataset:  40%|████      | 4024/10000 [00:56<01:13, 81.66it/s]Processing train dataset:  42%|████▏     | 4184/10000 [00:57<01:17, 74.97it/s]Processing train dataset:  33%|███▎      | 3256/10000 [00:54<02:22, 47.23it/s]Processing train dataset:  40%|████      | 4042/10000 [00:57<01:15, 78.73it/s]Processing train dataset:  45%|████▍     | 4477/10000 [01:00<01:38, 56.19it/s]Processing train dataset:  42%|████▏     | 4194/10000 [00:57<01:13, 79.25it/s]Processing train dataset:  33%|███▎      | 3261/10000 [00:54<02:21, 47.65it/s]Processing train dataset:  40%|████      | 4033/10000 [00:56<01:23, 71.66it/s]Processing train dataset:  41%|████      | 4051/10000 [00:57<01:12, 81.81it/s]Processing train dataset:  45%|████▍     | 4483/10000 [01:00<01:37, 56.78it/s]Processing train dataset:  42%|████▏     | 4202/10000 [00:57<01:14, 77.53it/s]Processing train dataset:  33%|███▎      | 3268/10000 [00:54<02:13, 50.48it/s]Processing train dataset:  40%|████      | 4041/10000 [00:57<01:26, 68.61it/s]Processing train dataset:  45%|████▍     | 4490/10000 [01:00<01:32, 59.80it/s]Processing train dataset:  41%|████      | 4060/10000 [00:57<01:20, 74.11it/s]Processing train dataset:  42%|████▏     | 4210/10000 [00:57<01:20, 71.49it/s]Processing train dataset:  33%|███▎      | 3276/10000 [00:55<02:04, 54.12it/s]Processing train dataset:  40%|████      | 4049/10000 [00:57<01:27, 67.67it/s]Processing train dataset:  45%|████▍     | 4497/10000 [01:01<01:29, 61.38it/s]Processing train dataset:  41%|████      | 4068/10000 [00:57<01:22, 71.99it/s]Processing train dataset:  42%|████▏     | 4219/10000 [00:57<01:16, 76.04it/s]Processing train dataset:  33%|███▎      | 3284/10000 [00:55<01:54, 58.44it/s]Processing train dataset:  41%|████      | 4056/10000 [00:57<01:31, 65.06it/s]Processing train dataset:  45%|████▌     | 4505/10000 [01:01<01:26, 63.48it/s]Processing train dataset:  41%|████      | 4076/10000 [00:57<01:23, 71.03it/s]Processing train dataset:  42%|████▏     | 4227/10000 [00:57<01:14, 76.99it/s]Processing train dataset:  33%|███▎      | 3294/10000 [00:55<01:39, 67.67it/s]Processing train dataset:  45%|████▌     | 4512/10000 [01:01<01:25, 64.49it/s]Processing train dataset:  41%|████      | 4063/10000 [00:57<01:34, 62.51it/s]Processing train dataset:  41%|████      | 4084/10000 [00:57<01:22, 71.69it/s]Processing train dataset:  42%|████▏     | 4235/10000 [00:57<01:18, 73.16it/s]Processing train dataset:  33%|███▎      | 3304/10000 [00:55<01:29, 74.81it/s]Processing train dataset:  45%|████▌     | 4521/10000 [01:01<01:17, 70.71it/s]Processing train dataset:  41%|████      | 4092/10000 [00:57<01:20, 73.46it/s]Processing train dataset:  41%|████      | 4070/10000 [00:57<01:37, 61.13it/s]Processing train dataset:  42%|████▏     | 4243/10000 [00:57<01:16, 74.81it/s]Processing train dataset:  33%|███▎      | 3314/10000 [00:55<01:23, 80.09it/s]Processing train dataset:  41%|████      | 4100/10000 [00:57<01:18, 74.80it/s]Processing train dataset:  45%|████▌     | 4529/10000 [01:01<01:21, 67.52it/s]Processing train dataset:  43%|████▎     | 4251/10000 [00:58<01:17, 74.00it/s]Processing train dataset:  41%|████      | 4077/10000 [00:57<01:45, 56.38it/s]Processing train dataset:  33%|███▎      | 3323/10000 [00:55<01:26, 77.34it/s]Processing train dataset:  41%|████      | 4108/10000 [00:58<01:20, 73.25it/s]Processing train dataset:  45%|████▌     | 4536/10000 [01:01<01:22, 65.95it/s]Processing train dataset:  43%|████▎     | 4259/10000 [00:58<01:19, 71.87it/s]Processing train dataset:  41%|████      | 4085/10000 [00:57<01:37, 60.40it/s]Processing train dataset:  33%|███▎      | 3331/10000 [00:55<01:30, 73.52it/s]Processing train dataset:  45%|████▌     | 4543/10000 [01:01<01:22, 65.98it/s]Processing train dataset:  41%|████      | 4116/10000 [00:58<01:20, 72.85it/s]Processing train dataset:  43%|████▎     | 4267/10000 [00:58<01:18, 73.04it/s]Processing train dataset:  41%|████      | 4094/10000 [00:57<01:30, 64.98it/s]Processing train dataset:  46%|████▌     | 4551/10000 [01:01<01:19, 68.43it/s]Processing train dataset:  41%|████▏     | 4125/10000 [00:58<01:18, 75.26it/s]Processing train dataset:  33%|███▎      | 3339/10000 [00:55<01:38, 67.74it/s]Processing train dataset:  43%|████▎     | 4275/10000 [00:58<01:19, 71.78it/s]Processing train dataset:  41%|████      | 4102/10000 [00:58<01:27, 67.06it/s]Processing train dataset:  46%|████▌     | 4559/10000 [01:01<01:16, 71.08it/s]Processing train dataset:  41%|████▏     | 4133/10000 [00:58<01:17, 75.53it/s]Processing train dataset:  43%|████▎     | 4283/10000 [00:58<01:17, 73.66it/s]Processing train dataset:  33%|███▎      | 3347/10000 [00:56<01:40, 66.08it/s]Processing train dataset:  41%|████      | 4110/10000 [00:58<01:26, 68.41it/s]Processing train dataset:  46%|████▌     | 4567/10000 [01:02<01:16, 70.79it/s]Processing train dataset:  41%|████▏     | 4141/10000 [00:58<01:18, 74.40it/s]Processing train dataset:  43%|████▎     | 4293/10000 [00:58<01:11, 79.55it/s]Processing train dataset:  34%|███▎      | 3354/10000 [00:56<01:39, 66.63it/s]Processing train dataset:  41%|████      | 4117/10000 [00:58<01:27, 67.05it/s]Processing train dataset:  42%|████▏     | 4150/10000 [00:58<01:17, 75.92it/s]Processing train dataset:  43%|████▎     | 4301/10000 [00:58<01:14, 76.87it/s]Processing train dataset:  46%|████▌     | 4575/10000 [01:02<01:24, 64.51it/s]Processing train dataset:  34%|███▎      | 3362/10000 [00:56<01:37, 68.09it/s]Processing train dataset:  41%|████      | 4124/10000 [00:58<01:28, 66.50it/s]Processing train dataset:  42%|████▏     | 4160/10000 [00:58<01:13, 79.72it/s]Processing train dataset:  43%|████▎     | 4309/10000 [00:58<01:15, 75.11it/s]Processing train dataset:  34%|███▎      | 3370/10000 [00:56<01:35, 69.48it/s]Processing train dataset:  46%|████▌     | 4582/10000 [01:02<01:26, 62.70it/s]Processing train dataset:  41%|████▏     | 4131/10000 [00:58<01:28, 66.01it/s]Processing train dataset:  42%|████▏     | 4168/10000 [00:58<01:14, 77.93it/s]Processing train dataset:  43%|████▎     | 4317/10000 [00:58<01:14, 75.99it/s]Processing train dataset:  34%|███▍      | 3378/10000 [00:56<01:34, 70.31it/s]Processing train dataset:  46%|████▌     | 4590/10000 [01:02<01:22, 65.24it/s]Processing train dataset:  41%|████▏     | 4138/10000 [00:58<01:30, 64.51it/s]Processing train dataset:  43%|████▎     | 4325/10000 [00:58<01:15, 75.60it/s]Processing train dataset:  42%|████▏     | 4176/10000 [00:59<01:20, 72.76it/s]Processing train dataset:  46%|████▌     | 4598/10000 [01:02<01:20, 67.18it/s]Processing train dataset:  41%|████▏     | 4146/10000 [00:58<01:26, 67.94it/s]Processing train dataset:  34%|███▍      | 3386/10000 [00:56<01:36, 68.66it/s]Processing train dataset:  43%|████▎     | 4334/10000 [00:59<01:13, 76.63it/s]Processing train dataset:  42%|████▏     | 4187/10000 [00:59<01:12, 79.63it/s]Processing train dataset:  42%|████▏     | 4154/10000 [00:58<01:23, 70.02it/s]Processing train dataset:  34%|███▍      | 3393/10000 [00:56<01:49, 60.16it/s]Processing train dataset:  46%|████▌     | 4605/10000 [01:02<01:32, 58.01it/s]Processing train dataset:  43%|████▎     | 4342/10000 [00:59<01:15, 75.43it/s]Processing train dataset:  42%|████▏     | 4196/10000 [00:59<01:12, 79.69it/s]Processing train dataset:  42%|████▏     | 4162/10000 [00:58<01:22, 70.75it/s]Processing train dataset:  42%|████▏     | 4204/10000 [00:59<01:12, 79.50it/s]Processing train dataset:  44%|████▎     | 4351/10000 [00:59<01:13, 77.01it/s]Processing train dataset:  42%|████▏     | 4170/10000 [00:59<01:34, 61.39it/s]Processing train dataset:  44%|████▎     | 4360/10000 [00:59<01:11, 78.42it/s]Processing train dataset:  42%|████▏     | 4213/10000 [00:59<01:14, 77.18it/s]Processing train dataset:  46%|████▌     | 4612/10000 [01:02<02:07, 42.21it/s]Processing train dataset:  34%|███▍      | 3400/10000 [00:57<02:39, 41.35it/s]Processing train dataset:  42%|████▏     | 4177/10000 [00:59<01:37, 59.69it/s]Processing train dataset:  44%|████▎     | 4369/10000 [00:59<01:11, 79.16it/s]Processing train dataset:  42%|████▏     | 4221/10000 [00:59<01:14, 77.16it/s]Processing train dataset:  46%|████▌     | 4618/10000 [01:03<01:58, 45.39it/s]Processing train dataset:  34%|███▍      | 3407/10000 [00:57<02:23, 45.88it/s]Processing train dataset:  42%|████▏     | 4229/10000 [00:59<01:14, 77.30it/s]Processing train dataset:  44%|████▍     | 4378/10000 [00:59<01:10, 80.15it/s]Processing train dataset:  42%|████▏     | 4184/10000 [00:59<01:39, 58.25it/s]Processing train dataset:  46%|████▋     | 4627/10000 [01:03<01:42, 52.65it/s]Processing train dataset:  34%|███▍      | 3414/10000 [00:57<02:12, 49.62it/s]Processing train dataset:  42%|████▏     | 4190/10000 [00:59<01:42, 56.51it/s]Processing train dataset:  42%|████▏     | 4237/10000 [00:59<01:19, 72.81it/s]Processing train dataset:  44%|████▍     | 4387/10000 [00:59<01:16, 73.46it/s]Processing train dataset:  46%|████▋     | 4633/10000 [01:03<01:50, 48.59it/s]Processing train dataset:  34%|███▍      | 3420/10000 [00:57<02:20, 46.86it/s]Processing train dataset:  42%|████▏     | 4196/10000 [00:59<01:41, 56.96it/s]Processing train dataset:  42%|████▏     | 4245/10000 [00:59<01:17, 74.10it/s]Processing train dataset:  44%|████▍     | 4396/10000 [00:59<01:12, 77.79it/s]Processing train dataset:  46%|████▋     | 4639/10000 [01:03<01:47, 50.03it/s]Processing train dataset:  34%|███▍      | 3428/10000 [00:57<02:04, 52.69it/s]Processing train dataset:  42%|████▏     | 4202/10000 [00:59<01:47, 53.98it/s]Processing train dataset:  44%|████▍     | 4404/10000 [01:00<01:15, 73.63it/s]Processing train dataset:  43%|████▎     | 4253/10000 [01:00<01:26, 66.66it/s]Processing train dataset:  46%|████▋     | 4645/10000 [01:03<01:42, 52.14it/s]Processing train dataset:  34%|███▍      | 3436/10000 [00:57<01:51, 58.96it/s]Processing train dataset:  42%|████▏     | 4208/10000 [00:59<01:53, 51.19it/s]Processing train dataset:  43%|████▎     | 4260/10000 [01:00<01:28, 64.64it/s]Processing train dataset:  44%|████▍     | 4412/10000 [01:00<01:20, 69.62it/s]Processing train dataset:  47%|████▋     | 4651/10000 [01:03<01:48, 49.23it/s]Processing train dataset:  34%|███▍      | 3443/10000 [00:57<01:56, 56.29it/s]Processing train dataset:  42%|████▏     | 4218/10000 [00:59<01:34, 61.17it/s]Processing train dataset:  43%|████▎     | 4269/10000 [01:00<01:22, 69.80it/s]Processing train dataset:  44%|████▍     | 4420/10000 [01:00<01:18, 70.77it/s]Processing train dataset:  47%|████▋     | 4657/10000 [01:03<01:56, 45.89it/s]Processing train dataset:  43%|████▎     | 4277/10000 [01:00<01:19, 72.15it/s]Processing train dataset:  34%|███▍      | 3449/10000 [00:57<02:08, 50.91it/s]Processing train dataset:  44%|████▍     | 4428/10000 [01:00<01:19, 70.21it/s]Processing train dataset:  42%|████▏     | 4225/10000 [01:00<01:44, 55.27it/s]Processing train dataset:  43%|████▎     | 4285/10000 [01:00<01:21, 69.91it/s]Processing train dataset:  47%|████▋     | 4662/10000 [01:03<02:08, 41.56it/s]Processing train dataset:  35%|███▍      | 3455/10000 [00:58<02:16, 48.01it/s]Processing train dataset:  44%|████▍     | 4436/10000 [01:00<01:22, 67.45it/s]Processing train dataset:  42%|████▏     | 4231/10000 [01:00<01:51, 51.85it/s]Processing train dataset:  43%|████▎     | 4295/10000 [01:00<01:15, 75.57it/s]Processing train dataset:  47%|████▋     | 4670/10000 [01:04<01:49, 48.55it/s]Processing train dataset:  35%|███▍      | 3462/10000 [00:58<02:05, 51.99it/s]Processing train dataset:  44%|████▍     | 4445/10000 [01:00<01:17, 71.76it/s]Processing train dataset:  42%|████▏     | 4238/10000 [01:00<01:47, 53.57it/s]Processing train dataset:  43%|████▎     | 4303/10000 [01:00<01:18, 72.44it/s]Processing train dataset:  47%|████▋     | 4676/10000 [01:04<01:49, 48.77it/s]Processing train dataset:  35%|███▍      | 3468/10000 [00:58<02:07, 51.22it/s]Processing train dataset:  45%|████▍     | 4453/10000 [01:00<01:18, 70.34it/s]Processing train dataset:  42%|████▏     | 4246/10000 [01:00<01:39, 57.87it/s]Processing train dataset:  43%|████▎     | 4311/10000 [01:00<01:17, 73.28it/s]Processing train dataset:  45%|████▍     | 4462/10000 [01:00<01:15, 73.57it/s]Processing train dataset:  35%|███▍      | 3474/10000 [00:58<02:10, 50.17it/s]Processing train dataset:  47%|████▋     | 4682/10000 [01:04<01:54, 46.43it/s]Processing train dataset:  43%|████▎     | 4252/10000 [01:00<01:46, 53.85it/s]Processing train dataset:  43%|████▎     | 4319/10000 [01:00<01:18, 72.32it/s]Processing train dataset:  35%|███▍      | 3481/10000 [00:58<01:58, 54.79it/s]Processing train dataset:  45%|████▍     | 4470/10000 [01:00<01:20, 68.95it/s]Processing train dataset:  43%|████▎     | 4329/10000 [01:01<01:15, 75.32it/s]Processing train dataset:  45%|████▍     | 4477/10000 [01:01<01:24, 65.44it/s]Processing train dataset:  47%|████▋     | 4690/10000 [01:04<02:07, 41.70it/s]Processing train dataset:  43%|████▎     | 4258/10000 [01:00<02:07, 45.02it/s]Processing train dataset:  35%|███▍      | 3487/10000 [00:58<02:19, 46.56it/s]Processing train dataset:  43%|████▎     | 4337/10000 [01:01<01:19, 70.90it/s]Processing train dataset:  43%|████▎     | 4264/10000 [01:00<01:58, 48.21it/s]Processing train dataset:  47%|████▋     | 4696/10000 [01:04<01:58, 44.75it/s]Processing train dataset:  45%|████▍     | 4486/10000 [01:01<01:19, 69.76it/s]Processing train dataset:  35%|███▍      | 3494/10000 [00:58<02:06, 51.48it/s]Processing train dataset:  43%|████▎     | 4346/10000 [01:01<01:16, 74.31it/s]Processing train dataset:  43%|████▎     | 4271/10000 [01:01<01:49, 52.42it/s]Processing train dataset:  47%|████▋     | 4705/10000 [01:04<01:38, 53.79it/s]Processing train dataset:  45%|████▍     | 4494/10000 [01:01<01:17, 70.85it/s]Processing train dataset:  35%|███▌      | 3502/10000 [00:58<01:52, 57.99it/s]Processing train dataset:  44%|████▎     | 4354/10000 [01:01<01:16, 73.76it/s]Processing train dataset:  43%|████▎     | 4280/10000 [01:01<01:34, 60.84it/s]Processing train dataset:  47%|████▋     | 4714/10000 [01:04<01:25, 62.00it/s]Processing train dataset:  45%|████▌     | 4502/10000 [01:01<01:20, 68.45it/s]Processing train dataset:  35%|███▌      | 3510/10000 [00:59<01:42, 63.16it/s]Processing train dataset:  44%|████▎     | 4364/10000 [01:01<01:12, 78.07it/s]Processing train dataset:  47%|████▋     | 4722/10000 [01:05<01:19, 66.29it/s]Processing train dataset:  43%|████▎     | 4291/10000 [01:01<01:18, 72.91it/s]Processing train dataset:  35%|███▌      | 3520/10000 [00:59<01:29, 72.75it/s]Processing train dataset:  45%|████▌     | 4510/10000 [01:01<01:18, 69.58it/s]Processing train dataset:  44%|████▎     | 4372/10000 [01:01<01:12, 77.89it/s]Processing train dataset:  43%|████▎     | 4299/10000 [01:01<01:17, 73.86it/s]Processing train dataset:  47%|████▋     | 4730/10000 [01:05<01:17, 67.65it/s]Processing train dataset:  45%|████▌     | 4520/10000 [01:01<01:10, 77.34it/s]Processing train dataset:  35%|███▌      | 3529/10000 [00:59<01:25, 75.82it/s]Processing train dataset:  44%|████▍     | 4380/10000 [01:01<01:15, 74.82it/s]Processing train dataset:  43%|████▎     | 4307/10000 [01:01<01:20, 70.92it/s]Processing train dataset:  45%|████▌     | 4528/10000 [01:01<01:11, 76.24it/s]Processing train dataset:  47%|████▋     | 4738/10000 [01:05<01:25, 61.28it/s]Processing train dataset:  44%|████▍     | 4388/10000 [01:01<01:18, 71.24it/s]Processing train dataset:  43%|████▎     | 4315/10000 [01:01<01:23, 67.99it/s]Processing train dataset:  45%|████▌     | 4536/10000 [01:01<01:17, 70.13it/s]Processing train dataset:  35%|███▌      | 3537/10000 [00:59<01:57, 54.79it/s]Processing train dataset:  44%|████▍     | 4396/10000 [01:01<01:16, 73.46it/s]Processing train dataset:  43%|████▎     | 4323/10000 [01:01<01:23, 67.88it/s]Processing train dataset:  45%|████▌     | 4544/10000 [01:02<01:17, 70.55it/s]Processing train dataset:  47%|████▋     | 4745/10000 [01:05<01:50, 47.67it/s]Processing train dataset:  44%|████▍     | 4404/10000 [01:02<01:15, 74.08it/s]Processing train dataset:  35%|███▌      | 3544/10000 [00:59<02:10, 49.49it/s]Processing train dataset:  43%|████▎     | 4331/10000 [01:01<01:21, 69.28it/s]Processing train dataset:  46%|████▌     | 4552/10000 [01:02<01:14, 72.74it/s]Processing train dataset:  48%|████▊     | 4753/10000 [01:05<01:37, 53.70it/s]Processing train dataset:  44%|████▍     | 4412/10000 [01:02<01:15, 74.46it/s]Processing train dataset:  36%|███▌      | 3551/10000 [00:59<02:02, 52.60it/s]Processing train dataset:  43%|████▎     | 4339/10000 [01:01<01:21, 69.60it/s]Processing train dataset:  48%|████▊     | 4760/10000 [01:05<01:31, 57.12it/s]Processing train dataset:  46%|████▌     | 4560/10000 [01:02<01:18, 69.27it/s]Processing train dataset:  44%|████▍     | 4420/10000 [01:02<01:14, 74.62it/s]Processing train dataset:  36%|███▌      | 3559/10000 [00:59<01:51, 57.79it/s]Processing train dataset:  48%|████▊     | 4767/10000 [01:05<01:27, 59.82it/s]Processing train dataset:  46%|████▌     | 4568/10000 [01:02<01:16, 71.42it/s]Processing train dataset:  43%|████▎     | 4347/10000 [01:02<01:24, 66.92it/s]Processing train dataset:  44%|████▍     | 4428/10000 [01:02<01:18, 70.66it/s]Processing train dataset:  36%|███▌      | 3566/10000 [00:59<01:50, 57.97it/s]Processing train dataset:  46%|████▌     | 4576/10000 [01:02<01:14, 72.50it/s]Processing train dataset:  48%|████▊     | 4774/10000 [01:05<01:29, 58.71it/s]Processing train dataset:  44%|████▎     | 4354/10000 [01:02<01:27, 64.39it/s]Processing train dataset:  44%|████▍     | 4436/10000 [01:02<01:18, 70.49it/s]Processing train dataset:  36%|███▌      | 3573/10000 [01:00<01:46, 60.60it/s]Processing train dataset:  46%|████▌     | 4584/10000 [01:02<01:13, 73.20it/s]Processing train dataset:  48%|████▊     | 4781/10000 [01:06<01:27, 59.53it/s]Processing train dataset:  44%|████▎     | 4362/10000 [01:02<01:25, 66.01it/s]Processing train dataset:  44%|████▍     | 4444/10000 [01:02<01:18, 70.67it/s]Processing train dataset:  46%|████▌     | 4592/10000 [01:02<01:12, 74.36it/s]Processing train dataset:  36%|███▌      | 3580/10000 [01:00<01:51, 57.35it/s]Processing train dataset:  48%|████▊     | 4789/10000 [01:06<01:22, 63.35it/s]Processing train dataset:  44%|████▎     | 4369/10000 [01:02<01:25, 66.02it/s]Processing train dataset:  45%|████▍     | 4452/10000 [01:02<01:19, 69.92it/s]Processing train dataset:  46%|████▌     | 4601/10000 [01:02<01:09, 77.54it/s]Processing train dataset:  36%|███▌      | 3588/10000 [01:00<01:51, 57.42it/s]Processing train dataset:  48%|████▊     | 4798/10000 [01:06<01:18, 66.40it/s]Processing train dataset:  44%|████▍     | 4377/10000 [01:02<01:24, 66.66it/s]Processing train dataset:  45%|████▍     | 4460/10000 [01:02<01:17, 71.05it/s]Processing train dataset:  46%|████▌     | 4609/10000 [01:02<01:12, 74.69it/s]Processing train dataset:  36%|███▌      | 3594/10000 [01:00<01:50, 57.95it/s]Processing train dataset:  48%|████▊     | 4807/10000 [01:06<01:12, 71.34it/s]Processing train dataset:  44%|████▍     | 4384/10000 [01:02<01:26, 64.60it/s]Processing train dataset:  46%|████▌     | 4617/10000 [01:03<01:14, 72.04it/s]Processing train dataset:  45%|████▍     | 4468/10000 [01:03<01:28, 62.51it/s]Processing train dataset:  36%|███▌      | 3600/10000 [01:00<01:57, 54.32it/s]Processing train dataset:  48%|████▊     | 4815/10000 [01:06<01:13, 70.40it/s]Processing train dataset:  44%|████▍     | 4392/10000 [01:02<01:23, 66.85it/s]Processing train dataset:  46%|████▋     | 4626/10000 [01:03<01:10, 75.77it/s]Processing train dataset:  36%|███▌      | 3607/10000 [01:00<01:51, 57.42it/s]Processing train dataset:  48%|████▊     | 4827/10000 [01:06<01:03, 81.86it/s]Processing train dataset:  44%|████▍     | 4400/10000 [01:02<01:20, 69.66it/s]Processing train dataset:  45%|████▍     | 4475/10000 [01:03<01:34, 58.39it/s]Processing train dataset:  46%|████▋     | 4634/10000 [01:03<01:13, 72.69it/s]Processing train dataset:  36%|███▌      | 3614/10000 [01:00<01:47, 59.48it/s]Processing train dataset:  44%|████▍     | 4408/10000 [01:02<01:19, 70.33it/s]Processing train dataset:  48%|████▊     | 4836/10000 [01:06<01:05, 79.32it/s]Processing train dataset:  46%|████▋     | 4643/10000 [01:03<01:11, 75.04it/s]Processing train dataset:  44%|████▍     | 4416/10000 [01:03<01:21, 68.74it/s]Processing train dataset:  36%|███▌      | 3621/10000 [01:00<01:50, 57.75it/s]Processing train dataset:  48%|████▊     | 4845/10000 [01:06<01:09, 74.03it/s]Processing train dataset:  45%|████▍     | 4482/10000 [01:03<02:03, 44.75it/s]Processing train dataset:  47%|████▋     | 4651/10000 [01:03<01:13, 73.15it/s]Processing train dataset:  36%|███▋      | 3627/10000 [01:01<01:52, 56.46it/s]Processing train dataset:  44%|████▍     | 4423/10000 [01:03<01:25, 65.55it/s]Processing train dataset:  49%|████▊     | 4853/10000 [01:07<01:16, 66.87it/s]Processing train dataset:  47%|████▋     | 4659/10000 [01:03<01:13, 72.62it/s]Processing train dataset:  44%|████▍     | 4430/10000 [01:03<01:26, 64.42it/s]Processing train dataset:  36%|███▋      | 3633/10000 [01:01<02:03, 51.66it/s]Processing train dataset:  47%|████▋     | 4667/10000 [01:03<01:13, 72.28it/s]Processing train dataset:  49%|████▊     | 4860/10000 [01:07<01:26, 59.30it/s]Processing train dataset:  44%|████▍     | 4438/10000 [01:03<01:22, 67.10it/s]Processing train dataset:  45%|████▍     | 4488/10000 [01:03<02:45, 33.28it/s]Processing train dataset:  36%|███▋      | 3639/10000 [01:01<02:01, 52.22it/s]Processing train dataset:  47%|████▋     | 4677/10000 [01:03<01:09, 76.26it/s]Processing train dataset:  44%|████▍     | 4446/10000 [01:03<01:19, 70.00it/s]Processing train dataset:  45%|████▍     | 4493/10000 [01:03<02:41, 34.19it/s]Processing train dataset:  49%|████▊     | 4867/10000 [01:07<01:36, 53.29it/s]Processing train dataset:  47%|████▋     | 4685/10000 [01:03<01:10, 75.45it/s]Processing train dataset:  36%|███▋      | 3645/10000 [01:01<02:18, 45.78it/s]Processing train dataset:  45%|████▍     | 4455/10000 [01:03<01:14, 74.70it/s]Processing train dataset:  45%|████▌     | 4500/10000 [01:03<02:16, 40.33it/s]Processing train dataset:  49%|████▉     | 4875/10000 [01:07<01:27, 58.45it/s]Processing train dataset:  37%|███▋      | 3653/10000 [01:01<01:58, 53.35it/s]Processing train dataset:  47%|████▋     | 4693/10000 [01:04<01:10, 74.99it/s]Processing train dataset:  45%|████▍     | 4465/10000 [01:03<01:09, 79.29it/s]Processing train dataset:  45%|████▌     | 4507/10000 [01:04<01:59, 46.14it/s]Processing train dataset:  49%|████▉     | 4882/10000 [01:07<01:26, 59.37it/s]Processing train dataset:  37%|███▋      | 3660/10000 [01:01<01:50, 57.37it/s]Processing train dataset:  47%|████▋     | 4702/10000 [01:04<01:08, 76.97it/s]Processing train dataset:  45%|████▍     | 4473/10000 [01:03<01:11, 77.06it/s]Processing train dataset:  45%|████▌     | 4514/10000 [01:04<01:48, 50.34it/s]Processing train dataset:  49%|████▉     | 4889/10000 [01:07<01:23, 60.97it/s]Processing train dataset:  37%|███▋      | 3667/10000 [01:01<01:45, 60.01it/s]Processing train dataset:  47%|████▋     | 4711/10000 [01:04<01:06, 80.14it/s]Processing train dataset:  45%|████▍     | 4481/10000 [01:03<01:13, 75.24it/s]Processing train dataset:  45%|████▌     | 4522/10000 [01:04<01:36, 56.97it/s]Processing train dataset:  49%|████▉     | 4897/10000 [01:07<01:18, 65.21it/s]Processing train dataset:  37%|███▋      | 3676/10000 [01:01<01:39, 63.84it/s]Processing train dataset:  47%|████▋     | 4720/10000 [01:04<01:07, 77.97it/s]Processing train dataset:  45%|████▍     | 4489/10000 [01:04<01:15, 72.66it/s]Processing train dataset:  45%|████▌     | 4529/10000 [01:04<01:30, 60.19it/s]Processing train dataset:  49%|████▉     | 4905/10000 [01:07<01:17, 65.50it/s]Processing train dataset:  47%|████▋     | 4728/10000 [01:04<01:08, 76.87it/s]Processing train dataset:  37%|███▋      | 3683/10000 [01:02<01:44, 60.69it/s]Processing train dataset:  45%|████▍     | 4498/10000 [01:04<01:13, 75.21it/s]Processing train dataset:  45%|████▌     | 4536/10000 [01:04<01:34, 58.02it/s]Processing train dataset:  49%|████▉     | 4912/10000 [01:08<01:16, 66.31it/s]Processing train dataset:  47%|████▋     | 4736/10000 [01:04<01:08, 76.86it/s]Processing train dataset:  45%|████▌     | 4506/10000 [01:04<01:12, 75.65it/s]Processing train dataset:  37%|███▋      | 3690/10000 [01:02<01:44, 60.50it/s]Processing train dataset:  45%|████▌     | 4544/10000 [01:04<01:28, 61.95it/s]Processing train dataset:  49%|████▉     | 4920/10000 [01:08<01:12, 70.01it/s]Processing train dataset:  47%|████▋     | 4744/10000 [01:04<01:09, 75.77it/s]Processing train dataset:  37%|███▋      | 3699/10000 [01:02<01:33, 67.06it/s]Processing train dataset:  45%|████▌     | 4516/10000 [01:04<01:07, 80.71it/s]Processing train dataset:  49%|████▉     | 4930/10000 [01:08<01:06, 76.42it/s]Processing train dataset:  46%|████▌     | 4552/10000 [01:04<01:27, 62.57it/s]Processing train dataset:  48%|████▊     | 4752/10000 [01:04<01:09, 75.09it/s]Processing train dataset:  45%|████▌     | 4525/10000 [01:04<01:07, 80.54it/s]Processing train dataset:  37%|███▋      | 3706/10000 [01:02<01:40, 62.65it/s]Processing train dataset:  49%|████▉     | 4938/10000 [01:08<01:06, 75.61it/s]Processing train dataset:  46%|████▌     | 4559/10000 [01:04<01:25, 63.32it/s]Processing train dataset:  48%|████▊     | 4760/10000 [01:04<01:10, 74.33it/s]Processing train dataset:  45%|████▌     | 4534/10000 [01:04<01:08, 79.57it/s]Processing train dataset:  49%|████▉     | 4947/10000 [01:08<01:05, 77.52it/s]Processing train dataset:  46%|████▌     | 4567/10000 [01:04<01:21, 66.91it/s]Processing train dataset:  37%|███▋      | 3713/10000 [01:02<01:45, 59.46it/s]Processing train dataset:  48%|████▊     | 4768/10000 [01:05<01:10, 73.83it/s]Processing train dataset:  45%|████▌     | 4542/10000 [01:04<01:13, 74.66it/s]Processing train dataset:  50%|████▉     | 4956/10000 [01:08<01:03, 79.38it/s]Processing train dataset:  37%|███▋      | 3720/10000 [01:02<01:42, 61.29it/s]Processing train dataset:  46%|████▌     | 4574/10000 [01:05<01:24, 64.06it/s]Processing train dataset:  48%|████▊     | 4776/10000 [01:05<01:10, 73.61it/s]Processing train dataset:  46%|████▌     | 4550/10000 [01:04<01:13, 73.92it/s]Processing train dataset:  50%|████▉     | 4964/10000 [01:08<01:05, 76.59it/s]Processing train dataset:  37%|███▋      | 3728/10000 [01:02<01:39, 63.29it/s]Processing train dataset:  46%|████▌     | 4581/10000 [01:05<01:28, 61.36it/s]Processing train dataset:  48%|████▊     | 4784/10000 [01:05<01:11, 73.46it/s]Processing train dataset:  46%|████▌     | 4558/10000 [01:05<01:14, 72.62it/s]Processing train dataset:  50%|████▉     | 4972/10000 [01:08<01:08, 73.19it/s]Processing train dataset:  37%|███▋      | 3735/10000 [01:02<01:42, 61.25it/s]Processing train dataset:  46%|████▌     | 4588/10000 [01:05<01:26, 62.23it/s]Processing train dataset:  48%|████▊     | 4793/10000 [01:05<01:08, 75.71it/s]Processing train dataset:  46%|████▌     | 4567/10000 [01:05<01:12, 74.74it/s]Processing train dataset:  46%|████▌     | 4596/10000 [01:05<01:21, 66.25it/s]Processing train dataset:  50%|████▉     | 4980/10000 [01:08<01:12, 68.94it/s]Processing train dataset:  48%|████▊     | 4801/10000 [01:05<01:09, 74.78it/s]Processing train dataset:  37%|███▋      | 3742/10000 [01:03<01:47, 57.97it/s]Processing train dataset:  46%|████▌     | 4575/10000 [01:05<01:12, 74.93it/s]Processing train dataset:  46%|████▌     | 4603/10000 [01:05<01:20, 66.81it/s]Processing train dataset:  48%|████▊     | 4809/10000 [01:05<01:09, 74.66it/s]Processing train dataset:  50%|████▉     | 4989/10000 [01:09<01:10, 71.22it/s]Processing train dataset:  37%|███▋      | 3749/10000 [01:03<01:45, 59.17it/s]Processing train dataset:  46%|████▌     | 4583/10000 [01:05<01:12, 74.66it/s]Processing train dataset:  46%|████▌     | 4610/10000 [01:05<01:19, 67.58it/s]Processing train dataset:  48%|████▊     | 4818/10000 [01:05<01:07, 76.42it/s]Processing train dataset:  50%|████▉     | 4997/10000 [01:09<01:13, 67.80it/s]Processing train dataset:  38%|███▊      | 3755/10000 [01:03<01:52, 55.32it/s]Processing train dataset:  46%|████▌     | 4591/10000 [01:05<01:13, 73.82it/s]Processing train dataset:  46%|████▌     | 4617/10000 [01:05<01:22, 65.60it/s]Processing train dataset:  48%|████▊     | 4828/10000 [01:05<01:03, 81.90it/s]Processing train dataset:  38%|███▊      | 3762/10000 [01:03<01:46, 58.52it/s]Processing train dataset:  50%|█████     | 5004/10000 [01:09<01:14, 67.00it/s]Processing train dataset:  46%|████▌     | 4600/10000 [01:05<01:10, 76.77it/s]Processing train dataset:  46%|████▋     | 4626/10000 [01:05<01:14, 71.85it/s]Processing train dataset:  48%|████▊     | 4837/10000 [01:05<01:03, 81.07it/s]Processing train dataset:  50%|█████     | 5012/10000 [01:09<01:12, 68.43it/s]Processing train dataset:  38%|███▊      | 3770/10000 [01:03<01:40, 61.99it/s]Processing train dataset:  46%|████▌     | 4608/10000 [01:05<01:15, 71.33it/s]Processing train dataset:  46%|████▋     | 4634/10000 [01:06<01:21, 66.01it/s]Processing train dataset:  48%|████▊     | 4846/10000 [01:06<01:03, 81.27it/s]Processing train dataset:  50%|█████     | 5020/10000 [01:09<01:10, 70.47it/s]Processing train dataset:  38%|███▊      | 3778/10000 [01:03<01:35, 64.90it/s]Processing train dataset:  46%|████▌     | 4616/10000 [01:05<01:19, 68.05it/s]Processing train dataset:  46%|████▋     | 4641/10000 [01:06<01:21, 65.45it/s]Processing train dataset:  49%|████▊     | 4855/10000 [01:06<01:05, 78.84it/s]Processing train dataset:  38%|███▊      | 3785/10000 [01:03<01:35, 65.17it/s]Processing train dataset:  50%|█████     | 5028/10000 [01:09<01:11, 69.99it/s]Processing train dataset:  46%|████▌     | 4623/10000 [01:05<01:19, 67.91it/s]Processing train dataset:  49%|████▊     | 4864/10000 [01:06<01:02, 81.82it/s]Processing train dataset:  50%|█████     | 5038/10000 [01:09<01:04, 77.49it/s]Processing train dataset:  38%|███▊      | 3792/10000 [01:03<01:38, 63.12it/s]Processing train dataset:  46%|████▋     | 4648/10000 [01:06<01:30, 59.12it/s]Processing train dataset:  46%|████▋     | 4631/10000 [01:06<01:16, 70.08it/s]Processing train dataset:  49%|████▊     | 4873/10000 [01:06<01:04, 79.17it/s]Processing train dataset:  50%|█████     | 5046/10000 [01:09<01:07, 73.28it/s]Processing train dataset:  47%|████▋     | 4657/10000 [01:06<01:22, 64.86it/s]Processing train dataset:  38%|███▊      | 3799/10000 [01:03<01:43, 59.85it/s]Processing train dataset:  46%|████▋     | 4640/10000 [01:06<01:12, 73.59it/s]Processing train dataset:  49%|████▉     | 4881/10000 [01:06<01:05, 77.95it/s]Processing train dataset:  47%|████▋     | 4665/10000 [01:06<01:18, 67.94it/s]Processing train dataset:  51%|█████     | 5054/10000 [01:09<01:11, 69.13it/s]Processing train dataset:  46%|████▋     | 4648/10000 [01:06<01:12, 73.99it/s]Processing train dataset:  38%|███▊      | 3806/10000 [01:04<01:52, 55.03it/s]Processing train dataset:  49%|████▉     | 4890/10000 [01:06<01:04, 79.83it/s]Processing train dataset:  47%|████▋     | 4674/10000 [01:06<01:12, 73.34it/s]Processing train dataset:  51%|█████     | 5062/10000 [01:10<01:09, 70.88it/s]Processing train dataset:  47%|████▋     | 4656/10000 [01:06<01:13, 72.78it/s]Processing train dataset:  49%|████▉     | 4899/10000 [01:06<01:02, 81.42it/s]Processing train dataset:  38%|███▊      | 3812/10000 [01:04<01:59, 51.60it/s]Processing train dataset:  47%|████▋     | 4683/10000 [01:06<01:09, 76.34it/s]Processing train dataset:  51%|█████     | 5071/10000 [01:10<01:05, 75.48it/s]Processing train dataset:  47%|████▋     | 4664/10000 [01:06<01:12, 73.88it/s]Processing train dataset:  49%|████▉     | 4908/10000 [01:06<01:04, 78.77it/s]Processing train dataset:  38%|███▊      | 3818/10000 [01:04<02:02, 50.29it/s]Processing train dataset:  51%|█████     | 5080/10000 [01:10<01:02, 78.90it/s]Processing train dataset:  47%|████▋     | 4691/10000 [01:06<01:14, 71.37it/s]Processing train dataset:  47%|████▋     | 4673/10000 [01:06<01:08, 77.36it/s]Processing train dataset:  49%|████▉     | 4916/10000 [01:06<01:06, 77.00it/s]Processing train dataset:  38%|███▊      | 3825/10000 [01:04<01:55, 53.42it/s]Processing train dataset:  51%|█████     | 5088/10000 [01:10<01:06, 74.25it/s]Processing train dataset:  47%|████▋     | 4699/10000 [01:06<01:15, 69.98it/s]Processing train dataset:  47%|████▋     | 4681/10000 [01:06<01:11, 74.51it/s]Processing train dataset:  49%|████▉     | 4924/10000 [01:07<01:07, 75.50it/s]Processing train dataset:  38%|███▊      | 3832/10000 [01:04<01:48, 57.05it/s]Processing train dataset:  51%|█████     | 5096/10000 [01:10<01:07, 73.10it/s]Processing train dataset:  47%|████▋     | 4707/10000 [01:07<01:16, 69.01it/s]Processing train dataset:  47%|████▋     | 4689/10000 [01:06<01:16, 69.00it/s]Processing train dataset:  49%|████▉     | 4933/10000 [01:07<01:05, 77.23it/s]Processing train dataset:  38%|███▊      | 3839/10000 [01:04<01:44, 58.80it/s]Processing train dataset:  51%|█████     | 5105/10000 [01:10<01:06, 74.14it/s]Processing train dataset:  47%|████▋     | 4714/10000 [01:07<01:19, 66.74it/s]Processing train dataset:  47%|████▋     | 4696/10000 [01:06<01:17, 68.64it/s]Processing train dataset:  49%|████▉     | 4941/10000 [01:07<01:06, 76.12it/s]Processing train dataset:  38%|███▊      | 3846/10000 [01:04<01:42, 60.26it/s]Processing train dataset:  51%|█████     | 5113/10000 [01:10<01:05, 74.73it/s]Processing train dataset:  47%|████▋     | 4722/10000 [01:07<01:16, 68.89it/s]Processing train dataset:  47%|████▋     | 4705/10000 [01:07<01:11, 73.79it/s]Processing train dataset:  50%|████▉     | 4950/10000 [01:07<01:05, 77.57it/s]Processing train dataset:  51%|█████     | 5121/10000 [01:10<01:04, 75.38it/s]Processing train dataset:  39%|███▊      | 3853/10000 [01:04<01:50, 55.77it/s]Processing train dataset:  47%|████▋     | 4730/10000 [01:07<01:15, 69.60it/s]Processing train dataset:  47%|████▋     | 4714/10000 [01:07<01:08, 77.55it/s]Processing train dataset:  50%|████▉     | 4959/10000 [01:07<01:03, 79.13it/s]Processing train dataset:  51%|█████▏    | 5130/10000 [01:10<01:02, 78.40it/s]Processing train dataset:  39%|███▊      | 3860/10000 [01:05<01:44, 58.73it/s]Processing train dataset:  47%|████▋     | 4739/10000 [01:07<01:12, 72.63it/s]Processing train dataset:  47%|████▋     | 4723/10000 [01:07<01:10, 74.98it/s]Processing train dataset:  50%|████▉     | 4967/10000 [01:07<01:04, 77.93it/s]Processing train dataset:  51%|█████▏    | 5139/10000 [01:11<01:01, 79.68it/s]Processing train dataset:  39%|███▊      | 3867/10000 [01:05<01:41, 60.59it/s]Processing train dataset:  47%|████▋     | 4747/10000 [01:07<01:12, 72.54it/s]Processing train dataset:  47%|████▋     | 4731/10000 [01:07<01:12, 72.68it/s]Processing train dataset:  50%|████▉     | 4975/10000 [01:07<01:05, 77.29it/s]Processing train dataset:  51%|█████▏    | 5148/10000 [01:11<00:59, 82.20it/s]Processing train dataset:  48%|████▊     | 4755/10000 [01:07<01:13, 71.49it/s]Processing train dataset:  39%|███▊      | 3874/10000 [01:05<01:45, 58.31it/s]Processing train dataset:  47%|████▋     | 4740/10000 [01:07<01:09, 75.41it/s]Processing train dataset:  50%|████▉     | 4983/10000 [01:07<01:06, 75.74it/s]Processing train dataset:  52%|█████▏    | 5157/10000 [01:11<00:57, 84.28it/s]Processing train dataset:  48%|████▊     | 4763/10000 [01:07<01:14, 70.75it/s]Processing train dataset:  39%|███▉      | 3880/10000 [01:05<01:51, 54.78it/s]Processing train dataset:  50%|████▉     | 4992/10000 [01:07<01:03, 79.10it/s]Processing train dataset:  47%|████▋     | 4748/10000 [01:07<01:10, 74.73it/s]Processing train dataset:  52%|█████▏    | 5166/10000 [01:11<01:00, 80.10it/s]Processing train dataset:  39%|███▉      | 3886/10000 [01:05<01:53, 53.87it/s]Processing train dataset:  50%|█████     | 5000/10000 [01:07<01:05, 76.86it/s]Processing train dataset:  48%|████▊     | 4771/10000 [01:08<01:20, 65.06it/s]Processing train dataset:  48%|████▊     | 4756/10000 [01:07<01:15, 69.70it/s]Processing train dataset:  52%|█████▏    | 5175/10000 [01:11<01:04, 75.29it/s]Processing train dataset:  39%|███▉      | 3893/10000 [01:05<01:50, 55.15it/s]Processing train dataset:  50%|█████     | 5009/10000 [01:08<01:04, 77.91it/s]Processing train dataset:  48%|████▊     | 4778/10000 [01:08<01:24, 61.60it/s]Processing train dataset:  48%|████▊     | 4764/10000 [01:07<01:20, 64.70it/s]Processing train dataset:  52%|█████▏    | 5183/10000 [01:11<01:04, 74.64it/s]Processing train dataset:  50%|█████     | 5017/10000 [01:08<01:05, 76.23it/s]Processing train dataset:  39%|███▉      | 3901/10000 [01:05<01:45, 58.05it/s]Processing train dataset:  48%|████▊     | 4785/10000 [01:08<01:27, 59.44it/s]Processing train dataset:  48%|████▊     | 4772/10000 [01:07<01:18, 66.39it/s]Processing train dataset:  52%|█████▏    | 5192/10000 [01:11<01:05, 73.76it/s]Processing train dataset:  50%|█████     | 5025/10000 [01:08<01:05, 75.60it/s]Processing train dataset:  39%|███▉      | 3908/10000 [01:05<01:46, 57.39it/s]Processing train dataset:  48%|████▊     | 4792/10000 [01:08<01:27, 59.82it/s]Processing train dataset:  48%|████▊     | 4780/10000 [01:08<01:15, 68.86it/s]Processing train dataset:  52%|█████▏    | 5202/10000 [01:11<01:00, 79.27it/s]Processing train dataset:  50%|█████     | 5034/10000 [01:08<01:02, 79.30it/s]Processing train dataset:  39%|███▉      | 3915/10000 [01:06<01:42, 59.20it/s]Processing train dataset:  48%|████▊     | 4788/10000 [01:08<01:15, 69.41it/s]Processing train dataset:  52%|█████▏    | 5213/10000 [01:11<00:55, 86.99it/s]Processing train dataset:  48%|████▊     | 4799/10000 [01:08<01:34, 54.88it/s]Processing train dataset:  50%|█████     | 5043/10000 [01:08<01:00, 82.09it/s]Processing train dataset:  39%|███▉      | 3921/10000 [01:06<01:49, 55.65it/s]Processing train dataset:  48%|████▊     | 4797/10000 [01:08<01:09, 74.44it/s]Processing train dataset:  52%|█████▏    | 5225/10000 [01:12<00:50, 94.29it/s]Processing train dataset:  51%|█████     | 5052/10000 [01:08<01:02, 79.26it/s]Processing train dataset:  48%|████▊     | 4805/10000 [01:08<01:39, 52.36it/s]Processing train dataset:  39%|███▉      | 3927/10000 [01:06<01:50, 54.98it/s]Processing train dataset:  48%|████▊     | 4805/10000 [01:08<01:12, 71.56it/s]Processing train dataset:  52%|█████▏    | 5235/10000 [01:12<00:53, 88.98it/s]Processing train dataset:  51%|█████     | 5061/10000 [01:08<01:02, 79.40it/s]Processing train dataset:  48%|████▊     | 4811/10000 [01:08<01:39, 52.20it/s]Processing train dataset:  39%|███▉      | 3933/10000 [01:06<01:48, 55.72it/s]Processing train dataset:  48%|████▊     | 4813/10000 [01:08<01:18, 66.10it/s]Processing train dataset:  48%|████▊     | 4818/10000 [01:08<01:32, 56.31it/s]Processing train dataset:  51%|█████     | 5069/10000 [01:08<01:03, 77.36it/s]Processing train dataset:  52%|█████▏    | 5245/10000 [01:12<00:58, 81.08it/s]Processing train dataset:  39%|███▉      | 3941/10000 [01:06<01:37, 62.35it/s]Processing train dataset:  48%|████▊     | 4828/10000 [01:08<01:16, 67.79it/s]Processing train dataset:  51%|█████     | 5077/10000 [01:08<01:05, 75.64it/s]Processing train dataset:  48%|████▊     | 4820/10000 [01:08<01:21, 63.26it/s]Processing train dataset:  53%|█████▎    | 5256/10000 [01:12<00:54, 86.70it/s]Processing train dataset:  40%|███▉      | 3952/10000 [01:06<01:21, 74.24it/s]Processing train dataset:  48%|████▊     | 4837/10000 [01:09<01:12, 71.68it/s]Processing train dataset:  51%|█████     | 5085/10000 [01:09<01:05, 75.10it/s]Processing train dataset:  53%|█████▎    | 5265/10000 [01:12<00:56, 84.32it/s]Processing train dataset:  40%|███▉      | 3960/10000 [01:06<01:21, 74.06it/s]Processing train dataset:  48%|████▊     | 4827/10000 [01:08<01:32, 56.19it/s]Processing train dataset:  48%|████▊     | 4846/10000 [01:09<01:09, 73.92it/s]Processing train dataset:  51%|█████     | 5094/10000 [01:09<01:03, 76.71it/s]Processing train dataset:  53%|█████▎    | 5274/10000 [01:12<00:56, 83.53it/s]Processing train dataset:  40%|███▉      | 3969/10000 [01:06<01:18, 76.52it/s]Processing train dataset:  49%|████▊     | 4854/10000 [01:09<01:10, 73.30it/s]Processing train dataset:  51%|█████     | 5102/10000 [01:09<01:04, 75.61it/s]Processing train dataset:  48%|████▊     | 4833/10000 [01:09<01:48, 47.57it/s]Processing train dataset:  53%|█████▎    | 5283/10000 [01:12<01:01, 77.22it/s]Processing train dataset:  40%|███▉      | 3977/10000 [01:06<01:25, 70.26it/s]Processing train dataset:  49%|████▊     | 4862/10000 [01:09<01:09, 73.53it/s]Processing train dataset:  51%|█████     | 5110/10000 [01:09<01:04, 75.28it/s]Processing train dataset:  48%|████▊     | 4839/10000 [01:09<01:43, 49.65it/s]Processing train dataset:  40%|███▉      | 3985/10000 [01:07<01:26, 69.42it/s]Processing train dataset:  53%|█████▎    | 5291/10000 [01:12<01:04, 73.04it/s]Processing train dataset:  51%|█████     | 5118/10000 [01:09<01:05, 74.92it/s]Processing train dataset:  48%|████▊     | 4846/10000 [01:09<01:36, 53.41it/s]Processing train dataset:  49%|████▊     | 4870/10000 [01:09<01:14, 68.88it/s]Processing train dataset:  53%|█████▎    | 5299/10000 [01:13<01:04, 73.13it/s]Processing train dataset:  40%|███▉      | 3993/10000 [01:07<01:35, 62.81it/s]Processing train dataset:  51%|█████▏    | 5126/10000 [01:09<01:05, 74.86it/s]Processing train dataset:  49%|████▊     | 4852/10000 [01:09<01:35, 53.82it/s]Processing train dataset:  49%|████▉     | 4877/10000 [01:09<01:18, 65.59it/s]Processing train dataset:  53%|█████▎    | 5307/10000 [01:13<01:07, 69.26it/s]Processing train dataset:  40%|████      | 4000/10000 [01:07<01:35, 63.12it/s]Processing train dataset:  51%|█████▏    | 5134/10000 [01:09<01:05, 74.09it/s]Processing train dataset:  49%|████▊     | 4859/10000 [01:09<01:32, 55.32it/s]Processing train dataset:  49%|████▉     | 4885/10000 [01:09<01:15, 67.51it/s]Processing train dataset:  51%|█████▏    | 5142/10000 [01:09<01:06, 73.51it/s]Processing train dataset:  53%|█████▎    | 5315/10000 [01:13<01:12, 64.24it/s]Processing train dataset:  49%|████▉     | 4893/10000 [01:09<01:12, 70.70it/s]Processing train dataset:  40%|████      | 4007/10000 [01:07<01:41, 59.22it/s]Processing train dataset:  49%|████▊     | 4865/10000 [01:09<01:34, 54.23it/s]Processing train dataset:  52%|█████▏    | 5150/10000 [01:09<01:06, 73.32it/s]Processing train dataset:  49%|████▉     | 4902/10000 [01:10<01:09, 73.87it/s]Processing train dataset:  53%|█████▎    | 5322/10000 [01:13<01:15, 61.92it/s]Processing train dataset:  40%|████      | 4014/10000 [01:07<01:43, 57.79it/s]Processing train dataset:  49%|████▊     | 4871/10000 [01:09<01:38, 52.08it/s]Processing train dataset:  52%|█████▏    | 5158/10000 [01:10<01:05, 73.52it/s]Processing train dataset:  49%|████▉     | 4910/10000 [01:10<01:08, 73.95it/s]Processing train dataset:  40%|████      | 4024/10000 [01:07<01:28, 67.51it/s]Processing train dataset:  53%|█████▎    | 5330/10000 [01:13<01:15, 61.59it/s]Processing train dataset:  49%|████▉     | 4877/10000 [01:09<01:48, 47.33it/s]Processing train dataset:  52%|█████▏    | 5166/10000 [01:10<01:05, 73.34it/s]Processing train dataset:  49%|████▉     | 4918/10000 [01:10<01:08, 74.12it/s]Processing train dataset:  40%|████      | 4033/10000 [01:07<01:22, 72.46it/s]Processing train dataset:  53%|█████▎    | 5337/10000 [01:13<01:22, 56.21it/s]Processing train dataset:  49%|████▉     | 4884/10000 [01:09<01:39, 51.33it/s]Processing train dataset:  52%|█████▏    | 5174/10000 [01:10<01:06, 73.10it/s]Processing train dataset:  49%|████▉     | 4927/10000 [01:10<01:06, 76.21it/s]Processing train dataset:  40%|████      | 4041/10000 [01:07<01:22, 72.55it/s]Processing train dataset:  52%|█████▏    | 5182/10000 [01:10<01:05, 73.22it/s]Processing train dataset:  49%|████▉     | 4891/10000 [01:10<01:36, 52.92it/s]Processing train dataset:  53%|█████▎    | 5343/10000 [01:13<01:28, 52.71it/s]Processing train dataset:  40%|████      | 4049/10000 [01:07<01:20, 74.30it/s]Processing train dataset:  49%|████▉     | 4935/10000 [01:10<01:11, 70.59it/s]Processing train dataset:  49%|████▉     | 4897/10000 [01:10<01:33, 54.54it/s]Processing train dataset:  52%|█████▏    | 5190/10000 [01:10<01:05, 73.45it/s]Processing train dataset:  53%|█████▎    | 5349/10000 [01:14<01:30, 51.54it/s]Processing train dataset:  41%|████      | 4057/10000 [01:08<01:24, 70.72it/s]Processing train dataset:  49%|████▉     | 4943/10000 [01:10<01:18, 64.08it/s]Processing train dataset:  52%|█████▏    | 5198/10000 [01:10<01:04, 74.00it/s]Processing train dataset:  49%|████▉     | 4903/10000 [01:10<01:35, 53.25it/s]Processing train dataset:  54%|█████▎    | 5355/10000 [01:14<01:30, 51.25it/s]Processing train dataset:  41%|████      | 4065/10000 [01:08<01:27, 67.53it/s]Processing train dataset:  50%|████▉     | 4951/10000 [01:10<01:14, 67.63it/s]Processing train dataset:  52%|█████▏    | 5207/10000 [01:10<01:02, 76.37it/s]Processing train dataset:  49%|████▉     | 4909/10000 [01:10<01:38, 51.57it/s]Processing train dataset:  54%|█████▎    | 5361/10000 [01:14<01:30, 51.53it/s]Processing train dataset:  41%|████      | 4072/10000 [01:08<01:27, 67.76it/s]Processing train dataset:  50%|████▉     | 4960/10000 [01:10<01:10, 71.31it/s]Processing train dataset:  52%|█████▏    | 5217/10000 [01:10<00:59, 80.13it/s]Processing train dataset:  49%|████▉     | 4915/10000 [01:10<01:38, 51.58it/s]Processing train dataset:  54%|█████▎    | 5367/10000 [01:14<01:29, 51.72it/s]Processing train dataset:  41%|████      | 4080/10000 [01:08<01:30, 65.62it/s]Processing train dataset:  50%|████▉     | 4968/10000 [01:10<01:09, 71.97it/s]Processing train dataset:  52%|█████▏    | 5226/10000 [01:10<01:02, 76.31it/s]Processing train dataset:  49%|████▉     | 4922/10000 [01:10<01:35, 53.43it/s]Processing train dataset:  54%|█████▎    | 5373/10000 [01:14<01:32, 50.22it/s]Processing train dataset:  41%|████      | 4088/10000 [01:08<01:29, 66.30it/s]Processing train dataset:  52%|█████▏    | 5235/10000 [01:11<01:01, 77.53it/s]Processing train dataset:  50%|████▉     | 4976/10000 [01:11<01:18, 63.68it/s]Processing train dataset:  49%|████▉     | 4929/10000 [01:10<01:30, 55.98it/s]Processing train dataset:  54%|█████▍    | 5379/10000 [01:14<01:28, 52.27it/s]Processing train dataset:  41%|████      | 4095/10000 [01:08<01:36, 61.04it/s]Processing train dataset:  52%|█████▏    | 5243/10000 [01:11<01:02, 76.34it/s]Processing train dataset:  49%|████▉     | 4935/10000 [01:10<01:33, 54.28it/s]Processing train dataset:  50%|████▉     | 4983/10000 [01:11<01:24, 59.04it/s]Processing train dataset:  54%|█████▍    | 5385/10000 [01:14<01:29, 51.84it/s]Processing train dataset:  53%|█████▎    | 5252/10000 [01:11<01:01, 77.59it/s]Processing train dataset:  41%|████      | 4102/10000 [01:08<01:42, 57.65it/s]Processing train dataset:  54%|█████▍    | 5394/10000 [01:14<01:15, 61.30it/s]Processing train dataset:  49%|████▉     | 4941/10000 [01:11<01:42, 49.52it/s]Processing train dataset:  50%|████▉     | 4990/10000 [01:11<01:30, 55.36it/s]Processing train dataset:  53%|█████▎    | 5261/10000 [01:11<01:00, 78.20it/s]Processing train dataset:  41%|████      | 4110/10000 [01:08<01:33, 62.79it/s]Processing train dataset:  54%|█████▍    | 5402/10000 [01:14<01:09, 65.87it/s]Processing train dataset:  50%|████▉     | 4996/10000 [01:11<01:29, 56.08it/s]Processing train dataset:  49%|████▉     | 4949/10000 [01:11<01:29, 56.17it/s]Processing train dataset:  41%|████      | 4118/10000 [01:09<01:27, 66.89it/s]Processing train dataset:  53%|█████▎    | 5269/10000 [01:11<01:05, 72.04it/s]Processing train dataset:  54%|█████▍    | 5410/10000 [01:15<01:08, 67.01it/s]Processing train dataset:  50%|████▉     | 4957/10000 [01:11<01:21, 61.56it/s]Processing train dataset:  50%|█████     | 5003/10000 [01:11<01:26, 57.70it/s]Processing train dataset:  41%|████▏     | 4128/10000 [01:09<01:19, 73.97it/s]Processing train dataset:  54%|█████▍    | 5417/10000 [01:15<01:07, 67.76it/s]Processing train dataset:  53%|█████▎    | 5278/10000 [01:11<01:03, 74.29it/s]Processing train dataset:  50%|████▉     | 4964/10000 [01:11<01:18, 63.82it/s]Processing train dataset:  50%|█████     | 5011/10000 [01:11<01:21, 61.43it/s]Processing train dataset:  41%|████▏     | 4136/10000 [01:09<01:19, 73.89it/s]Processing train dataset:  54%|█████▍    | 5424/10000 [01:15<01:07, 67.52it/s]Processing train dataset:  53%|█████▎    | 5286/10000 [01:11<01:03, 73.68it/s]Processing train dataset:  50%|█████     | 5018/10000 [01:11<01:20, 62.24it/s]Processing train dataset:  50%|████▉     | 4971/10000 [01:11<01:27, 57.69it/s]Processing train dataset:  41%|████▏     | 4144/10000 [01:09<01:19, 73.42it/s]Processing train dataset:  54%|█████▍    | 5431/10000 [01:15<01:07, 67.94it/s]Processing train dataset:  53%|█████▎    | 5294/10000 [01:11<01:02, 74.70it/s]Processing train dataset:  50%|█████     | 5026/10000 [01:11<01:17, 64.15it/s]Processing train dataset:  50%|████▉     | 4979/10000 [01:11<01:21, 61.72it/s]Processing train dataset:  42%|████▏     | 4152/10000 [01:09<01:21, 71.79it/s]Processing train dataset:  53%|█████▎    | 5302/10000 [01:11<01:01, 76.06it/s]Processing train dataset:  54%|█████▍    | 5438/10000 [01:15<01:09, 65.28it/s]Processing train dataset:  50%|█████     | 5036/10000 [01:12<01:08, 72.86it/s]Processing train dataset:  50%|████▉     | 4987/10000 [01:11<01:16, 65.89it/s]Processing train dataset:  42%|████▏     | 4160/10000 [01:09<01:19, 73.69it/s]Processing train dataset:  53%|█████▎    | 5311/10000 [01:12<01:00, 77.09it/s]Processing train dataset:  54%|█████▍    | 5445/10000 [01:15<01:14, 61.36it/s]Processing train dataset:  50%|█████     | 5044/10000 [01:12<01:06, 74.34it/s]Processing train dataset:  50%|████▉     | 4995/10000 [01:11<01:13, 67.76it/s]Processing train dataset:  53%|█████▎    | 5319/10000 [01:12<01:01, 76.69it/s]Processing train dataset:  42%|████▏     | 4168/10000 [01:09<01:28, 65.90it/s]Processing train dataset:  55%|█████▍    | 5452/10000 [01:15<01:15, 60.37it/s]Processing train dataset:  51%|█████     | 5052/10000 [01:12<01:08, 72.02it/s]Processing train dataset:  50%|█████     | 5003/10000 [01:11<01:12, 68.73it/s]Processing train dataset:  53%|█████▎    | 5329/10000 [01:12<00:57, 80.72it/s]Processing train dataset:  42%|████▏     | 4177/10000 [01:09<01:26, 67.29it/s]Processing train dataset:  55%|█████▍    | 5459/10000 [01:15<01:16, 59.27it/s]Processing train dataset:  50%|█████     | 5011/10000 [01:12<01:10, 71.18it/s]Processing train dataset:  51%|█████     | 5060/10000 [01:12<01:12, 67.91it/s]Processing train dataset:  53%|█████▎    | 5338/10000 [01:12<01:00, 76.44it/s]Processing train dataset:  55%|█████▍    | 5467/10000 [01:15<01:10, 64.41it/s]Processing train dataset:  42%|████▏     | 4187/10000 [01:10<01:18, 74.13it/s]Processing train dataset:  51%|█████     | 5067/10000 [01:12<01:13, 67.05it/s]Processing train dataset:  50%|█████     | 5019/10000 [01:12<01:18, 63.22it/s]Processing train dataset:  53%|█████▎    | 5346/10000 [01:12<01:01, 75.41it/s]Processing train dataset:  55%|█████▍    | 5477/10000 [01:16<01:02, 71.83it/s]Processing train dataset:  42%|████▏     | 4195/10000 [01:10<01:25, 67.85it/s]Processing train dataset:  51%|█████     | 5075/10000 [01:12<01:11, 68.68it/s]Processing train dataset:  50%|█████     | 5027/10000 [01:12<01:15, 65.99it/s]Processing train dataset:  54%|█████▎    | 5354/10000 [01:12<01:02, 74.78it/s]Processing train dataset:  55%|█████▍    | 5486/10000 [01:16<00:59, 76.19it/s]Processing train dataset:  42%|████▏     | 4202/10000 [01:10<01:27, 66.30it/s]Processing train dataset:  51%|█████     | 5083/10000 [01:12<01:10, 69.50it/s]Processing train dataset:  50%|█████     | 5038/10000 [01:12<01:04, 77.31it/s]Processing train dataset:  54%|█████▎    | 5363/10000 [01:12<01:00, 76.83it/s]Processing train dataset:  55%|█████▍    | 5495/10000 [01:16<00:57, 77.71it/s]Processing train dataset:  42%|████▏     | 4209/10000 [01:10<01:27, 66.11it/s]Processing train dataset:  51%|█████     | 5091/10000 [01:12<01:09, 70.82it/s]Processing train dataset:  55%|█████▌    | 5503/10000 [01:16<00:57, 78.24it/s]Processing train dataset:  54%|█████▎    | 5371/10000 [01:12<01:01, 74.80it/s]Processing train dataset:  50%|█████     | 5047/10000 [01:12<01:08, 72.57it/s]Processing train dataset:  42%|████▏     | 4216/10000 [01:10<01:29, 64.70it/s]Processing train dataset:  51%|█████     | 5099/10000 [01:12<01:10, 69.55it/s]Processing train dataset:  55%|█████▌    | 5512/10000 [01:16<00:55, 81.02it/s]Processing train dataset:  51%|█████     | 5055/10000 [01:12<01:08, 72.62it/s]Processing train dataset:  54%|█████▍    | 5380/10000 [01:12<01:00, 76.25it/s]Processing train dataset:  51%|█████     | 5106/10000 [01:13<01:16, 64.13it/s]Processing train dataset:  54%|█████▍    | 5390/10000 [01:13<00:58, 79.47it/s]Processing train dataset:  42%|████▏     | 4224/10000 [01:10<01:43, 55.70it/s]Processing train dataset:  55%|█████▌    | 5521/10000 [01:16<01:11, 62.96it/s]Processing train dataset:  51%|█████     | 5063/10000 [01:12<01:25, 58.07it/s]Processing train dataset:  54%|█████▍    | 5399/10000 [01:13<00:57, 80.22it/s]Processing train dataset:  51%|█████     | 5113/10000 [01:13<01:31, 53.38it/s]Processing train dataset:  42%|████▏     | 4230/10000 [01:10<02:01, 47.34it/s]Processing train dataset:  51%|█████     | 5070/10000 [01:13<01:25, 57.80it/s]Processing train dataset:  55%|█████▌    | 5528/10000 [01:16<01:13, 60.76it/s]Processing train dataset:  54%|█████▍    | 5408/10000 [01:13<00:58, 78.42it/s]Processing train dataset:  51%|█████     | 5119/10000 [01:13<01:29, 54.76it/s]Processing train dataset:  42%|████▏     | 4236/10000 [01:10<01:55, 50.11it/s]Processing train dataset:  51%|█████     | 5077/10000 [01:13<01:22, 60.00it/s]Processing train dataset:  55%|█████▌    | 5537/10000 [01:16<01:06, 67.12it/s]Processing train dataset:  54%|█████▍    | 5416/10000 [01:13<00:59, 77.45it/s]Processing train dataset:  51%|█████▏    | 5125/10000 [01:13<01:31, 53.02it/s]Processing train dataset:  42%|████▏     | 4245/10000 [01:11<01:37, 59.29it/s]Processing train dataset:  55%|█████▌    | 5548/10000 [01:17<00:58, 76.74it/s]Processing train dataset:  51%|█████     | 5085/10000 [01:13<01:18, 62.80it/s]Processing train dataset:  54%|█████▍    | 5424/10000 [01:13<00:59, 76.47it/s]Processing train dataset:  51%|█████▏    | 5131/10000 [01:13<01:36, 50.71it/s]Processing train dataset:  54%|█████▍    | 5433/10000 [01:13<00:58, 77.71it/s]Processing train dataset:  43%|████▎     | 4252/10000 [01:11<01:47, 53.42it/s]Processing train dataset:  51%|█████     | 5092/10000 [01:13<01:23, 58.88it/s]Processing train dataset:  56%|█████▌    | 5557/10000 [01:17<01:05, 68.27it/s]Processing train dataset:  51%|█████▏    | 5137/10000 [01:13<01:32, 52.58it/s]Processing train dataset:  54%|█████▍    | 5441/10000 [01:13<00:59, 76.19it/s]Processing train dataset:  43%|████▎     | 4259/10000 [01:11<01:48, 53.14it/s]Processing train dataset:  51%|█████     | 5099/10000 [01:13<01:26, 56.68it/s]Processing train dataset:  56%|█████▌    | 5565/10000 [01:17<01:06, 66.70it/s]Processing train dataset:  51%|█████▏    | 5143/10000 [01:13<01:37, 49.68it/s]Processing train dataset:  54%|█████▍    | 5449/10000 [01:13<01:00, 75.30it/s]Processing train dataset:  43%|████▎     | 4267/10000 [01:11<01:36, 59.17it/s]Processing train dataset:  56%|█████▌    | 5573/10000 [01:17<01:03, 69.70it/s]Processing train dataset:  51%|█████     | 5105/10000 [01:13<01:32, 52.81it/s]Processing train dataset:  55%|█████▍    | 5457/10000 [01:13<01:00, 74.53it/s]Processing train dataset:  51%|█████▏    | 5149/10000 [01:14<01:42, 47.54it/s]Processing train dataset:  56%|█████▌    | 5581/10000 [01:17<01:04, 68.08it/s]Processing train dataset:  51%|█████     | 5111/10000 [01:13<01:32, 52.58it/s]Processing train dataset:  43%|████▎     | 4274/10000 [01:11<01:47, 53.50it/s]Processing train dataset:  52%|█████▏    | 5155/10000 [01:14<01:36, 50.00it/s]Processing train dataset:  55%|█████▍    | 5465/10000 [01:14<01:01, 73.94it/s]Processing train dataset:  51%|█████     | 5117/10000 [01:13<01:33, 52.28it/s]Processing train dataset:  56%|█████▌    | 5589/10000 [01:17<01:06, 66.09it/s]Processing train dataset:  43%|████▎     | 4280/10000 [01:11<01:48, 52.70it/s]Processing train dataset:  55%|█████▍    | 5473/10000 [01:14<01:03, 70.81it/s]Processing train dataset:  52%|█████▏    | 5161/10000 [01:14<01:40, 48.06it/s]Processing train dataset:  51%|█████     | 5124/10000 [01:13<01:26, 56.37it/s]Processing train dataset:  56%|█████▌    | 5598/10000 [01:17<01:01, 71.35it/s]Processing train dataset:  43%|████▎     | 4287/10000 [01:11<01:41, 56.20it/s]Processing train dataset:  55%|█████▍    | 5482/10000 [01:14<01:00, 74.34it/s]Processing train dataset:  52%|█████▏    | 5166/10000 [01:14<01:43, 46.66it/s]Processing train dataset:  43%|████▎     | 4293/10000 [01:11<01:41, 56.09it/s]Processing train dataset:  56%|█████▌    | 5606/10000 [01:17<01:03, 69.16it/s]Processing train dataset:  51%|█████▏    | 5130/10000 [01:14<01:36, 50.62it/s]Processing train dataset:  55%|█████▍    | 5490/10000 [01:14<01:00, 74.42it/s]Processing train dataset:  52%|█████▏    | 5172/10000 [01:14<01:38, 49.21it/s]Processing train dataset:  56%|█████▌    | 5614/10000 [01:18<01:05, 66.48it/s]Processing train dataset:  43%|████▎     | 4300/10000 [01:12<01:48, 52.58it/s]Processing train dataset:  51%|█████▏    | 5136/10000 [01:14<01:37, 50.00it/s]Processing train dataset:  55%|█████▍    | 5498/10000 [01:14<01:03, 70.68it/s]Processing train dataset:  52%|█████▏    | 5177/10000 [01:14<01:43, 46.68it/s]Processing train dataset:  56%|█████▌    | 5621/10000 [01:18<01:10, 62.07it/s]Processing train dataset:  43%|████▎     | 4306/10000 [01:12<01:52, 50.78it/s]Processing train dataset:  55%|█████▌    | 5506/10000 [01:14<01:03, 71.33it/s]Processing train dataset:  51%|█████▏    | 5142/10000 [01:14<01:43, 46.91it/s]Processing train dataset:  52%|█████▏    | 5183/10000 [01:14<01:44, 46.08it/s]Processing train dataset:  56%|█████▋    | 5628/10000 [01:18<01:08, 63.65it/s]Processing train dataset:  43%|████▎     | 4312/10000 [01:12<01:52, 50.36it/s]Processing train dataset:  51%|█████▏    | 5149/10000 [01:14<01:34, 51.54it/s]Processing train dataset:  52%|█████▏    | 5189/10000 [01:14<01:39, 48.25it/s]Processing train dataset:  55%|█████▌    | 5514/10000 [01:14<01:09, 64.26it/s]Processing train dataset:  43%|████▎     | 4318/10000 [01:12<02:00, 47.09it/s]Processing train dataset:  52%|█████▏    | 5194/10000 [01:14<01:43, 46.23it/s]Processing train dataset:  55%|█████▌    | 5521/10000 [01:14<01:11, 62.98it/s]Processing train dataset:  56%|█████▋    | 5635/10000 [01:18<01:20, 54.21it/s]Processing train dataset:  52%|█████▏    | 5155/10000 [01:14<01:43, 47.01it/s]Processing train dataset:  52%|█████▏    | 5201/10000 [01:15<01:32, 51.85it/s]Processing train dataset:  43%|████▎     | 4324/10000 [01:12<01:55, 49.09it/s]Processing train dataset:  56%|█████▋    | 5641/10000 [01:18<01:19, 54.69it/s]Processing train dataset:  55%|█████▌    | 5529/10000 [01:15<01:08, 65.39it/s]Processing train dataset:  52%|█████▏    | 5161/10000 [01:14<01:37, 49.68it/s]Processing train dataset:  52%|█████▏    | 5210/10000 [01:15<01:17, 61.89it/s]Processing train dataset:  43%|████▎     | 4333/10000 [01:12<01:36, 58.73it/s]Processing train dataset:  56%|█████▋    | 5650/10000 [01:18<01:08, 63.20it/s]Processing train dataset:  55%|█████▌    | 5537/10000 [01:15<01:06, 67.40it/s]Processing train dataset:  52%|█████▏    | 5168/10000 [01:14<01:29, 53.87it/s]Processing train dataset:  52%|█████▏    | 5219/10000 [01:15<01:09, 69.15it/s]Processing train dataset:  43%|████▎     | 4341/10000 [01:12<01:28, 63.94it/s]Processing train dataset:  57%|█████▋    | 5659/10000 [01:18<01:02, 69.00it/s]Processing train dataset:  55%|█████▌    | 5545/10000 [01:15<01:04, 69.40it/s]Processing train dataset:  52%|█████▏    | 5175/10000 [01:14<01:24, 57.40it/s]Processing train dataset:  44%|████▎     | 4350/10000 [01:12<01:21, 69.27it/s]Processing train dataset:  57%|█████▋    | 5667/10000 [01:18<01:01, 70.57it/s]Processing train dataset:  52%|█████▏    | 5182/10000 [01:15<01:19, 60.61it/s]Processing train dataset:  56%|█████▌    | 5553/10000 [01:15<01:02, 71.32it/s]Processing train dataset:  52%|█████▏    | 5227/10000 [01:15<01:12, 66.08it/s]Processing train dataset:  44%|████▎     | 4359/10000 [01:13<01:15, 74.53it/s]Processing train dataset:  57%|█████▋    | 5675/10000 [01:18<01:00, 71.68it/s]Processing train dataset:  52%|█████▏    | 5190/10000 [01:15<01:14, 64.47it/s]Processing train dataset:  56%|█████▌    | 5562/10000 [01:15<00:59, 74.64it/s]Processing train dataset:  52%|█████▏    | 5235/10000 [01:15<01:11, 66.94it/s]Processing train dataset:  44%|████▎     | 4368/10000 [01:13<01:12, 77.33it/s]Processing train dataset:  57%|█████▋    | 5684/10000 [01:19<00:57, 75.66it/s]Processing train dataset:  52%|█████▏    | 5198/10000 [01:15<01:10, 67.88it/s]Processing train dataset:  56%|█████▌    | 5570/10000 [01:15<00:59, 74.57it/s]Processing train dataset:  52%|█████▏    | 5242/10000 [01:15<01:12, 65.20it/s]Processing train dataset:  52%|█████▏    | 5205/10000 [01:15<01:11, 67.26it/s]Processing train dataset:  56%|█████▌    | 5578/10000 [01:15<00:58, 75.42it/s]Processing train dataset:  44%|████▍     | 4376/10000 [01:13<01:22, 67.79it/s]Processing train dataset:  57%|█████▋    | 5692/10000 [01:19<01:10, 61.19it/s]Processing train dataset:  56%|█████▌    | 5586/10000 [01:15<01:00, 73.01it/s]Processing train dataset:  52%|█████▏    | 5249/10000 [01:15<01:35, 49.81it/s]Processing train dataset:  52%|█████▏    | 5212/10000 [01:15<01:21, 58.47it/s]Processing train dataset:  56%|█████▌    | 5594/10000 [01:15<01:00, 73.00it/s]Processing train dataset:  57%|█████▋    | 5699/10000 [01:19<01:16, 56.44it/s]Processing train dataset:  53%|█████▎    | 5257/10000 [01:15<01:26, 55.08it/s]Processing train dataset:  52%|█████▏    | 5219/10000 [01:15<01:19, 60.13it/s]Processing train dataset:  44%|████▍     | 4384/10000 [01:13<01:48, 51.57it/s]Processing train dataset:  57%|█████▋    | 5707/10000 [01:19<01:09, 61.81it/s]Processing train dataset:  56%|█████▌    | 5602/10000 [01:16<00:59, 73.38it/s]Processing train dataset:  53%|█████▎    | 5264/10000 [01:16<01:24, 56.18it/s]Processing train dataset:  44%|████▍     | 4393/10000 [01:13<01:35, 58.70it/s]Processing train dataset:  52%|█████▏    | 5226/10000 [01:15<01:20, 59.06it/s]Processing train dataset:  56%|█████▌    | 5612/10000 [01:16<00:54, 80.45it/s]Processing train dataset:  57%|█████▋    | 5716/10000 [01:19<01:03, 67.34it/s]Processing train dataset:  53%|█████▎    | 5273/10000 [01:16<01:14, 63.33it/s]Processing train dataset:  44%|████▍     | 4400/10000 [01:13<01:42, 54.62it/s]Processing train dataset:  52%|█████▏    | 5233/10000 [01:15<01:31, 52.16it/s]Processing train dataset:  56%|█████▌    | 5621/10000 [01:16<00:58, 75.43it/s]Processing train dataset:  57%|█████▋    | 5724/10000 [01:19<01:06, 64.72it/s]Processing train dataset:  53%|█████▎    | 5280/10000 [01:16<01:13, 64.08it/s]Processing train dataset:  56%|█████▋    | 5630/10000 [01:16<00:56, 77.70it/s]Processing train dataset:  57%|█████▋    | 5731/10000 [01:19<01:07, 62.81it/s]Processing train dataset:  53%|█████▎    | 5287/10000 [01:16<01:14, 63.12it/s]Processing train dataset:  44%|████▍     | 4407/10000 [01:13<01:50, 50.52it/s]Processing train dataset:  52%|█████▏    | 5239/10000 [01:16<01:39, 48.03it/s]Processing train dataset:  56%|█████▋    | 5639/10000 [01:16<00:55, 79.27it/s]Processing train dataset:  53%|█████▎    | 5296/10000 [01:16<01:08, 69.16it/s]Processing train dataset:  57%|█████▋    | 5742/10000 [01:20<01:03, 66.70it/s]Processing train dataset:  52%|█████▏    | 5244/10000 [01:16<01:49, 43.26it/s]Processing train dataset:  44%|████▍     | 4413/10000 [01:14<02:03, 45.17it/s]Processing train dataset:  56%|█████▋    | 5647/10000 [01:16<00:58, 74.08it/s]Processing train dataset:  53%|█████▎    | 5304/10000 [01:16<01:11, 66.00it/s]Processing train dataset:  57%|█████▋    | 5749/10000 [01:20<01:03, 66.89it/s]Processing train dataset:  52%|█████▎    | 5250/10000 [01:16<01:46, 44.64it/s]Processing train dataset:  44%|████▍     | 4418/10000 [01:14<02:11, 42.40it/s]Processing train dataset:  57%|█████▋    | 5655/10000 [01:16<01:01, 70.17it/s]Processing train dataset:  53%|█████▎    | 5311/10000 [01:16<01:15, 62.44it/s]Processing train dataset:  58%|█████▊    | 5756/10000 [01:20<01:10, 59.83it/s]Processing train dataset:  53%|█████▎    | 5256/10000 [01:16<01:42, 46.37it/s]Processing train dataset:  57%|█████▋    | 5663/10000 [01:16<01:02, 69.37it/s]Processing train dataset:  44%|████▍     | 4426/10000 [01:14<02:02, 45.55it/s]Processing train dataset:  53%|█████▎    | 5318/10000 [01:16<01:16, 61.35it/s]Processing train dataset:  58%|█████▊    | 5763/10000 [01:20<01:12, 58.33it/s]Processing train dataset:  53%|█████▎    | 5261/10000 [01:16<01:50, 42.77it/s]Processing train dataset:  57%|█████▋    | 5671/10000 [01:16<01:01, 70.86it/s]Processing train dataset:  53%|█████▎    | 5327/10000 [01:17<01:10, 66.68it/s]Processing train dataset:  44%|████▍     | 4432/10000 [01:14<02:12, 42.12it/s]Processing train dataset:  58%|█████▊    | 5769/10000 [01:20<01:18, 53.58it/s]Processing train dataset:  53%|█████▎    | 5266/10000 [01:16<01:55, 40.95it/s]Processing train dataset:  57%|█████▋    | 5679/10000 [01:17<01:02, 69.13it/s]Processing train dataset:  53%|█████▎    | 5334/10000 [01:17<01:12, 64.45it/s]Processing train dataset:  58%|█████▊    | 5776/10000 [01:20<01:15, 55.72it/s]Processing train dataset:  44%|████▍     | 4438/10000 [01:14<02:11, 42.23it/s]Processing train dataset:  57%|█████▋    | 5687/10000 [01:17<01:00, 71.80it/s]Processing train dataset:  53%|█████▎    | 5271/10000 [01:16<01:55, 41.01it/s]Processing train dataset:  53%|█████▎    | 5341/10000 [01:17<01:12, 64.46it/s]Processing train dataset:  44%|████▍     | 4445/10000 [01:14<01:55, 48.04it/s]Processing train dataset:  58%|█████▊    | 5784/10000 [01:20<01:10, 59.88it/s]Processing train dataset:  57%|█████▋    | 5695/10000 [01:17<00:58, 73.19it/s]Processing train dataset:  53%|█████▎    | 5276/10000 [01:17<01:53, 41.61it/s]Processing train dataset:  53%|█████▎    | 5348/10000 [01:17<01:14, 62.67it/s]Processing train dataset:  57%|█████▋    | 5704/10000 [01:17<00:56, 76.61it/s]Processing train dataset:  54%|█████▎    | 5355/10000 [01:17<01:15, 61.32it/s]Processing train dataset:  53%|█████▎    | 5281/10000 [01:17<02:09, 36.45it/s]Processing train dataset:  57%|█████▋    | 5713/10000 [01:17<00:54, 78.56it/s]Processing train dataset:  54%|█████▎    | 5363/10000 [01:17<01:12, 64.26it/s]Processing train dataset:  58%|█████▊    | 5791/10000 [01:21<01:44, 40.33it/s]Processing train dataset:  57%|█████▋    | 5721/10000 [01:17<00:54, 78.17it/s]Processing train dataset:  53%|█████▎    | 5285/10000 [01:17<02:12, 35.51it/s]Processing train dataset:  45%|████▍     | 4451/10000 [01:15<02:57, 31.28it/s]Processing train dataset:  54%|█████▎    | 5371/10000 [01:17<01:10, 66.02it/s]Processing train dataset:  57%|█████▋    | 5730/10000 [01:17<00:53, 80.08it/s]Processing train dataset:  53%|█████▎    | 5291/10000 [01:17<01:55, 40.75it/s]Processing train dataset:  58%|█████▊    | 5797/10000 [01:21<01:40, 41.95it/s]Processing train dataset:  45%|████▍     | 4458/10000 [01:15<02:31, 36.61it/s]Processing train dataset:  54%|█████▍    | 5378/10000 [01:17<01:10, 65.22it/s]Processing train dataset:  57%|█████▋    | 5740/10000 [01:17<00:49, 85.65it/s]Processing train dataset:  53%|█████▎    | 5298/10000 [01:17<01:39, 47.45it/s]Processing train dataset:  58%|█████▊    | 5803/10000 [01:21<01:37, 43.03it/s]Processing train dataset:  45%|████▍     | 4468/10000 [01:15<01:54, 48.16it/s]Processing train dataset:  54%|█████▍    | 5387/10000 [01:17<01:07, 68.02it/s]Processing train dataset:  53%|█████▎    | 5307/10000 [01:17<01:20, 58.25it/s]Processing train dataset:  57%|█████▋    | 5749/10000 [01:17<00:51, 82.11it/s]Processing train dataset:  58%|█████▊    | 5810/10000 [01:21<01:27, 47.70it/s]Processing train dataset:  45%|████▍     | 4476/10000 [01:15<01:42, 53.90it/s]Processing train dataset:  54%|█████▍    | 5396/10000 [01:18<01:03, 72.88it/s]Processing train dataset:  53%|█████▎    | 5315/10000 [01:17<01:15, 62.11it/s]Processing train dataset:  58%|█████▊    | 5758/10000 [01:18<00:53, 79.67it/s]Processing train dataset:  58%|█████▊    | 5816/10000 [01:21<01:27, 48.03it/s]Processing train dataset:  45%|████▍     | 4485/10000 [01:15<01:31, 60.58it/s]Processing train dataset:  54%|█████▍    | 5404/10000 [01:18<01:02, 73.86it/s]Processing train dataset:  53%|█████▎    | 5322/10000 [01:17<01:16, 61.03it/s]Processing train dataset:  58%|█████▊    | 5767/10000 [01:18<00:55, 76.04it/s]Processing train dataset:  58%|█████▊    | 5822/10000 [01:21<01:28, 47.34it/s]Processing train dataset:  45%|████▍     | 4492/10000 [01:15<01:36, 57.07it/s]Processing train dataset:  54%|█████▍    | 5412/10000 [01:18<01:04, 70.74it/s]Processing train dataset:  53%|█████▎    | 5330/10000 [01:17<01:10, 65.78it/s]Processing train dataset:  58%|█████▊    | 5775/10000 [01:18<00:55, 75.92it/s]Processing train dataset:  58%|█████▊    | 5830/10000 [01:21<01:17, 53.85it/s]Processing train dataset:  45%|████▌     | 4500/10000 [01:15<01:29, 61.67it/s]Processing train dataset:  53%|█████▎    | 5337/10000 [01:18<01:11, 65.45it/s]Processing train dataset:  54%|█████▍    | 5420/10000 [01:18<01:06, 68.96it/s]Processing train dataset:  58%|█████▊    | 5783/10000 [01:18<00:55, 75.82it/s]Processing train dataset:  58%|█████▊    | 5839/10000 [01:21<01:06, 62.21it/s]Processing train dataset:  45%|████▌     | 4509/10000 [01:16<01:21, 67.37it/s]Processing train dataset:  54%|█████▍    | 5428/10000 [01:18<01:05, 70.12it/s]Processing train dataset:  53%|█████▎    | 5344/10000 [01:18<01:13, 63.51it/s]Processing train dataset:  58%|█████▊    | 5791/10000 [01:18<00:55, 75.23it/s]Processing train dataset:  58%|█████▊    | 5846/10000 [01:22<01:09, 59.89it/s]Processing train dataset:  45%|████▌     | 4518/10000 [01:16<01:18, 69.59it/s]Processing train dataset:  54%|█████▍    | 5436/10000 [01:18<01:04, 70.43it/s]Processing train dataset:  54%|█████▎    | 5351/10000 [01:18<01:13, 62.98it/s]Processing train dataset:  58%|█████▊    | 5799/10000 [01:18<00:55, 75.28it/s]Processing train dataset:  59%|█████▊    | 5853/10000 [01:22<01:13, 56.79it/s]Processing train dataset:  45%|████▌     | 4526/10000 [01:16<01:22, 66.28it/s]Processing train dataset:  54%|█████▍    | 5444/10000 [01:18<01:06, 68.54it/s]Processing train dataset:  58%|█████▊    | 5807/10000 [01:18<00:55, 74.91it/s]Processing train dataset:  54%|█████▎    | 5358/10000 [01:18<01:19, 58.51it/s]Processing train dataset:  45%|████▌     | 4533/10000 [01:16<01:23, 65.64it/s]Processing train dataset:  59%|█████▊    | 5859/10000 [01:22<01:15, 54.68it/s]Processing train dataset:  58%|█████▊    | 5816/10000 [01:18<00:53, 77.71it/s]Processing train dataset:  55%|█████▍    | 5451/10000 [01:18<01:10, 64.62it/s]Processing train dataset:  54%|█████▎    | 5364/10000 [01:18<01:21, 57.13it/s]Processing train dataset:  58%|█████▊    | 5826/10000 [01:18<00:50, 82.15it/s]Processing train dataset:  55%|█████▍    | 5459/10000 [01:18<01:08, 66.33it/s]Processing train dataset:  54%|█████▎    | 5372/10000 [01:18<01:14, 61.91it/s]Processing train dataset:  59%|█████▊    | 5865/10000 [01:22<01:21, 50.66it/s]Processing train dataset:  45%|████▌     | 4540/10000 [01:16<01:33, 58.64it/s]Processing train dataset:  58%|█████▊    | 5835/10000 [01:19<00:52, 79.80it/s]Processing train dataset:  55%|█████▍    | 5467/10000 [01:19<01:06, 68.17it/s]Processing train dataset:  59%|█████▊    | 5871/10000 [01:22<01:19, 52.14it/s]Processing train dataset:  54%|█████▍    | 5381/10000 [01:18<01:08, 67.57it/s]Processing train dataset:  45%|████▌     | 4547/10000 [01:16<01:35, 57.17it/s]Processing train dataset:  58%|█████▊    | 5844/10000 [01:19<00:51, 80.08it/s]Processing train dataset:  55%|█████▍    | 5475/10000 [01:19<01:04, 69.85it/s]Processing train dataset:  54%|█████▍    | 5388/10000 [01:18<01:08, 66.95it/s]Processing train dataset:  59%|█████▉    | 5877/10000 [01:22<01:19, 51.73it/s]Processing train dataset:  46%|████▌     | 4554/10000 [01:16<01:36, 56.67it/s]Processing train dataset:  54%|█████▍    | 5397/10000 [01:19<01:03, 72.58it/s]Processing train dataset:  55%|█████▍    | 5484/10000 [01:19<01:01, 73.16it/s]Processing train dataset:  59%|█████▊    | 5853/10000 [01:19<00:53, 77.97it/s]Processing train dataset:  59%|█████▉    | 5884/10000 [01:22<01:17, 53.35it/s]Processing train dataset:  46%|████▌     | 4560/10000 [01:16<01:34, 57.35it/s]Processing train dataset:  54%|█████▍    | 5405/10000 [01:19<01:03, 72.67it/s]Processing train dataset:  55%|█████▍    | 5492/10000 [01:19<01:01, 73.31it/s]Processing train dataset:  59%|█████▊    | 5862/10000 [01:19<00:52, 78.80it/s]Processing train dataset:  59%|█████▉    | 5891/10000 [01:22<01:12, 56.89it/s]Processing train dataset:  46%|████▌     | 4569/10000 [01:17<01:28, 61.35it/s]Processing train dataset:  55%|█████▌    | 5500/10000 [01:19<01:01, 73.55it/s]Processing train dataset:  54%|█████▍    | 5413/10000 [01:19<01:03, 72.33it/s]Processing train dataset:  59%|█████▊    | 5871/10000 [01:19<00:51, 79.76it/s]Processing train dataset:  59%|█████▉    | 5898/10000 [01:23<01:09, 59.25it/s]Processing train dataset:  46%|████▌     | 4576/10000 [01:17<01:34, 57.47it/s]Processing train dataset:  54%|█████▍    | 5421/10000 [01:19<01:02, 73.39it/s]Processing train dataset:  55%|█████▌    | 5508/10000 [01:19<01:00, 73.87it/s]Processing train dataset:  59%|█████▉    | 5879/10000 [01:19<00:52, 78.24it/s]Processing train dataset:  59%|█████▉    | 5905/10000 [01:23<01:06, 61.33it/s]Processing train dataset:  46%|████▌     | 4582/10000 [01:17<01:36, 56.01it/s]Processing train dataset:  54%|█████▍    | 5430/10000 [01:19<01:00, 75.97it/s]Processing train dataset:  55%|█████▌    | 5516/10000 [01:19<01:01, 73.39it/s]Processing train dataset:  59%|█████▉    | 5887/10000 [01:19<00:53, 77.11it/s]Processing train dataset:  59%|█████▉    | 5912/10000 [01:23<01:05, 61.97it/s]Processing train dataset:  46%|████▌     | 4589/10000 [01:17<01:31, 58.89it/s]Processing train dataset:  55%|█████▌    | 5524/10000 [01:19<01:01, 73.16it/s]Processing train dataset:  54%|█████▍    | 5438/10000 [01:19<01:01, 73.75it/s]Processing train dataset:  59%|█████▉    | 5895/10000 [01:19<00:54, 75.06it/s]Processing train dataset:  59%|█████▉    | 5919/10000 [01:23<01:04, 63.63it/s]Processing train dataset:  46%|████▌     | 4597/10000 [01:17<01:25, 63.54it/s]Processing train dataset:  55%|█████▌    | 5532/10000 [01:19<01:01, 72.42it/s]Processing train dataset:  59%|█████▉    | 5903/10000 [01:19<00:54, 75.04it/s]Processing train dataset:  59%|█████▉    | 5926/10000 [01:23<01:03, 63.73it/s]Processing train dataset:  54%|█████▍    | 5446/10000 [01:19<01:04, 70.34it/s]Processing train dataset:  55%|█████▌    | 5541/10000 [01:20<00:57, 77.12it/s]Processing train dataset:  46%|████▌     | 4604/10000 [01:17<01:30, 59.68it/s]Processing train dataset:  59%|█████▉    | 5912/10000 [01:20<00:53, 76.62it/s]Processing train dataset:  59%|█████▉    | 5933/10000 [01:23<01:03, 63.70it/s]Processing train dataset:  55%|█████▍    | 5454/10000 [01:19<01:10, 64.88it/s]Processing train dataset:  55%|█████▌    | 5549/10000 [01:20<00:58, 76.32it/s]Processing train dataset:  59%|█████▉    | 5920/10000 [01:20<00:53, 75.69it/s]Processing train dataset:  46%|████▌     | 4611/10000 [01:17<01:33, 57.65it/s]Processing train dataset:  59%|█████▉    | 5940/10000 [01:23<01:08, 59.29it/s]Processing train dataset:  55%|█████▍    | 5461/10000 [01:19<01:09, 64.90it/s]Processing train dataset:  56%|█████▌    | 5557/10000 [01:20<00:58, 76.60it/s]Processing train dataset:  59%|█████▉    | 5928/10000 [01:20<00:53, 75.44it/s]Processing train dataset:  59%|█████▉    | 5947/10000 [01:23<01:07, 60.41it/s]Processing train dataset:  46%|████▌     | 4617/10000 [01:17<01:38, 54.68it/s]Processing train dataset:  55%|█████▍    | 5469/10000 [01:20<01:07, 67.19it/s]Processing train dataset:  56%|█████▌    | 5566/10000 [01:20<00:56, 78.66it/s]Processing train dataset:  59%|█████▉    | 5936/10000 [01:20<00:54, 74.93it/s]Processing train dataset:  46%|████▌     | 4623/10000 [01:17<01:38, 54.62it/s]Processing train dataset:  55%|█████▍    | 5477/10000 [01:20<01:04, 70.60it/s]Processing train dataset:  60%|█████▉    | 5954/10000 [01:23<01:09, 58.09it/s]Processing train dataset:  56%|█████▌    | 5574/10000 [01:20<00:57, 76.79it/s]Processing train dataset:  59%|█████▉    | 5944/10000 [01:20<00:54, 74.59it/s]Processing train dataset:  55%|█████▍    | 5485/10000 [01:20<01:03, 71.22it/s]Processing train dataset:  46%|████▋     | 4630/10000 [01:18<01:37, 55.06it/s]Processing train dataset:  60%|█████▉    | 5960/10000 [01:24<01:11, 56.50it/s]Processing train dataset:  56%|█████▌    | 5583/10000 [01:20<00:56, 77.92it/s]Processing train dataset:  60%|█████▉    | 5953/10000 [01:20<00:52, 76.89it/s]Processing train dataset:  46%|████▋     | 4637/10000 [01:18<01:38, 54.28it/s]Processing train dataset:  60%|█████▉    | 5966/10000 [01:24<01:15, 53.15it/s]Processing train dataset:  56%|█████▌    | 5591/10000 [01:20<00:57, 76.96it/s]Processing train dataset:  55%|█████▍    | 5493/10000 [01:20<01:12, 62.49it/s]Processing train dataset:  60%|█████▉    | 5961/10000 [01:20<00:52, 77.27it/s]Processing train dataset:  60%|█████▉    | 5974/10000 [01:24<01:07, 59.83it/s]Processing train dataset:  56%|█████▌    | 5599/10000 [01:20<00:58, 75.08it/s]Processing train dataset:  60%|█████▉    | 5970/10000 [01:20<00:50, 79.29it/s]Processing train dataset:  46%|████▋     | 4644/10000 [01:18<01:41, 52.68it/s]Processing train dataset:  55%|█████▌    | 5500/10000 [01:20<01:19, 56.66it/s]Processing train dataset:  60%|█████▉    | 5983/10000 [01:24<01:00, 66.22it/s]Processing train dataset:  60%|█████▉    | 5980/10000 [01:20<00:47, 84.79it/s]Processing train dataset:  56%|█████▌    | 5609/10000 [01:20<00:54, 80.47it/s]Processing train dataset:  47%|████▋     | 4651/10000 [01:18<01:38, 54.45it/s]Processing train dataset:  55%|█████▌    | 5506/10000 [01:20<01:21, 55.32it/s]Processing train dataset:  60%|█████▉    | 5992/10000 [01:24<00:55, 72.63it/s]Processing train dataset:  60%|█████▉    | 5989/10000 [01:21<00:49, 81.52it/s]Processing train dataset:  56%|█████▌    | 5618/10000 [01:21<00:56, 77.47it/s]Processing train dataset:  47%|████▋     | 4657/10000 [01:18<01:36, 55.37it/s]Processing train dataset:  60%|██████    | 6002/10000 [01:24<00:50, 79.79it/s]Processing train dataset:  55%|█████▌    | 5512/10000 [01:20<01:27, 51.10it/s]Processing train dataset:  47%|████▋     | 4663/10000 [01:18<01:35, 55.65it/s]Processing train dataset:  56%|█████▋    | 5627/10000 [01:21<00:55, 78.77it/s]Processing train dataset:  60%|█████▉    | 5998/10000 [01:21<00:50, 79.57it/s]Processing train dataset:  60%|██████    | 6013/10000 [01:24<00:46, 85.61it/s]Processing train dataset:  55%|█████▌    | 5518/10000 [01:20<01:27, 51.22it/s]Processing train dataset:  60%|██████    | 6008/10000 [01:21<00:47, 84.89it/s]Processing train dataset:  56%|█████▋    | 5636/10000 [01:21<00:54, 79.46it/s]Processing train dataset:  47%|████▋     | 4670/10000 [01:18<01:35, 55.63it/s]Processing train dataset:  60%|██████    | 6023/10000 [01:24<00:44, 88.81it/s]Processing train dataset:  55%|█████▌    | 5524/10000 [01:21<01:26, 51.72it/s]Processing train dataset:  60%|██████    | 6018/10000 [01:21<00:44, 88.87it/s]Processing train dataset:  56%|█████▋    | 5644/10000 [01:21<00:55, 77.96it/s]Processing train dataset:  47%|████▋     | 4677/10000 [01:18<01:33, 56.72it/s]Processing train dataset:  60%|██████    | 6032/10000 [01:24<00:45, 86.40it/s]Processing train dataset:  55%|█████▌    | 5530/10000 [01:21<01:26, 51.44it/s]Processing train dataset:  57%|█████▋    | 5652/10000 [01:21<00:56, 77.52it/s]Processing train dataset:  60%|██████    | 6027/10000 [01:21<00:47, 83.84it/s]Processing train dataset:  47%|████▋     | 4683/10000 [01:19<01:37, 54.36it/s]Processing train dataset:  60%|██████    | 6042/10000 [01:25<00:45, 87.70it/s]Processing train dataset:  55%|█████▌    | 5536/10000 [01:21<01:26, 51.86it/s]Processing train dataset:  57%|█████▋    | 5660/10000 [01:21<00:56, 76.88it/s]Processing train dataset:  60%|██████    | 6036/10000 [01:21<00:49, 80.62it/s]Processing train dataset:  47%|████▋     | 4690/10000 [01:19<01:36, 54.76it/s]Processing train dataset:  61%|██████    | 6051/10000 [01:25<00:46, 84.67it/s]Processing train dataset:  55%|█████▌    | 5545/10000 [01:21<01:13, 60.33it/s]Processing train dataset:  57%|█████▋    | 5668/10000 [01:21<00:56, 76.34it/s]Processing train dataset:  60%|██████    | 6045/10000 [01:21<00:49, 80.48it/s]Processing train dataset:  47%|████▋     | 4697/10000 [01:19<01:33, 56.52it/s]Processing train dataset:  57%|█████▋    | 5676/10000 [01:21<00:56, 75.87it/s]Processing train dataset:  56%|█████▌    | 5552/10000 [01:21<01:16, 58.50it/s]Processing train dataset:  61%|██████    | 6060/10000 [01:25<00:53, 73.15it/s]Processing train dataset:  61%|██████    | 6054/10000 [01:21<00:50, 78.77it/s]Processing train dataset:  47%|████▋     | 4703/10000 [01:19<01:36, 54.76it/s]Processing train dataset:  57%|█████▋    | 5685/10000 [01:21<00:55, 77.79it/s]Processing train dataset:  56%|█████▌    | 5560/10000 [01:21<01:11, 62.32it/s]Processing train dataset:  61%|██████    | 6063/10000 [01:21<00:49, 79.37it/s]Processing train dataset:  61%|██████    | 6068/10000 [01:25<01:01, 64.24it/s]Processing train dataset:  47%|████▋     | 4709/10000 [01:19<01:40, 52.55it/s]Processing train dataset:  57%|█████▋    | 5693/10000 [01:22<00:55, 77.18it/s]Processing train dataset:  56%|█████▌    | 5567/10000 [01:21<01:11, 62.25it/s]Processing train dataset:  61%|██████    | 6072/10000 [01:22<00:48, 80.32it/s]Processing train dataset:  61%|██████    | 6075/10000 [01:25<01:00, 64.39it/s]Processing train dataset:  47%|████▋     | 4717/10000 [01:19<01:31, 57.92it/s]Processing train dataset:  57%|█████▋    | 5702/10000 [01:22<00:54, 79.03it/s]Processing train dataset:  56%|█████▌    | 5574/10000 [01:21<01:10, 62.54it/s]Processing train dataset:  61%|██████    | 6081/10000 [01:22<00:49, 78.71it/s]Processing train dataset:  61%|██████    | 6082/10000 [01:25<01:02, 63.11it/s]Processing train dataset:  57%|█████▋    | 5711/10000 [01:22<00:53, 80.52it/s]Processing train dataset:  47%|████▋     | 4723/10000 [01:19<01:35, 55.17it/s]Processing train dataset:  56%|█████▌    | 5581/10000 [01:21<01:08, 64.35it/s]Processing train dataset:  61%|██████    | 6089/10000 [01:22<00:50, 77.64it/s]Processing train dataset:  61%|██████    | 6089/10000 [01:25<01:05, 60.07it/s]Processing train dataset:  47%|████▋     | 4730/10000 [01:19<01:31, 57.34it/s]Processing train dataset:  57%|█████▋    | 5720/10000 [01:22<00:54, 78.20it/s]Processing train dataset:  56%|█████▌    | 5588/10000 [01:22<01:11, 61.36it/s]Processing train dataset:  61%|██████    | 6097/10000 [01:22<00:50, 77.36it/s]Processing train dataset:  61%|██████    | 6096/10000 [01:25<01:03, 61.36it/s]Processing train dataset:  47%|████▋     | 4737/10000 [01:20<01:30, 58.28it/s]Processing train dataset:  57%|█████▋    | 5728/10000 [01:22<00:57, 74.87it/s]Processing train dataset:  56%|█████▌    | 5595/10000 [01:22<01:10, 62.46it/s]Processing train dataset:  61%|██████    | 6105/10000 [01:22<00:50, 77.84it/s]Processing train dataset:  61%|██████    | 6103/10000 [01:26<01:01, 63.56it/s]Processing train dataset:  57%|█████▋    | 5737/10000 [01:22<00:54, 78.88it/s]Processing train dataset:  47%|████▋     | 4744/10000 [01:20<01:30, 57.92it/s]Processing train dataset:  61%|██████    | 6114/10000 [01:22<00:49, 79.11it/s]Processing train dataset:  56%|█████▌    | 5602/10000 [01:22<01:13, 59.52it/s]Processing train dataset:  61%|██████    | 6110/10000 [01:26<01:00, 64.15it/s]Processing train dataset:  57%|█████▋    | 5745/10000 [01:22<00:53, 79.15it/s]Processing train dataset:  61%|██████    | 6122/10000 [01:22<00:49, 77.76it/s]Processing train dataset:  48%|████▊     | 4751/10000 [01:20<01:31, 57.14it/s]Processing train dataset:  56%|█████▌    | 5610/10000 [01:22<01:09, 63.18it/s]Processing train dataset:  61%|██████    | 6117/10000 [01:26<01:02, 62.29it/s]Processing train dataset:  58%|█████▊    | 5753/10000 [01:22<00:55, 77.11it/s]Processing train dataset:  61%|██████▏   | 6130/10000 [01:22<00:50, 76.21it/s]Processing train dataset:  48%|████▊     | 4758/10000 [01:20<01:28, 59.12it/s]Processing train dataset:  56%|█████▌    | 5617/10000 [01:22<01:12, 60.05it/s]Processing train dataset:  58%|█████▊    | 5761/10000 [01:22<00:55, 75.82it/s]Processing train dataset:  61%|██████    | 6124/10000 [01:26<01:03, 61.34it/s]Processing train dataset:  61%|██████▏   | 6138/10000 [01:22<00:51, 75.12it/s]Processing train dataset:  48%|████▊     | 4764/10000 [01:20<01:30, 57.87it/s]Processing train dataset:  56%|█████▌    | 5624/10000 [01:22<01:12, 60.36it/s]Processing train dataset:  58%|█████▊    | 5769/10000 [01:23<00:58, 72.85it/s]Processing train dataset:  61%|██████▏   | 6131/10000 [01:26<01:04, 60.34it/s]Processing train dataset:  61%|██████▏   | 6146/10000 [01:23<00:51, 74.43it/s]Processing train dataset:  48%|████▊     | 4770/10000 [01:20<01:33, 55.98it/s]Processing train dataset:  56%|█████▋    | 5631/10000 [01:22<01:10, 61.61it/s]Processing train dataset:  58%|█████▊    | 5777/10000 [01:23<00:58, 72.75it/s]Processing train dataset:  62%|██████▏   | 6154/10000 [01:23<00:51, 74.47it/s]Processing train dataset:  61%|██████▏   | 6138/10000 [01:26<01:06, 58.38it/s]Processing train dataset:  48%|████▊     | 4776/10000 [01:20<01:31, 57.05it/s]Processing train dataset:  56%|█████▋    | 5640/10000 [01:22<01:03, 69.09it/s]Processing train dataset:  58%|█████▊    | 5785/10000 [01:23<00:57, 72.89it/s]Processing train dataset:  62%|██████▏   | 6162/10000 [01:23<00:51, 74.99it/s]Processing train dataset:  61%|██████▏   | 6145/10000 [01:26<01:08, 56.64it/s]Processing train dataset:  48%|████▊     | 4783/10000 [01:20<01:33, 55.81it/s]Processing train dataset:  56%|█████▋    | 5648/10000 [01:23<01:02, 69.78it/s]Processing train dataset:  58%|█████▊    | 5793/10000 [01:23<00:57, 72.88it/s]Processing train dataset:  62%|██████▏   | 6170/10000 [01:23<00:51, 74.95it/s]Processing train dataset:  48%|████▊     | 4789/10000 [01:20<01:32, 56.44it/s]Processing train dataset:  62%|██████▏   | 6152/10000 [01:26<01:06, 58.17it/s]Processing train dataset:  57%|█████▋    | 5656/10000 [01:23<01:03, 67.95it/s]Processing train dataset:  58%|█████▊    | 5801/10000 [01:23<00:57, 73.05it/s]Processing train dataset:  62%|██████▏   | 6178/10000 [01:23<00:51, 74.46it/s]Processing train dataset:  62%|██████▏   | 6159/10000 [01:26<01:03, 60.86it/s]Processing train dataset:  48%|████▊     | 4797/10000 [01:21<01:25, 60.83it/s]Processing train dataset:  57%|█████▋    | 5663/10000 [01:23<01:07, 64.17it/s]Processing train dataset:  58%|█████▊    | 5810/10000 [01:23<00:55, 75.19it/s]Processing train dataset:  62%|██████▏   | 6186/10000 [01:23<00:51, 74.26it/s]Processing train dataset:  62%|██████▏   | 6166/10000 [01:27<01:03, 60.41it/s]Processing train dataset:  48%|████▊     | 4804/10000 [01:21<01:25, 60.47it/s]Processing train dataset:  58%|█████▊    | 5818/10000 [01:23<00:56, 73.77it/s]Processing train dataset:  62%|██████▏   | 6195/10000 [01:23<00:48, 78.03it/s]Processing train dataset:  57%|█████▋    | 5670/10000 [01:23<01:15, 57.66it/s]Processing train dataset:  62%|██████▏   | 6173/10000 [01:27<01:03, 60.38it/s]Processing train dataset:  48%|████▊     | 4811/10000 [01:21<01:25, 60.96it/s]Processing train dataset:  58%|█████▊    | 5827/10000 [01:23<00:53, 78.00it/s]Processing train dataset:  62%|██████▏   | 6203/10000 [01:23<00:49, 76.44it/s]Processing train dataset:  57%|█████▋    | 5676/10000 [01:23<01:17, 55.93it/s]Processing train dataset:  62%|██████▏   | 6180/10000 [01:27<01:06, 57.36it/s]Processing train dataset:  48%|████▊     | 4818/10000 [01:21<01:31, 56.81it/s]Processing train dataset:  58%|█████▊    | 5835/10000 [01:23<00:55, 74.64it/s]Processing train dataset:  62%|██████▏   | 6211/10000 [01:23<00:50, 75.43it/s]Processing train dataset:  57%|█████▋    | 5682/10000 [01:23<01:23, 51.72it/s]Processing train dataset:  48%|████▊     | 4825/10000 [01:21<01:26, 59.61it/s]Processing train dataset:  62%|██████▏   | 6188/10000 [01:27<01:02, 61.22it/s]Processing train dataset:  62%|██████▏   | 6219/10000 [01:24<00:49, 76.69it/s]Processing train dataset:  58%|█████▊    | 5844/10000 [01:24<00:54, 76.50it/s]Processing train dataset:  57%|█████▋    | 5688/10000 [01:23<01:23, 51.71it/s]Processing train dataset:  62%|██████▏   | 6197/10000 [01:27<00:56, 67.72it/s]Processing train dataset:  48%|████▊     | 4832/10000 [01:21<01:28, 58.26it/s]Processing train dataset:  62%|██████▏   | 6229/10000 [01:24<00:46, 80.96it/s]Processing train dataset:  59%|█████▊    | 5852/10000 [01:24<00:54, 75.52it/s]Processing train dataset:  62%|██████▏   | 6206/10000 [01:27<00:51, 73.68it/s]Processing train dataset:  57%|█████▋    | 5694/10000 [01:23<01:26, 49.63it/s]Processing train dataset:  48%|████▊     | 4839/10000 [01:21<01:27, 59.04it/s]Processing train dataset:  62%|██████▏   | 6238/10000 [01:24<00:46, 80.98it/s]Processing train dataset:  59%|█████▊    | 5861/10000 [01:24<00:53, 76.73it/s]Processing train dataset:  62%|██████▏   | 6215/10000 [01:27<00:51, 73.63it/s]Processing train dataset:  57%|█████▋    | 5701/10000 [01:24<01:21, 52.65it/s]Processing train dataset:  48%|████▊     | 4846/10000 [01:21<01:27, 58.70it/s]Processing train dataset:  62%|██████▏   | 6247/10000 [01:24<00:47, 78.84it/s]Processing train dataset:  59%|█████▊    | 5870/10000 [01:24<00:53, 77.63it/s]Processing train dataset:  62%|██████▏   | 6224/10000 [01:27<00:51, 73.71it/s]Processing train dataset:  57%|█████▋    | 5707/10000 [01:24<01:22, 52.21it/s]Processing train dataset:  63%|██████▎   | 6255/10000 [01:24<00:47, 78.05it/s]Processing train dataset:  59%|█████▉    | 5878/10000 [01:24<00:54, 76.20it/s]Processing train dataset:  49%|████▊     | 4852/10000 [01:22<01:38, 52.52it/s]Processing train dataset:  57%|█████▋    | 5713/10000 [01:24<01:19, 54.18it/s]Processing train dataset:  63%|██████▎   | 6263/10000 [01:24<00:48, 77.72it/s]Processing train dataset:  62%|██████▏   | 6232/10000 [01:28<00:54, 69.63it/s]Processing train dataset:  59%|█████▉    | 5886/10000 [01:24<00:54, 75.67it/s]Processing train dataset:  49%|████▊     | 4860/10000 [01:22<01:32, 55.28it/s]Processing train dataset:  57%|█████▋    | 5719/10000 [01:24<01:19, 54.14it/s]Processing train dataset:  62%|██████▏   | 6240/10000 [01:28<00:53, 70.31it/s]Processing train dataset:  63%|██████▎   | 6271/10000 [01:24<00:50, 73.80it/s]Processing train dataset:  59%|█████▉    | 5894/10000 [01:24<00:56, 73.06it/s]Processing train dataset:  49%|████▊     | 4866/10000 [01:22<01:34, 54.47it/s]Processing train dataset:  57%|█████▋    | 5725/10000 [01:24<01:17, 55.12it/s]Processing train dataset:  62%|██████▏   | 6248/10000 [01:28<00:52, 71.45it/s]Processing train dataset:  63%|██████▎   | 6279/10000 [01:24<00:51, 71.58it/s]Processing train dataset:  59%|█████▉    | 5902/10000 [01:24<00:56, 72.54it/s]Processing train dataset:  49%|████▊     | 4873/10000 [01:22<01:33, 55.04it/s]Processing train dataset:  57%|█████▋    | 5731/10000 [01:24<01:22, 51.84it/s]Processing train dataset:  63%|██████▎   | 6257/10000 [01:28<00:50, 74.33it/s]Processing train dataset:  59%|█████▉    | 5910/10000 [01:24<00:54, 74.48it/s]Processing train dataset:  63%|██████▎   | 6287/10000 [01:24<00:52, 70.10it/s]Processing train dataset:  49%|████▉     | 4880/10000 [01:22<01:28, 57.96it/s]Processing train dataset:  59%|█████▉    | 5918/10000 [01:25<00:55, 73.52it/s]Processing train dataset:  57%|█████▋    | 5738/10000 [01:24<01:19, 53.39it/s]Processing train dataset:  63%|██████▎   | 6296/10000 [01:25<00:49, 74.59it/s]Processing train dataset:  63%|██████▎   | 6265/10000 [01:28<00:55, 67.02it/s]Processing train dataset:  49%|████▉     | 4888/10000 [01:22<01:23, 61.46it/s]Processing train dataset:  59%|█████▉    | 5926/10000 [01:25<00:55, 73.12it/s]Processing train dataset:  57%|█████▋    | 5745/10000 [01:24<01:15, 56.56it/s]Processing train dataset:  63%|██████▎   | 6305/10000 [01:25<00:47, 77.12it/s]Processing train dataset:  63%|██████▎   | 6272/10000 [01:28<00:55, 67.39it/s]Processing train dataset:  49%|████▉     | 4895/10000 [01:22<01:30, 56.21it/s]Processing train dataset:  63%|██████▎   | 6314/10000 [01:25<00:45, 80.43it/s]Processing train dataset:  59%|█████▉    | 5934/10000 [01:25<00:55, 72.90it/s]Processing train dataset:  58%|█████▊    | 5753/10000 [01:24<01:09, 61.42it/s]Processing train dataset:  63%|██████▎   | 6281/10000 [01:28<00:51, 71.98it/s]Processing train dataset:  63%|██████▎   | 6323/10000 [01:25<00:45, 80.89it/s]Processing train dataset:  58%|█████▊    | 5761/10000 [01:25<01:05, 64.69it/s]Processing train dataset:  59%|█████▉    | 5942/10000 [01:25<00:55, 72.53it/s]Processing train dataset:  63%|██████▎   | 6291/10000 [01:28<00:47, 78.06it/s]Processing train dataset:  49%|████▉     | 4901/10000 [01:22<01:42, 49.75it/s]Processing train dataset:  58%|█████▊    | 5768/10000 [01:25<01:05, 64.13it/s]Processing train dataset:  60%|█████▉    | 5951/10000 [01:25<00:53, 75.09it/s]Processing train dataset:  63%|██████▎   | 6300/10000 [01:28<00:45, 81.03it/s]Processing train dataset:  63%|██████▎   | 6332/10000 [01:25<00:47, 77.59it/s]Processing train dataset:  49%|████▉     | 4907/10000 [01:23<01:37, 52.04it/s]Processing train dataset:  58%|█████▊    | 5776/10000 [01:25<01:02, 67.42it/s]Processing train dataset:  63%|██████▎   | 6342/10000 [01:25<00:44, 81.60it/s]Processing train dataset:  63%|██████▎   | 6309/10000 [01:29<00:47, 78.07it/s]Processing train dataset:  60%|█████▉    | 5959/10000 [01:25<00:57, 69.94it/s]Processing train dataset:  49%|████▉     | 4913/10000 [01:23<01:37, 52.13it/s]Processing train dataset:  58%|█████▊    | 5784/10000 [01:25<01:00, 69.21it/s]Processing train dataset:  64%|██████▎   | 6351/10000 [01:25<00:44, 82.15it/s]Processing train dataset:  60%|█████▉    | 5967/10000 [01:25<00:55, 72.25it/s]Processing train dataset:  63%|██████▎   | 6320/10000 [01:29<00:43, 84.06it/s]Processing train dataset:  49%|████▉     | 4920/10000 [01:23<01:31, 55.48it/s]Processing train dataset:  58%|█████▊    | 5791/10000 [01:25<01:01, 68.74it/s]Processing train dataset:  64%|██████▎   | 6361/10000 [01:25<00:42, 86.06it/s]Processing train dataset:  60%|█████▉    | 5976/10000 [01:25<00:52, 77.03it/s]Processing train dataset:  63%|██████▎   | 6329/10000 [01:29<00:43, 85.24it/s]Processing train dataset:  49%|████▉     | 4928/10000 [01:23<01:22, 61.35it/s]Processing train dataset:  60%|█████▉    | 5985/10000 [01:25<00:50, 79.30it/s]Processing train dataset:  63%|██████▎   | 6338/10000 [01:29<00:44, 82.08it/s]Processing train dataset:  58%|█████▊    | 5798/10000 [01:25<01:08, 60.91it/s]Processing train dataset:  64%|██████▎   | 6370/10000 [01:25<00:45, 79.13it/s]Processing train dataset:  49%|████▉     | 4935/10000 [01:23<01:25, 58.94it/s]Processing train dataset:  60%|█████▉    | 5993/10000 [01:26<00:51, 78.35it/s]Processing train dataset:  58%|█████▊    | 5806/10000 [01:25<01:04, 65.51it/s]Processing train dataset:  63%|██████▎   | 6347/10000 [01:29<00:45, 80.97it/s]Processing train dataset:  64%|██████▍   | 6379/10000 [01:26<00:45, 79.30it/s]Processing train dataset:  49%|████▉     | 4942/10000 [01:23<01:26, 58.18it/s]Processing train dataset:  60%|██████    | 6002/10000 [01:26<00:50, 79.25it/s]Processing train dataset:  58%|█████▊    | 5815/10000 [01:25<00:59, 70.00it/s]Processing train dataset:  64%|██████▎   | 6356/10000 [01:29<00:44, 81.50it/s]Processing train dataset:  64%|██████▍   | 6388/10000 [01:26<00:47, 76.64it/s]Processing train dataset:  50%|████▉     | 4950/10000 [01:23<01:20, 62.36it/s]Processing train dataset:  60%|██████    | 6010/10000 [01:26<00:53, 75.20it/s]Processing train dataset:  58%|█████▊    | 5823/10000 [01:25<00:57, 72.32it/s]Processing train dataset:  64%|██████▎   | 6366/10000 [01:29<00:42, 85.51it/s]Processing train dataset:  64%|██████▍   | 6396/10000 [01:26<00:48, 75.04it/s]Processing train dataset:  50%|████▉     | 4958/10000 [01:23<01:18, 63.96it/s]Processing train dataset:  58%|█████▊    | 5831/10000 [01:26<00:56, 74.28it/s]Processing train dataset:  60%|██████    | 6020/10000 [01:26<00:49, 80.62it/s]Processing train dataset:  64%|██████▍   | 6375/10000 [01:29<00:42, 84.85it/s]Processing train dataset:  64%|██████▍   | 6405/10000 [01:26<00:46, 77.04it/s]Processing train dataset:  50%|████▉     | 4965/10000 [01:23<01:21, 62.16it/s]Processing train dataset:  64%|██████▍   | 6384/10000 [01:29<00:42, 85.79it/s]Processing train dataset:  60%|██████    | 6029/10000 [01:26<00:51, 77.36it/s]Processing train dataset:  58%|█████▊    | 5839/10000 [01:26<00:59, 69.35it/s]Processing train dataset:  64%|██████▍   | 6413/10000 [01:26<00:46, 76.60it/s]Processing train dataset:  50%|████▉     | 4973/10000 [01:24<01:19, 63.34it/s]Processing train dataset:  64%|██████▍   | 6394/10000 [01:30<00:41, 87.79it/s]Processing train dataset:  60%|██████    | 6037/10000 [01:26<00:52, 74.91it/s]Processing train dataset:  58%|█████▊    | 5847/10000 [01:26<01:02, 66.69it/s]Processing train dataset:  64%|██████▍   | 6422/10000 [01:26<00:46, 77.48it/s]Processing train dataset:  50%|████▉     | 4980/10000 [01:24<01:20, 62.54it/s]Processing train dataset:  64%|██████▍   | 6405/10000 [01:30<00:39, 91.95it/s]Processing train dataset:  60%|██████    | 6045/10000 [01:26<00:52, 75.49it/s]Processing train dataset:  59%|█████▊    | 5855/10000 [01:26<00:59, 69.58it/s]Processing train dataset:  64%|██████▍   | 6430/10000 [01:26<00:47, 74.98it/s]Processing train dataset:  50%|████▉     | 4987/10000 [01:24<01:20, 61.91it/s]Processing train dataset:  61%|██████    | 6053/10000 [01:26<00:52, 75.14it/s]Processing train dataset:  64%|██████▍   | 6415/10000 [01:30<00:42, 85.35it/s]Processing train dataset:  59%|█████▊    | 5863/10000 [01:26<00:58, 70.25it/s]Processing train dataset:  64%|██████▍   | 6438/10000 [01:26<00:47, 75.60it/s]Processing train dataset:  50%|████▉     | 4996/10000 [01:24<01:13, 68.51it/s]Processing train dataset:  61%|██████    | 6062/10000 [01:26<00:51, 76.76it/s]Processing train dataset:  64%|██████▍   | 6446/10000 [01:26<00:46, 76.82it/s]Processing train dataset:  59%|█████▊    | 5872/10000 [01:26<00:56, 73.37it/s]Processing train dataset:  64%|██████▍   | 6424/10000 [01:30<00:45, 78.18it/s]Processing train dataset:  50%|█████     | 5003/10000 [01:24<01:16, 65.62it/s]Processing train dataset:  61%|██████    | 6070/10000 [01:27<00:50, 77.62it/s]Processing train dataset:  65%|██████▍   | 6454/10000 [01:27<00:45, 77.52it/s]Processing train dataset:  59%|█████▉    | 5880/10000 [01:26<00:55, 74.61it/s]Processing train dataset:  64%|██████▍   | 6432/10000 [01:30<00:48, 73.63it/s]Processing train dataset:  50%|█████     | 5011/10000 [01:24<01:14, 66.68it/s]Processing train dataset:  65%|██████▍   | 6462/10000 [01:27<00:45, 77.90it/s]Processing train dataset:  59%|█████▉    | 5888/10000 [01:26<00:55, 74.67it/s]Processing train dataset:  61%|██████    | 6078/10000 [01:27<00:57, 68.52it/s]Processing train dataset:  64%|██████▍   | 6440/10000 [01:30<00:49, 71.23it/s]Processing train dataset:  50%|█████     | 5018/10000 [01:24<01:16, 65.35it/s]Processing train dataset:  65%|██████▍   | 6471/10000 [01:27<00:44, 79.37it/s]Processing train dataset:  59%|█████▉    | 5896/10000 [01:26<00:55, 74.09it/s]Processing train dataset:  61%|██████    | 6086/10000 [01:27<00:56, 69.19it/s]Processing train dataset:  64%|██████▍   | 6448/10000 [01:30<00:52, 68.09it/s]Processing train dataset:  65%|██████▍   | 6479/10000 [01:27<00:45, 77.17it/s]Processing train dataset:  50%|█████     | 5025/10000 [01:24<01:20, 62.10it/s]Processing train dataset:  59%|█████▉    | 5904/10000 [01:27<00:55, 73.25it/s]Processing train dataset:  61%|██████    | 6094/10000 [01:27<00:56, 69.51it/s]Processing train dataset:  50%|█████     | 5032/10000 [01:25<01:17, 63.72it/s]Processing train dataset:  65%|██████▍   | 6487/10000 [01:27<00:46, 75.79it/s]Processing train dataset:  59%|█████▉    | 5912/10000 [01:27<00:54, 74.52it/s]Processing train dataset:  65%|██████▍   | 6455/10000 [01:30<00:58, 60.73it/s]Processing train dataset:  61%|██████    | 6103/10000 [01:27<00:52, 74.34it/s]Processing train dataset:  50%|█████     | 5039/10000 [01:25<01:17, 64.17it/s]Processing train dataset:  65%|██████▍   | 6496/10000 [01:27<00:45, 77.35it/s]Processing train dataset:  59%|█████▉    | 5920/10000 [01:27<00:55, 74.02it/s]Processing train dataset:  61%|██████    | 6111/10000 [01:27<00:51, 75.40it/s]Processing train dataset:  65%|██████▍   | 6462/10000 [01:31<01:00, 58.78it/s]Processing train dataset:  65%|██████▌   | 6504/10000 [01:27<00:45, 76.91it/s]Processing train dataset:  59%|█████▉    | 5928/10000 [01:27<00:54, 74.49it/s]Processing train dataset:  50%|█████     | 5046/10000 [01:25<01:18, 62.95it/s]Processing train dataset:  61%|██████    | 6119/10000 [01:27<00:52, 73.67it/s]Processing train dataset:  65%|██████▍   | 6471/10000 [01:31<00:55, 63.53it/s]Processing train dataset:  65%|██████▌   | 6512/10000 [01:27<00:45, 77.03it/s]Processing train dataset:  59%|█████▉    | 5936/10000 [01:27<00:59, 68.21it/s]Processing train dataset:  61%|██████▏   | 6127/10000 [01:27<01:01, 63.03it/s]Processing train dataset:  51%|█████     | 5053/10000 [01:25<01:37, 50.93it/s]Processing train dataset:  65%|██████▌   | 6520/10000 [01:27<00:45, 76.86it/s]Processing train dataset:  65%|██████▌   | 6528/10000 [01:27<00:45, 77.14it/s]Processing train dataset:  61%|██████▏   | 6134/10000 [01:28<01:04, 60.15it/s]Processing train dataset:  65%|██████▍   | 6478/10000 [01:31<01:17, 45.22it/s]Processing train dataset:  59%|█████▉    | 5943/10000 [01:27<01:14, 54.64it/s]Processing train dataset:  51%|█████     | 5059/10000 [01:25<01:56, 42.39it/s]Processing train dataset:  65%|██████▌   | 6536/10000 [01:28<00:45, 76.90it/s]Processing train dataset:  61%|██████▏   | 6141/10000 [01:28<01:05, 59.04it/s]Processing train dataset:  60%|█████▉    | 5950/10000 [01:27<01:12, 55.90it/s]Processing train dataset:  65%|██████▍   | 6484/10000 [01:31<01:17, 45.15it/s]Processing train dataset:  65%|██████▌   | 6544/10000 [01:28<00:45, 76.38it/s]Processing train dataset:  51%|█████     | 5066/10000 [01:25<01:45, 46.59it/s]Processing train dataset:  61%|██████▏   | 6149/10000 [01:28<01:01, 62.64it/s]Processing train dataset:  60%|█████▉    | 5957/10000 [01:27<01:10, 56.97it/s]Processing train dataset:  65%|██████▍   | 6491/10000 [01:31<01:11, 49.13it/s]Processing train dataset:  66%|██████▌   | 6552/10000 [01:28<00:46, 74.89it/s]Processing train dataset:  51%|█████     | 5072/10000 [01:25<01:48, 45.62it/s]Processing train dataset:  62%|██████▏   | 6156/10000 [01:28<01:03, 60.61it/s]Processing train dataset:  65%|██████▍   | 6497/10000 [01:31<01:10, 49.52it/s]Processing train dataset:  60%|█████▉    | 5963/10000 [01:28<01:17, 52.25it/s]Processing train dataset:  66%|██████▌   | 6563/10000 [01:28<00:41, 82.90it/s]Processing train dataset:  51%|█████     | 5078/10000 [01:25<01:41, 48.29it/s]Processing train dataset:  62%|██████▏   | 6163/10000 [01:28<01:08, 56.08it/s]Processing train dataset:  65%|██████▌   | 6503/10000 [01:32<01:16, 45.97it/s]Processing train dataset:  60%|█████▉    | 5969/10000 [01:28<01:21, 49.65it/s]Processing train dataset:  66%|██████▌   | 6572/10000 [01:28<00:43, 78.44it/s]Processing train dataset:  51%|█████     | 5084/10000 [01:26<01:43, 47.27it/s]Processing train dataset:  62%|██████▏   | 6170/10000 [01:28<01:05, 58.70it/s]Processing train dataset:  60%|█████▉    | 5976/10000 [01:28<01:13, 54.42it/s]Processing train dataset:  65%|██████▌   | 6509/10000 [01:32<01:12, 48.48it/s]Processing train dataset:  66%|██████▌   | 6580/10000 [01:28<00:43, 77.77it/s]Processing train dataset:  51%|█████     | 5089/10000 [01:26<01:51, 44.18it/s]Processing train dataset:  62%|██████▏   | 6177/10000 [01:28<01:07, 56.82it/s]Processing train dataset:  60%|█████▉    | 5982/10000 [01:28<01:16, 52.63it/s]Processing train dataset:  66%|██████▌   | 6588/10000 [01:28<00:43, 77.73it/s]Processing train dataset:  65%|██████▌   | 6515/10000 [01:32<01:11, 48.56it/s]Processing train dataset:  51%|█████     | 5096/10000 [01:26<01:37, 50.43it/s]Processing train dataset:  62%|██████▏   | 6184/10000 [01:28<01:05, 58.39it/s]Processing train dataset:  66%|██████▌   | 6596/10000 [01:28<00:46, 73.09it/s]Processing train dataset:  65%|██████▌   | 6521/10000 [01:32<01:15, 46.28it/s]Processing train dataset:  60%|█████▉    | 5988/10000 [01:28<01:23, 47.96it/s]Processing train dataset:  51%|█████     | 5102/10000 [01:26<01:44, 46.72it/s]Processing train dataset:  62%|██████▏   | 6192/10000 [01:28<01:01, 62.07it/s]Processing train dataset:  66%|██████▌   | 6605/10000 [01:28<00:44, 76.04it/s]Processing train dataset:  65%|██████▌   | 6527/10000 [01:32<01:10, 49.59it/s]Processing train dataset:  60%|█████▉    | 5994/10000 [01:28<01:22, 48.51it/s]Processing train dataset:  51%|█████     | 5107/10000 [01:26<01:54, 42.83it/s]Processing train dataset:  66%|██████▌   | 6613/10000 [01:29<00:46, 72.35it/s]Processing train dataset:  62%|██████▏   | 6199/10000 [01:29<01:05, 58.21it/s]Processing train dataset:  65%|██████▌   | 6533/10000 [01:32<01:14, 46.39it/s]Processing train dataset:  60%|█████▉    | 5999/10000 [01:28<01:27, 45.85it/s]Processing train dataset:  66%|██████▌   | 6621/10000 [01:29<00:47, 71.17it/s]Processing train dataset:  51%|█████     | 5112/10000 [01:26<01:55, 42.45it/s]Processing train dataset:  62%|██████▏   | 6205/10000 [01:29<01:07, 56.03it/s]Processing train dataset:  60%|██████    | 6006/10000 [01:28<01:19, 50.27it/s]Processing train dataset:  65%|██████▌   | 6538/10000 [01:32<01:17, 44.92it/s]Processing train dataset:  66%|██████▋   | 6629/10000 [01:29<00:46, 72.28it/s]Processing train dataset:  62%|██████▏   | 6212/10000 [01:29<01:06, 57.01it/s]Processing train dataset:  51%|█████     | 5118/10000 [01:26<01:49, 44.59it/s]Processing train dataset:  60%|██████    | 6014/10000 [01:29<01:09, 57.32it/s]Processing train dataset:  65%|██████▌   | 6544/10000 [01:32<01:14, 46.45it/s]Processing train dataset:  66%|██████▋   | 6637/10000 [01:29<00:47, 70.30it/s]Processing train dataset:  62%|██████▏   | 6218/10000 [01:29<01:08, 55.61it/s]Processing train dataset:  51%|█████     | 5123/10000 [01:27<01:56, 41.77it/s]Processing train dataset:  60%|██████    | 6020/10000 [01:29<01:14, 53.62it/s]Processing train dataset:  65%|██████▌   | 6549/10000 [01:33<01:16, 45.20it/s]Processing train dataset:  66%|██████▋   | 6647/10000 [01:29<00:43, 76.37it/s]Processing train dataset:  62%|██████▏   | 6226/10000 [01:29<01:01, 61.59it/s]Processing train dataset:  60%|██████    | 6026/10000 [01:29<01:17, 51.33it/s]Processing train dataset:  51%|█████▏    | 5128/10000 [01:27<02:12, 36.80it/s]Processing train dataset:  67%|██████▋   | 6655/10000 [01:29<00:46, 72.44it/s]Processing train dataset:  66%|██████▌   | 6556/10000 [01:33<01:22, 41.86it/s]Processing train dataset:  60%|██████    | 6034/10000 [01:29<01:09, 57.40it/s]Processing train dataset:  62%|██████▏   | 6233/10000 [01:29<01:14, 50.86it/s]Processing train dataset:  51%|█████▏    | 5133/10000 [01:27<02:02, 39.71it/s]Processing train dataset:  67%|██████▋   | 6663/10000 [01:29<00:45, 73.44it/s]Processing train dataset:  66%|██████▌   | 6564/10000 [01:33<01:08, 50.39it/s]Processing train dataset:  60%|██████    | 6042/10000 [01:29<01:04, 61.78it/s]Processing train dataset:  62%|██████▏   | 6241/10000 [01:29<01:06, 56.85it/s]Processing train dataset:  51%|█████▏    | 5141/10000 [01:27<01:39, 48.85it/s]Processing train dataset:  67%|██████▋   | 6672/10000 [01:29<00:43, 76.27it/s]Processing train dataset:  66%|██████▌   | 6574/10000 [01:33<00:55, 61.87it/s]Processing train dataset:  61%|██████    | 6051/10000 [01:29<00:58, 67.63it/s]Processing train dataset:  62%|██████▏   | 6249/10000 [01:29<01:01, 61.42it/s]Processing train dataset:  51%|█████▏    | 5149/10000 [01:27<01:26, 55.76it/s]Processing train dataset:  66%|██████▌   | 6584/10000 [01:33<00:48, 70.90it/s]Processing train dataset:  67%|██████▋   | 6680/10000 [01:30<00:43, 76.22it/s]Processing train dataset:  61%|██████    | 6060/10000 [01:29<00:54, 72.19it/s]Processing train dataset:  63%|██████▎   | 6257/10000 [01:30<00:57, 64.98it/s]Processing train dataset:  52%|█████▏    | 5158/10000 [01:27<01:16, 63.15it/s]Processing train dataset:  67%|██████▋   | 6688/10000 [01:30<00:43, 75.96it/s]Processing train dataset:  66%|██████▌   | 6594/10000 [01:33<00:44, 77.25it/s]Processing train dataset:  61%|██████    | 6068/10000 [01:29<00:55, 71.44it/s]Processing train dataset:  63%|██████▎   | 6264/10000 [01:30<00:56, 66.21it/s]Processing train dataset:  67%|██████▋   | 6696/10000 [01:30<00:43, 75.15it/s]Processing train dataset:  52%|█████▏    | 5165/10000 [01:27<01:20, 59.77it/s]Processing train dataset:  61%|██████    | 6076/10000 [01:30<01:00, 64.82it/s]Processing train dataset:  63%|██████▎   | 6271/10000 [01:30<01:02, 59.26it/s]Processing train dataset:  67%|██████▋   | 6704/10000 [01:30<00:44, 74.16it/s]Processing train dataset:  66%|██████▌   | 6603/10000 [01:33<00:56, 60.22it/s]Processing train dataset:  67%|██████▋   | 6712/10000 [01:30<00:43, 75.37it/s]Processing train dataset:  52%|█████▏    | 5172/10000 [01:27<01:42, 47.04it/s]Processing train dataset:  61%|██████    | 6083/10000 [01:30<01:02, 62.22it/s]Processing train dataset:  63%|██████▎   | 6278/10000 [01:30<01:05, 56.45it/s]Processing train dataset:  66%|██████▌   | 6610/10000 [01:34<01:02, 54.33it/s]Processing train dataset:  67%|██████▋   | 6720/10000 [01:30<00:43, 76.02it/s]Processing train dataset:  52%|█████▏    | 5182/10000 [01:28<01:23, 57.72it/s]Processing train dataset:  61%|██████    | 6091/10000 [01:30<00:59, 65.29it/s]Processing train dataset:  63%|██████▎   | 6284/10000 [01:30<01:05, 56.52it/s]Processing train dataset:  66%|██████▌   | 6618/10000 [01:34<00:57, 59.09it/s]Processing train dataset:  67%|██████▋   | 6728/10000 [01:30<00:42, 77.10it/s]Processing train dataset:  52%|█████▏    | 5192/10000 [01:28<01:11, 66.81it/s]Processing train dataset:  61%|██████    | 6100/10000 [01:30<00:54, 71.69it/s]Processing train dataset:  63%|██████▎   | 6292/10000 [01:30<01:01, 60.53it/s]Processing train dataset:  66%|██████▋   | 6626/10000 [01:34<00:54, 61.51it/s]Processing train dataset:  67%|██████▋   | 6736/10000 [01:30<00:42, 76.95it/s]Processing train dataset:  52%|█████▏    | 5201/10000 [01:28<01:06, 71.89it/s]Processing train dataset:  61%|██████    | 6109/10000 [01:30<00:52, 73.91it/s]Processing train dataset:  63%|██████▎   | 6299/10000 [01:30<01:00, 61.11it/s]Processing train dataset:  67%|██████▋   | 6746/10000 [01:30<00:39, 82.01it/s]Processing train dataset:  52%|█████▏    | 5209/10000 [01:28<01:08, 70.20it/s]Processing train dataset:  66%|██████▋   | 6633/10000 [01:34<01:00, 55.47it/s]Processing train dataset:  61%|██████    | 6117/10000 [01:30<00:57, 67.06it/s]Processing train dataset:  63%|██████▎   | 6306/10000 [01:30<01:04, 57.13it/s]Processing train dataset:  52%|█████▏    | 5220/10000 [01:28<01:00, 79.46it/s]Processing train dataset:  68%|██████▊   | 6755/10000 [01:31<00:44, 73.67it/s]Processing train dataset:  66%|██████▋   | 6643/10000 [01:34<00:52, 63.57it/s]Processing train dataset:  61%|██████    | 6124/10000 [01:30<01:02, 61.83it/s]Processing train dataset:  63%|██████▎   | 6312/10000 [01:31<01:07, 54.65it/s]Processing train dataset:  68%|██████▊   | 6763/10000 [01:31<00:43, 74.75it/s]Processing train dataset:  66%|██████▋   | 6650/10000 [01:34<00:56, 59.32it/s]Processing train dataset:  52%|█████▏    | 5229/10000 [01:28<01:06, 72.00it/s]Processing train dataset:  61%|██████▏   | 6132/10000 [01:30<00:59, 65.01it/s]Processing train dataset:  63%|██████▎   | 6321/10000 [01:31<01:00, 61.06it/s]Processing train dataset:  68%|██████▊   | 6771/10000 [01:31<00:42, 75.24it/s]Processing train dataset:  52%|█████▏    | 5237/10000 [01:28<01:07, 71.03it/s]Processing train dataset:  67%|██████▋   | 6657/10000 [01:34<00:57, 58.08it/s]Processing train dataset:  61%|██████▏   | 6139/10000 [01:31<01:02, 61.70it/s]Processing train dataset:  63%|██████▎   | 6328/10000 [01:31<01:01, 59.35it/s]Processing train dataset:  68%|██████▊   | 6781/10000 [01:31<00:40, 80.18it/s]Processing train dataset:  52%|█████▏    | 5247/10000 [01:28<01:01, 76.76it/s]Processing train dataset:  67%|██████▋   | 6664/10000 [01:34<00:55, 60.00it/s]Processing train dataset:  61%|██████▏   | 6147/10000 [01:31<00:59, 64.83it/s]Processing train dataset:  63%|██████▎   | 6336/10000 [01:31<00:57, 63.48it/s]Processing train dataset:  68%|██████▊   | 6790/10000 [01:31<00:39, 81.31it/s]Processing train dataset:  53%|█████▎    | 5256/10000 [01:29<01:04, 73.81it/s]Processing train dataset:  67%|██████▋   | 6671/10000 [01:35<00:56, 58.47it/s]Processing train dataset:  68%|██████▊   | 6799/10000 [01:31<00:38, 82.59it/s]Processing train dataset:  63%|██████▎   | 6343/10000 [01:31<00:59, 61.08it/s]Processing train dataset:  62%|██████▏   | 6154/10000 [01:31<01:03, 60.24it/s]Processing train dataset:  67%|██████▋   | 6677/10000 [01:35<00:56, 58.82it/s]Processing train dataset:  53%|█████▎    | 5266/10000 [01:29<01:00, 78.79it/s]Processing train dataset:  62%|██████▏   | 6161/10000 [01:31<01:01, 62.51it/s]Processing train dataset:  64%|██████▎   | 6350/10000 [01:31<01:02, 58.63it/s]Processing train dataset:  68%|██████▊   | 6808/10000 [01:31<00:45, 70.90it/s]Processing train dataset:  67%|██████▋   | 6683/10000 [01:35<01:00, 55.18it/s]Processing train dataset:  53%|█████▎    | 5275/10000 [01:29<01:03, 73.84it/s]Processing train dataset:  64%|██████▎   | 6356/10000 [01:31<01:02, 58.53it/s]Processing train dataset:  62%|██████▏   | 6168/10000 [01:31<01:03, 59.90it/s]Processing train dataset:  68%|██████▊   | 6817/10000 [01:31<00:43, 73.52it/s]Processing train dataset:  67%|██████▋   | 6690/10000 [01:35<00:56, 58.25it/s]Processing train dataset:  53%|█████▎    | 5285/10000 [01:29<01:07, 70.14it/s]Processing train dataset:  64%|██████▎   | 6365/10000 [01:31<00:59, 61.13it/s]Processing train dataset:  62%|██████▏   | 6175/10000 [01:31<01:07, 56.84it/s]Processing train dataset:  68%|██████▊   | 6825/10000 [01:31<00:45, 70.19it/s]Processing train dataset:  67%|██████▋   | 6696/10000 [01:35<01:00, 54.62it/s]Processing train dataset:  64%|██████▎   | 6373/10000 [01:32<00:56, 64.45it/s]Processing train dataset:  53%|█████▎    | 5296/10000 [01:29<01:00, 77.68it/s]Processing train dataset:  62%|██████▏   | 6183/10000 [01:31<01:02, 61.34it/s]Processing train dataset:  68%|██████▊   | 6834/10000 [01:32<00:43, 73.32it/s]Processing train dataset:  67%|██████▋   | 6704/10000 [01:35<00:58, 56.47it/s]Processing train dataset:  53%|█████▎    | 5305/10000 [01:29<01:01, 76.07it/s]Processing train dataset:  64%|██████▍   | 6380/10000 [01:32<00:59, 60.86it/s]Processing train dataset:  62%|██████▏   | 6190/10000 [01:31<01:05, 58.12it/s]Processing train dataset:  68%|██████▊   | 6842/10000 [01:32<00:44, 70.49it/s]Processing train dataset:  67%|██████▋   | 6711/10000 [01:35<00:55, 58.94it/s]Processing train dataset:  53%|█████▎    | 5315/10000 [01:29<00:58, 80.28it/s]Processing train dataset:  64%|██████▍   | 6387/10000 [01:32<00:59, 60.90it/s]Processing train dataset:  62%|██████▏   | 6200/10000 [01:31<00:56, 66.94it/s]Processing train dataset:  69%|██████▊   | 6851/10000 [01:32<00:42, 73.80it/s]Processing train dataset:  64%|██████▍   | 6394/10000 [01:32<00:58, 61.81it/s]Processing train dataset:  67%|██████▋   | 6718/10000 [01:35<01:04, 50.81it/s]Processing train dataset:  69%|██████▊   | 6860/10000 [01:32<00:41, 76.38it/s]Processing train dataset:  62%|██████▏   | 6207/10000 [01:32<01:08, 55.66it/s]Processing train dataset:  64%|██████▍   | 6403/10000 [01:32<00:53, 67.73it/s]Processing train dataset:  69%|██████▊   | 6868/10000 [01:32<00:41, 75.11it/s]Processing train dataset:  53%|█████▎    | 5324/10000 [01:30<01:31, 51.36it/s]Processing train dataset:  64%|██████▍   | 6411/10000 [01:32<00:51, 69.19it/s]Processing train dataset:  62%|██████▏   | 6213/10000 [01:32<01:13, 51.25it/s]Processing train dataset:  69%|██████▉   | 6876/10000 [01:32<00:41, 75.53it/s]Processing train dataset:  67%|██████▋   | 6724/10000 [01:36<01:27, 37.40it/s]Processing train dataset:  62%|██████▏   | 6219/10000 [01:32<01:11, 52.76it/s]Processing train dataset:  64%|██████▍   | 6419/10000 [01:32<00:50, 70.44it/s]Processing train dataset:  69%|██████▉   | 6886/10000 [01:32<00:38, 80.61it/s]Processing train dataset:  53%|█████▎    | 5331/10000 [01:30<01:31, 51.29it/s]Processing train dataset:  67%|██████▋   | 6729/10000 [01:36<01:24, 38.76it/s]Processing train dataset:  62%|██████▏   | 6227/10000 [01:32<01:04, 58.85it/s]Processing train dataset:  64%|██████▍   | 6427/10000 [01:32<00:49, 71.65it/s]Processing train dataset:  69%|██████▉   | 6895/10000 [01:32<00:39, 79.42it/s]Processing train dataset:  53%|█████▎    | 5338/10000 [01:30<01:37, 47.82it/s]Processing train dataset:  67%|██████▋   | 6734/10000 [01:36<01:24, 38.67it/s]Processing train dataset:  64%|██████▍   | 6435/10000 [01:32<00:48, 72.97it/s]Processing train dataset:  62%|██████▏   | 6234/10000 [01:32<01:03, 58.89it/s]Processing train dataset:  69%|██████▉   | 6904/10000 [01:32<00:38, 80.70it/s]Processing train dataset:  64%|██████▍   | 6443/10000 [01:33<00:48, 74.07it/s]Processing train dataset:  67%|██████▋   | 6739/10000 [01:36<01:24, 38.80it/s]Processing train dataset:  53%|█████▎    | 5344/10000 [01:30<01:39, 46.65it/s]Processing train dataset:  62%|██████▏   | 6241/10000 [01:32<01:05, 57.19it/s]Processing train dataset:  69%|██████▉   | 6913/10000 [01:33<00:39, 78.03it/s]Processing train dataset:  65%|██████▍   | 6451/10000 [01:33<00:47, 74.30it/s]Processing train dataset:  67%|██████▋   | 6747/10000 [01:36<01:09, 46.57it/s]Processing train dataset:  54%|█████▎    | 5350/10000 [01:30<01:36, 48.32it/s]Processing train dataset:  62%|██████▏   | 6247/10000 [01:32<01:05, 56.94it/s]Processing train dataset:  69%|██████▉   | 6921/10000 [01:33<00:39, 77.32it/s]Processing train dataset:  65%|██████▍   | 6459/10000 [01:33<00:47, 74.52it/s]Processing train dataset:  68%|██████▊   | 6752/10000 [01:36<01:09, 46.83it/s]Processing train dataset:  54%|█████▎    | 5356/10000 [01:30<01:33, 49.69it/s]Processing train dataset:  69%|██████▉   | 6931/10000 [01:33<00:37, 80.99it/s]Processing train dataset:  63%|██████▎   | 6253/10000 [01:32<01:07, 55.13it/s]Processing train dataset:  65%|██████▍   | 6468/10000 [01:33<00:46, 76.56it/s]Processing train dataset:  54%|█████▎    | 5364/10000 [01:30<01:23, 55.81it/s]Processing train dataset:  68%|██████▊   | 6759/10000 [01:36<01:04, 50.20it/s]Processing train dataset:  69%|██████▉   | 6940/10000 [01:33<00:38, 79.46it/s]Processing train dataset:  63%|██████▎   | 6260/10000 [01:33<01:07, 55.06it/s]Processing train dataset:  65%|██████▍   | 6476/10000 [01:33<00:46, 75.17it/s]Processing train dataset:  54%|█████▎    | 5370/10000 [01:31<01:24, 54.75it/s]Processing train dataset:  68%|██████▊   | 6765/10000 [01:36<01:04, 50.15it/s]Processing train dataset:  69%|██████▉   | 6949/10000 [01:33<00:37, 80.82it/s]Processing train dataset:  63%|██████▎   | 6266/10000 [01:33<01:11, 52.02it/s]Processing train dataset:  65%|██████▍   | 6484/10000 [01:33<00:47, 74.33it/s]Processing train dataset:  54%|█████▍    | 5378/10000 [01:31<01:16, 60.70it/s]Processing train dataset:  68%|██████▊   | 6771/10000 [01:37<01:03, 50.73it/s]Processing train dataset:  70%|██████▉   | 6958/10000 [01:33<00:38, 79.42it/s]Processing train dataset:  63%|██████▎   | 6272/10000 [01:33<01:10, 52.99it/s]Processing train dataset:  65%|██████▍   | 6492/10000 [01:33<00:47, 73.72it/s]Processing train dataset:  54%|█████▍    | 5387/10000 [01:31<01:08, 67.29it/s]Processing train dataset:  68%|██████▊   | 6777/10000 [01:37<01:01, 52.39it/s]Processing train dataset:  70%|██████▉   | 6967/10000 [01:33<00:37, 80.99it/s]Processing train dataset:  63%|██████▎   | 6278/10000 [01:33<01:09, 53.22it/s]Processing train dataset:  65%|██████▌   | 6501/10000 [01:33<00:45, 76.14it/s]Processing train dataset:  54%|█████▍    | 5395/10000 [01:31<01:05, 69.94it/s]Processing train dataset:  70%|██████▉   | 6977/10000 [01:33<00:35, 84.12it/s]Processing train dataset:  68%|██████▊   | 6783/10000 [01:37<01:04, 49.60it/s]Processing train dataset:  63%|██████▎   | 6284/10000 [01:33<01:13, 50.80it/s]Processing train dataset:  65%|██████▌   | 6509/10000 [01:33<00:45, 76.11it/s]Processing train dataset:  54%|█████▍    | 5403/10000 [01:31<01:04, 71.27it/s]Processing train dataset:  70%|██████▉   | 6986/10000 [01:33<00:37, 81.32it/s]Processing train dataset:  68%|██████▊   | 6789/10000 [01:37<01:06, 48.50it/s]Processing train dataset:  65%|██████▌   | 6517/10000 [01:34<00:46, 75.35it/s]Processing train dataset:  54%|█████▍    | 5411/10000 [01:31<01:04, 71.66it/s]Processing train dataset:  63%|██████▎   | 6290/10000 [01:33<01:15, 49.38it/s]Processing train dataset:  70%|██████▉   | 6995/10000 [01:34<00:36, 81.97it/s]Processing train dataset:  68%|██████▊   | 6795/10000 [01:37<01:04, 49.53it/s]Processing train dataset:  65%|██████▌   | 6525/10000 [01:34<00:46, 75.12it/s]Processing train dataset:  54%|█████▍    | 5419/10000 [01:31<01:04, 71.52it/s]Processing train dataset:  63%|██████▎   | 6296/10000 [01:33<01:16, 48.17it/s]Processing train dataset:  70%|███████   | 7004/10000 [01:34<00:37, 80.37it/s]Processing train dataset:  68%|██████▊   | 6803/10000 [01:37<00:56, 56.43it/s]Processing train dataset:  65%|██████▌   | 6533/10000 [01:34<00:46, 75.31it/s]Processing train dataset:  54%|█████▍    | 5430/10000 [01:31<00:56, 80.19it/s]Processing train dataset:  63%|██████▎   | 6303/10000 [01:33<01:10, 52.61it/s]Processing train dataset:  70%|███████   | 7014/10000 [01:34<00:35, 84.03it/s]Processing train dataset:  65%|██████▌   | 6541/10000 [01:34<00:45, 75.70it/s]Processing train dataset:  68%|██████▊   | 6809/10000 [01:37<01:00, 52.93it/s]Processing train dataset:  54%|█████▍    | 5439/10000 [01:31<00:58, 78.38it/s]Processing train dataset:  63%|██████▎   | 6309/10000 [01:34<01:12, 50.86it/s]Processing train dataset:  70%|███████   | 7023/10000 [01:34<00:35, 84.70it/s]Processing train dataset:  65%|██████▌   | 6549/10000 [01:34<00:46, 74.81it/s]Processing train dataset:  68%|██████▊   | 6817/10000 [01:37<00:54, 58.11it/s]Processing train dataset:  54%|█████▍    | 5447/10000 [01:32<01:01, 73.96it/s]Processing train dataset:  63%|██████▎   | 6315/10000 [01:34<01:09, 52.92it/s]Processing train dataset:  70%|███████   | 7032/10000 [01:34<00:36, 81.70it/s]Processing train dataset:  66%|██████▌   | 6558/10000 [01:34<00:44, 77.22it/s]Processing train dataset:  68%|██████▊   | 6826/10000 [01:38<00:50, 62.83it/s]Processing train dataset:  63%|██████▎   | 6323/10000 [01:34<01:01, 59.90it/s]Processing train dataset:  70%|███████   | 7041/10000 [01:34<00:37, 79.84it/s]Processing train dataset:  55%|█████▍    | 5455/10000 [01:32<01:09, 65.55it/s]Processing train dataset:  66%|██████▌   | 6568/10000 [01:34<00:42, 81.47it/s]Processing train dataset:  68%|██████▊   | 6834/10000 [01:38<00:48, 65.59it/s]Processing train dataset:  63%|██████▎   | 6330/10000 [01:34<01:00, 60.39it/s]Processing train dataset:  70%|███████   | 7050/10000 [01:34<00:37, 79.36it/s]Processing train dataset:  66%|██████▌   | 6577/10000 [01:34<00:41, 81.79it/s]Processing train dataset:  55%|█████▍    | 5462/10000 [01:32<01:11, 63.08it/s]Processing train dataset:  68%|██████▊   | 6842/10000 [01:38<00:48, 64.76it/s]Processing train dataset:  63%|██████▎   | 6339/10000 [01:34<00:57, 63.94it/s]Processing train dataset:  71%|███████   | 7058/10000 [01:34<00:38, 76.43it/s]Processing train dataset:  66%|██████▌   | 6586/10000 [01:34<00:42, 80.74it/s]Processing train dataset:  55%|█████▍    | 5469/10000 [01:32<01:18, 57.67it/s]Processing train dataset:  68%|██████▊   | 6850/10000 [01:38<00:47, 66.62it/s]Processing train dataset:  63%|██████▎   | 6346/10000 [01:34<00:57, 63.98it/s]Processing train dataset:  71%|███████   | 7067/10000 [01:34<00:36, 79.67it/s]Processing train dataset:  66%|██████▌   | 6595/10000 [01:35<00:42, 79.40it/s]Processing train dataset:  55%|█████▍    | 5475/10000 [01:32<01:18, 57.59it/s]Processing train dataset:  69%|██████▊   | 6858/10000 [01:38<00:45, 68.91it/s]Processing train dataset:  64%|██████▎   | 6354/10000 [01:34<00:55, 65.93it/s]Processing train dataset:  71%|███████   | 7076/10000 [01:35<00:36, 79.54it/s]Processing train dataset:  66%|██████▌   | 6603/10000 [01:35<00:43, 78.99it/s]Processing train dataset:  55%|█████▍    | 5481/10000 [01:32<01:18, 57.59it/s]Processing train dataset:  69%|██████▊   | 6865/10000 [01:38<00:46, 68.08it/s]Processing train dataset:  64%|██████▎   | 6363/10000 [01:34<00:50, 72.10it/s]Processing train dataset:  71%|███████   | 7085/10000 [01:35<00:36, 79.58it/s]Processing train dataset:  55%|█████▍    | 5488/10000 [01:32<01:14, 60.28it/s]Processing train dataset:  66%|██████▌   | 6611/10000 [01:35<00:47, 71.58it/s]Processing train dataset:  69%|██████▊   | 6873/10000 [01:38<00:44, 69.86it/s]Processing train dataset:  64%|██████▎   | 6372/10000 [01:34<00:49, 72.60it/s]Processing train dataset:  71%|███████   | 7093/10000 [01:35<00:37, 77.56it/s]Processing train dataset:  69%|██████▉   | 6881/10000 [01:38<00:43, 72.38it/s]Processing train dataset:  66%|██████▌   | 6619/10000 [01:35<00:47, 71.00it/s]Processing train dataset:  55%|█████▍    | 5495/10000 [01:32<01:17, 58.10it/s]Processing train dataset:  64%|██████▍   | 6380/10000 [01:35<00:49, 72.77it/s]Processing train dataset:  71%|███████   | 7101/10000 [01:35<00:37, 76.56it/s]Processing train dataset:  69%|██████▉   | 6890/10000 [01:38<00:40, 76.12it/s]Processing train dataset:  55%|█████▌    | 5503/10000 [01:33<01:12, 61.70it/s]Processing train dataset:  66%|██████▋   | 6627/10000 [01:35<00:50, 67.17it/s]Processing train dataset:  64%|██████▍   | 6388/10000 [01:35<00:48, 74.56it/s]Processing train dataset:  71%|███████   | 7111/10000 [01:35<00:35, 80.33it/s]Processing train dataset:  69%|██████▉   | 6898/10000 [01:39<00:41, 75.05it/s]Processing train dataset:  66%|██████▋   | 6634/10000 [01:35<00:49, 67.44it/s]Processing train dataset:  64%|██████▍   | 6396/10000 [01:35<00:48, 74.97it/s]Processing train dataset:  55%|█████▌    | 5510/10000 [01:33<01:15, 59.58it/s]Processing train dataset:  71%|███████   | 7121/10000 [01:35<00:33, 85.44it/s]Processing train dataset:  69%|██████▉   | 6906/10000 [01:39<00:41, 73.76it/s]Processing train dataset:  66%|██████▋   | 6641/10000 [01:35<00:50, 66.12it/s]Processing train dataset:  64%|██████▍   | 6404/10000 [01:35<00:49, 72.26it/s]Processing train dataset:  55%|█████▌    | 5517/10000 [01:33<01:18, 57.23it/s]Processing train dataset:  71%|███████▏  | 7131/10000 [01:35<00:33, 86.38it/s]Processing train dataset:  69%|██████▉   | 6914/10000 [01:39<00:43, 71.46it/s]Processing train dataset:  66%|██████▋   | 6649/10000 [01:35<00:48, 69.36it/s]Processing train dataset:  64%|██████▍   | 6412/10000 [01:35<00:51, 69.98it/s]Processing train dataset:  55%|█████▌    | 5523/10000 [01:33<01:20, 55.30it/s]Processing train dataset:  71%|███████▏  | 7140/10000 [01:35<00:34, 82.90it/s]Processing train dataset:  69%|██████▉   | 6923/10000 [01:39<00:42, 72.62it/s]Processing train dataset:  67%|██████▋   | 6656/10000 [01:35<00:51, 64.80it/s]Processing train dataset:  64%|██████▍   | 6421/10000 [01:35<00:47, 75.35it/s]Processing train dataset:  55%|█████▌    | 5529/10000 [01:33<01:19, 56.16it/s]Processing train dataset:  71%|███████▏  | 7149/10000 [01:35<00:34, 82.63it/s]Processing train dataset:  69%|██████▉   | 6933/10000 [01:39<00:38, 78.93it/s]Processing train dataset:  67%|██████▋   | 6663/10000 [01:36<00:53, 62.30it/s]Processing train dataset:  64%|██████▍   | 6429/10000 [01:35<00:48, 74.06it/s]Processing train dataset:  55%|█████▌    | 5535/10000 [01:33<01:20, 55.26it/s]Processing train dataset:  72%|███████▏  | 7159/10000 [01:36<00:33, 84.69it/s]Processing train dataset:  69%|██████▉   | 6941/10000 [01:39<00:39, 76.72it/s]Processing train dataset:  64%|██████▍   | 6437/10000 [01:35<00:48, 73.51it/s]Processing train dataset:  67%|██████▋   | 6670/10000 [01:36<00:54, 61.16it/s]Processing train dataset:  55%|█████▌    | 5543/10000 [01:33<01:13, 60.85it/s]Processing train dataset:  72%|███████▏  | 7168/10000 [01:36<00:34, 83.14it/s]Processing train dataset:  69%|██████▉   | 6949/10000 [01:39<00:40, 76.09it/s]Processing train dataset:  64%|██████▍   | 6445/10000 [01:35<00:50, 70.92it/s]Processing train dataset:  67%|██████▋   | 6677/10000 [01:36<00:56, 59.18it/s]Processing train dataset:  56%|█████▌    | 5550/10000 [01:33<01:16, 58.39it/s]Processing train dataset:  72%|███████▏  | 7177/10000 [01:36<00:35, 80.19it/s]Processing train dataset:  70%|██████▉   | 6957/10000 [01:39<00:42, 71.69it/s]Processing train dataset:  65%|██████▍   | 6453/10000 [01:36<00:51, 69.29it/s]Processing train dataset:  67%|██████▋   | 6683/10000 [01:36<00:57, 57.29it/s]Processing train dataset:  56%|█████▌    | 5556/10000 [01:33<01:16, 57.85it/s]Processing train dataset:  72%|███████▏  | 7186/10000 [01:36<00:36, 77.46it/s]Processing train dataset:  70%|██████▉   | 6965/10000 [01:39<00:42, 70.78it/s]Processing train dataset:  67%|██████▋   | 6689/10000 [01:36<00:58, 56.16it/s]Processing train dataset:  56%|█████▌    | 5564/10000 [01:34<01:11, 62.45it/s]Processing train dataset:  65%|██████▍   | 6460/10000 [01:36<00:53, 65.66it/s]Processing train dataset:  72%|███████▏  | 7194/10000 [01:36<00:35, 77.98it/s]Processing train dataset:  70%|██████▉   | 6974/10000 [01:40<00:40, 74.45it/s]Processing train dataset:  67%|██████▋   | 6695/10000 [01:36<00:59, 55.20it/s]Processing train dataset:  65%|██████▍   | 6467/10000 [01:36<00:55, 64.14it/s]Processing train dataset:  72%|███████▏  | 7202/10000 [01:36<00:36, 76.96it/s]Processing train dataset:  56%|█████▌    | 5571/10000 [01:34<01:14, 59.34it/s]Processing train dataset:  70%|██████▉   | 6984/10000 [01:40<00:37, 80.28it/s]Processing train dataset:  67%|██████▋   | 6701/10000 [01:36<00:59, 55.65it/s]Processing train dataset:  72%|███████▏  | 7211/10000 [01:36<00:35, 78.24it/s]Processing train dataset:  56%|█████▌    | 5578/10000 [01:34<01:13, 60.05it/s]Processing train dataset:  65%|██████▍   | 6474/10000 [01:36<00:59, 59.09it/s]Processing train dataset:  70%|██████▉   | 6994/10000 [01:40<00:35, 84.31it/s]Processing train dataset:  67%|██████▋   | 6707/10000 [01:36<01:00, 54.24it/s]Processing train dataset:  72%|███████▏  | 7219/10000 [01:36<00:35, 78.50it/s]Processing train dataset:  56%|█████▌    | 5585/10000 [01:34<01:12, 61.07it/s]Processing train dataset:  65%|██████▍   | 6481/10000 [01:36<00:58, 60.35it/s]Processing train dataset:  72%|███████▏  | 7228/10000 [01:36<00:34, 80.95it/s]Processing train dataset:  70%|███████   | 7003/10000 [01:40<00:41, 71.50it/s]Processing train dataset:  67%|██████▋   | 6714/10000 [01:36<00:59, 55.08it/s]Processing train dataset:  65%|██████▍   | 6488/10000 [01:36<00:55, 62.88it/s]Processing train dataset:  56%|█████▌    | 5592/10000 [01:34<01:15, 58.30it/s]Processing train dataset:  67%|██████▋   | 6720/10000 [01:37<00:58, 55.68it/s]Processing train dataset:  72%|███████▏  | 7237/10000 [01:37<00:35, 78.44it/s]Processing train dataset:  70%|███████   | 7011/10000 [01:40<00:42, 70.86it/s]Processing train dataset:  65%|██████▍   | 6495/10000 [01:36<00:54, 64.66it/s]Processing train dataset:  56%|█████▌    | 5599/10000 [01:34<01:17, 56.45it/s]Processing train dataset:  72%|███████▏  | 7245/10000 [01:37<00:35, 77.22it/s]Processing train dataset:  65%|██████▌   | 6502/10000 [01:36<00:53, 64.96it/s]Processing train dataset:  67%|██████▋   | 6726/10000 [01:37<01:01, 53.29it/s]Processing train dataset:  70%|███████   | 7019/10000 [01:40<00:44, 66.77it/s]Processing train dataset:  56%|█████▌    | 5609/10000 [01:34<01:07, 65.43it/s]Processing train dataset:  73%|███████▎  | 7254/10000 [01:37<00:35, 78.18it/s]Processing train dataset:  65%|██████▌   | 6509/10000 [01:37<00:53, 65.30it/s]Processing train dataset:  67%|██████▋   | 6733/10000 [01:37<00:58, 55.60it/s]Processing train dataset:  70%|███████   | 7026/10000 [01:40<00:44, 67.21it/s]Processing train dataset:  56%|█████▌    | 5616/10000 [01:34<01:13, 60.04it/s]Processing train dataset:  73%|███████▎  | 7263/10000 [01:37<00:33, 80.65it/s]Processing train dataset:  65%|██████▌   | 6516/10000 [01:37<00:52, 65.76it/s]Processing train dataset:  70%|███████   | 7033/10000 [01:40<00:46, 64.49it/s]Processing train dataset:  67%|██████▋   | 6739/10000 [01:37<01:06, 49.36it/s]Processing train dataset:  73%|███████▎  | 7272/10000 [01:37<00:33, 80.40it/s]Processing train dataset:  65%|██████▌   | 6523/10000 [01:37<00:53, 65.47it/s]Processing train dataset:  56%|█████▌    | 5623/10000 [01:35<01:19, 55.07it/s]Processing train dataset:  70%|███████   | 7040/10000 [01:41<00:48, 60.74it/s]Processing train dataset:  67%|██████▋   | 6747/10000 [01:37<00:58, 55.15it/s]Processing train dataset:  65%|██████▌   | 6530/10000 [01:37<00:52, 65.79it/s]Processing train dataset:  73%|███████▎  | 7281/10000 [01:37<00:33, 80.52it/s]Processing train dataset:  56%|█████▋    | 5629/10000 [01:35<01:23, 52.43it/s]Processing train dataset:  70%|███████   | 7047/10000 [01:41<00:49, 59.41it/s]Processing train dataset:  68%|██████▊   | 6753/10000 [01:37<01:01, 52.44it/s]Processing train dataset:  65%|██████▌   | 6537/10000 [01:37<00:52, 66.00it/s]Processing train dataset:  73%|███████▎  | 7291/10000 [01:37<00:32, 83.24it/s]Processing train dataset:  56%|█████▋    | 5635/10000 [01:35<01:21, 53.69it/s]Processing train dataset:  71%|███████   | 7054/10000 [01:41<00:47, 61.63it/s]Processing train dataset:  65%|██████▌   | 6544/10000 [01:37<00:51, 66.94it/s]Processing train dataset:  68%|██████▊   | 6759/10000 [01:37<01:03, 51.40it/s]Processing train dataset:  73%|███████▎  | 7300/10000 [01:37<00:32, 82.44it/s]Processing train dataset:  56%|█████▋    | 5642/10000 [01:35<01:21, 53.33it/s]Processing train dataset:  71%|███████   | 7061/10000 [01:41<00:48, 60.28it/s]Processing train dataset:  66%|██████▌   | 6552/10000 [01:37<00:48, 70.51it/s]Processing train dataset:  68%|██████▊   | 6765/10000 [01:37<01:01, 52.58it/s]Processing train dataset:  73%|███████▎  | 7309/10000 [01:37<00:32, 84.00it/s]Processing train dataset:  56%|█████▋    | 5648/10000 [01:35<01:19, 54.67it/s]Processing train dataset:  71%|███████   | 7068/10000 [01:41<00:47, 62.23it/s]Processing train dataset:  66%|██████▌   | 6563/10000 [01:37<00:42, 81.08it/s]Processing train dataset:  68%|██████▊   | 6771/10000 [01:38<01:01, 52.50it/s]Processing train dataset:  73%|███████▎  | 7318/10000 [01:38<00:33, 80.99it/s]Processing train dataset:  57%|█████▋    | 5655/10000 [01:35<01:16, 57.07it/s]Processing train dataset:  66%|██████▌   | 6572/10000 [01:37<00:41, 81.85it/s]Processing train dataset:  71%|███████   | 7075/10000 [01:41<00:47, 61.80it/s]Processing train dataset:  68%|██████▊   | 6778/10000 [01:38<00:57, 56.32it/s]Processing train dataset:  73%|███████▎  | 7327/10000 [01:38<00:33, 80.31it/s]Processing train dataset:  57%|█████▋    | 5662/10000 [01:35<01:12, 60.00it/s]Processing train dataset:  66%|██████▌   | 6581/10000 [01:37<00:41, 81.83it/s]Processing train dataset:  71%|███████   | 7082/10000 [01:41<00:48, 60.68it/s]Processing train dataset:  68%|██████▊   | 6785/10000 [01:38<00:56, 57.02it/s]Processing train dataset:  73%|███████▎  | 7336/10000 [01:38<00:32, 82.41it/s]Processing train dataset:  57%|█████▋    | 5669/10000 [01:35<01:10, 61.18it/s]Processing train dataset:  66%|██████▌   | 6590/10000 [01:38<00:41, 82.06it/s]Processing train dataset:  71%|███████   | 7089/10000 [01:41<00:50, 57.91it/s]Processing train dataset:  73%|███████▎  | 7345/10000 [01:38<00:32, 82.13it/s]Processing train dataset:  68%|██████▊   | 6792/10000 [01:38<00:55, 58.23it/s]Processing train dataset:  66%|██████▌   | 6599/10000 [01:38<00:40, 83.21it/s]Processing train dataset:  57%|█████▋    | 5676/10000 [01:36<01:14, 58.34it/s]Processing train dataset:  68%|██████▊   | 6798/10000 [01:38<00:55, 58.15it/s]Processing train dataset:  71%|███████   | 7097/10000 [01:42<00:46, 62.14it/s]Processing train dataset:  74%|███████▎  | 7354/10000 [01:38<00:33, 80.03it/s]Processing train dataset:  66%|██████▌   | 6608/10000 [01:38<00:42, 80.70it/s]Processing train dataset:  57%|█████▋    | 5684/10000 [01:36<01:13, 58.53it/s]Processing train dataset:  68%|██████▊   | 6805/10000 [01:38<00:54, 58.57it/s]Processing train dataset:  71%|███████   | 7104/10000 [01:42<00:47, 60.76it/s]Processing train dataset:  74%|███████▎  | 7363/10000 [01:38<00:33, 78.06it/s]Processing train dataset:  66%|██████▌   | 6617/10000 [01:38<00:42, 79.93it/s]Processing train dataset:  57%|█████▋    | 5690/10000 [01:36<01:15, 57.25it/s]Processing train dataset:  71%|███████   | 7113/10000 [01:42<00:44, 64.77it/s]Processing train dataset:  74%|███████▎  | 7372/10000 [01:38<00:33, 79.23it/s]Processing train dataset:  68%|██████▊   | 6811/10000 [01:38<00:59, 53.97it/s]Processing train dataset:  66%|██████▋   | 6626/10000 [01:38<00:42, 79.36it/s]Processing train dataset:  57%|█████▋    | 5696/10000 [01:36<01:14, 57.72it/s]Processing train dataset:  74%|███████▍  | 7380/10000 [01:38<00:33, 77.61it/s]Processing train dataset:  71%|███████   | 7124/10000 [01:42<00:38, 74.47it/s]Processing train dataset:  68%|██████▊   | 6817/10000 [01:38<01:01, 51.65it/s]Processing train dataset:  66%|██████▋   | 6634/10000 [01:38<00:43, 78.13it/s]Processing train dataset:  57%|█████▋    | 5702/10000 [01:36<01:20, 53.26it/s]Processing train dataset:  71%|███████▏  | 7133/10000 [01:42<00:36, 78.16it/s]Processing train dataset:  74%|███████▍  | 7389/10000 [01:38<00:33, 78.70it/s]Processing train dataset:  68%|██████▊   | 6823/10000 [01:39<01:01, 51.37it/s]Processing train dataset:  66%|██████▋   | 6644/10000 [01:38<00:40, 82.51it/s]Processing train dataset:  57%|█████▋    | 5710/10000 [01:36<01:12, 59.04it/s]Processing train dataset:  71%|███████▏  | 7143/10000 [01:42<00:34, 82.08it/s]Processing train dataset:  74%|███████▍  | 7397/10000 [01:39<00:33, 77.36it/s]Processing train dataset:  68%|██████▊   | 6830/10000 [01:39<00:58, 54.54it/s]Processing train dataset:  67%|██████▋   | 6653/10000 [01:38<00:41, 80.91it/s]Processing train dataset:  57%|█████▋    | 5718/10000 [01:36<01:09, 61.88it/s]Processing train dataset:  74%|███████▍  | 7405/10000 [01:39<00:34, 76.21it/s]Processing train dataset:  72%|███████▏  | 7152/10000 [01:42<00:38, 74.67it/s]Processing train dataset:  68%|██████▊   | 6836/10000 [01:39<01:00, 52.21it/s]Processing train dataset:  67%|██████▋   | 6662/10000 [01:38<00:43, 76.17it/s]Processing train dataset:  57%|█████▋    | 5725/10000 [01:36<01:07, 63.38it/s]Processing train dataset:  74%|███████▍  | 7413/10000 [01:39<00:34, 75.76it/s]Processing train dataset:  72%|███████▏  | 7161/10000 [01:42<00:36, 77.34it/s]Processing train dataset:  68%|██████▊   | 6842/10000 [01:39<01:00, 52.33it/s]Processing train dataset:  67%|██████▋   | 6670/10000 [01:39<00:44, 75.08it/s]Processing train dataset:  57%|█████▋    | 5732/10000 [01:36<01:07, 63.25it/s]Processing train dataset:  74%|███████▍  | 7423/10000 [01:39<00:31, 80.90it/s]Processing train dataset:  72%|███████▏  | 7171/10000 [01:42<00:34, 82.42it/s]Processing train dataset:  68%|██████▊   | 6848/10000 [01:39<00:58, 54.33it/s]Processing train dataset:  57%|█████▋    | 5741/10000 [01:37<01:00, 70.22it/s]Processing train dataset:  67%|██████▋   | 6678/10000 [01:39<00:44, 74.13it/s]Processing train dataset:  74%|███████▍  | 7432/10000 [01:39<00:31, 82.15it/s]Processing train dataset:  72%|███████▏  | 7180/10000 [01:43<00:35, 79.65it/s]Processing train dataset:  69%|██████▊   | 6856/10000 [01:39<00:55, 56.63it/s]Processing train dataset:  74%|███████▍  | 7441/10000 [01:39<00:31, 80.78it/s]Processing train dataset:  67%|██████▋   | 6686/10000 [01:39<00:47, 69.66it/s]Processing train dataset:  57%|█████▋    | 5749/10000 [01:37<01:08, 62.30it/s]Processing train dataset:  72%|███████▏  | 7189/10000 [01:43<00:36, 77.68it/s]Processing train dataset:  69%|██████▊   | 6862/10000 [01:39<00:55, 56.12it/s]Processing train dataset:  74%|███████▍  | 7450/10000 [01:39<00:31, 79.76it/s]Processing train dataset:  67%|██████▋   | 6694/10000 [01:39<00:47, 68.97it/s]Processing train dataset:  58%|█████▊    | 5756/10000 [01:37<01:08, 61.95it/s]Processing train dataset:  72%|███████▏  | 7199/10000 [01:43<00:34, 80.63it/s]Processing train dataset:  69%|██████▊   | 6868/10000 [01:39<00:56, 55.27it/s]Processing train dataset:  67%|██████▋   | 6702/10000 [01:39<00:46, 70.72it/s]Processing train dataset:  75%|███████▍  | 7458/10000 [01:39<00:34, 74.48it/s]Processing train dataset:  58%|█████▊    | 5763/10000 [01:37<01:09, 61.19it/s]Processing train dataset:  72%|███████▏  | 7208/10000 [01:43<00:36, 76.14it/s]Processing train dataset:  69%|██████▊   | 6874/10000 [01:39<00:59, 52.42it/s]Processing train dataset:  67%|██████▋   | 6710/10000 [01:39<00:45, 71.79it/s]Processing train dataset:  75%|███████▍  | 7468/10000 [01:39<00:32, 78.59it/s]Processing train dataset:  58%|█████▊    | 5770/10000 [01:37<01:10, 60.03it/s]Processing train dataset:  69%|██████▉   | 6882/10000 [01:40<00:52, 59.48it/s]Processing train dataset:  72%|███████▏  | 7216/10000 [01:43<00:38, 71.71it/s]Processing train dataset:  75%|███████▍  | 7476/10000 [01:40<00:32, 76.55it/s]Processing train dataset:  67%|██████▋   | 6718/10000 [01:39<00:51, 63.36it/s]Processing train dataset:  58%|█████▊    | 5777/10000 [01:37<01:11, 58.84it/s]Processing train dataset:  69%|██████▉   | 6890/10000 [01:40<00:47, 64.91it/s]Processing train dataset:  72%|███████▏  | 7225/10000 [01:43<00:36, 75.52it/s]Processing train dataset:  75%|███████▍  | 7484/10000 [01:40<00:33, 75.66it/s]Processing train dataset:  69%|██████▉   | 6897/10000 [01:40<00:46, 66.07it/s]Processing train dataset:  58%|█████▊    | 5784/10000 [01:37<01:09, 60.51it/s]Processing train dataset:  67%|██████▋   | 6725/10000 [01:39<00:53, 61.03it/s]Processing train dataset:  72%|███████▏  | 7234/10000 [01:43<00:34, 79.19it/s]Processing train dataset:  75%|███████▍  | 7492/10000 [01:40<00:33, 74.70it/s]Processing train dataset:  58%|█████▊    | 5791/10000 [01:37<01:07, 62.74it/s]Processing train dataset:  69%|██████▉   | 6906/10000 [01:40<00:44, 70.28it/s]Processing train dataset:  72%|███████▏  | 7244/10000 [01:43<00:33, 82.48it/s]Processing train dataset:  67%|██████▋   | 6732/10000 [01:40<00:55, 59.17it/s]Processing train dataset:  75%|███████▌  | 7500/10000 [01:40<00:33, 74.91it/s]Processing train dataset:  69%|██████▉   | 6914/10000 [01:40<00:43, 71.01it/s]Processing train dataset:  58%|█████▊    | 5799/10000 [01:38<01:07, 62.45it/s]Processing train dataset:  73%|███████▎  | 7253/10000 [01:43<00:33, 81.76it/s]Processing train dataset:  67%|██████▋   | 6739/10000 [01:40<00:56, 57.66it/s]Processing train dataset:  75%|███████▌  | 7508/10000 [01:40<00:33, 73.69it/s]Processing train dataset:  69%|██████▉   | 6922/10000 [01:40<00:42, 72.05it/s]Processing train dataset:  73%|███████▎  | 7264/10000 [01:44<00:31, 87.33it/s]Processing train dataset:  58%|█████▊    | 5807/10000 [01:38<01:06, 63.07it/s]Processing train dataset:  67%|██████▋   | 6747/10000 [01:40<00:53, 61.31it/s]Processing train dataset:  75%|███████▌  | 7518/10000 [01:40<00:31, 78.52it/s]Processing train dataset:  69%|██████▉   | 6932/10000 [01:40<00:39, 77.35it/s]Processing train dataset:  73%|███████▎  | 7273/10000 [01:44<00:31, 87.11it/s]Processing train dataset:  58%|█████▊    | 5814/10000 [01:38<01:04, 64.41it/s]Processing train dataset:  75%|███████▌  | 7526/10000 [01:40<00:31, 77.88it/s]Processing train dataset:  68%|██████▊   | 6754/10000 [01:40<00:54, 59.80it/s]Processing train dataset:  69%|██████▉   | 6940/10000 [01:40<00:40, 76.33it/s]Processing train dataset:  73%|███████▎  | 7285/10000 [01:44<00:28, 94.44it/s]Processing train dataset:  58%|█████▊    | 5823/10000 [01:38<01:02, 66.87it/s]Processing train dataset:  75%|███████▌  | 7534/10000 [01:40<00:32, 76.06it/s]Processing train dataset:  68%|██████▊   | 6761/10000 [01:40<00:55, 57.86it/s]Processing train dataset:  69%|██████▉   | 6948/10000 [01:40<00:39, 77.32it/s]Processing train dataset:  73%|███████▎  | 7295/10000 [01:44<00:28, 93.88it/s]Processing train dataset:  58%|█████▊    | 5832/10000 [01:38<00:59, 70.01it/s]Processing train dataset:  75%|███████▌  | 7542/10000 [01:40<00:32, 74.93it/s]Processing train dataset:  68%|██████▊   | 6767/10000 [01:40<00:55, 58.22it/s]Processing train dataset:  70%|██████▉   | 6956/10000 [01:41<00:40, 75.61it/s]Processing train dataset:  73%|███████▎  | 7305/10000 [01:44<00:29, 92.52it/s]Processing train dataset:  58%|█████▊    | 5840/10000 [01:38<01:00, 68.43it/s]Processing train dataset:  76%|███████▌  | 7550/10000 [01:41<00:33, 73.68it/s]Processing train dataset:  68%|██████▊   | 6776/10000 [01:40<00:49, 65.47it/s]Processing train dataset:  70%|██████▉   | 6965/10000 [01:41<00:39, 77.11it/s]Processing train dataset:  73%|███████▎  | 7315/10000 [01:44<00:28, 93.87it/s]Processing train dataset:  58%|█████▊    | 5848/10000 [01:38<00:59, 70.05it/s]Processing train dataset:  76%|███████▌  | 7558/10000 [01:41<00:32, 75.40it/s]Processing train dataset:  68%|██████▊   | 6785/10000 [01:40<00:45, 70.70it/s]Processing train dataset:  70%|██████▉   | 6974/10000 [01:41<00:38, 78.77it/s]Processing train dataset:  73%|███████▎  | 7325/10000 [01:44<00:28, 93.09it/s]Processing train dataset:  76%|███████▌  | 7566/10000 [01:41<00:32, 75.15it/s]Processing train dataset:  59%|█████▊    | 5857/10000 [01:38<00:57, 72.26it/s]Processing train dataset:  68%|██████▊   | 6794/10000 [01:41<00:43, 74.20it/s]Processing train dataset:  70%|██████▉   | 6983/10000 [01:41<00:37, 80.11it/s]Processing train dataset:  73%|███████▎  | 7335/10000 [01:44<00:28, 92.63it/s]Processing train dataset:  59%|█████▊    | 5865/10000 [01:38<00:55, 74.16it/s]Processing train dataset:  76%|███████▌  | 7574/10000 [01:41<00:32, 74.93it/s]Processing train dataset:  68%|██████▊   | 6802/10000 [01:41<00:43, 72.93it/s]Processing train dataset:  70%|██████▉   | 6992/10000 [01:41<00:38, 77.21it/s]Processing train dataset:  73%|███████▎  | 7345/10000 [01:44<00:31, 85.36it/s]Processing train dataset:  59%|█████▊    | 5873/10000 [01:39<00:54, 75.56it/s]Processing train dataset:  76%|███████▌  | 7583/10000 [01:41<00:31, 76.36it/s]Processing train dataset:  68%|██████▊   | 6810/10000 [01:41<00:43, 74.15it/s]Processing train dataset:  70%|███████   | 7000/10000 [01:41<00:41, 72.75it/s]Processing train dataset:  59%|█████▉    | 5881/10000 [01:39<00:56, 73.40it/s]Processing train dataset:  76%|███████▌  | 7591/10000 [01:41<00:32, 75.27it/s]Processing train dataset:  74%|███████▎  | 7354/10000 [01:45<00:33, 78.57it/s]Processing train dataset:  68%|██████▊   | 6819/10000 [01:41<00:41, 76.00it/s]Processing train dataset:  70%|███████   | 7008/10000 [01:41<00:40, 73.88it/s]Processing train dataset:  59%|█████▉    | 5890/10000 [01:39<00:54, 75.98it/s]Processing train dataset:  76%|███████▌  | 7599/10000 [01:41<00:32, 74.90it/s]Processing train dataset:  68%|██████▊   | 6828/10000 [01:41<00:41, 76.67it/s]Processing train dataset:  74%|███████▎  | 7363/10000 [01:45<00:37, 69.49it/s]Processing train dataset:  70%|███████   | 7017/10000 [01:41<00:38, 77.86it/s]Processing train dataset:  59%|█████▉    | 5899/10000 [01:39<00:51, 79.23it/s]Processing train dataset:  76%|███████▌  | 7607/10000 [01:41<00:31, 75.01it/s]Processing train dataset:  68%|██████▊   | 6836/10000 [01:41<00:42, 73.77it/s]Processing train dataset:  70%|███████   | 7025/10000 [01:41<00:37, 78.39it/s]Processing train dataset:  74%|███████▎  | 7371/10000 [01:45<00:38, 67.52it/s]Processing train dataset:  59%|█████▉    | 5910/10000 [01:39<00:47, 85.52it/s]Processing train dataset:  76%|███████▌  | 7616/10000 [01:41<00:30, 78.82it/s]Processing train dataset:  68%|██████▊   | 6844/10000 [01:41<00:43, 72.89it/s]Processing train dataset:  70%|███████   | 7033/10000 [01:42<00:38, 76.53it/s]Processing train dataset:  59%|█████▉    | 5920/10000 [01:39<00:46, 87.07it/s]Processing train dataset:  76%|███████▌  | 7624/10000 [01:42<00:30, 76.68it/s]Processing train dataset:  74%|███████▍  | 7378/10000 [01:45<00:42, 61.84it/s]Processing train dataset:  69%|██████▊   | 6852/10000 [01:41<00:45, 69.65it/s]Processing train dataset:  76%|███████▋  | 7632/10000 [01:42<00:31, 76.04it/s]Processing train dataset:  70%|███████   | 7041/10000 [01:42<00:44, 66.55it/s]Processing train dataset:  76%|███████▋  | 7641/10000 [01:42<00:30, 78.25it/s]Processing train dataset:  69%|██████▊   | 6860/10000 [01:41<00:50, 62.22it/s]Processing train dataset:  70%|███████   | 7049/10000 [01:42<00:43, 67.83it/s]Processing train dataset:  59%|█████▉    | 5929/10000 [01:39<01:08, 59.53it/s]Processing train dataset:  74%|███████▍  | 7385/10000 [01:45<00:58, 44.44it/s]Processing train dataset:  76%|███████▋  | 7650/10000 [01:42<00:29, 79.09it/s]Processing train dataset:  71%|███████   | 7058/10000 [01:42<00:41, 71.64it/s]Processing train dataset:  69%|██████▊   | 6867/10000 [01:42<00:53, 58.41it/s]Processing train dataset:  59%|█████▉    | 5937/10000 [01:39<01:05, 61.97it/s]Processing train dataset:  74%|███████▍  | 7391/10000 [01:45<00:57, 45.65it/s]Processing train dataset:  77%|███████▋  | 7658/10000 [01:42<00:29, 78.11it/s]Processing train dataset:  71%|███████   | 7068/10000 [01:42<00:38, 76.74it/s]Processing train dataset:  69%|██████▉   | 6875/10000 [01:42<00:49, 62.99it/s]Processing train dataset:  59%|█████▉    | 5948/10000 [01:40<00:56, 71.57it/s]Processing train dataset:  74%|███████▍  | 7398/10000 [01:46<00:51, 50.69it/s]Processing train dataset:  77%|███████▋  | 7666/10000 [01:42<00:31, 73.88it/s]Processing train dataset:  71%|███████   | 7076/10000 [01:42<00:39, 74.47it/s]Processing train dataset:  69%|██████▉   | 6882/10000 [01:42<00:49, 63.36it/s]Processing train dataset:  60%|█████▉    | 5956/10000 [01:40<00:56, 71.02it/s]Processing train dataset:  74%|███████▍  | 7404/10000 [01:46<00:51, 50.79it/s]Processing train dataset:  77%|███████▋  | 7674/10000 [01:42<00:31, 73.19it/s]Processing train dataset:  69%|██████▉   | 6891/10000 [01:42<00:45, 68.86it/s]Processing train dataset:  71%|███████   | 7085/10000 [01:42<00:39, 74.11it/s]Processing train dataset:  60%|█████▉    | 5966/10000 [01:40<00:52, 77.52it/s]Processing train dataset:  74%|███████▍  | 7411/10000 [01:46<00:52, 49.17it/s]Processing train dataset:  77%|███████▋  | 7682/10000 [01:42<00:32, 71.00it/s]Processing train dataset:  69%|██████▉   | 6899/10000 [01:42<00:47, 65.23it/s]Processing train dataset:  71%|███████   | 7093/10000 [01:42<00:42, 68.95it/s]Processing train dataset:  60%|█████▉    | 5975/10000 [01:40<00:52, 76.58it/s]Processing train dataset:  77%|███████▋  | 7693/10000 [01:42<00:29, 78.93it/s]Processing train dataset:  74%|███████▍  | 7419/10000 [01:46<00:52, 49.38it/s]Processing train dataset:  71%|███████   | 7100/10000 [01:43<00:44, 65.62it/s]Processing train dataset:  69%|██████▉   | 6906/10000 [01:42<00:49, 61.92it/s]Processing train dataset:  60%|█████▉    | 5984/10000 [01:40<00:55, 72.99it/s]Processing train dataset:  77%|███████▋  | 7701/10000 [01:43<00:29, 78.21it/s]Processing train dataset:  74%|███████▍  | 7429/10000 [01:46<00:42, 60.25it/s]Processing train dataset:  69%|██████▉   | 6914/10000 [01:42<00:46, 66.01it/s]Processing train dataset:  71%|███████   | 7110/10000 [01:43<00:39, 73.01it/s]Processing train dataset:  60%|█████▉    | 5994/10000 [01:40<00:50, 78.64it/s]Processing train dataset:  77%|███████▋  | 7709/10000 [01:43<00:30, 74.14it/s]Processing train dataset:  71%|███████   | 7119/10000 [01:43<00:37, 75.92it/s]Processing train dataset:  69%|██████▉   | 6921/10000 [01:42<00:49, 62.10it/s]Processing train dataset:  74%|███████▍  | 7436/10000 [01:46<00:46, 55.32it/s]Processing train dataset:  60%|██████    | 6003/10000 [01:40<00:53, 74.39it/s]Processing train dataset:  77%|███████▋  | 7718/10000 [01:43<00:29, 77.34it/s]Processing train dataset:  71%|███████▏  | 7127/10000 [01:43<00:37, 76.48it/s]Processing train dataset:  69%|██████▉   | 6929/10000 [01:43<00:49, 61.80it/s]Processing train dataset:  60%|██████    | 6013/10000 [01:40<00:50, 79.28it/s]Processing train dataset:  74%|███████▍  | 7442/10000 [01:46<00:48, 52.68it/s]Processing train dataset:  77%|███████▋  | 7728/10000 [01:43<00:28, 81.12it/s]Processing train dataset:  71%|███████▏  | 7135/10000 [01:43<00:37, 77.43it/s]Processing train dataset:  69%|██████▉   | 6938/10000 [01:43<00:45, 67.32it/s]Processing train dataset:  60%|██████    | 6024/10000 [01:41<00:46, 85.80it/s]Processing train dataset:  74%|███████▍  | 7449/10000 [01:46<00:45, 56.42it/s]Processing train dataset:  77%|███████▋  | 7737/10000 [01:43<00:28, 79.34it/s]Processing train dataset:  71%|███████▏  | 7144/10000 [01:43<00:37, 76.44it/s]Processing train dataset:  69%|██████▉   | 6945/10000 [01:43<00:48, 63.21it/s]Processing train dataset:  77%|███████▋  | 7745/10000 [01:43<00:30, 75.00it/s]Processing train dataset:  72%|███████▏  | 7152/10000 [01:43<00:38, 73.71it/s]Processing train dataset:  60%|██████    | 6033/10000 [01:41<00:56, 70.49it/s]Processing train dataset:  75%|███████▍  | 7455/10000 [01:47<00:53, 47.59it/s]Processing train dataset:  72%|███████▏  | 7160/10000 [01:43<00:38, 74.35it/s]Processing train dataset:  70%|██████▉   | 6952/10000 [01:43<00:55, 54.46it/s]Processing train dataset:  78%|███████▊  | 7753/10000 [01:43<00:32, 68.24it/s]Processing train dataset:  60%|██████    | 6041/10000 [01:41<00:59, 66.91it/s]Processing train dataset:  75%|███████▍  | 7461/10000 [01:47<00:54, 46.65it/s]Processing train dataset:  72%|███████▏  | 7169/10000 [01:43<00:38, 74.21it/s]Processing train dataset:  70%|██████▉   | 6960/10000 [01:43<00:51, 59.42it/s]Processing train dataset:  78%|███████▊  | 7762/10000 [01:43<00:31, 72.12it/s]Processing train dataset:  75%|███████▍  | 7467/10000 [01:47<00:54, 46.72it/s]Processing train dataset:  70%|██████▉   | 6967/10000 [01:43<00:51, 59.36it/s]Processing train dataset:  78%|███████▊  | 7770/10000 [01:44<00:31, 71.20it/s]Processing train dataset:  60%|██████    | 6049/10000 [01:41<01:12, 54.59it/s]Processing train dataset:  72%|███████▏  | 7177/10000 [01:44<00:41, 68.83it/s]Processing train dataset:  75%|███████▍  | 7472/10000 [01:47<00:58, 42.85it/s]Processing train dataset:  78%|███████▊  | 7780/10000 [01:44<00:28, 76.86it/s]Processing train dataset:  70%|██████▉   | 6977/10000 [01:43<00:44, 67.39it/s]Processing train dataset:  61%|██████    | 6058/10000 [01:41<01:03, 61.80it/s]Processing train dataset:  72%|███████▏  | 7185/10000 [01:44<00:39, 71.16it/s]Processing train dataset:  75%|███████▍  | 7479/10000 [01:47<00:51, 48.54it/s]Processing train dataset:  78%|███████▊  | 7788/10000 [01:44<00:28, 77.04it/s]Processing train dataset:  61%|██████    | 6066/10000 [01:41<01:00, 65.34it/s]Processing train dataset:  70%|██████▉   | 6984/10000 [01:43<00:45, 66.23it/s]Processing train dataset:  72%|███████▏  | 7196/10000 [01:44<00:35, 79.62it/s]Processing train dataset:  75%|███████▍  | 7486/10000 [01:47<00:46, 53.64it/s]Processing train dataset:  78%|███████▊  | 7796/10000 [01:44<00:28, 77.11it/s]Processing train dataset:  61%|██████    | 6076/10000 [01:41<00:53, 72.80it/s]Processing train dataset:  70%|██████▉   | 6992/10000 [01:44<00:43, 69.25it/s]Processing train dataset:  72%|███████▏  | 7205/10000 [01:44<00:36, 76.41it/s]Processing train dataset:  75%|███████▍  | 7493/10000 [01:47<00:43, 57.69it/s]Processing train dataset:  78%|███████▊  | 7807/10000 [01:44<00:26, 83.35it/s]Processing train dataset:  61%|██████    | 6084/10000 [01:41<00:53, 73.71it/s]Processing train dataset:  70%|███████   | 7000/10000 [01:44<00:44, 67.40it/s]Processing train dataset:  72%|███████▏  | 7213/10000 [01:44<00:37, 74.55it/s]Processing train dataset:  75%|███████▌  | 7500/10000 [01:47<00:41, 60.07it/s]Processing train dataset:  78%|███████▊  | 7816/10000 [01:44<00:27, 80.62it/s]Processing train dataset:  61%|██████    | 6092/10000 [01:42<00:55, 70.19it/s]Processing train dataset:  70%|███████   | 7007/10000 [01:44<00:45, 66.27it/s]Processing train dataset:  72%|███████▏  | 7221/10000 [01:44<00:38, 72.24it/s]Processing train dataset:  75%|███████▌  | 7507/10000 [01:48<00:46, 54.15it/s]Processing train dataset:  78%|███████▊  | 7825/10000 [01:44<00:26, 81.19it/s]Processing train dataset:  70%|███████   | 7014/10000 [01:44<00:44, 67.00it/s]Processing train dataset:  72%|███████▏  | 7229/10000 [01:44<00:40, 68.91it/s]Processing train dataset:  78%|███████▊  | 7834/10000 [01:44<00:27, 79.50it/s]Processing train dataset:  61%|██████    | 6100/10000 [01:42<01:12, 53.70it/s]Processing train dataset:  70%|███████   | 7021/10000 [01:44<00:49, 59.94it/s]Processing train dataset:  72%|███████▏  | 7236/10000 [01:44<00:40, 68.03it/s]Processing train dataset:  75%|███████▌  | 7513/10000 [01:48<00:56, 44.06it/s]Processing train dataset:  78%|███████▊  | 7842/10000 [01:44<00:27, 78.52it/s]Processing train dataset:  61%|██████    | 6107/10000 [01:42<01:10, 55.01it/s]Processing train dataset:  70%|███████   | 7029/10000 [01:44<00:46, 64.00it/s]Processing train dataset:  72%|███████▏  | 7244/10000 [01:44<00:39, 70.01it/s]Processing train dataset:  75%|███████▌  | 7520/10000 [01:48<00:50, 49.35it/s]Processing train dataset:  78%|███████▊  | 7850/10000 [01:44<00:27, 77.56it/s]Processing train dataset:  70%|███████   | 7038/10000 [01:44<00:48, 61.30it/s]Processing train dataset:  61%|██████    | 6114/10000 [01:42<01:18, 49.77it/s]Processing train dataset:  75%|███████▌  | 7526/10000 [01:48<00:51, 48.01it/s]Processing train dataset:  73%|███████▎  | 7252/10000 [01:45<00:43, 62.56it/s]Processing train dataset:  79%|███████▊  | 7858/10000 [01:45<00:29, 72.81it/s]Processing train dataset:  73%|███████▎  | 7261/10000 [01:45<00:40, 67.40it/s]Processing train dataset:  70%|███████   | 7047/10000 [01:44<00:46, 63.31it/s]Processing train dataset:  75%|███████▌  | 7534/10000 [01:48<00:47, 52.31it/s]Processing train dataset:  79%|███████▊  | 7866/10000 [01:45<00:28, 73.87it/s]Processing train dataset:  61%|██████    | 6121/10000 [01:42<01:16, 50.51it/s]Processing train dataset:  79%|███████▊  | 7874/10000 [01:45<00:30, 70.71it/s]Processing train dataset:  75%|███████▌  | 7540/10000 [01:48<00:49, 50.14it/s]Processing train dataset:  73%|███████▎  | 7268/10000 [01:45<00:45, 59.73it/s]Processing train dataset:  71%|███████   | 7054/10000 [01:45<00:51, 57.21it/s]Processing train dataset:  61%|██████▏   | 6127/10000 [01:42<01:24, 45.65it/s]Processing train dataset:  79%|███████▉  | 7882/10000 [01:45<00:29, 72.07it/s]Processing train dataset:  75%|███████▌  | 7548/10000 [01:48<00:43, 56.84it/s]Processing train dataset:  73%|███████▎  | 7275/10000 [01:45<00:44, 61.11it/s]Processing train dataset:  71%|███████   | 7062/10000 [01:45<00:52, 55.78it/s]Processing train dataset:  61%|██████▏   | 6132/10000 [01:43<01:29, 43.02it/s]Processing train dataset:  79%|███████▉  | 7890/10000 [01:45<00:30, 70.13it/s]Processing train dataset:  76%|███████▌  | 7554/10000 [01:49<00:45, 54.29it/s]Processing train dataset:  73%|███████▎  | 7282/10000 [01:45<00:46, 58.28it/s]Processing train dataset:  71%|███████   | 7071/10000 [01:45<00:47, 62.00it/s]Processing train dataset:  61%|██████▏   | 6140/10000 [01:43<01:15, 50.82it/s]Processing train dataset:  79%|███████▉  | 7899/10000 [01:45<00:28, 74.33it/s]Processing train dataset:  76%|███████▌  | 7564/10000 [01:49<00:37, 64.22it/s]Processing train dataset:  73%|███████▎  | 7289/10000 [01:45<00:48, 55.55it/s]Processing train dataset:  71%|███████   | 7078/10000 [01:45<00:49, 59.52it/s]Processing train dataset:  79%|███████▉  | 7907/10000 [01:45<00:27, 74.97it/s]Processing train dataset:  61%|██████▏   | 6146/10000 [01:43<01:22, 46.61it/s]Processing train dataset:  76%|███████▌  | 7571/10000 [01:49<00:42, 57.27it/s]Processing train dataset:  73%|███████▎  | 7296/10000 [01:45<00:47, 57.45it/s]Processing train dataset:  71%|███████   | 7085/10000 [01:45<00:47, 61.60it/s]Processing train dataset:  79%|███████▉  | 7915/10000 [01:45<00:27, 75.59it/s]Processing train dataset:  62%|██████▏   | 6152/10000 [01:43<01:18, 49.10it/s]Processing train dataset:  76%|███████▌  | 7577/10000 [01:49<00:45, 53.32it/s]Processing train dataset:  71%|███████   | 7092/10000 [01:45<00:48, 60.08it/s]Processing train dataset:  73%|███████▎  | 7302/10000 [01:46<00:50, 53.53it/s]Processing train dataset:  79%|███████▉  | 7923/10000 [01:45<00:27, 76.30it/s]Processing train dataset:  62%|██████▏   | 6158/10000 [01:43<01:21, 47.08it/s]Processing train dataset:  79%|███████▉  | 7932/10000 [01:46<00:25, 79.62it/s]Processing train dataset:  73%|███████▎  | 7309/10000 [01:46<00:47, 56.80it/s]Processing train dataset:  76%|███████▌  | 7587/10000 [01:49<00:41, 58.47it/s]Processing train dataset:  71%|███████   | 7099/10000 [01:45<00:53, 54.27it/s]Processing train dataset:  62%|██████▏   | 6163/10000 [01:43<01:23, 45.96it/s]Processing train dataset:  79%|███████▉  | 7940/10000 [01:46<00:27, 75.84it/s]Processing train dataset:  73%|███████▎  | 7315/10000 [01:46<00:49, 54.26it/s]Processing train dataset:  76%|███████▌  | 7596/10000 [01:49<00:36, 65.37it/s]Processing train dataset:  62%|██████▏   | 6171/10000 [01:43<01:11, 53.66it/s]Processing train dataset:  71%|███████   | 7108/10000 [01:45<00:47, 60.58it/s]Processing train dataset:  80%|███████▉  | 7950/10000 [01:46<00:25, 80.91it/s]Processing train dataset:  73%|███████▎  | 7322/10000 [01:46<00:47, 55.82it/s]Processing train dataset:  71%|███████   | 7115/10000 [01:46<00:47, 60.56it/s]Processing train dataset:  76%|███████▌  | 7603/10000 [01:49<00:41, 58.20it/s]Processing train dataset:  62%|██████▏   | 6177/10000 [01:43<01:15, 50.48it/s]Processing train dataset:  80%|███████▉  | 7959/10000 [01:46<00:25, 80.04it/s]Processing train dataset:  73%|███████▎  | 7330/10000 [01:46<00:44, 60.47it/s]Processing train dataset:  76%|███████▌  | 7610/10000 [01:49<00:39, 60.91it/s]Processing train dataset:  62%|██████▏   | 6184/10000 [01:44<01:11, 53.63it/s]Processing train dataset:  80%|███████▉  | 7968/10000 [01:46<00:24, 81.79it/s]Processing train dataset:  71%|███████   | 7122/10000 [01:46<00:53, 53.81it/s]Processing train dataset:  73%|███████▎  | 7338/10000 [01:46<00:41, 64.26it/s]Processing train dataset:  80%|███████▉  | 7977/10000 [01:46<00:26, 76.67it/s]Processing train dataset:  73%|███████▎  | 7345/10000 [01:46<00:43, 61.58it/s]Processing train dataset:  71%|███████▏  | 7128/10000 [01:46<00:59, 48.49it/s]Processing train dataset:  62%|██████▏   | 6190/10000 [01:44<01:26, 43.98it/s]Processing train dataset:  76%|███████▌  | 7617/10000 [01:50<00:50, 47.03it/s]Processing train dataset:  80%|███████▉  | 7986/10000 [01:46<00:25, 78.69it/s]Processing train dataset:  74%|███████▎  | 7353/10000 [01:46<00:40, 65.43it/s]Processing train dataset:  71%|███████▏  | 7136/10000 [01:46<00:52, 54.90it/s]Processing train dataset:  62%|██████▏   | 6199/10000 [01:44<01:11, 53.33it/s]Processing train dataset:  76%|███████▌  | 7624/10000 [01:50<00:46, 50.90it/s]Processing train dataset:  80%|███████▉  | 7994/10000 [01:46<00:25, 77.71it/s]Processing train dataset:  74%|███████▎  | 7361/10000 [01:46<00:38, 68.39it/s]Processing train dataset:  71%|███████▏  | 7145/10000 [01:46<00:45, 62.13it/s]Processing train dataset:  62%|██████▏   | 6205/10000 [01:44<01:09, 54.56it/s]Processing train dataset:  76%|███████▋  | 7630/10000 [01:50<00:45, 52.45it/s]Processing train dataset:  80%|████████  | 8002/10000 [01:46<00:26, 76.67it/s]Processing train dataset:  74%|███████▎  | 7370/10000 [01:47<00:35, 73.22it/s]Processing train dataset:  62%|██████▏   | 6213/10000 [01:44<01:03, 59.75it/s]Processing train dataset:  72%|███████▏  | 7153/10000 [01:46<00:44, 64.62it/s]Processing train dataset:  76%|███████▋  | 7637/10000 [01:50<00:42, 56.23it/s]Processing train dataset:  80%|████████  | 8011/10000 [01:47<00:24, 80.31it/s]Processing train dataset:  74%|███████▍  | 7378/10000 [01:47<00:36, 72.69it/s]Processing train dataset:  72%|███████▏  | 7164/10000 [01:46<00:38, 73.90it/s]Processing train dataset:  62%|██████▏   | 6222/10000 [01:44<00:58, 64.83it/s]Processing train dataset:  76%|███████▋  | 7647/10000 [01:50<00:35, 65.62it/s]Processing train dataset:  80%|████████  | 8020/10000 [01:47<00:24, 80.67it/s]Processing train dataset:  74%|███████▍  | 7386/10000 [01:47<00:39, 65.92it/s]Processing train dataset:  80%|████████  | 8030/10000 [01:47<00:23, 83.57it/s]Processing train dataset:  72%|███████▏  | 7172/10000 [01:47<00:46, 60.46it/s]Processing train dataset:  77%|███████▋  | 7654/10000 [01:50<00:47, 49.81it/s]Processing train dataset:  74%|███████▍  | 7393/10000 [01:47<00:44, 57.95it/s]Processing train dataset:  80%|████████  | 8040/10000 [01:47<00:22, 87.73it/s]Processing train dataset:  62%|██████▏   | 6229/10000 [01:44<01:23, 45.34it/s]Processing train dataset:  77%|███████▋  | 7660/10000 [01:50<00:45, 51.72it/s]Processing train dataset:  72%|███████▏  | 7179/10000 [01:47<00:49, 56.65it/s]Processing train dataset:  80%|████████  | 8050/10000 [01:47<00:21, 90.96it/s]Processing train dataset:  62%|██████▏   | 6235/10000 [01:45<01:19, 47.53it/s]Processing train dataset:  74%|███████▍  | 7400/10000 [01:47<00:44, 57.98it/s]Processing train dataset:  77%|███████▋  | 7671/10000 [01:51<00:36, 64.17it/s]Processing train dataset:  72%|███████▏  | 7188/10000 [01:47<00:45, 61.59it/s]Processing train dataset:  81%|████████  | 8060/10000 [01:47<00:21, 90.27it/s]Processing train dataset:  62%|██████▏   | 6242/10000 [01:45<01:11, 52.23it/s]Processing train dataset:  74%|███████▍  | 7407/10000 [01:47<00:44, 58.78it/s]Processing train dataset:  77%|███████▋  | 7682/10000 [01:51<00:31, 73.77it/s]Processing train dataset:  72%|███████▏  | 7196/10000 [01:47<00:43, 64.61it/s]Processing train dataset:  62%|██████▎   | 6250/10000 [01:45<01:04, 58.37it/s]Processing train dataset:  81%|████████  | 8070/10000 [01:47<00:23, 83.63it/s]Processing train dataset:  74%|███████▍  | 7414/10000 [01:47<00:46, 55.30it/s]Processing train dataset:  77%|███████▋  | 7695/10000 [01:51<00:26, 86.55it/s]Processing train dataset:  72%|███████▏  | 7203/10000 [01:47<00:44, 62.52it/s]Processing train dataset:  63%|██████▎   | 6258/10000 [01:45<01:04, 58.23it/s]Processing train dataset:  74%|███████▍  | 7420/10000 [01:47<00:45, 56.15it/s]Processing train dataset:  81%|████████  | 8079/10000 [01:47<00:24, 77.82it/s]Processing train dataset:  77%|███████▋  | 7705/10000 [01:51<00:27, 82.57it/s]Processing train dataset:  63%|██████▎   | 6266/10000 [01:45<00:58, 63.38it/s]Processing train dataset:  72%|███████▏  | 7210/10000 [01:47<00:48, 57.94it/s]Processing train dataset:  81%|████████  | 8089/10000 [01:48<00:23, 82.52it/s]Processing train dataset:  74%|███████▍  | 7428/10000 [01:48<00:42, 59.99it/s]Processing train dataset:  77%|███████▋  | 7714/10000 [01:51<00:32, 71.13it/s]Processing train dataset:  81%|████████  | 8098/10000 [01:48<00:22, 83.11it/s]Processing train dataset:  72%|███████▏  | 7216/10000 [01:47<00:54, 50.73it/s]Processing train dataset:  63%|██████▎   | 6273/10000 [01:45<01:07, 54.99it/s]Processing train dataset:  74%|███████▍  | 7435/10000 [01:48<00:46, 55.09it/s]Processing train dataset:  81%|████████  | 8107/10000 [01:48<00:22, 83.13it/s]Processing train dataset:  77%|███████▋  | 7722/10000 [01:51<00:34, 66.42it/s]Processing train dataset:  72%|███████▏  | 7222/10000 [01:47<00:57, 47.93it/s]Processing train dataset:  63%|██████▎   | 6279/10000 [01:45<01:14, 49.94it/s]Processing train dataset:  74%|███████▍  | 7441/10000 [01:48<00:49, 51.97it/s]Processing train dataset:  81%|████████  | 8116/10000 [01:48<00:22, 83.80it/s]Processing train dataset:  77%|███████▋  | 7733/10000 [01:51<00:29, 75.89it/s]Processing train dataset:  72%|███████▏  | 7228/10000 [01:48<00:54, 50.66it/s]Processing train dataset:  74%|███████▍  | 7447/10000 [01:48<00:49, 51.66it/s]Processing train dataset:  81%|████████▏ | 8125/10000 [01:48<00:22, 84.96it/s]Processing train dataset:  63%|██████▎   | 6285/10000 [01:45<01:18, 47.32it/s]Processing train dataset:  75%|███████▍  | 7453/10000 [01:48<00:48, 52.85it/s]Processing train dataset:  72%|███████▏  | 7234/10000 [01:48<00:57, 48.07it/s]Processing train dataset:  77%|███████▋  | 7742/10000 [01:52<00:32, 68.57it/s]Processing train dataset:  81%|████████▏ | 8134/10000 [01:48<00:22, 83.06it/s]Processing train dataset:  63%|██████▎   | 6293/10000 [01:46<01:09, 53.70it/s]Processing train dataset:  75%|███████▍  | 7459/10000 [01:48<00:48, 52.01it/s]Processing train dataset:  72%|███████▏  | 7239/10000 [01:48<01:01, 45.06it/s]Processing train dataset:  78%|███████▊  | 7750/10000 [01:52<00:34, 64.73it/s]Processing train dataset:  81%|████████▏ | 8143/10000 [01:48<00:23, 78.11it/s]Processing train dataset:  63%|██████▎   | 6299/10000 [01:46<01:12, 50.74it/s]Processing train dataset:  75%|███████▍  | 7466/10000 [01:48<00:45, 55.52it/s]Processing train dataset:  82%|████████▏ | 8151/10000 [01:48<00:24, 76.50it/s]Processing train dataset:  72%|███████▏  | 7245/10000 [01:48<01:02, 44.10it/s]Processing train dataset:  78%|███████▊  | 7757/10000 [01:52<00:37, 59.71it/s]Processing train dataset:  63%|██████▎   | 6305/10000 [01:46<01:19, 46.52it/s]Processing train dataset:  75%|███████▍  | 7472/10000 [01:48<00:47, 53.40it/s]Processing train dataset:  82%|████████▏ | 8160/10000 [01:48<00:23, 77.95it/s]Processing train dataset:  73%|███████▎  | 7251/10000 [01:48<00:59, 46.48it/s]Processing train dataset:  78%|███████▊  | 7767/10000 [01:52<00:38, 57.78it/s]Processing train dataset:  63%|██████▎   | 6311/10000 [01:46<01:25, 43.25it/s]Processing train dataset:  75%|███████▍  | 7478/10000 [01:49<00:50, 49.47it/s]Processing train dataset:  82%|████████▏ | 8168/10000 [01:49<00:24, 74.03it/s]Processing train dataset:  73%|███████▎  | 7256/10000 [01:48<01:01, 44.88it/s]Processing train dataset:  78%|███████▊  | 7775/10000 [01:52<00:36, 61.28it/s]Processing train dataset:  63%|██████▎   | 6318/10000 [01:46<01:14, 49.15it/s]Processing train dataset:  75%|███████▍  | 7485/10000 [01:49<00:46, 54.08it/s]Processing train dataset:  82%|████████▏ | 8177/10000 [01:49<00:23, 77.61it/s]Processing train dataset:  73%|███████▎  | 7265/10000 [01:48<00:54, 49.98it/s]Processing train dataset:  75%|███████▍  | 7491/10000 [01:49<00:48, 51.60it/s]Processing train dataset:  82%|████████▏ | 8185/10000 [01:49<00:25, 71.16it/s]Processing train dataset:  73%|███████▎  | 7270/10000 [01:49<01:02, 43.47it/s]Processing train dataset:  82%|████████▏ | 8193/10000 [01:49<00:24, 73.23it/s]Processing train dataset:  75%|███████▍  | 7498/10000 [01:49<00:45, 54.96it/s]Processing train dataset:  63%|██████▎   | 6324/10000 [01:46<01:37, 37.76it/s]Processing train dataset:  73%|███████▎  | 7275/10000 [01:49<01:01, 44.37it/s]Processing train dataset:  82%|████████▏ | 8201/10000 [01:49<00:24, 74.81it/s]Processing train dataset:  75%|███████▌  | 7506/10000 [01:49<00:40, 61.33it/s]Processing train dataset:  63%|██████▎   | 6329/10000 [01:47<01:33, 39.17it/s]Processing train dataset:  78%|███████▊  | 7782/10000 [01:53<00:59, 37.46it/s]Processing train dataset:  82%|████████▏ | 8209/10000 [01:49<00:23, 75.88it/s]Processing train dataset:  73%|███████▎  | 7285/10000 [01:49<00:48, 56.23it/s]Processing train dataset:  75%|███████▌  | 7515/10000 [01:49<00:37, 67.08it/s]Processing train dataset:  63%|██████▎   | 6336/10000 [01:47<01:19, 45.92it/s]Processing train dataset:  78%|███████▊  | 7789/10000 [01:53<00:51, 42.70it/s]Processing train dataset:  82%|████████▏ | 8217/10000 [01:49<00:23, 76.92it/s]Processing train dataset:  73%|███████▎  | 7294/10000 [01:49<00:43, 62.85it/s]Processing train dataset:  63%|██████▎   | 6345/10000 [01:47<01:06, 55.37it/s]Processing train dataset:  75%|███████▌  | 7524/10000 [01:49<00:34, 71.34it/s]Processing train dataset:  78%|███████▊  | 7796/10000 [01:53<00:46, 47.20it/s]Processing train dataset:  82%|████████▏ | 8226/10000 [01:49<00:22, 79.51it/s]Processing train dataset:  73%|███████▎  | 7302/10000 [01:49<00:40, 65.96it/s]Processing train dataset:  75%|███████▌  | 7532/10000 [01:49<00:34, 71.86it/s]Processing train dataset:  78%|███████▊  | 7807/10000 [01:53<00:36, 59.43it/s]Processing train dataset:  64%|██████▎   | 6352/10000 [01:47<01:13, 49.51it/s]Processing train dataset:  82%|████████▏ | 8234/10000 [01:49<00:22, 78.36it/s]Processing train dataset:  73%|███████▎  | 7311/10000 [01:49<00:37, 71.26it/s]Processing train dataset:  75%|███████▌  | 7540/10000 [01:49<00:34, 72.18it/s]Processing train dataset:  64%|██████▎   | 6360/10000 [01:47<01:05, 55.21it/s]Processing train dataset:  78%|███████▊  | 7815/10000 [01:53<00:38, 56.56it/s]Processing train dataset:  82%|████████▏ | 8243/10000 [01:49<00:21, 80.03it/s]Processing train dataset:  75%|███████▌  | 7548/10000 [01:50<00:33, 72.18it/s]Processing train dataset:  73%|███████▎  | 7319/10000 [01:49<00:39, 67.76it/s]Processing train dataset:  64%|██████▎   | 6369/10000 [01:47<00:58, 62.42it/s]Processing train dataset:  83%|████████▎ | 8254/10000 [01:50<00:20, 86.10it/s]Processing train dataset:  78%|███████▊  | 7822/10000 [01:53<00:39, 54.60it/s]Processing train dataset:  76%|███████▌  | 7556/10000 [01:50<00:33, 71.98it/s]Processing train dataset:  73%|███████▎  | 7327/10000 [01:49<00:38, 69.11it/s]Processing train dataset:  83%|████████▎ | 8263/10000 [01:50<00:20, 86.12it/s]Processing train dataset:  64%|██████▍   | 6378/10000 [01:47<00:54, 66.06it/s]Processing train dataset:  73%|███████▎  | 7336/10000 [01:49<00:35, 74.20it/s]Processing train dataset:  76%|███████▌  | 7565/10000 [01:50<00:32, 74.23it/s]Processing train dataset:  78%|███████▊  | 7829/10000 [01:53<00:39, 55.14it/s]Processing train dataset:  64%|██████▍   | 6386/10000 [01:47<00:52, 69.48it/s]Processing train dataset:  83%|████████▎ | 8272/10000 [01:50<00:20, 83.64it/s]Processing train dataset:  73%|███████▎  | 7344/10000 [01:50<00:35, 75.03it/s]Processing train dataset:  76%|███████▌  | 7573/10000 [01:50<00:32, 73.93it/s]Processing train dataset:  78%|███████▊  | 7835/10000 [01:53<00:39, 55.23it/s]Processing train dataset:  64%|██████▍   | 6395/10000 [01:47<00:48, 74.40it/s]Processing train dataset:  83%|████████▎ | 8281/10000 [01:50<00:20, 83.87it/s]Processing train dataset:  74%|███████▎  | 7352/10000 [01:50<00:34, 75.89it/s]Processing train dataset:  76%|███████▌  | 7582/10000 [01:50<00:31, 76.10it/s]Processing train dataset:  64%|██████▍   | 6405/10000 [01:48<00:44, 80.63it/s]Processing train dataset:  78%|███████▊  | 7841/10000 [01:54<00:43, 49.07it/s]Processing train dataset:  83%|████████▎ | 8290/10000 [01:50<00:20, 84.08it/s]Processing train dataset:  74%|███████▎  | 7360/10000 [01:50<00:34, 76.46it/s]Processing train dataset:  76%|███████▌  | 7590/10000 [01:50<00:32, 74.86it/s]Processing train dataset:  78%|███████▊  | 7847/10000 [01:54<00:44, 48.86it/s]Processing train dataset:  83%|████████▎ | 8299/10000 [01:50<00:21, 80.47it/s]Processing train dataset:  64%|██████▍   | 6414/10000 [01:48<00:49, 71.99it/s]Processing train dataset:  74%|███████▎  | 7368/10000 [01:50<00:35, 73.53it/s]Processing train dataset:  76%|███████▌  | 7598/10000 [01:50<00:35, 67.63it/s]Processing train dataset:  79%|███████▊  | 7853/10000 [01:54<00:43, 48.90it/s]Processing train dataset:  83%|████████▎ | 8308/10000 [01:50<00:20, 80.70it/s]Processing train dataset:  74%|███████▍  | 7376/10000 [01:50<00:36, 71.34it/s]Processing train dataset:  76%|███████▌  | 7606/10000 [01:50<00:34, 68.94it/s]Processing train dataset:  64%|██████▍   | 6422/10000 [01:48<00:57, 62.10it/s]Processing train dataset:  83%|████████▎ | 8317/10000 [01:50<00:20, 80.70it/s]Processing train dataset:  79%|███████▊  | 7860/10000 [01:54<00:40, 52.35it/s]Processing train dataset:  74%|███████▍  | 7384/10000 [01:50<00:37, 69.43it/s]Processing train dataset:  76%|███████▌  | 7615/10000 [01:50<00:32, 74.17it/s]Processing train dataset:  64%|██████▍   | 6429/10000 [01:48<01:01, 58.51it/s]Processing train dataset:  79%|███████▊  | 7867/10000 [01:54<00:38, 55.71it/s]Processing train dataset:  83%|████████▎ | 8326/10000 [01:50<00:21, 78.68it/s]Processing train dataset:  74%|███████▍  | 7391/10000 [01:50<00:40, 64.24it/s]Processing train dataset:  76%|███████▌  | 7623/10000 [01:51<00:34, 69.56it/s]Processing train dataset:  79%|███████▊  | 7873/10000 [01:54<00:37, 56.70it/s]Processing train dataset:  83%|████████▎ | 8335/10000 [01:51<00:20, 79.80it/s]Processing train dataset:  64%|██████▍   | 6436/10000 [01:48<01:05, 54.20it/s]Processing train dataset:  76%|███████▋  | 7631/10000 [01:51<00:33, 70.95it/s]Processing train dataset:  74%|███████▍  | 7398/10000 [01:50<00:44, 59.04it/s]Processing train dataset:  83%|████████▎ | 8343/10000 [01:51<00:21, 78.44it/s]Processing train dataset:  79%|███████▉  | 7882/10000 [01:54<00:34, 60.83it/s]Processing train dataset:  64%|██████▍   | 6442/10000 [01:48<01:04, 55.47it/s]Processing train dataset:  76%|███████▋  | 7639/10000 [01:51<00:32, 71.62it/s]Processing train dataset:  74%|███████▍  | 7405/10000 [01:50<00:42, 61.18it/s]Processing train dataset:  79%|███████▉  | 7889/10000 [01:54<00:33, 62.58it/s]Processing train dataset:  84%|████████▎ | 8352/10000 [01:51<00:20, 79.42it/s]Processing train dataset:  64%|██████▍   | 6449/10000 [01:48<01:03, 55.80it/s]Processing train dataset:  76%|███████▋  | 7648/10000 [01:51<00:30, 76.53it/s]Processing train dataset:  74%|███████▍  | 7413/10000 [01:51<00:39, 65.07it/s]Processing train dataset:  84%|████████▎ | 8360/10000 [01:51<00:21, 77.71it/s]Processing train dataset:  79%|███████▉  | 7896/10000 [01:54<00:35, 58.67it/s]Processing train dataset:  65%|██████▍   | 6455/10000 [01:49<01:04, 54.67it/s]Processing train dataset:  77%|███████▋  | 7657/10000 [01:51<00:30, 77.64it/s]Processing train dataset:  74%|███████▍  | 7422/10000 [01:51<00:36, 70.40it/s]Processing train dataset:  84%|████████▎ | 8368/10000 [01:51<00:21, 76.88it/s]Processing train dataset:  79%|███████▉  | 7902/10000 [01:55<00:36, 57.16it/s]Processing train dataset:  65%|██████▍   | 6462/10000 [01:49<01:00, 58.16it/s]Processing train dataset:  77%|███████▋  | 7665/10000 [01:51<00:30, 77.12it/s]Processing train dataset:  74%|███████▍  | 7430/10000 [01:51<00:35, 71.47it/s]Processing train dataset:  84%|████████▍ | 8376/10000 [01:51<00:20, 77.46it/s]Processing train dataset:  79%|███████▉  | 7908/10000 [01:55<00:37, 56.18it/s]Processing train dataset:  65%|██████▍   | 6468/10000 [01:49<01:02, 56.97it/s]Processing train dataset:  77%|███████▋  | 7673/10000 [01:51<00:30, 75.19it/s]Processing train dataset:  84%|████████▍ | 8384/10000 [01:51<00:20, 77.48it/s]Processing train dataset:  74%|███████▍  | 7438/10000 [01:51<00:37, 67.50it/s]Processing train dataset:  65%|██████▍   | 6474/10000 [01:49<01:02, 56.76it/s]Processing train dataset:  79%|███████▉  | 7915/10000 [01:55<00:36, 57.37it/s]Processing train dataset:  77%|███████▋  | 7682/10000 [01:51<00:30, 76.96it/s]Processing train dataset:  84%|████████▍ | 8392/10000 [01:51<00:20, 77.05it/s]Processing train dataset:  74%|███████▍  | 7446/10000 [01:51<00:37, 68.97it/s]Processing train dataset:  65%|██████▍   | 6481/10000 [01:49<00:59, 59.06it/s]Processing train dataset:  79%|███████▉  | 7924/10000 [01:55<00:32, 64.30it/s]Processing train dataset:  77%|███████▋  | 7692/10000 [01:51<00:27, 82.47it/s]Processing train dataset:  84%|████████▍ | 8400/10000 [01:51<00:20, 76.53it/s]Processing train dataset:  75%|███████▍  | 7453/10000 [01:51<00:38, 66.58it/s]Processing train dataset:  79%|███████▉  | 7932/10000 [01:55<00:30, 67.56it/s]Processing train dataset:  65%|██████▍   | 6488/10000 [01:49<00:59, 59.52it/s]Processing train dataset:  77%|███████▋  | 7701/10000 [01:52<00:27, 82.88it/s]Processing train dataset:  84%|████████▍ | 8408/10000 [01:52<00:21, 75.23it/s]Processing train dataset:  75%|███████▍  | 7460/10000 [01:51<00:43, 59.00it/s]Processing train dataset:  79%|███████▉  | 7941/10000 [01:55<00:28, 71.51it/s]Processing train dataset:  65%|██████▍   | 6494/10000 [01:49<00:59, 58.73it/s]Processing train dataset:  77%|███████▋  | 7710/10000 [01:52<00:28, 80.11it/s]Processing train dataset:  84%|████████▍ | 8417/10000 [01:52<00:20, 78.34it/s]Processing train dataset:  80%|███████▉  | 7950/10000 [01:55<00:27, 74.75it/s]Processing train dataset:  75%|███████▍  | 7467/10000 [01:51<00:44, 57.50it/s]Processing train dataset:  77%|███████▋  | 7719/10000 [01:52<00:28, 81.24it/s]Processing train dataset:  65%|██████▌   | 6500/10000 [01:49<01:05, 53.22it/s]Processing train dataset:  84%|████████▍ | 8425/10000 [01:52<00:20, 78.21it/s]Processing train dataset:  75%|███████▍  | 7473/10000 [01:52<00:43, 57.49it/s]Processing train dataset:  77%|███████▋  | 7728/10000 [01:52<00:27, 83.42it/s]Processing train dataset:  65%|██████▌   | 6506/10000 [01:49<01:04, 53.78it/s]Processing train dataset:  80%|███████▉  | 7958/10000 [01:55<00:29, 68.57it/s]Processing train dataset:  84%|████████▍ | 8434/10000 [01:52<00:19, 80.13it/s]Processing train dataset:  75%|███████▍  | 7480/10000 [01:52<00:44, 56.13it/s]Processing train dataset:  77%|███████▋  | 7737/10000 [01:52<00:28, 79.55it/s]Processing train dataset:  84%|████████▍ | 8443/10000 [01:52<00:19, 79.20it/s]Processing train dataset:  80%|███████▉  | 7965/10000 [01:55<00:31, 64.49it/s]Processing train dataset:  65%|██████▌   | 6512/10000 [01:50<01:07, 51.48it/s]Processing train dataset:  85%|████████▍ | 8451/10000 [01:52<00:19, 78.69it/s]Processing train dataset:  75%|███████▍  | 7487/10000 [01:52<00:45, 55.21it/s]Processing train dataset:  80%|███████▉  | 7972/10000 [01:56<00:32, 62.02it/s]Processing train dataset:  65%|██████▌   | 6519/10000 [01:50<01:05, 53.22it/s]Processing train dataset:  77%|███████▋  | 7746/10000 [01:52<00:33, 67.47it/s]Processing train dataset:  85%|████████▍ | 8463/10000 [01:52<00:17, 87.59it/s]Processing train dataset:  75%|███████▍  | 7493/10000 [01:52<00:45, 54.89it/s]Processing train dataset:  65%|██████▌   | 6526/10000 [01:50<01:02, 55.98it/s]Processing train dataset:  80%|███████▉  | 7979/10000 [01:56<00:33, 60.21it/s]Processing train dataset:  78%|███████▊  | 7754/10000 [01:52<00:33, 67.88it/s]Processing train dataset:  85%|████████▍ | 8472/10000 [01:52<00:17, 84.98it/s]Processing train dataset:  75%|███████▍  | 7499/10000 [01:52<00:47, 53.06it/s]Processing train dataset:  65%|██████▌   | 6532/10000 [01:50<01:03, 54.36it/s]Processing train dataset:  80%|███████▉  | 7989/10000 [01:56<00:29, 68.78it/s]Processing train dataset:  78%|███████▊  | 7762/10000 [01:52<00:33, 66.98it/s]Processing train dataset:  85%|████████▍ | 8481/10000 [01:52<00:18, 82.21it/s]Processing train dataset:  75%|███████▌  | 7505/10000 [01:52<00:45, 54.75it/s]Processing train dataset:  80%|███████▉  | 7998/10000 [01:56<00:26, 74.39it/s]Processing train dataset:  65%|██████▌   | 6539/10000 [01:50<01:00, 57.03it/s]Processing train dataset:  78%|███████▊  | 7770/10000 [01:53<00:31, 70.25it/s]Processing train dataset:  75%|███████▌  | 7511/10000 [01:52<00:44, 55.85it/s]Processing train dataset:  85%|████████▍ | 8490/10000 [01:53<00:18, 80.12it/s]Processing train dataset:  80%|████████  | 8006/10000 [01:56<00:27, 73.83it/s]Processing train dataset:  65%|██████▌   | 6545/10000 [01:50<01:00, 56.74it/s]Processing train dataset:  78%|███████▊  | 7780/10000 [01:53<00:30, 73.98it/s]Processing train dataset:  75%|███████▌  | 7519/10000 [01:52<00:39, 62.06it/s]Processing train dataset:  80%|████████  | 8014/10000 [01:56<00:27, 73.16it/s]Processing train dataset:  85%|████████▍ | 8499/10000 [01:53<00:19, 78.01it/s]Processing train dataset:  66%|██████▌   | 6555/10000 [01:50<00:52, 66.24it/s]Processing train dataset:  78%|███████▊  | 7788/10000 [01:53<00:29, 74.38it/s]Processing train dataset:  85%|████████▌ | 8507/10000 [01:53<00:19, 77.28it/s]Processing train dataset:  66%|██████▌   | 6562/10000 [01:50<00:52, 65.18it/s]Processing train dataset:  75%|███████▌  | 7526/10000 [01:53<00:44, 56.04it/s]Processing train dataset:  80%|████████  | 8022/10000 [01:56<00:29, 68.19it/s]Processing train dataset:  78%|███████▊  | 7796/10000 [01:53<00:29, 73.94it/s]Processing train dataset:  85%|████████▌ | 8515/10000 [01:53<00:19, 76.96it/s]Processing train dataset:  75%|███████▌  | 7532/10000 [01:53<00:44, 55.30it/s]Processing train dataset:  80%|████████  | 8030/10000 [01:56<00:28, 69.97it/s]Processing train dataset:  66%|██████▌   | 6571/10000 [01:50<00:51, 66.15it/s]Processing train dataset:  78%|███████▊  | 7805/10000 [01:53<00:28, 77.53it/s]Processing train dataset:  85%|████████▌ | 8523/10000 [01:53<00:19, 76.64it/s]Processing train dataset:  80%|████████  | 8038/10000 [01:57<00:27, 70.95it/s]Processing train dataset:  75%|███████▌  | 7539/10000 [01:53<00:42, 57.60it/s]Processing train dataset:  66%|██████▌   | 6579/10000 [01:51<00:50, 68.00it/s]Processing train dataset:  78%|███████▊  | 7813/10000 [01:53<00:27, 78.17it/s]Processing train dataset:  85%|████████▌ | 8531/10000 [01:53<00:19, 77.03it/s]Processing train dataset:  75%|███████▌  | 7545/10000 [01:53<00:42, 58.13it/s]Processing train dataset:  66%|██████▌   | 6586/10000 [01:51<00:51, 66.88it/s]Processing train dataset:  80%|████████  | 8046/10000 [01:57<00:29, 65.47it/s]Processing train dataset:  78%|███████▊  | 7821/10000 [01:53<00:30, 72.20it/s]Processing train dataset:  85%|████████▌ | 8539/10000 [01:53<00:19, 76.06it/s]Processing train dataset:  76%|███████▌  | 7552/10000 [01:53<00:40, 60.49it/s]Processing train dataset:  81%|████████  | 8055/10000 [01:57<00:27, 70.43it/s]Processing train dataset:  78%|███████▊  | 7829/10000 [01:53<00:30, 71.21it/s]Processing train dataset:  66%|██████▌   | 6593/10000 [01:51<00:58, 58.30it/s]Processing train dataset:  85%|████████▌ | 8547/10000 [01:53<00:18, 77.15it/s]Processing train dataset:  76%|███████▌  | 7561/10000 [01:53<00:36, 66.93it/s]Processing train dataset:  81%|████████  | 8063/10000 [01:57<00:26, 71.87it/s]Processing train dataset:  86%|████████▌ | 8556/10000 [01:53<00:18, 78.76it/s]Processing train dataset:  78%|███████▊  | 7837/10000 [01:53<00:31, 67.70it/s]Processing train dataset:  66%|██████▌   | 6600/10000 [01:51<00:59, 57.39it/s]Processing train dataset:  76%|███████▌  | 7568/10000 [01:53<00:35, 67.60it/s]Processing train dataset:  81%|████████  | 8071/10000 [01:57<00:27, 69.14it/s]Processing train dataset:  86%|████████▌ | 8568/10000 [01:54<00:16, 88.03it/s]Processing train dataset:  78%|███████▊  | 7845/10000 [01:54<00:30, 69.62it/s]Processing train dataset:  66%|██████▌   | 6606/10000 [01:51<01:00, 56.06it/s]Processing train dataset:  76%|███████▌  | 7575/10000 [01:53<00:36, 65.87it/s]Processing train dataset:  86%|████████▌ | 8578/10000 [01:54<00:15, 89.11it/s]Processing train dataset:  81%|████████  | 8079/10000 [01:57<00:28, 67.24it/s]Processing train dataset:  79%|███████▊  | 7853/10000 [01:54<00:30, 71.27it/s]Processing train dataset:  66%|██████▌   | 6612/10000 [01:51<00:59, 56.57it/s]Processing train dataset:  76%|███████▌  | 7583/10000 [01:53<00:35, 69.04it/s]Processing train dataset:  86%|████████▌ | 8587/10000 [01:54<00:16, 87.63it/s]Processing train dataset:  81%|████████  | 8089/10000 [01:57<00:26, 73.35it/s]Processing train dataset:  79%|███████▊  | 7862/10000 [01:54<00:28, 74.00it/s]Processing train dataset:  76%|███████▌  | 7591/10000 [01:53<00:33, 70.87it/s]Processing train dataset:  66%|██████▌   | 6618/10000 [01:51<01:03, 53.15it/s]Processing train dataset:  86%|████████▌ | 8597/10000 [01:54<00:15, 88.45it/s]Processing train dataset:  81%|████████  | 8097/10000 [01:57<00:25, 74.01it/s]Processing train dataset:  79%|███████▊  | 7870/10000 [01:54<00:28, 74.13it/s]Processing train dataset:  76%|███████▌  | 7599/10000 [01:54<00:33, 71.97it/s]Processing train dataset:  66%|██████▌   | 6624/10000 [01:51<01:03, 52.78it/s]Processing train dataset:  86%|████████▌ | 8607/10000 [01:54<00:15, 90.59it/s]Processing train dataset:  79%|███████▉  | 7878/10000 [01:54<00:28, 74.24it/s]Processing train dataset:  81%|████████  | 8105/10000 [01:57<00:26, 72.69it/s]Processing train dataset:  76%|███████▌  | 7607/10000 [01:54<00:32, 73.17it/s]Processing train dataset:  66%|██████▋   | 6631/10000 [01:52<01:04, 51.86it/s]Processing train dataset:  79%|███████▉  | 7886/10000 [01:54<00:28, 74.46it/s]Processing train dataset:  81%|████████  | 8113/10000 [01:58<00:25, 74.21it/s]Processing train dataset:  86%|████████▌ | 8617/10000 [01:54<00:15, 88.50it/s]Processing train dataset:  76%|███████▌  | 7617/10000 [01:54<00:29, 79.84it/s]Processing train dataset:  66%|██████▋   | 6640/10000 [01:52<00:55, 60.90it/s]Processing train dataset:  86%|████████▋ | 8626/10000 [01:54<00:16, 85.26it/s]Processing train dataset:  81%|████████  | 8121/10000 [01:58<00:25, 72.47it/s]Processing train dataset:  79%|███████▉  | 7894/10000 [01:54<00:29, 72.25it/s]Processing train dataset:  76%|███████▋  | 7626/10000 [01:54<00:29, 79.16it/s]Processing train dataset:  66%|██████▋   | 6647/10000 [01:52<00:57, 57.98it/s]Processing train dataset:  86%|████████▋ | 8635/10000 [01:54<00:16, 83.95it/s]Processing train dataset:  76%|███████▋  | 7634/10000 [01:54<00:30, 78.70it/s]Processing train dataset:  79%|███████▉  | 7903/10000 [01:54<00:28, 74.01it/s]Processing train dataset:  81%|████████▏ | 8129/10000 [01:58<00:27, 68.35it/s]Processing train dataset:  67%|██████▋   | 6653/10000 [01:52<00:59, 56.26it/s]Processing train dataset:  86%|████████▋ | 8644/10000 [01:54<00:16, 83.76it/s]Processing train dataset:  76%|███████▋  | 7643/10000 [01:54<00:29, 79.75it/s]Processing train dataset:  79%|███████▉  | 7911/10000 [01:54<00:28, 73.50it/s]Processing train dataset:  81%|████████▏ | 8137/10000 [01:58<00:26, 70.81it/s]Processing train dataset:  79%|███████▉  | 7920/10000 [01:55<00:26, 78.05it/s]Processing train dataset:  77%|███████▋  | 7651/10000 [01:54<00:30, 75.98it/s]Processing train dataset:  67%|██████▋   | 6659/10000 [01:52<01:05, 51.01it/s]Processing train dataset:  87%|████████▋ | 8653/10000 [01:55<00:16, 79.90it/s]Processing train dataset:  81%|████████▏ | 8145/10000 [01:58<00:25, 71.84it/s]Processing train dataset:  79%|███████▉  | 7928/10000 [01:55<00:26, 77.43it/s]Processing train dataset:  87%|████████▋ | 8662/10000 [01:55<00:16, 80.84it/s]Processing train dataset:  77%|███████▋  | 7659/10000 [01:54<00:31, 73.35it/s]Processing train dataset:  82%|████████▏ | 8153/10000 [01:58<00:26, 69.04it/s]Processing train dataset:  67%|██████▋   | 6665/10000 [01:52<01:07, 49.39it/s]Processing train dataset:  79%|███████▉  | 7937/10000 [01:55<00:26, 79.27it/s]Processing train dataset:  77%|███████▋  | 7667/10000 [01:54<00:31, 73.81it/s]Processing train dataset:  87%|████████▋ | 8671/10000 [01:55<00:16, 79.05it/s]Processing train dataset:  82%|████████▏ | 8161/10000 [01:58<00:27, 67.87it/s]Processing train dataset:  67%|██████▋   | 6671/10000 [01:52<01:07, 49.55it/s]Processing train dataset:  79%|███████▉  | 7946/10000 [01:55<00:25, 80.57it/s]Processing train dataset:  87%|████████▋ | 8680/10000 [01:55<00:16, 81.28it/s]Processing train dataset:  77%|███████▋  | 7675/10000 [01:55<00:33, 70.05it/s]Processing train dataset:  67%|██████▋   | 6679/10000 [01:52<00:58, 56.47it/s]Processing train dataset:  82%|████████▏ | 8168/10000 [01:58<00:31, 58.39it/s]Processing train dataset:  87%|████████▋ | 8689/10000 [01:55<00:15, 83.16it/s]Processing train dataset:  80%|███████▉  | 7955/10000 [01:55<00:28, 72.75it/s]Processing train dataset:  77%|███████▋  | 7683/10000 [01:55<00:32, 70.41it/s]Processing train dataset:  67%|██████▋   | 6685/10000 [01:53<01:00, 54.53it/s]Processing train dataset:  87%|████████▋ | 8698/10000 [01:55<00:15, 84.02it/s]Processing train dataset:  82%|████████▏ | 8175/10000 [01:59<00:32, 55.94it/s]Processing train dataset:  80%|███████▉  | 7963/10000 [01:55<00:27, 73.15it/s]Processing train dataset:  77%|███████▋  | 7693/10000 [01:55<00:29, 77.29it/s]Processing train dataset:  67%|██████▋   | 6692/10000 [01:53<00:56, 58.54it/s]Processing train dataset:  87%|████████▋ | 8707/10000 [01:55<00:15, 82.48it/s]Processing train dataset:  77%|███████▋  | 7702/10000 [01:55<00:28, 79.26it/s]Processing train dataset:  82%|████████▏ | 8182/10000 [01:59<00:32, 55.12it/s]Processing train dataset:  67%|██████▋   | 6699/10000 [01:53<00:55, 59.65it/s]Processing train dataset:  80%|███████▉  | 7971/10000 [01:55<00:29, 68.64it/s]Processing train dataset:  87%|████████▋ | 8716/10000 [01:55<00:15, 81.81it/s]Processing train dataset:  82%|████████▏ | 8188/10000 [01:59<00:33, 54.80it/s]Processing train dataset:  67%|██████▋   | 6706/10000 [01:53<00:54, 60.07it/s]Processing train dataset:  77%|███████▋  | 7710/10000 [01:55<00:31, 73.10it/s]Processing train dataset:  80%|███████▉  | 7978/10000 [01:55<00:30, 67.13it/s]Processing train dataset:  87%|████████▋ | 8725/10000 [01:55<00:15, 83.54it/s]Processing train dataset:  80%|███████▉  | 7986/10000 [01:55<00:28, 69.54it/s]Processing train dataset:  77%|███████▋  | 7718/10000 [01:55<00:31, 72.39it/s]Processing train dataset:  82%|████████▏ | 8194/10000 [01:59<00:34, 52.08it/s]Processing train dataset:  67%|██████▋   | 6713/10000 [01:53<00:56, 58.09it/s]Processing train dataset:  87%|████████▋ | 8734/10000 [01:56<00:15, 81.46it/s]Processing train dataset:  77%|███████▋  | 7727/10000 [01:55<00:29, 76.38it/s]Processing train dataset:  82%|████████▏ | 8200/10000 [01:59<00:33, 53.25it/s]Processing train dataset:  80%|███████▉  | 7994/10000 [01:56<00:29, 68.38it/s]Processing train dataset:  67%|██████▋   | 6720/10000 [01:53<00:57, 57.43it/s]Processing train dataset:  87%|████████▋ | 8745/10000 [01:56<00:14, 87.41it/s]Processing train dataset:  80%|████████  | 8002/10000 [01:56<00:28, 70.35it/s]Processing train dataset:  82%|████████▏ | 8206/10000 [01:59<00:33, 53.39it/s]Processing train dataset:  77%|███████▋  | 7735/10000 [01:55<00:31, 71.89it/s]Processing train dataset:  67%|██████▋   | 6726/10000 [01:53<00:58, 55.71it/s]Processing train dataset:  88%|████████▊ | 8754/10000 [01:56<00:14, 85.00it/s]Processing train dataset:  80%|████████  | 8011/10000 [01:56<00:26, 73.80it/s]Processing train dataset:  82%|████████▏ | 8212/10000 [01:59<00:32, 54.25it/s]Processing train dataset:  77%|███████▋  | 7743/10000 [01:56<00:32, 68.93it/s]Processing train dataset:  67%|██████▋   | 6732/10000 [01:53<01:00, 53.78it/s]Processing train dataset:  88%|████████▊ | 8763/10000 [01:56<00:14, 85.28it/s]Processing train dataset:  82%|████████▏ | 8220/10000 [01:59<00:29, 60.02it/s]Processing train dataset:  80%|████████  | 8019/10000 [01:56<00:26, 73.70it/s]Processing train dataset:  78%|███████▊  | 7751/10000 [01:56<00:32, 69.63it/s]Processing train dataset:  88%|████████▊ | 8772/10000 [01:56<00:14, 85.61it/s]Processing train dataset:  67%|██████▋   | 6738/10000 [01:54<01:04, 50.30it/s]Processing train dataset:  82%|████████▏ | 8230/10000 [02:00<00:26, 68.03it/s]Processing train dataset:  80%|████████  | 8027/10000 [01:56<00:27, 72.27it/s]Processing train dataset:  78%|███████▊  | 7760/10000 [01:56<00:30, 73.84it/s]Processing train dataset:  88%|████████▊ | 8781/10000 [01:56<00:14, 82.82it/s]Processing train dataset:  67%|██████▋   | 6746/10000 [01:54<00:58, 55.26it/s]Processing train dataset:  80%|████████  | 8036/10000 [01:56<00:25, 76.29it/s]Processing train dataset:  82%|████████▏ | 8237/10000 [02:00<00:26, 65.62it/s]Processing train dataset:  78%|███████▊  | 7768/10000 [01:56<00:30, 72.68it/s]Processing train dataset:  88%|████████▊ | 8790/10000 [01:56<00:14, 83.40it/s]Processing train dataset:  68%|██████▊   | 6752/10000 [01:54<00:58, 55.96it/s]Processing train dataset:  82%|████████▏ | 8244/10000 [02:00<00:27, 62.91it/s]Processing train dataset:  78%|███████▊  | 7778/10000 [01:56<00:28, 79.10it/s]Processing train dataset:  80%|████████  | 8044/10000 [01:56<00:28, 69.82it/s]Processing train dataset:  88%|████████▊ | 8799/10000 [01:56<00:14, 84.00it/s]Processing train dataset:  68%|██████▊   | 6760/10000 [01:54<00:55, 58.08it/s]Processing train dataset:  78%|███████▊  | 7786/10000 [01:56<00:27, 79.09it/s]Processing train dataset:  83%|████████▎ | 8253/10000 [02:00<00:25, 67.58it/s]Processing train dataset:  81%|████████  | 8053/10000 [01:56<00:26, 72.75it/s]Processing train dataset:  88%|████████▊ | 8808/10000 [01:56<00:14, 83.98it/s]Processing train dataset:  68%|██████▊   | 6766/10000 [01:54<00:55, 58.53it/s]Processing train dataset:  81%|████████  | 8061/10000 [01:57<00:26, 72.02it/s]Processing train dataset:  83%|████████▎ | 8260/10000 [02:00<00:26, 64.87it/s]Processing train dataset:  78%|███████▊  | 7794/10000 [01:56<00:30, 72.54it/s]Processing train dataset:  88%|████████▊ | 8817/10000 [01:56<00:13, 84.60it/s]Processing train dataset:  68%|██████▊   | 6773/10000 [01:54<00:54, 59.17it/s]Processing train dataset:  81%|████████  | 8069/10000 [01:57<00:26, 71.55it/s]Processing train dataset:  83%|████████▎ | 8267/10000 [02:00<00:26, 64.28it/s]Processing train dataset:  78%|███████▊  | 7802/10000 [01:56<00:30, 71.03it/s]Processing train dataset:  88%|████████▊ | 8826/10000 [01:57<00:14, 82.38it/s]Processing train dataset:  68%|██████▊   | 6780/10000 [01:54<00:53, 60.61it/s]Processing train dataset:  78%|███████▊  | 7810/10000 [01:56<00:29, 73.39it/s]Processing train dataset:  81%|████████  | 8077/10000 [01:57<00:27, 71.18it/s]Processing train dataset:  88%|████████▊ | 8835/10000 [01:57<00:14, 80.87it/s]Processing train dataset:  83%|████████▎ | 8274/10000 [02:00<00:28, 60.92it/s]Processing train dataset:  68%|██████▊   | 6787/10000 [01:54<00:55, 57.93it/s]Processing train dataset:  81%|████████  | 8085/10000 [01:57<00:26, 72.31it/s]Processing train dataset:  78%|███████▊  | 7818/10000 [01:57<00:29, 73.53it/s]Processing train dataset:  88%|████████▊ | 8844/10000 [01:57<00:14, 82.25it/s]Processing train dataset:  83%|████████▎ | 8282/10000 [02:00<00:27, 63.28it/s]Processing train dataset:  68%|██████▊   | 6794/10000 [01:54<00:52, 60.62it/s]Processing train dataset:  78%|███████▊  | 7827/10000 [01:57<00:28, 76.28it/s]Processing train dataset:  81%|████████  | 8094/10000 [01:57<00:25, 74.54it/s]Processing train dataset:  89%|████████▊ | 8855/10000 [01:57<00:13, 86.79it/s]Processing train dataset:  83%|████████▎ | 8291/10000 [02:00<00:24, 68.83it/s]Processing train dataset:  68%|██████▊   | 6801/10000 [01:55<00:51, 61.53it/s]Processing train dataset:  78%|███████▊  | 7835/10000 [01:57<00:28, 74.95it/s]Processing train dataset:  81%|████████  | 8102/10000 [01:57<00:26, 72.90it/s]Processing train dataset:  83%|████████▎ | 8299/10000 [02:01<00:23, 71.37it/s]Processing train dataset:  89%|████████▊ | 8864/10000 [01:57<00:13, 82.79it/s]Processing train dataset:  68%|██████▊   | 6808/10000 [01:55<00:52, 60.47it/s]Processing train dataset:  78%|███████▊  | 7843/10000 [01:57<00:28, 74.39it/s]Processing train dataset:  83%|████████▎ | 8309/10000 [02:01<00:21, 78.80it/s]Processing train dataset:  81%|████████  | 8110/10000 [01:57<00:26, 72.22it/s]Processing train dataset:  89%|████████▊ | 8873/10000 [01:57<00:13, 80.56it/s]Processing train dataset:  68%|██████▊   | 6815/10000 [01:55<00:50, 62.68it/s]Processing train dataset:  79%|███████▊  | 7851/10000 [01:57<00:28, 74.60it/s]Processing train dataset:  83%|████████▎ | 8318/10000 [02:01<00:20, 80.78it/s]Processing train dataset:  81%|████████  | 8119/10000 [01:57<00:24, 76.04it/s]Processing train dataset:  89%|████████▉ | 8882/10000 [01:57<00:14, 78.74it/s]Processing train dataset:  68%|██████▊   | 6822/10000 [01:55<00:50, 63.31it/s]Processing train dataset:  79%|███████▊  | 7860/10000 [01:57<00:27, 78.51it/s]Processing train dataset:  81%|████████▏ | 8127/10000 [01:57<00:25, 73.63it/s]Processing train dataset:  83%|████████▎ | 8327/10000 [02:01<00:21, 77.08it/s]Processing train dataset:  89%|████████▉ | 8890/10000 [01:57<00:15, 70.77it/s]Processing train dataset:  68%|██████▊   | 6831/10000 [01:55<00:47, 66.05it/s]Processing train dataset:  79%|███████▊  | 7868/10000 [01:57<00:27, 77.47it/s]Processing train dataset:  81%|████████▏ | 8135/10000 [01:58<00:26, 71.72it/s]Processing train dataset:  83%|████████▎ | 8335/10000 [02:01<00:22, 73.33it/s]Processing train dataset:  68%|██████▊   | 6838/10000 [01:55<00:47, 66.90it/s]Processing train dataset:  89%|████████▉ | 8898/10000 [01:58<00:15, 71.05it/s]Processing train dataset:  79%|███████▉  | 7876/10000 [01:57<00:28, 73.76it/s]Processing train dataset:  81%|████████▏ | 8143/10000 [01:58<00:26, 69.52it/s]Processing train dataset:  68%|██████▊   | 6845/10000 [01:55<00:46, 67.26it/s]Processing train dataset:  83%|████████▎ | 8343/10000 [02:01<00:24, 66.87it/s]Processing train dataset:  89%|████████▉ | 8907/10000 [01:58<00:14, 75.07it/s]Processing train dataset:  79%|███████▉  | 7884/10000 [01:57<00:28, 73.22it/s]Processing train dataset:  82%|████████▏ | 8151/10000 [01:58<00:26, 70.37it/s]Processing train dataset:  84%|████████▎ | 8350/10000 [02:01<00:25, 65.87it/s]Processing train dataset:  89%|████████▉ | 8915/10000 [01:58<00:14, 74.54it/s]Processing train dataset:  69%|██████▊   | 6852/10000 [01:55<00:48, 64.28it/s]Processing train dataset:  79%|███████▉  | 7892/10000 [01:58<00:31, 67.72it/s]Processing train dataset:  82%|████████▏ | 8159/10000 [01:58<00:25, 71.10it/s]Processing train dataset:  89%|████████▉ | 8924/10000 [01:58<00:14, 76.52it/s]Processing train dataset:  69%|██████▊   | 6859/10000 [01:55<00:49, 63.17it/s]Processing train dataset:  84%|████████▎ | 8357/10000 [02:01<00:25, 63.55it/s]Processing train dataset:  79%|███████▉  | 7900/10000 [01:58<00:29, 70.56it/s]Processing train dataset:  82%|████████▏ | 8167/10000 [01:58<00:26, 70.01it/s]Processing train dataset:  89%|████████▉ | 8932/10000 [01:58<00:14, 75.52it/s]Processing train dataset:  84%|████████▎ | 8364/10000 [02:01<00:25, 63.93it/s]Processing train dataset:  69%|██████▊   | 6866/10000 [01:56<00:51, 60.83it/s]Processing train dataset:  79%|███████▉  | 7908/10000 [01:58<00:28, 72.85it/s]Processing train dataset:  82%|████████▏ | 8175/10000 [01:58<00:26, 69.01it/s]Processing train dataset:  84%|████████▎ | 8371/10000 [02:02<00:25, 64.76it/s]Processing train dataset:  89%|████████▉ | 8942/10000 [01:58<00:13, 80.21it/s]Processing train dataset:  69%|██████▊   | 6873/10000 [01:56<00:51, 60.41it/s]Processing train dataset:  79%|███████▉  | 7916/10000 [01:58<00:28, 71.99it/s]Processing train dataset:  82%|████████▏ | 8184/10000 [01:58<00:24, 72.69it/s]Processing train dataset:  84%|████████▍ | 8378/10000 [02:02<00:24, 65.18it/s]Processing train dataset:  69%|██████▉   | 6881/10000 [01:56<00:49, 63.22it/s]Processing train dataset:  90%|████████▉ | 8951/10000 [01:58<00:14, 73.51it/s]Processing train dataset:  79%|███████▉  | 7925/10000 [01:58<00:27, 76.64it/s]Processing train dataset:  82%|████████▏ | 8192/10000 [01:58<00:24, 73.71it/s]Processing train dataset:  84%|████████▍ | 8385/10000 [02:02<00:24, 64.72it/s]Processing train dataset:  90%|████████▉ | 8962/10000 [01:58<00:12, 81.04it/s]Processing train dataset:  79%|███████▉  | 7934/10000 [01:58<00:26, 78.96it/s]Processing train dataset:  69%|██████▉   | 6889/10000 [01:56<00:47, 65.31it/s]Processing train dataset:  82%|████████▏ | 8200/10000 [01:58<00:24, 72.70it/s]Processing train dataset:  84%|████████▍ | 8392/10000 [02:02<00:25, 62.05it/s]Processing train dataset:  79%|███████▉  | 7943/10000 [01:58<00:25, 82.02it/s]Processing train dataset:  90%|████████▉ | 8971/10000 [01:58<00:12, 82.44it/s]Processing train dataset:  69%|██████▉   | 6896/10000 [01:56<00:49, 62.92it/s]Processing train dataset:  82%|████████▏ | 8208/10000 [01:59<00:25, 69.35it/s]Processing train dataset:  84%|████████▍ | 8399/10000 [02:02<00:26, 60.61it/s]Processing train dataset:  90%|████████▉ | 8980/10000 [01:59<00:12, 81.39it/s]Processing train dataset:  80%|███████▉  | 7952/10000 [01:58<00:26, 76.80it/s]Processing train dataset:  69%|██████▉   | 6905/10000 [01:56<00:46, 67.08it/s]Processing train dataset:  82%|████████▏ | 8215/10000 [01:59<00:25, 68.67it/s]Processing train dataset:  84%|████████▍ | 8406/10000 [02:02<00:26, 60.71it/s]Processing train dataset:  90%|████████▉ | 8989/10000 [01:59<00:12, 81.51it/s]Processing train dataset:  80%|███████▉  | 7960/10000 [01:58<00:27, 75.20it/s]Processing train dataset:  69%|██████▉   | 6913/10000 [01:56<00:45, 67.89it/s]Processing train dataset:  82%|████████▏ | 8224/10000 [01:59<00:24, 72.91it/s]Processing train dataset:  84%|████████▍ | 8415/10000 [02:02<00:24, 64.88it/s]Processing train dataset:  90%|████████▉ | 8998/10000 [01:59<00:12, 80.77it/s]Processing train dataset:  80%|███████▉  | 7968/10000 [01:59<00:26, 75.44it/s]Processing train dataset:  69%|██████▉   | 6921/10000 [01:56<00:44, 69.49it/s]Processing train dataset:  82%|████████▏ | 8232/10000 [01:59<00:23, 74.24it/s]Processing train dataset:  84%|████████▍ | 8423/10000 [02:02<00:23, 67.29it/s]Processing train dataset:  90%|█████████ | 9007/10000 [01:59<00:12, 80.16it/s]Processing train dataset:  82%|████████▏ | 8240/10000 [01:59<00:23, 74.72it/s]Processing train dataset:  80%|███████▉  | 7976/10000 [01:59<00:31, 65.22it/s]Processing train dataset:  90%|█████████ | 9016/10000 [01:59<00:12, 81.20it/s]Processing train dataset:  69%|██████▉   | 6929/10000 [01:57<00:55, 55.54it/s]Processing train dataset:  83%|████████▎ | 8251/10000 [01:59<00:21, 82.70it/s]Processing train dataset:  80%|███████▉  | 7983/10000 [01:59<00:34, 58.62it/s]Processing train dataset:  90%|█████████ | 9025/10000 [01:59<00:11, 82.26it/s]Processing train dataset:  83%|████████▎ | 8260/10000 [01:59<00:21, 81.04it/s]Processing train dataset:  84%|████████▍ | 8430/10000 [02:03<00:35, 43.97it/s]Processing train dataset:  69%|██████▉   | 6936/10000 [01:57<01:03, 48.26it/s]Processing train dataset:  90%|█████████ | 9034/10000 [01:59<00:11, 83.41it/s]Processing train dataset:  80%|███████▉  | 7992/10000 [01:59<00:30, 64.93it/s]Processing train dataset:  83%|████████▎ | 8269/10000 [01:59<00:22, 78.03it/s]Processing train dataset:  84%|████████▍ | 8438/10000 [02:03<00:30, 50.55it/s]Processing train dataset:  69%|██████▉   | 6942/10000 [01:57<01:00, 50.68it/s]Processing train dataset:  80%|███████▉  | 7999/10000 [01:59<00:30, 64.85it/s]Processing train dataset:  90%|█████████ | 9043/10000 [01:59<00:11, 81.63it/s]Processing train dataset:  83%|████████▎ | 8277/10000 [01:59<00:22, 77.52it/s]Processing train dataset:  84%|████████▍ | 8446/10000 [02:03<00:27, 56.21it/s]Processing train dataset:  69%|██████▉   | 6949/10000 [01:57<00:55, 54.75it/s]Processing train dataset:  91%|█████████ | 9052/10000 [01:59<00:11, 81.29it/s]Processing train dataset:  80%|████████  | 8007/10000 [01:59<00:30, 65.73it/s]Processing train dataset:  83%|████████▎ | 8285/10000 [02:00<00:23, 73.85it/s]Processing train dataset:  85%|████████▍ | 8453/10000 [02:03<00:26, 57.79it/s]Processing train dataset:  70%|██████▉   | 6955/10000 [01:57<00:58, 52.05it/s]Processing train dataset:  91%|█████████ | 9061/10000 [02:00<00:11, 79.99it/s]Processing train dataset:  80%|████████  | 8014/10000 [01:59<00:31, 62.15it/s]Processing train dataset:  85%|████████▍ | 8460/10000 [02:03<00:25, 59.96it/s]Processing train dataset:  83%|████████▎ | 8294/10000 [02:00<00:22, 75.00it/s]Processing train dataset:  70%|██████▉   | 6962/10000 [01:57<00:55, 54.60it/s]Processing train dataset:  80%|████████  | 8021/10000 [01:59<00:31, 62.77it/s]Processing train dataset:  91%|█████████ | 9070/10000 [02:00<00:12, 76.26it/s]Processing train dataset:  85%|████████▍ | 8467/10000 [02:03<00:27, 54.90it/s]Processing train dataset:  83%|████████▎ | 8302/10000 [02:00<00:25, 66.40it/s]Processing train dataset:  70%|██████▉   | 6968/10000 [01:57<01:02, 48.21it/s]Processing train dataset:  91%|█████████ | 9078/10000 [02:00<00:13, 69.50it/s]Processing train dataset:  80%|████████  | 8028/10000 [02:00<00:36, 53.58it/s]Processing train dataset:  85%|████████▍ | 8475/10000 [02:03<00:25, 59.95it/s]Processing train dataset:  83%|████████▎ | 8309/10000 [02:00<00:25, 67.14it/s]Processing train dataset:  70%|██████▉   | 6977/10000 [01:58<00:53, 56.83it/s]Processing train dataset:  91%|█████████ | 9087/10000 [02:00<00:12, 73.27it/s]Processing train dataset:  80%|████████  | 8036/10000 [02:00<00:33, 57.90it/s]Processing train dataset:  83%|████████▎ | 8317/10000 [02:00<00:25, 66.53it/s]Processing train dataset:  85%|████████▍ | 8482/10000 [02:04<00:27, 54.23it/s]Processing train dataset:  91%|█████████ | 9095/10000 [02:00<00:12, 73.75it/s]Processing train dataset:  70%|██████▉   | 6984/10000 [01:58<00:57, 52.73it/s]Processing train dataset:  80%|████████  | 8043/10000 [02:00<00:35, 54.82it/s]Processing train dataset:  83%|████████▎ | 8325/10000 [02:00<00:24, 68.94it/s]Processing train dataset:  85%|████████▍ | 8490/10000 [02:04<00:25, 59.88it/s]Processing train dataset:  91%|█████████ | 9105/10000 [02:00<00:11, 80.22it/s]Processing train dataset:  83%|████████▎ | 8332/10000 [02:00<00:24, 67.61it/s]Processing train dataset:  70%|██████▉   | 6991/10000 [01:58<00:57, 51.95it/s]Processing train dataset:  80%|████████  | 8049/10000 [02:00<00:36, 54.11it/s]Processing train dataset:  91%|█████████ | 9114/10000 [02:00<00:11, 74.47it/s]Processing train dataset:  85%|████████▍ | 8497/10000 [02:04<00:26, 55.95it/s]Processing train dataset:  83%|████████▎ | 8340/10000 [02:00<00:23, 69.72it/s]Processing train dataset:  70%|███████   | 7000/10000 [01:58<00:50, 59.39it/s]Processing train dataset:  81%|████████  | 8057/10000 [02:00<00:33, 58.54it/s]Processing train dataset:  85%|████████▌ | 8504/10000 [02:04<00:25, 58.50it/s]Processing train dataset:  91%|█████████ | 9123/10000 [02:00<00:11, 76.21it/s]Processing train dataset:  83%|████████▎ | 8348/10000 [02:00<00:23, 69.85it/s]Processing train dataset:  81%|████████  | 8063/10000 [02:00<00:38, 50.47it/s]Processing train dataset:  70%|███████   | 7007/10000 [01:58<00:58, 51.11it/s]Processing train dataset:  91%|█████████▏| 9131/10000 [02:01<00:12, 69.64it/s]Processing train dataset:  85%|████████▌ | 8511/10000 [02:04<00:27, 53.27it/s]Processing train dataset:  84%|████████▎ | 8356/10000 [02:01<00:23, 68.84it/s]Processing train dataset:  81%|████████  | 8071/10000 [02:00<00:35, 54.80it/s]Processing train dataset:  70%|███████   | 7014/10000 [01:58<00:55, 53.93it/s]Processing train dataset:  91%|█████████▏| 9140/10000 [02:01<00:11, 72.31it/s]Processing train dataset:  84%|████████▎ | 8364/10000 [02:01<00:24, 67.32it/s]Processing train dataset:  85%|████████▌ | 8520/10000 [02:04<00:25, 56.96it/s]Processing train dataset:  91%|█████████▏| 9148/10000 [02:01<00:11, 72.45it/s]Processing train dataset:  70%|███████   | 7020/10000 [01:58<00:58, 51.06it/s]Processing train dataset:  81%|████████  | 8077/10000 [02:01<00:38, 50.22it/s]Processing train dataset:  84%|████████▎ | 8372/10000 [02:01<00:23, 69.97it/s]Processing train dataset:  85%|████████▌ | 8529/10000 [02:04<00:23, 63.91it/s]Processing train dataset:  92%|█████████▏| 9157/10000 [02:01<00:11, 76.10it/s]Processing train dataset:  70%|███████   | 7027/10000 [01:58<00:57, 52.06it/s]Processing train dataset:  85%|████████▌ | 8536/10000 [02:04<00:23, 62.89it/s]Processing train dataset:  84%|████████▍ | 8380/10000 [02:01<00:24, 67.12it/s]Processing train dataset:  81%|████████  | 8083/10000 [02:01<00:40, 47.11it/s]Processing train dataset:  92%|█████████▏| 9165/10000 [02:01<00:10, 76.94it/s]Processing train dataset:  70%|███████   | 7033/10000 [01:59<00:55, 53.78it/s]Processing train dataset:  85%|████████▌ | 8543/10000 [02:05<00:22, 64.45it/s]Processing train dataset:  84%|████████▍ | 8388/10000 [02:01<00:23, 69.30it/s]Processing train dataset:  81%|████████  | 8090/10000 [02:01<00:37, 51.07it/s]Processing train dataset:  92%|█████████▏| 9173/10000 [02:01<00:10, 77.69it/s]Processing train dataset:  70%|███████   | 7040/10000 [01:59<00:56, 52.12it/s]Processing train dataset:  86%|████████▌ | 8550/10000 [02:05<00:24, 58.23it/s]Processing train dataset:  84%|████████▍ | 8395/10000 [02:01<00:26, 60.07it/s]Processing train dataset:  92%|█████████▏| 9181/10000 [02:01<00:12, 67.94it/s]Processing train dataset:  81%|████████  | 8096/10000 [02:01<00:43, 43.81it/s]Processing train dataset:  70%|███████   | 7046/10000 [01:59<00:56, 52.44it/s]Processing train dataset:  86%|████████▌ | 8557/10000 [02:05<00:23, 60.34it/s]Processing train dataset:  84%|████████▍ | 8403/10000 [02:01<00:25, 63.60it/s]Processing train dataset:  92%|█████████▏| 9191/10000 [02:01<00:10, 75.32it/s]Processing train dataset:  81%|████████  | 8102/10000 [02:01<00:40, 47.03it/s]Processing train dataset:  71%|███████   | 7054/10000 [01:59<00:49, 59.01it/s]Processing train dataset:  86%|████████▌ | 8566/10000 [02:05<00:21, 66.63it/s]Processing train dataset:  84%|████████▍ | 8410/10000 [02:01<00:24, 64.15it/s]Processing train dataset:  92%|█████████▏| 9201/10000 [02:01<00:09, 81.16it/s]Processing train dataset:  81%|████████  | 8110/10000 [02:01<00:35, 53.54it/s]Processing train dataset:  71%|███████   | 7063/10000 [01:59<00:44, 66.74it/s]Processing train dataset:  86%|████████▌ | 8575/10000 [02:05<00:19, 72.53it/s]Processing train dataset:  84%|████████▍ | 8418/10000 [02:02<00:23, 67.20it/s]Processing train dataset:  92%|█████████▏| 9210/10000 [02:02<00:09, 82.87it/s]Processing train dataset:  81%|████████  | 8119/10000 [02:01<00:30, 62.48it/s]Processing train dataset:  71%|███████   | 7073/10000 [01:59<00:38, 75.37it/s]Processing train dataset:  86%|████████▌ | 8584/10000 [02:05<00:18, 76.75it/s]Processing train dataset:  84%|████████▍ | 8426/10000 [02:02<00:22, 70.00it/s]Processing train dataset:  92%|█████████▏| 9219/10000 [02:02<00:09, 84.76it/s]Processing train dataset:  81%|████████▏ | 8127/10000 [02:01<00:28, 65.30it/s]Processing train dataset:  71%|███████   | 7085/10000 [01:59<00:34, 85.73it/s]Processing train dataset:  86%|████████▌ | 8593/10000 [02:05<00:18, 74.93it/s]Processing train dataset:  84%|████████▍ | 8434/10000 [02:02<00:22, 71.08it/s]Processing train dataset:  92%|█████████▏| 9228/10000 [02:02<00:09, 84.56it/s]Processing train dataset:  81%|████████▏ | 8134/10000 [02:01<00:28, 64.90it/s]Processing train dataset:  71%|███████   | 7094/10000 [01:59<00:33, 85.76it/s]Processing train dataset:  84%|████████▍ | 8442/10000 [02:02<00:22, 68.29it/s]Processing train dataset:  86%|████████▌ | 8601/10000 [02:05<00:20, 68.54it/s]Processing train dataset:  92%|█████████▏| 9237/10000 [02:02<00:09, 82.90it/s]Processing train dataset:  81%|████████▏ | 8141/10000 [02:02<00:35, 52.56it/s]Processing train dataset:  84%|████████▍ | 8449/10000 [02:02<00:23, 64.80it/s]Processing train dataset:  92%|█████████▏| 9246/10000 [02:02<00:09, 78.61it/s]Processing train dataset:  71%|███████   | 7103/10000 [02:00<00:49, 58.27it/s]Processing train dataset:  81%|████████▏ | 8147/10000 [02:02<00:35, 52.26it/s]Processing train dataset:  85%|████████▍ | 8456/10000 [02:02<00:24, 63.64it/s]Processing train dataset:  93%|█████████▎| 9254/10000 [02:02<00:10, 74.25it/s]Processing train dataset:  86%|████████▌ | 8609/10000 [02:06<00:27, 49.95it/s]Processing train dataset:  71%|███████   | 7112/10000 [02:00<00:44, 64.21it/s]Processing train dataset:  82%|████████▏ | 8155/10000 [02:02<00:31, 58.01it/s]Processing train dataset:  85%|████████▍ | 8464/10000 [02:02<00:23, 66.69it/s]Processing train dataset:  93%|█████████▎| 9262/10000 [02:02<00:09, 74.89it/s]Processing train dataset:  86%|████████▌ | 8617/10000 [02:06<00:24, 55.49it/s]Processing train dataset:  71%|███████   | 7124/10000 [02:00<00:37, 75.83it/s]Processing train dataset:  82%|████████▏ | 8163/10000 [02:02<00:29, 62.98it/s]Processing train dataset:  85%|████████▍ | 8471/10000 [02:02<00:24, 63.51it/s]Processing train dataset:  93%|█████████▎| 9271/10000 [02:02<00:09, 76.46it/s]Processing train dataset:  86%|████████▋ | 8625/10000 [02:06<00:22, 60.94it/s]Processing train dataset:  71%|███████▏  | 7136/10000 [02:00<00:33, 84.65it/s]Processing train dataset:  82%|████████▏ | 8171/10000 [02:02<00:27, 67.05it/s]Processing train dataset:  93%|█████████▎| 9279/10000 [02:02<00:09, 74.02it/s]Processing train dataset:  86%|████████▋ | 8632/10000 [02:06<00:22, 59.48it/s]Processing train dataset:  85%|████████▍ | 8478/10000 [02:03<00:26, 56.57it/s]Processing train dataset:  82%|████████▏ | 8178/10000 [02:02<00:27, 66.71it/s]Processing train dataset:  71%|███████▏  | 7146/10000 [02:00<00:35, 80.75it/s]Processing train dataset:  93%|█████████▎| 9289/10000 [02:03<00:08, 79.97it/s]Processing train dataset:  86%|████████▋ | 8639/10000 [02:06<00:25, 54.43it/s]Processing train dataset:  85%|████████▍ | 8484/10000 [02:03<00:30, 49.52it/s]Processing train dataset:  82%|████████▏ | 8185/10000 [02:02<00:30, 59.48it/s]Processing train dataset:  93%|█████████▎| 9298/10000 [02:03<00:08, 80.26it/s]Processing train dataset:  72%|███████▏  | 7155/10000 [02:00<00:38, 74.03it/s]Processing train dataset:  86%|████████▋ | 8645/10000 [02:06<00:26, 50.68it/s]Processing train dataset:  85%|████████▍ | 8490/10000 [02:03<00:30, 49.61it/s]Processing train dataset:  93%|█████████▎| 9307/10000 [02:03<00:08, 80.46it/s]Processing train dataset:  72%|███████▏  | 7163/10000 [02:00<00:40, 70.50it/s]Processing train dataset:  82%|████████▏ | 8192/10000 [02:03<00:32, 55.02it/s]Processing train dataset:  87%|████████▋ | 8651/10000 [02:06<00:26, 51.50it/s]Processing train dataset:  85%|████████▍ | 8496/10000 [02:03<00:29, 50.45it/s]Processing train dataset:  93%|█████████▎| 9316/10000 [02:03<00:08, 80.68it/s]Processing train dataset:  72%|███████▏  | 7171/10000 [02:00<00:39, 71.95it/s]Processing train dataset:  82%|████████▏ | 8199/10000 [02:03<00:33, 54.42it/s]Processing train dataset:  87%|████████▋ | 8657/10000 [02:06<00:25, 51.87it/s]Processing train dataset:  93%|█████████▎| 9325/10000 [02:03<00:08, 79.77it/s]Processing train dataset:  85%|████████▌ | 8502/10000 [02:03<00:30, 48.46it/s]Processing train dataset:  72%|███████▏  | 7179/10000 [02:01<00:40, 70.21it/s]Processing train dataset:  82%|████████▏ | 8206/10000 [02:03<00:30, 58.10it/s]Processing train dataset:  87%|████████▋ | 8664/10000 [02:07<00:24, 54.41it/s]Processing train dataset:  85%|████████▌ | 8507/10000 [02:03<00:31, 47.90it/s]Processing train dataset:  93%|█████████▎| 9334/10000 [02:03<00:08, 77.04it/s]Processing train dataset:  72%|███████▏  | 7187/10000 [02:01<00:40, 68.91it/s]Processing train dataset:  82%|████████▏ | 8213/10000 [02:03<00:34, 51.79it/s]Processing train dataset:  87%|████████▋ | 8670/10000 [02:07<00:25, 51.78it/s]Processing train dataset:  93%|█████████▎| 9342/10000 [02:03<00:08, 77.00it/s]Processing train dataset:  85%|████████▌ | 8513/10000 [02:03<00:30, 49.01it/s]Processing train dataset:  72%|███████▏  | 7198/10000 [02:01<00:36, 77.47it/s]Processing train dataset:  82%|████████▏ | 8219/10000 [02:03<00:34, 51.03it/s]Processing train dataset:  87%|████████▋ | 8676/10000 [02:07<00:25, 51.78it/s]Processing train dataset:  94%|█████████▎| 9350/10000 [02:03<00:08, 74.89it/s]Processing train dataset:  85%|████████▌ | 8518/10000 [02:03<00:31, 47.64it/s]Processing train dataset:  72%|███████▏  | 7206/10000 [02:01<00:38, 72.67it/s]Processing train dataset:  82%|████████▏ | 8228/10000 [02:03<00:29, 59.24it/s]Processing train dataset:  94%|█████████▎| 9359/10000 [02:03<00:08, 78.91it/s]Processing train dataset:  87%|████████▋ | 8685/10000 [02:07<00:21, 60.21it/s]Processing train dataset:  85%|████████▌ | 8524/10000 [02:03<00:29, 49.92it/s]Processing train dataset:  72%|███████▏  | 7214/10000 [02:01<00:38, 72.77it/s]Processing train dataset:  94%|█████████▎| 9367/10000 [02:04<00:08, 76.77it/s]Processing train dataset:  82%|████████▏ | 8235/10000 [02:03<00:30, 58.00it/s]Processing train dataset:  85%|████████▌ | 8530/10000 [02:04<00:29, 49.14it/s]Processing train dataset:  87%|████████▋ | 8692/10000 [02:07<00:22, 57.63it/s]Processing train dataset:  72%|███████▏  | 7223/10000 [02:01<00:36, 75.96it/s]Processing train dataset:  94%|█████████▍| 9375/10000 [02:04<00:08, 75.04it/s]Processing train dataset:  82%|████████▏ | 8241/10000 [02:03<00:32, 53.73it/s]Processing train dataset:  85%|████████▌ | 8535/10000 [02:04<00:32, 45.64it/s]Processing train dataset:  87%|████████▋ | 8698/10000 [02:07<00:26, 49.35it/s]Processing train dataset:  94%|█████████▍| 9384/10000 [02:04<00:07, 77.21it/s]Processing train dataset:  85%|████████▌ | 8540/10000 [02:04<00:33, 43.99it/s]Processing train dataset:  82%|████████▏ | 8247/10000 [02:04<00:36, 48.66it/s]Processing train dataset:  94%|█████████▍| 9393/10000 [02:04<00:07, 78.74it/s]Processing train dataset:  85%|████████▌ | 8546/10000 [02:04<00:30, 47.65it/s]Processing train dataset:  83%|████████▎ | 8254/10000 [02:04<00:33, 52.10it/s]Processing train dataset:  87%|████████▋ | 8704/10000 [02:07<00:31, 40.53it/s]Processing train dataset:  72%|███████▏  | 7231/10000 [02:02<01:03, 43.55it/s]Processing train dataset:  94%|█████████▍| 9402/10000 [02:04<00:07, 81.48it/s]Processing train dataset:  86%|████████▌ | 8554/10000 [02:04<00:26, 55.24it/s]Processing train dataset:  83%|████████▎ | 8261/10000 [02:04<00:31, 56.01it/s]Processing train dataset:  87%|████████▋ | 8710/10000 [02:08<00:28, 44.51it/s]Processing train dataset:  94%|█████████▍| 9411/10000 [02:04<00:07, 81.27it/s]Processing train dataset:  72%|███████▏  | 7238/10000 [02:02<01:02, 44.02it/s]Processing train dataset:  86%|████████▌ | 8564/10000 [02:04<00:21, 67.24it/s]Processing train dataset:  83%|████████▎ | 8268/10000 [02:04<00:29, 59.65it/s]Processing train dataset:  87%|████████▋ | 8717/10000 [02:08<00:27, 47.32it/s]Processing train dataset:  94%|█████████▍| 9420/10000 [02:04<00:07, 81.45it/s]Processing train dataset:  72%|███████▏  | 7245/10000 [02:02<00:56, 48.64it/s]Processing train dataset:  86%|████████▌ | 8571/10000 [02:04<00:21, 66.83it/s]Processing train dataset:  83%|████████▎ | 8275/10000 [02:04<00:27, 61.67it/s]Processing train dataset:  94%|█████████▍| 9429/10000 [02:04<00:06, 83.50it/s]Processing train dataset:  87%|████████▋ | 8725/10000 [02:08<00:23, 53.77it/s]Processing train dataset:  73%|███████▎  | 7252/10000 [02:02<00:53, 51.43it/s]Processing train dataset:  86%|████████▌ | 8579/10000 [02:04<00:20, 68.54it/s]Processing train dataset:  83%|████████▎ | 8283/10000 [02:04<00:26, 65.77it/s]Processing train dataset:  94%|█████████▍| 9438/10000 [02:04<00:06, 85.33it/s]Processing train dataset:  87%|████████▋ | 8731/10000 [02:08<00:23, 54.66it/s]Processing train dataset:  73%|███████▎  | 7258/10000 [02:02<00:52, 52.65it/s]Processing train dataset:  86%|████████▌ | 8587/10000 [02:05<00:20, 70.12it/s]Processing train dataset:  83%|████████▎ | 8292/10000 [02:04<00:23, 71.66it/s]Processing train dataset:  94%|█████████▍| 9447/10000 [02:05<00:06, 85.81it/s]Processing train dataset:  87%|████████▋ | 8740/10000 [02:08<00:20, 62.53it/s]Processing train dataset:  73%|███████▎  | 7266/10000 [02:02<00:47, 57.81it/s]Processing train dataset:  83%|████████▎ | 8300/10000 [02:04<00:23, 73.19it/s]Processing train dataset:  86%|████████▌ | 8595/10000 [02:05<00:20, 69.49it/s]Processing train dataset:  95%|█████████▍| 9457/10000 [02:05<00:06, 89.19it/s]Processing train dataset:  87%|████████▋ | 8747/10000 [02:08<00:20, 62.35it/s]Processing train dataset:  73%|███████▎  | 7274/10000 [02:02<00:44, 61.94it/s]Processing train dataset:  83%|████████▎ | 8309/10000 [02:04<00:22, 76.50it/s]Processing train dataset:  86%|████████▌ | 8605/10000 [02:05<00:18, 75.48it/s]Processing train dataset:  95%|█████████▍| 9466/10000 [02:05<00:06, 87.77it/s]Processing train dataset:  88%|████████▊ | 8754/10000 [02:08<00:19, 63.25it/s]Processing train dataset:  83%|████████▎ | 8317/10000 [02:05<00:22, 76.07it/s]Processing train dataset:  73%|███████▎  | 7281/10000 [02:02<00:44, 60.65it/s]Processing train dataset:  95%|█████████▍| 9475/10000 [02:05<00:06, 86.73it/s]Processing train dataset:  86%|████████▌ | 8615/10000 [02:05<00:18, 76.39it/s]Processing train dataset:  88%|████████▊ | 8761/10000 [02:08<00:19, 63.75it/s]Processing train dataset:  73%|███████▎  | 7288/10000 [02:03<00:46, 58.32it/s]Processing train dataset:  86%|████████▌ | 8623/10000 [02:05<00:17, 77.18it/s]Processing train dataset:  95%|█████████▍| 9484/10000 [02:05<00:06, 83.41it/s]Processing train dataset:  83%|████████▎ | 8325/10000 [02:05<00:25, 65.75it/s]Processing train dataset:  88%|████████▊ | 8768/10000 [02:08<00:19, 64.10it/s]Processing train dataset:  73%|███████▎  | 7297/10000 [02:03<00:41, 65.71it/s]Processing train dataset:  86%|████████▋ | 8632/10000 [02:05<00:17, 78.47it/s]Processing train dataset:  95%|█████████▍| 9493/10000 [02:05<00:06, 83.99it/s]Processing train dataset:  83%|████████▎ | 8333/10000 [02:05<00:24, 66.95it/s]Processing train dataset:  88%|████████▊ | 8777/10000 [02:09<00:17, 68.82it/s]Processing train dataset:  86%|████████▋ | 8641/10000 [02:05<00:17, 79.08it/s]Processing train dataset:  73%|███████▎  | 7304/10000 [02:03<00:43, 62.60it/s]Processing train dataset:  95%|█████████▌| 9502/10000 [02:05<00:06, 77.98it/s]Processing train dataset:  83%|████████▎ | 8340/10000 [02:05<00:26, 63.49it/s]Processing train dataset:  88%|████████▊ | 8784/10000 [02:09<00:19, 62.93it/s]Processing train dataset:  86%|████████▋ | 8649/10000 [02:05<00:17, 78.21it/s]Processing train dataset:  95%|█████████▌| 9511/10000 [02:05<00:06, 79.74it/s]Processing train dataset:  73%|███████▎  | 7311/10000 [02:03<00:46, 57.64it/s]Processing train dataset:  83%|████████▎ | 8347/10000 [02:05<00:26, 61.85it/s]Processing train dataset:  88%|████████▊ | 8791/10000 [02:09<00:19, 60.51it/s]Processing train dataset:  87%|████████▋ | 8658/10000 [02:05<00:16, 79.93it/s]Processing train dataset:  95%|█████████▌| 9520/10000 [02:05<00:05, 81.44it/s]Processing train dataset:  73%|███████▎  | 7317/10000 [02:03<00:46, 57.13it/s]Processing train dataset:  84%|████████▎ | 8355/10000 [02:05<00:25, 64.98it/s]Processing train dataset:  88%|████████▊ | 8798/10000 [02:09<00:20, 59.10it/s]Processing train dataset:  87%|████████▋ | 8666/10000 [02:06<00:18, 73.14it/s]Processing train dataset:  95%|█████████▌| 9529/10000 [02:06<00:05, 79.45it/s]Processing train dataset:  73%|███████▎  | 7324/10000 [02:03<00:45, 59.27it/s]Processing train dataset:  84%|████████▎ | 8363/10000 [02:05<00:24, 67.93it/s]Processing train dataset:  88%|████████▊ | 8805/10000 [02:09<00:20, 59.71it/s]Processing train dataset:  87%|████████▋ | 8674/10000 [02:06<00:17, 73.94it/s]Processing train dataset:  95%|█████████▌| 9538/10000 [02:06<00:05, 78.56it/s]Processing train dataset:  84%|████████▎ | 8370/10000 [02:05<00:24, 67.35it/s]Processing train dataset:  73%|███████▎  | 7331/10000 [02:03<00:45, 59.18it/s]Processing train dataset:  88%|████████▊ | 8812/10000 [02:09<00:19, 60.38it/s]Processing train dataset:  87%|████████▋ | 8682/10000 [02:06<00:17, 74.40it/s]Processing train dataset:  95%|█████████▌| 9547/10000 [02:06<00:05, 80.12it/s]Processing train dataset:  84%|████████▍ | 8378/10000 [02:05<00:23, 68.73it/s]Processing train dataset:  73%|███████▎  | 7338/10000 [02:03<00:45, 58.76it/s]Processing train dataset:  88%|████████▊ | 8819/10000 [02:09<00:20, 58.21it/s]Processing train dataset:  87%|████████▋ | 8690/10000 [02:06<00:17, 74.21it/s]Processing train dataset:  96%|█████████▌| 9556/10000 [02:06<00:05, 81.41it/s]Processing train dataset:  84%|████████▍ | 8386/10000 [02:06<00:22, 70.35it/s]Processing train dataset:  73%|███████▎  | 7344/10000 [02:03<00:46, 56.51it/s]Processing train dataset:  87%|████████▋ | 8698/10000 [02:06<00:17, 74.54it/s]Processing train dataset:  88%|████████▊ | 8825/10000 [02:09<00:20, 56.42it/s]Processing train dataset:  96%|█████████▌| 9565/10000 [02:06<00:05, 77.38it/s]Processing train dataset:  84%|████████▍ | 8394/10000 [02:06<00:23, 67.69it/s]Processing train dataset:  74%|███████▎  | 7351/10000 [02:04<00:46, 56.78it/s]Processing train dataset:  87%|████████▋ | 8706/10000 [02:06<00:17, 73.19it/s]Processing train dataset:  88%|████████▊ | 8832/10000 [02:10<00:19, 58.44it/s]Processing train dataset:  96%|█████████▌| 9576/10000 [02:06<00:05, 83.53it/s]Processing train dataset:  84%|████████▍ | 8401/10000 [02:06<00:24, 66.15it/s]Processing train dataset:  74%|███████▎  | 7358/10000 [02:04<00:45, 58.20it/s]Processing train dataset:  87%|████████▋ | 8715/10000 [02:06<00:16, 76.04it/s]Processing train dataset:  88%|████████▊ | 8838/10000 [02:10<00:20, 56.31it/s]Processing train dataset:  96%|█████████▌| 9585/10000 [02:06<00:04, 83.29it/s]Processing train dataset:  74%|███████▎  | 7364/10000 [02:04<00:45, 57.45it/s]Processing train dataset:  84%|████████▍ | 8408/10000 [02:06<00:25, 62.45it/s]Processing train dataset:  87%|████████▋ | 8724/10000 [02:06<00:16, 77.85it/s]Processing train dataset:  88%|████████▊ | 8846/10000 [02:10<00:19, 58.36it/s]Processing train dataset:  96%|█████████▌| 9594/10000 [02:06<00:05, 80.57it/s]Processing train dataset:  74%|███████▎  | 7371/10000 [02:04<00:43, 60.07it/s]Processing train dataset:  84%|████████▍ | 8416/10000 [02:06<00:23, 66.44it/s]Processing train dataset:  87%|████████▋ | 8732/10000 [02:06<00:16, 75.61it/s]Processing train dataset:  89%|████████▊ | 8857/10000 [02:10<00:16, 69.12it/s]Processing train dataset:  96%|█████████▌| 9603/10000 [02:06<00:04, 83.11it/s]Processing train dataset:  84%|████████▍ | 8423/10000 [02:06<00:24, 63.85it/s]Processing train dataset:  74%|███████▍  | 7378/10000 [02:04<00:45, 57.62it/s]Processing train dataset:  87%|████████▋ | 8742/10000 [02:07<00:15, 80.52it/s]Processing train dataset:  89%|████████▊ | 8864/10000 [02:10<00:17, 65.46it/s]Processing train dataset:  96%|█████████▌| 9612/10000 [02:07<00:04, 80.02it/s]Processing train dataset:  84%|████████▍ | 8430/10000 [02:06<00:24, 65.16it/s]Processing train dataset:  74%|███████▍  | 7385/10000 [02:04<00:45, 57.35it/s]Processing train dataset:  88%|████████▊ | 8751/10000 [02:07<00:16, 75.86it/s]Processing train dataset:  84%|████████▍ | 8439/10000 [02:06<00:22, 69.81it/s]Processing train dataset:  89%|████████▊ | 8871/10000 [02:10<00:18, 60.33it/s]Processing train dataset:  96%|█████████▌| 9621/10000 [02:07<00:05, 74.01it/s]Processing train dataset:  74%|███████▍  | 7393/10000 [02:04<00:42, 61.54it/s]Processing train dataset:  88%|████████▊ | 8759/10000 [02:07<00:16, 73.18it/s]Processing train dataset:  84%|████████▍ | 8447/10000 [02:07<00:21, 71.29it/s]Processing train dataset:  96%|█████████▋| 9629/10000 [02:07<00:04, 74.77it/s]Processing train dataset:  74%|███████▍  | 7400/10000 [02:04<00:43, 60.46it/s]Processing train dataset:  88%|████████▊ | 8767/10000 [02:07<00:16, 74.46it/s]Processing train dataset:  85%|████████▍ | 8457/10000 [02:07<00:20, 76.71it/s]Processing train dataset:  96%|█████████▋| 9637/10000 [02:07<00:04, 75.65it/s]Processing train dataset:  89%|████████▉ | 8878/10000 [02:10<00:23, 47.28it/s]Processing train dataset:  74%|███████▍  | 7407/10000 [02:04<00:41, 61.97it/s]Processing train dataset:  88%|████████▊ | 8775/10000 [02:07<00:16, 75.74it/s]Processing train dataset:  85%|████████▍ | 8466/10000 [02:07<00:19, 78.10it/s]Processing train dataset:  96%|█████████▋| 9646/10000 [02:07<00:04, 78.92it/s]Processing train dataset:  89%|████████▉ | 8885/10000 [02:11<00:22, 49.83it/s]Processing train dataset:  88%|████████▊ | 8783/10000 [02:07<00:16, 75.68it/s]Processing train dataset:  74%|███████▍  | 7414/10000 [02:05<00:44, 57.70it/s]Processing train dataset:  85%|████████▍ | 8474/10000 [02:07<00:19, 76.87it/s]Processing train dataset:  97%|█████████▋| 9657/10000 [02:07<00:04, 85.39it/s]Processing train dataset:  89%|████████▉ | 8892/10000 [02:11<00:21, 52.25it/s]Processing train dataset:  88%|████████▊ | 8792/10000 [02:07<00:15, 77.59it/s]Processing train dataset:  74%|███████▍  | 7422/10000 [02:05<00:43, 59.38it/s]Processing train dataset:  85%|████████▍ | 8482/10000 [02:07<00:19, 76.61it/s]Processing train dataset:  97%|█████████▋| 9666/10000 [02:07<00:03, 85.53it/s]Processing train dataset:  89%|████████▉ | 8900/10000 [02:11<00:19, 55.29it/s]Processing train dataset:  88%|████████▊ | 8802/10000 [02:07<00:14, 82.08it/s]Processing train dataset:  74%|███████▍  | 7429/10000 [02:05<00:41, 62.03it/s]Processing train dataset:  97%|█████████▋| 9675/10000 [02:07<00:03, 83.82it/s]Processing train dataset:  85%|████████▍ | 8490/10000 [02:07<00:20, 73.65it/s]Processing train dataset:  89%|████████▉ | 8907/10000 [02:11<00:18, 58.04it/s]Processing train dataset:  88%|████████▊ | 8811/10000 [02:07<00:15, 79.02it/s]Processing train dataset:  74%|███████▍  | 7436/10000 [02:05<00:42, 59.95it/s]Processing train dataset:  97%|█████████▋| 9684/10000 [02:07<00:03, 82.00it/s]Processing train dataset:  85%|████████▍ | 8498/10000 [02:07<00:21, 70.25it/s]Processing train dataset:  89%|████████▉ | 8914/10000 [02:11<00:19, 56.92it/s]Processing train dataset:  88%|████████▊ | 8820/10000 [02:08<00:14, 79.40it/s]Processing train dataset:  74%|███████▍  | 7443/10000 [02:05<00:41, 61.14it/s]Processing train dataset:  97%|█████████▋| 9693/10000 [02:08<00:03, 80.59it/s]Processing train dataset:  85%|████████▌ | 8506/10000 [02:07<00:21, 68.82it/s]Processing train dataset:  88%|████████▊ | 8828/10000 [02:08<00:15, 75.92it/s]Processing train dataset:  89%|████████▉ | 8922/10000 [02:11<00:18, 58.35it/s]Processing train dataset:  74%|███████▍  | 7450/10000 [02:05<00:42, 59.35it/s]Processing train dataset:  97%|█████████▋| 9702/10000 [02:08<00:03, 79.46it/s]Processing train dataset:  85%|████████▌ | 8513/10000 [02:07<00:22, 65.71it/s]Processing train dataset:  89%|████████▉ | 8929/10000 [02:11<00:17, 59.59it/s]Processing train dataset:  88%|████████▊ | 8836/10000 [02:08<00:16, 68.99it/s]Processing train dataset:  75%|███████▍  | 7458/10000 [02:05<00:41, 61.81it/s]Processing train dataset:  97%|█████████▋| 9710/10000 [02:08<00:03, 78.64it/s]Processing train dataset:  85%|████████▌ | 8521/10000 [02:08<00:21, 67.37it/s]Processing train dataset:  89%|████████▉ | 8936/10000 [02:11<00:17, 59.82it/s]Processing train dataset:  88%|████████▊ | 8845/10000 [02:08<00:16, 71.98it/s]Processing train dataset:  75%|███████▍  | 7466/10000 [02:05<00:38, 65.10it/s]Processing train dataset:  97%|█████████▋| 9719/10000 [02:08<00:03, 79.90it/s]Processing train dataset:  85%|████████▌ | 8529/10000 [02:08<00:21, 69.65it/s]Processing train dataset:  89%|████████▉ | 8944/10000 [02:11<00:16, 63.40it/s]Processing train dataset:  89%|████████▊ | 8856/10000 [02:08<00:14, 79.12it/s]Processing train dataset:  75%|███████▍  | 7473/10000 [02:06<00:39, 63.31it/s]Processing train dataset:  97%|█████████▋| 9727/10000 [02:08<00:03, 75.88it/s]Processing train dataset:  85%|████████▌ | 8536/10000 [02:08<00:21, 67.01it/s]Processing train dataset:  90%|████████▉ | 8951/10000 [02:12<00:16, 63.51it/s]Processing train dataset:  89%|████████▊ | 8865/10000 [02:08<00:14, 78.98it/s]Processing train dataset:  75%|███████▍  | 7480/10000 [02:06<00:39, 63.46it/s]Processing train dataset:  97%|█████████▋| 9737/10000 [02:08<00:03, 79.34it/s]Processing train dataset:  85%|████████▌ | 8544/10000 [02:08<00:20, 69.36it/s]Processing train dataset:  90%|████████▉ | 8962/10000 [02:12<00:13, 74.46it/s]Processing train dataset:  89%|████████▊ | 8873/10000 [02:08<00:14, 77.75it/s]Processing train dataset:  97%|█████████▋| 9745/10000 [02:08<00:03, 77.68it/s]Processing train dataset:  75%|███████▍  | 7487/10000 [02:06<00:41, 61.17it/s]Processing train dataset:  86%|████████▌ | 8553/10000 [02:08<00:19, 73.11it/s]Processing train dataset:  90%|████████▉ | 8970/10000 [02:12<00:14, 69.85it/s]Processing train dataset:  89%|████████▉ | 8881/10000 [02:08<00:14, 75.09it/s]Processing train dataset:  98%|█████████▊| 9753/10000 [02:08<00:03, 77.05it/s]Processing train dataset:  86%|████████▌ | 8563/10000 [02:08<00:17, 80.39it/s]Processing train dataset:  75%|███████▍  | 7494/10000 [02:06<00:42, 59.10it/s]Processing train dataset:  98%|█████████▊| 9761/10000 [02:08<00:03, 77.62it/s]Processing train dataset:  89%|████████▉ | 8889/10000 [02:08<00:15, 73.38it/s]Processing train dataset:  90%|████████▉ | 8978/10000 [02:12<00:15, 65.28it/s]Processing train dataset:  75%|███████▌  | 7500/10000 [02:06<00:42, 58.67it/s]Processing train dataset:  86%|████████▌ | 8572/10000 [02:08<00:18, 76.07it/s]Processing train dataset:  98%|█████████▊| 9770/10000 [02:09<00:02, 80.98it/s]Processing train dataset:  89%|████████▉ | 8897/10000 [02:09<00:15, 72.98it/s]Processing train dataset:  75%|███████▌  | 7506/10000 [02:06<00:42, 58.18it/s]Processing train dataset:  90%|████████▉ | 8985/10000 [02:12<00:17, 59.61it/s]Processing train dataset:  86%|████████▌ | 8580/10000 [02:08<00:19, 71.09it/s]Processing train dataset:  89%|████████▉ | 8905/10000 [02:09<00:14, 74.73it/s]Processing train dataset:  98%|█████████▊| 9779/10000 [02:09<00:02, 78.37it/s]Processing train dataset:  75%|███████▌  | 7513/10000 [02:06<00:41, 60.66it/s]Processing train dataset:  86%|████████▌ | 8588/10000 [02:08<00:19, 72.79it/s]Processing train dataset:  90%|████████▉ | 8993/10000 [02:12<00:16, 61.88it/s]Processing train dataset:  89%|████████▉ | 8913/10000 [02:09<00:15, 72.29it/s]Processing train dataset:  98%|█████████▊| 9788/10000 [02:09<00:02, 79.07it/s]Processing train dataset:  75%|███████▌  | 7520/10000 [02:06<00:43, 57.59it/s]Processing train dataset:  86%|████████▌ | 8597/10000 [02:09<00:18, 75.17it/s]Processing train dataset:  90%|█████████ | 9000/10000 [02:12<00:16, 59.84it/s]Processing train dataset:  98%|█████████▊| 9797/10000 [02:09<00:02, 80.67it/s]Processing train dataset:  89%|████████▉ | 8922/10000 [02:09<00:14, 75.46it/s]Processing train dataset:  75%|███████▌  | 7527/10000 [02:06<00:40, 60.85it/s]Processing train dataset:  86%|████████▌ | 8606/10000 [02:09<00:17, 78.03it/s]Processing train dataset:  90%|█████████ | 9007/10000 [02:12<00:17, 56.99it/s]Processing train dataset:  89%|████████▉ | 8930/10000 [02:09<00:14, 74.84it/s]Processing train dataset:  98%|█████████▊| 9806/10000 [02:09<00:02, 79.97it/s]Processing train dataset:  75%|███████▌  | 7534/10000 [02:07<00:41, 59.85it/s]Processing train dataset:  86%|████████▌ | 8616/10000 [02:09<00:16, 81.64it/s]Processing train dataset:  90%|█████████ | 9013/10000 [02:13<00:17, 55.71it/s]Processing train dataset:  89%|████████▉ | 8940/10000 [02:09<00:13, 78.83it/s]Processing train dataset:  98%|█████████▊| 9815/10000 [02:09<00:02, 79.26it/s]Processing train dataset:  86%|████████▋ | 8625/10000 [02:09<00:16, 81.72it/s]Processing train dataset:  75%|███████▌  | 7541/10000 [02:07<00:42, 58.52it/s]Processing train dataset:  90%|█████████ | 9020/10000 [02:13<00:16, 58.93it/s]Processing train dataset:  98%|█████████▊| 9823/10000 [02:09<00:02, 78.90it/s]Processing train dataset:  89%|████████▉ | 8948/10000 [02:09<00:13, 75.74it/s]Processing train dataset:  86%|████████▋ | 8634/10000 [02:09<00:16, 82.54it/s]Processing train dataset:  75%|███████▌  | 7548/10000 [02:07<00:40, 59.93it/s]Processing train dataset:  90%|█████████ | 9028/10000 [02:13<00:15, 63.07it/s]Processing train dataset:  98%|█████████▊| 9832/10000 [02:09<00:02, 81.14it/s]Processing train dataset:  90%|████████▉ | 8957/10000 [02:09<00:13, 78.90it/s]Processing train dataset:  86%|████████▋ | 8643/10000 [02:09<00:16, 83.18it/s]Processing train dataset:  76%|███████▌  | 7555/10000 [02:07<00:42, 57.96it/s]Processing train dataset:  90%|█████████ | 9035/10000 [02:13<00:14, 64.49it/s]Processing train dataset:  98%|█████████▊| 9841/10000 [02:09<00:01, 82.67it/s]Processing train dataset:  90%|████████▉ | 8967/10000 [02:09<00:12, 83.73it/s]Processing train dataset:  87%|████████▋ | 8652/10000 [02:09<00:16, 81.21it/s]Processing train dataset:  76%|███████▌  | 7562/10000 [02:07<00:39, 61.04it/s]Processing train dataset:  90%|█████████ | 9042/10000 [02:13<00:14, 64.46it/s]Processing train dataset:  98%|█████████▊| 9850/10000 [02:10<00:01, 83.85it/s]Processing train dataset:  90%|████████▉ | 8976/10000 [02:10<00:12, 79.80it/s]Processing train dataset:  87%|████████▋ | 8661/10000 [02:09<00:16, 81.25it/s]Processing train dataset:  91%|█████████ | 9051/10000 [02:13<00:13, 71.53it/s]Processing train dataset:  99%|█████████▊| 9859/10000 [02:10<00:01, 84.69it/s]Processing train dataset:  90%|████████▉ | 8985/10000 [02:10<00:12, 79.06it/s]Processing train dataset:  87%|████████▋ | 8670/10000 [02:09<00:16, 79.11it/s]Processing train dataset:  91%|█████████ | 9059/10000 [02:13<00:12, 73.04it/s]Processing train dataset:  99%|█████████▊| 9868/10000 [02:10<00:01, 84.08it/s]Processing train dataset:  76%|███████▌  | 7569/10000 [02:07<00:56, 43.31it/s]Processing train dataset:  90%|████████▉ | 8994/10000 [02:10<00:12, 79.00it/s]Processing train dataset:  87%|████████▋ | 8679/10000 [02:10<00:16, 80.50it/s]Processing train dataset:  91%|█████████ | 9069/10000 [02:13<00:11, 79.82it/s]Processing train dataset:  99%|█████████▉| 9877/10000 [02:10<00:01, 79.05it/s]Processing train dataset:  76%|███████▌  | 7575/10000 [02:07<00:52, 46.43it/s]Processing train dataset:  90%|█████████ | 9002/10000 [02:10<00:12, 77.15it/s]Processing train dataset:  87%|████████▋ | 8688/10000 [02:10<00:16, 81.65it/s]Processing train dataset:  99%|█████████▉| 9886/10000 [02:10<00:01, 79.40it/s]Processing train dataset:  91%|█████████ | 9078/10000 [02:14<00:12, 71.19it/s]Processing train dataset:  76%|███████▌  | 7582/10000 [02:08<00:49, 49.23it/s]Processing train dataset:  90%|█████████ | 9011/10000 [02:10<00:12, 79.59it/s]Processing train dataset:  87%|████████▋ | 8697/10000 [02:10<00:16, 78.64it/s]Processing train dataset:  99%|█████████▉| 9895/10000 [02:10<00:01, 80.00it/s]Processing train dataset:  76%|███████▌  | 7588/10000 [02:08<00:46, 51.67it/s]Processing train dataset:  90%|█████████ | 9021/10000 [02:10<00:11, 82.54it/s]Processing train dataset:  91%|█████████ | 9086/10000 [02:14<00:13, 65.99it/s]Processing train dataset:  87%|████████▋ | 8705/10000 [02:10<00:17, 74.05it/s]Processing train dataset:  99%|█████████▉| 9904/10000 [02:10<00:01, 80.24it/s]Processing train dataset:  76%|███████▌  | 7595/10000 [02:08<00:45, 53.21it/s]Processing train dataset:  90%|█████████ | 9030/10000 [02:10<00:11, 81.36it/s]Processing train dataset:  91%|█████████ | 9093/10000 [02:14<00:13, 65.32it/s]Processing train dataset:  87%|████████▋ | 8714/10000 [02:10<00:16, 77.15it/s]Processing train dataset:  99%|█████████▉| 9913/10000 [02:10<00:01, 81.29it/s]Processing train dataset:  91%|█████████ | 9100/10000 [02:14<00:13, 66.30it/s]Processing train dataset:  76%|███████▌  | 7601/10000 [02:08<00:46, 52.08it/s]Processing train dataset:  90%|█████████ | 9039/10000 [02:10<00:12, 79.29it/s]Processing train dataset:  87%|████████▋ | 8723/10000 [02:10<00:16, 79.73it/s]Processing train dataset:  99%|█████████▉| 9923/10000 [02:10<00:00, 86.28it/s]Processing train dataset:  90%|█████████ | 9047/10000 [02:10<00:12, 75.59it/s]Processing train dataset:  76%|███████▌  | 7607/10000 [02:08<00:46, 51.19it/s]Processing train dataset:  91%|█████████ | 9107/10000 [02:14<00:14, 63.03it/s]Processing train dataset:  87%|████████▋ | 8732/10000 [02:10<00:16, 77.97it/s]Processing train dataset:  99%|█████████▉| 9933/10000 [02:11<00:00, 88.08it/s]Processing train dataset:  76%|███████▌  | 7615/10000 [02:08<00:40, 58.60it/s]Processing train dataset:  91%|█████████ | 9055/10000 [02:11<00:12, 73.29it/s]Processing train dataset:  91%|█████████ | 9114/10000 [02:14<00:15, 58.30it/s]Processing train dataset:  87%|████████▋ | 8743/10000 [02:10<00:14, 83.92it/s]Processing train dataset:  99%|█████████▉| 9942/10000 [02:11<00:00, 84.75it/s]Processing train dataset:  91%|█████████ | 9064/10000 [02:11<00:12, 75.77it/s]Processing train dataset:  76%|███████▌  | 7622/10000 [02:08<00:42, 56.35it/s]Processing train dataset:  91%|█████████ | 9120/10000 [02:14<00:15, 58.65it/s]Processing train dataset:  88%|████████▊ | 8752/10000 [02:10<00:15, 80.78it/s]Processing train dataset: 100%|█████████▉| 9951/10000 [02:11<00:00, 80.80it/s]Processing train dataset:  76%|███████▋  | 7628/10000 [02:08<00:42, 56.42it/s]Processing train dataset:  91%|█████████ | 9072/10000 [02:11<00:13, 68.17it/s]Processing train dataset:  91%|█████████▏| 9126/10000 [02:14<00:15, 54.87it/s]Processing train dataset:  88%|████████▊ | 8761/10000 [02:11<00:15, 79.26it/s]Processing train dataset: 100%|█████████▉| 9960/10000 [02:11<00:00, 81.08it/s]Processing train dataset:  76%|███████▋  | 7635/10000 [02:08<00:39, 59.91it/s]Processing train dataset:  91%|█████████ | 9082/10000 [02:11<00:12, 75.04it/s]Processing train dataset:  91%|█████████▏| 9134/10000 [02:14<00:14, 60.30it/s]Processing train dataset:  88%|████████▊ | 8770/10000 [02:11<00:15, 80.44it/s]Processing train dataset: 100%|█████████▉| 9969/10000 [02:11<00:00, 81.48it/s]Processing train dataset:  76%|███████▋  | 7642/10000 [02:09<00:39, 59.05it/s]Processing train dataset:  91%|█████████ | 9092/10000 [02:11<00:11, 79.79it/s]Processing train dataset:  91%|█████████▏| 9143/10000 [02:15<00:12, 66.79it/s]Processing train dataset:  88%|████████▊ | 8779/10000 [02:11<00:15, 80.24it/s]Processing train dataset: 100%|█████████▉| 9978/10000 [02:11<00:00, 81.78it/s]Processing train dataset:  77%|███████▋  | 7651/10000 [02:09<00:36, 65.12it/s]Processing train dataset:  91%|█████████ | 9101/10000 [02:11<00:10, 82.49it/s]Processing train dataset:  92%|█████████▏| 9153/10000 [02:15<00:11, 73.96it/s]Processing train dataset: 100%|█████████▉| 9987/10000 [02:11<00:00, 81.46it/s]Processing train dataset:  88%|████████▊ | 8788/10000 [02:11<00:15, 78.40it/s]Processing train dataset:  77%|███████▋  | 7659/10000 [02:09<00:35, 65.95it/s]Processing train dataset:  91%|█████████ | 9110/10000 [02:11<00:10, 82.96it/s]Processing train dataset:  92%|█████████▏| 9162/10000 [02:15<00:10, 78.04it/s]Processing train dataset: 100%|█████████▉| 9996/10000 [02:11<00:00, 83.03it/s]Processing train dataset:  88%|████████▊ | 8796/10000 [02:11<00:15, 78.02it/s]Processing train dataset: 100%|██████████| 10000/10000 [02:11<00:00, 75.84it/s]Processing train dataset:  92%|█████████▏| 9172/10000 [02:15<00:10, 82.21it/s]Processing train dataset:  91%|█████████ | 9119/10000 [02:11<00:11, 76.52it/s]Processing train dataset:  77%|███████▋  | 7666/10000 [02:09<00:38, 60.41it/s]Processing train dataset:  88%|████████▊ | 8804/10000 [02:11<00:16, 74.30it/s]Processing train dataset:  92%|█████████▏| 9181/10000 [02:15<00:09, 84.25it/s]Processing train dataset:  88%|████████▊ | 8812/10000 [02:11<00:16, 73.60it/s]Processing train dataset:  91%|█████████▏| 9127/10000 [02:12<00:12, 69.24it/s]Processing train dataset:  77%|███████▋  | 7673/10000 [02:09<00:43, 53.04it/s]Processing train dataset:  92%|█████████▏| 9192/10000 [02:15<00:09, 89.05it/s]Processing train dataset:  88%|████████▊ | 8822/10000 [02:11<00:15, 77.95it/s]Processing train dataset:  91%|█████████▏| 9137/10000 [02:12<00:11, 75.13it/s]Processing train dataset:  77%|███████▋  | 7679/10000 [02:09<00:46, 50.01it/s]Processing train dataset:  92%|█████████▏| 9201/10000 [02:15<00:09, 82.11it/s]Processing train dataset:  91%|█████████▏| 9147/10000 [02:12<00:10, 79.91it/s]Processing train dataset:  88%|████████▊ | 8830/10000 [02:12<00:16, 72.22it/s]Processing train dataset:  92%|█████████▏| 9212/10000 [02:15<00:08, 89.50it/s]Processing train dataset:  77%|███████▋  | 7689/10000 [02:09<00:38, 60.47it/s]Processing train dataset:  92%|█████████▏| 9156/10000 [02:12<00:10, 78.91it/s]Processing train dataset:  88%|████████▊ | 8840/10000 [02:12<00:14, 77.89it/s]Processing train dataset:  92%|█████████▏| 9225/10000 [02:15<00:07, 99.41it/s]Processing train dataset:  77%|███████▋  | 7696/10000 [02:10<00:39, 58.71it/s]Processing train dataset:  89%|████████▊ | 8851/10000 [02:12<00:13, 86.24it/s]Processing train dataset:  92%|█████████▏| 9165/10000 [02:12<00:10, 78.48it/s]Processing train dataset:  92%|█████████▏| 9238/10000 [02:16<00:07, 105.01it/s]Processing train dataset:  77%|███████▋  | 7703/10000 [02:10<00:37, 60.95it/s]Processing train dataset:  92%|█████████▏| 9173/10000 [02:12<00:10, 78.63it/s]Processing train dataset:  89%|████████▊ | 8862/10000 [02:12<00:12, 90.21it/s]Processing train dataset:  92%|█████████▏| 9249/10000 [02:16<00:07, 102.70it/s]Processing train dataset:  77%|███████▋  | 7711/10000 [02:10<00:34, 65.59it/s]Processing train dataset:  92%|█████████▏| 9182/10000 [02:12<00:10, 80.51it/s]Processing train dataset:  89%|████████▊ | 8872/10000 [02:12<00:13, 84.43it/s]Processing train dataset:  77%|███████▋  | 7718/10000 [02:10<00:35, 64.42it/s]Processing train dataset:  93%|█████████▎| 9260/10000 [02:16<00:07, 92.99it/s] Processing train dataset:  92%|█████████▏| 9193/10000 [02:12<00:09, 87.45it/s]Processing train dataset:  89%|████████▉ | 8881/10000 [02:12<00:13, 80.23it/s]Processing train dataset:  77%|███████▋  | 7727/10000 [02:10<00:32, 69.10it/s]Processing train dataset:  93%|█████████▎| 9270/10000 [02:16<00:07, 92.24it/s]Processing train dataset:  92%|█████████▏| 9202/10000 [02:12<00:09, 87.71it/s]Processing train dataset:  89%|████████▉ | 8890/10000 [02:12<00:13, 82.73it/s]Processing train dataset:  77%|███████▋  | 7735/10000 [02:10<00:33, 67.53it/s]Processing train dataset:  93%|█████████▎| 9280/10000 [02:16<00:07, 91.66it/s]Processing train dataset:  92%|█████████▏| 9211/10000 [02:13<00:08, 87.72it/s]Processing train dataset:  89%|████████▉ | 8903/10000 [02:12<00:11, 94.74it/s]Processing train dataset:  77%|███████▋  | 7742/10000 [02:10<00:33, 68.12it/s]Processing train dataset:  93%|█████████▎| 9292/10000 [02:16<00:07, 97.75it/s]Processing train dataset:  92%|█████████▏| 9223/10000 [02:13<00:08, 95.91it/s]Processing train dataset:  89%|████████▉ | 8916/10000 [02:12<00:10, 100.04it/s]Processing train dataset:  77%|███████▋  | 7749/10000 [02:10<00:33, 66.34it/s]Processing train dataset:  93%|█████████▎| 9302/10000 [02:16<00:07, 97.13it/s]Processing train dataset:  92%|█████████▏| 9234/10000 [02:13<00:07, 98.79it/s]Processing train dataset:  89%|████████▉ | 8928/10000 [02:13<00:10, 104.55it/s]Processing train dataset:  93%|█████████▎| 9312/10000 [02:16<00:07, 97.81it/s]Processing train dataset:  78%|███████▊  | 7756/10000 [02:10<00:34, 65.60it/s]Processing train dataset:  92%|█████████▏| 9247/10000 [02:13<00:07, 103.78it/s]Processing train dataset:  89%|████████▉ | 8940/10000 [02:13<00:09, 108.74it/s]Processing train dataset:  78%|███████▊  | 7764/10000 [02:10<00:32, 69.50it/s]Processing train dataset:  93%|█████████▎| 9322/10000 [02:16<00:07, 95.44it/s]Processing train dataset:  93%|█████████▎| 9258/10000 [02:13<00:07, 102.42it/s]Processing train dataset:  90%|████████▉ | 8951/10000 [02:13<00:09, 108.40it/s]Processing train dataset:  93%|█████████▎| 9332/10000 [02:17<00:06, 96.16it/s]Processing train dataset:  78%|███████▊  | 7773/10000 [02:11<00:31, 71.47it/s]Processing train dataset:  93%|█████████▎| 9269/10000 [02:13<00:07, 93.63it/s] Processing train dataset:  90%|████████▉ | 8963/10000 [02:13<00:09, 110.76it/s]Processing train dataset:  93%|█████████▎| 9342/10000 [02:17<00:07, 93.65it/s]Processing train dataset:  78%|███████▊  | 7781/10000 [02:11<00:31, 70.90it/s]Processing train dataset:  93%|█████████▎| 9279/10000 [02:13<00:07, 92.83it/s]Processing train dataset:  90%|████████▉ | 8975/10000 [02:13<00:09, 107.03it/s]Processing train dataset:  94%|█████████▎| 9352/10000 [02:17<00:06, 92.76it/s]Processing train dataset:  78%|███████▊  | 7789/10000 [02:11<00:31, 69.54it/s]Processing train dataset:  93%|█████████▎| 9294/10000 [02:13<00:06, 105.43it/s]Processing train dataset:  90%|████████▉ | 8986/10000 [02:13<00:09, 105.11it/s]Processing train dataset:  94%|█████████▎| 9362/10000 [02:17<00:06, 93.24it/s]Processing train dataset:  78%|███████▊  | 7798/10000 [02:11<00:30, 71.50it/s]Processing train dataset:  93%|█████████▎| 9307/10000 [02:13<00:06, 107.43it/s]Processing train dataset:  90%|████████▉ | 8997/10000 [02:13<00:09, 101.01it/s]Processing train dataset:  94%|█████████▎| 9372/10000 [02:17<00:06, 92.83it/s]Processing train dataset:  78%|███████▊  | 7807/10000 [02:11<00:29, 74.96it/s]Processing train dataset:  93%|█████████▎| 9318/10000 [02:14<00:06, 101.72it/s]Processing train dataset:  90%|█████████ | 9008/10000 [02:13<00:10, 95.77it/s] Processing train dataset:  94%|█████████▍| 9382/10000 [02:17<00:06, 91.91it/s]Processing train dataset:  78%|███████▊  | 7815/10000 [02:11<00:30, 71.67it/s]Processing train dataset:  93%|█████████▎| 9329/10000 [02:14<00:06, 96.15it/s] Processing train dataset:  90%|█████████ | 9019/10000 [02:13<00:10, 97.61it/s]Processing train dataset:  94%|█████████▍| 9392/10000 [02:17<00:06, 93.67it/s]Processing train dataset:  78%|███████▊  | 7824/10000 [02:11<00:29, 73.00it/s]Processing train dataset:  94%|█████████▍| 9402/10000 [02:17<00:06, 94.29it/s]Processing train dataset:  93%|█████████▎| 9339/10000 [02:14<00:07, 92.61it/s]Processing train dataset:  90%|█████████ | 9029/10000 [02:14<00:10, 92.35it/s]Processing train dataset:  78%|███████▊  | 7832/10000 [02:11<00:30, 71.53it/s]Processing train dataset:  94%|█████████▍| 9412/10000 [02:17<00:06, 92.93it/s]Processing train dataset:  90%|█████████ | 9039/10000 [02:14<00:10, 93.06it/s]Processing train dataset:  93%|█████████▎| 9349/10000 [02:14<00:07, 91.18it/s]Processing train dataset:  78%|███████▊  | 7840/10000 [02:12<00:34, 61.86it/s]Processing train dataset:  90%|█████████ | 9049/10000 [02:14<00:11, 82.30it/s]Processing train dataset:  94%|█████████▎| 9359/10000 [02:14<00:08, 78.62it/s]Processing train dataset:  94%|█████████▍| 9422/10000 [02:18<00:07, 72.57it/s]Processing train dataset:  91%|█████████ | 9058/10000 [02:14<00:12, 77.23it/s]Processing train dataset:  94%|█████████▎| 9368/10000 [02:14<00:08, 74.05it/s]Processing train dataset:  94%|█████████▍| 9430/10000 [02:18<00:08, 67.29it/s]Processing train dataset:  78%|███████▊  | 7847/10000 [02:12<00:44, 48.68it/s]Processing train dataset:  91%|█████████ | 9069/10000 [02:14<00:10, 84.82it/s]Processing train dataset:  94%|█████████▍| 9376/10000 [02:14<00:08, 75.40it/s]Processing train dataset:  94%|█████████▍| 9439/10000 [02:18<00:07, 71.75it/s]Processing train dataset:  79%|███████▊  | 7854/10000 [02:12<00:41, 51.88it/s]Processing train dataset:  91%|█████████ | 9082/10000 [02:14<00:09, 95.44it/s]Processing train dataset:  94%|█████████▍| 9385/10000 [02:14<00:07, 77.24it/s]Processing train dataset:  94%|█████████▍| 9447/10000 [02:18<00:07, 71.21it/s]Processing train dataset:  79%|███████▊  | 7860/10000 [02:12<00:41, 52.09it/s]Processing train dataset:  91%|█████████ | 9092/10000 [02:14<00:09, 96.47it/s]Processing train dataset:  94%|█████████▍| 9393/10000 [02:15<00:08, 75.07it/s]Processing train dataset:  95%|█████████▍| 9458/10000 [02:18<00:06, 79.54it/s]Processing train dataset:  79%|███████▊  | 7867/10000 [02:12<00:38, 56.05it/s]Processing train dataset:  94%|█████████▍| 9401/10000 [02:15<00:07, 76.14it/s]Processing train dataset:  91%|█████████ | 9102/10000 [02:14<00:10, 87.57it/s]Processing train dataset:  95%|█████████▍| 9467/10000 [02:18<00:07, 73.78it/s]Processing train dataset:  79%|███████▊  | 7873/10000 [02:12<00:40, 52.23it/s]Processing train dataset:  94%|█████████▍| 9409/10000 [02:15<00:07, 75.71it/s]Processing train dataset:  91%|█████████ | 9112/10000 [02:15<00:11, 80.47it/s]Processing train dataset:  95%|█████████▍| 9475/10000 [02:18<00:07, 67.15it/s]Processing train dataset:  94%|█████████▍| 9417/10000 [02:15<00:08, 72.67it/s]Processing train dataset:  79%|███████▉  | 7879/10000 [02:12<00:44, 47.61it/s]Processing train dataset:  91%|█████████ | 9121/10000 [02:15<00:10, 81.08it/s]Processing train dataset:  95%|█████████▍| 9484/10000 [02:18<00:07, 71.91it/s]Processing train dataset:  94%|█████████▍| 9427/10000 [02:15<00:07, 78.63it/s]Processing train dataset:  79%|███████▉  | 7886/10000 [02:13<00:44, 47.33it/s]Processing train dataset:  91%|█████████▏| 9130/10000 [02:15<00:11, 76.84it/s]Processing train dataset:  95%|█████████▍| 9492/10000 [02:19<00:07, 68.20it/s]Processing train dataset:  94%|█████████▍| 9435/10000 [02:15<00:07, 72.54it/s]Processing train dataset:  79%|███████▉  | 7895/10000 [02:13<00:38, 55.22it/s]Processing train dataset:  91%|█████████▏| 9140/10000 [02:15<00:10, 78.81it/s]Processing train dataset:  94%|█████████▍| 9443/10000 [02:15<00:08, 67.62it/s]Processing train dataset:  95%|█████████▌| 9500/10000 [02:19<00:07, 63.41it/s]Processing train dataset:  79%|███████▉  | 7901/10000 [02:13<00:40, 51.58it/s]Processing train dataset:  91%|█████████▏| 9149/10000 [02:15<00:11, 72.36it/s]Processing train dataset:  95%|█████████▍| 9451/10000 [02:15<00:07, 70.48it/s]Processing train dataset:  95%|█████████▌| 9511/10000 [02:19<00:07, 66.06it/s]Processing train dataset:  79%|███████▉  | 7908/10000 [02:13<00:39, 52.67it/s]Processing train dataset:  92%|█████████▏| 9157/10000 [02:15<00:12, 69.66it/s]Processing train dataset:  95%|█████████▍| 9459/10000 [02:15<00:07, 72.39it/s]Processing train dataset:  95%|█████████▌| 9521/10000 [02:19<00:06, 73.79it/s]Processing train dataset:  79%|███████▉  | 7916/10000 [02:13<00:36, 57.13it/s]Processing train dataset:  95%|█████████▍| 9467/10000 [02:16<00:07, 70.20it/s]Processing train dataset:  92%|█████████▏| 9165/10000 [02:15<00:12, 64.60it/s]Processing train dataset:  79%|███████▉  | 7923/10000 [02:13<00:35, 58.21it/s]Processing train dataset:  95%|█████████▌| 9529/10000 [02:19<00:06, 69.15it/s]Processing train dataset:  95%|█████████▍| 9475/10000 [02:16<00:07, 69.97it/s]Processing train dataset:  92%|█████████▏| 9172/10000 [02:15<00:14, 55.96it/s]Processing train dataset:  79%|███████▉  | 7929/10000 [02:13<00:40, 50.87it/s]Processing train dataset:  95%|█████████▍| 9483/10000 [02:16<00:07, 64.66it/s]Processing train dataset:  95%|█████████▌| 9537/10000 [02:19<00:08, 55.03it/s]Processing train dataset:  92%|█████████▏| 9178/10000 [02:16<00:16, 50.89it/s]Processing train dataset:  79%|███████▉  | 7935/10000 [02:13<00:40, 51.10it/s]Processing train dataset:  95%|█████████▍| 9493/10000 [02:16<00:07, 71.32it/s]Processing train dataset:  95%|█████████▌| 9546/10000 [02:19<00:07, 61.50it/s]Processing train dataset:  92%|█████████▏| 9186/10000 [02:16<00:14, 56.66it/s]Processing train dataset:  79%|███████▉  | 7945/10000 [02:14<00:33, 62.02it/s]Processing train dataset:  95%|█████████▌| 9505/10000 [02:16<00:06, 80.38it/s]Processing train dataset:  96%|█████████▌| 9556/10000 [02:20<00:06, 68.64it/s]Processing train dataset:  80%|███████▉  | 7954/10000 [02:14<00:30, 67.28it/s]Processing train dataset:  92%|█████████▏| 9197/10000 [02:16<00:12, 63.53it/s]Processing train dataset:  95%|█████████▌| 9514/10000 [02:16<00:06, 80.05it/s]Processing train dataset:  96%|█████████▌| 9564/10000 [02:20<00:06, 70.21it/s]Processing train dataset:  80%|███████▉  | 7962/10000 [02:14<00:29, 69.77it/s]Processing train dataset:  92%|█████████▏| 9206/10000 [02:16<00:11, 66.32it/s]Processing train dataset:  95%|█████████▌| 9523/10000 [02:16<00:05, 82.56it/s]Processing train dataset:  96%|█████████▌| 9575/10000 [02:20<00:05, 79.47it/s]Processing train dataset:  80%|███████▉  | 7971/10000 [02:14<00:27, 72.58it/s]Processing train dataset:  92%|█████████▏| 9215/10000 [02:16<00:10, 71.52it/s]Processing train dataset:  95%|█████████▌| 9532/10000 [02:16<00:05, 83.41it/s]Processing train dataset:  96%|█████████▌| 9584/10000 [02:20<00:05, 79.56it/s]Processing train dataset:  95%|█████████▌| 9541/10000 [02:17<00:06, 76.10it/s]Processing train dataset:  92%|█████████▏| 9223/10000 [02:16<00:12, 62.70it/s]Processing train dataset:  80%|███████▉  | 7979/10000 [02:14<00:38, 52.99it/s]Processing train dataset:  96%|█████████▌| 9551/10000 [02:17<00:05, 80.30it/s]Processing train dataset:  92%|█████████▏| 9230/10000 [02:16<00:12, 61.34it/s]Processing train dataset:  96%|█████████▌| 9593/10000 [02:20<00:07, 56.04it/s]Processing train dataset:  80%|███████▉  | 7986/10000 [02:14<00:37, 54.13it/s]Processing train dataset:  92%|█████████▏| 9238/10000 [02:17<00:11, 65.39it/s]Processing train dataset:  96%|█████████▌| 9560/10000 [02:17<00:05, 75.90it/s]Processing train dataset:  96%|█████████▌| 9601/10000 [02:20<00:06, 60.49it/s]Processing train dataset:  80%|███████▉  | 7996/10000 [02:14<00:31, 64.22it/s]Processing train dataset:  92%|█████████▏| 9248/10000 [02:17<00:10, 73.44it/s]Processing train dataset:  96%|█████████▌| 9569/10000 [02:17<00:05, 78.02it/s]Processing train dataset:  96%|█████████▌| 9609/10000 [02:20<00:06, 61.09it/s]Processing train dataset:  80%|████████  | 8007/10000 [02:15<00:26, 75.18it/s]Processing train dataset:  93%|█████████▎| 9259/10000 [02:17<00:09, 82.08it/s]Processing train dataset:  96%|█████████▌| 9578/10000 [02:17<00:05, 80.83it/s]Processing train dataset:  96%|█████████▌| 9616/10000 [02:21<00:06, 61.71it/s]Processing train dataset:  80%|████████  | 8016/10000 [02:15<00:25, 78.74it/s]Processing train dataset:  93%|█████████▎| 9269/10000 [02:17<00:08, 85.44it/s]Processing train dataset:  96%|█████████▌| 9587/10000 [02:17<00:05, 72.60it/s]Processing train dataset:  80%|████████  | 8027/10000 [02:15<00:23, 85.74it/s]Processing train dataset:  96%|█████████▌| 9624/10000 [02:21<00:05, 64.39it/s]Processing train dataset:  93%|█████████▎| 9279/10000 [02:17<00:08, 87.20it/s]Processing train dataset:  80%|████████  | 8037/10000 [02:15<00:22, 86.54it/s]Processing train dataset:  96%|█████████▋| 9631/10000 [02:21<00:05, 62.56it/s]Processing train dataset:  93%|█████████▎| 9290/10000 [02:17<00:07, 93.16it/s]Processing train dataset:  96%|█████████▌| 9595/10000 [02:17<00:06, 64.32it/s]Processing train dataset:  96%|█████████▋| 9638/10000 [02:21<00:05, 64.06it/s]Processing train dataset:  80%|████████  | 8048/10000 [02:15<00:21, 89.94it/s]Processing train dataset:  93%|█████████▎| 9301/10000 [02:17<00:07, 95.14it/s]Processing train dataset:  96%|█████████▌| 9604/10000 [02:17<00:05, 69.06it/s]Processing train dataset:  96%|█████████▋| 9645/10000 [02:21<00:05, 61.93it/s]Processing train dataset:  81%|████████  | 8058/10000 [02:15<00:24, 80.21it/s]Processing train dataset:  96%|█████████▌| 9612/10000 [02:18<00:05, 67.75it/s]Processing train dataset:  93%|█████████▎| 9311/10000 [02:17<00:08, 82.02it/s]Processing train dataset:  97%|█████████▋| 9652/10000 [02:21<00:05, 63.79it/s]Processing train dataset:  96%|█████████▌| 9619/10000 [02:18<00:05, 67.45it/s]Processing train dataset:  81%|████████  | 8067/10000 [02:15<00:27, 70.81it/s]Processing train dataset:  97%|█████████▋| 9659/10000 [02:21<00:05, 63.52it/s]Processing train dataset:  93%|█████████▎| 9320/10000 [02:17<00:09, 73.52it/s]Processing train dataset:  96%|█████████▋| 9626/10000 [02:18<00:05, 65.50it/s]Processing train dataset:  81%|████████  | 8077/10000 [02:15<00:25, 76.51it/s]Processing train dataset:  97%|█████████▋| 9666/10000 [02:21<00:05, 65.06it/s]Processing train dataset:  96%|█████████▋| 9633/10000 [02:18<00:05, 66.58it/s]Processing train dataset:  93%|█████████▎| 9330/10000 [02:18<00:09, 74.12it/s]Processing train dataset:  81%|████████  | 8086/10000 [02:15<00:25, 74.46it/s]Processing train dataset:  97%|█████████▋| 9673/10000 [02:21<00:05, 60.24it/s]Processing train dataset:  93%|█████████▎| 9341/10000 [02:18<00:08, 81.59it/s]Processing train dataset:  96%|█████████▋| 9640/10000 [02:18<00:05, 64.61it/s]Processing train dataset:  81%|████████  | 8097/10000 [02:16<00:22, 82.78it/s]Processing train dataset:  94%|█████████▎| 9351/10000 [02:18<00:07, 84.74it/s]Processing train dataset:  97%|█████████▋| 9681/10000 [02:22<00:05, 59.55it/s]Processing train dataset:  96%|█████████▋| 9647/10000 [02:18<00:05, 64.12it/s]Processing train dataset:  81%|████████  | 8106/10000 [02:16<00:24, 77.38it/s]Processing train dataset:  94%|█████████▎| 9360/10000 [02:18<00:07, 86.10it/s]Processing train dataset:  97%|█████████▋| 9657/10000 [02:18<00:04, 73.44it/s]Processing train dataset:  97%|█████████▋| 9689/10000 [02:22<00:04, 63.37it/s]Processing train dataset:  94%|█████████▎| 9369/10000 [02:18<00:07, 82.84it/s]Processing train dataset:  81%|████████  | 8115/10000 [02:16<00:25, 73.92it/s]Processing train dataset:  97%|█████████▋| 9665/10000 [02:18<00:04, 71.87it/s]Processing train dataset:  97%|█████████▋| 9696/10000 [02:22<00:05, 58.43it/s]Processing train dataset:  94%|█████████▍| 9378/10000 [02:18<00:07, 81.52it/s]Processing train dataset:  97%|█████████▋| 9673/10000 [02:18<00:04, 72.72it/s]Processing train dataset:  81%|████████  | 8123/10000 [02:16<00:30, 62.32it/s]Processing train dataset:  97%|█████████▋| 9681/10000 [02:19<00:04, 74.20it/s]Processing train dataset:  97%|█████████▋| 9702/10000 [02:22<00:07, 40.17it/s]Processing train dataset:  97%|█████████▋| 9689/10000 [02:19<00:04, 71.90it/s]Processing train dataset:  94%|█████████▍| 9387/10000 [02:18<00:10, 60.18it/s]Processing train dataset:  97%|█████████▋| 9707/10000 [02:22<00:07, 41.39it/s]Processing train dataset:  81%|████████▏ | 8130/10000 [02:16<00:38, 48.32it/s]Processing train dataset:  97%|█████████▋| 9699/10000 [02:19<00:03, 78.41it/s]Processing train dataset:  94%|█████████▍| 9394/10000 [02:19<00:10, 59.21it/s]Processing train dataset:  97%|█████████▋| 9714/10000 [02:22<00:06, 45.81it/s]Processing train dataset:  81%|████████▏ | 8136/10000 [02:16<00:37, 49.23it/s]Processing train dataset:  97%|█████████▋| 9710/10000 [02:19<00:03, 85.39it/s]Processing train dataset:  94%|█████████▍| 9403/10000 [02:19<00:09, 64.82it/s]Processing train dataset:  97%|█████████▋| 9721/10000 [02:22<00:05, 51.10it/s]Processing train dataset:  81%|████████▏ | 8143/10000 [02:17<00:34, 53.54it/s]Processing train dataset:  97%|█████████▋| 9722/10000 [02:19<00:02, 93.54it/s]Processing train dataset:  94%|█████████▍| 9411/10000 [02:19<00:08, 65.93it/s]Processing train dataset:  82%|████████▏ | 8151/10000 [02:17<00:31, 58.92it/s]Processing train dataset:  97%|█████████▋| 9730/10000 [02:23<00:04, 59.09it/s]Processing train dataset:  97%|█████████▋| 9735/10000 [02:19<00:02, 102.25it/s]Processing train dataset:  94%|█████████▍| 9420/10000 [02:19<00:08, 70.64it/s]Processing train dataset:  82%|████████▏ | 8159/10000 [02:17<00:28, 63.60it/s]Processing train dataset:  97%|█████████▋| 9748/10000 [02:19<00:02, 109.29it/s]Processing train dataset:  97%|█████████▋| 9737/10000 [02:23<00:04, 59.54it/s]Processing train dataset:  94%|█████████▍| 9429/10000 [02:19<00:07, 73.41it/s]Processing train dataset:  98%|█████████▊| 9759/10000 [02:19<00:02, 103.07it/s]Processing train dataset:  82%|████████▏ | 8167/10000 [02:17<00:29, 61.37it/s]Processing train dataset:  97%|█████████▋| 9744/10000 [02:23<00:04, 58.12it/s]Processing train dataset:  94%|█████████▍| 9437/10000 [02:19<00:07, 72.11it/s]Processing train dataset:  98%|█████████▊| 9751/10000 [02:23<00:04, 60.89it/s]Processing train dataset:  82%|████████▏ | 8174/10000 [02:17<00:29, 62.28it/s]Processing train dataset:  98%|█████████▊| 9770/10000 [02:19<00:02, 93.73it/s] Processing train dataset:  94%|█████████▍| 9445/10000 [02:19<00:07, 72.35it/s]Processing train dataset:  98%|█████████▊| 9760/10000 [02:23<00:03, 66.96it/s]Processing train dataset:  82%|████████▏ | 8183/10000 [02:17<00:26, 67.43it/s]Processing train dataset:  95%|█████████▍| 9454/10000 [02:19<00:07, 75.79it/s]Processing train dataset:  98%|█████████▊| 9780/10000 [02:20<00:02, 88.16it/s]Processing train dataset:  82%|████████▏ | 8190/10000 [02:17<00:26, 67.61it/s]Processing train dataset:  98%|█████████▊| 9767/10000 [02:23<00:03, 65.04it/s]Processing train dataset:  95%|█████████▍| 9462/10000 [02:19<00:07, 74.03it/s]Processing train dataset:  98%|█████████▊| 9789/10000 [02:20<00:02, 85.63it/s]Processing train dataset:  82%|████████▏ | 8197/10000 [02:17<00:27, 65.44it/s]Processing train dataset:  98%|█████████▊| 9774/10000 [02:23<00:03, 62.20it/s]Processing train dataset:  95%|█████████▍| 9471/10000 [02:19<00:06, 77.95it/s]Processing train dataset:  98%|█████████▊| 9799/10000 [02:20<00:02, 89.23it/s]Processing train dataset:  98%|█████████▊| 9781/10000 [02:23<00:03, 60.32it/s]Processing train dataset:  82%|████████▏ | 8204/10000 [02:17<00:30, 59.42it/s]Processing train dataset:  95%|█████████▍| 9479/10000 [02:20<00:06, 74.71it/s]Processing train dataset:  98%|█████████▊| 9809/10000 [02:20<00:02, 84.97it/s]Processing train dataset:  98%|█████████▊| 9788/10000 [02:24<00:03, 57.33it/s]Processing train dataset:  82%|████████▏ | 8211/10000 [02:18<00:31, 56.23it/s]Processing train dataset:  95%|█████████▍| 9487/10000 [02:20<00:07, 69.77it/s]Processing train dataset:  98%|█████████▊| 9818/10000 [02:20<00:02, 76.71it/s]Processing train dataset:  82%|████████▏ | 8217/10000 [02:18<00:31, 56.72it/s]Processing train dataset:  95%|█████████▍| 9495/10000 [02:20<00:07, 71.39it/s]Processing train dataset:  98%|█████████▊| 9794/10000 [02:24<00:03, 55.70it/s]Processing train dataset:  98%|█████████▊| 9826/10000 [02:20<00:02, 76.04it/s]Processing train dataset:  82%|████████▏ | 8223/10000 [02:18<00:31, 56.91it/s]Processing train dataset:  98%|█████████▊| 9801/10000 [02:24<00:03, 59.23it/s]Processing train dataset:  95%|█████████▌| 9504/10000 [02:20<00:06, 75.01it/s]Processing train dataset:  98%|█████████▊| 9835/10000 [02:20<00:02, 77.00it/s]Processing train dataset:  95%|█████████▌| 9513/10000 [02:20<00:06, 78.44it/s]Processing train dataset:  98%|█████████▊| 9808/10000 [02:24<00:03, 58.83it/s]Processing train dataset:  82%|████████▏ | 8229/10000 [02:18<00:32, 53.86it/s]Processing train dataset:  98%|█████████▊| 9845/10000 [02:20<00:01, 78.15it/s]Processing train dataset:  95%|█████████▌| 9521/10000 [02:20<00:06, 77.41it/s]Processing train dataset:  82%|████████▏ | 8236/10000 [02:18<00:30, 57.99it/s]Processing train dataset:  98%|█████████▊| 9815/10000 [02:24<00:03, 58.37it/s]Processing train dataset:  99%|█████████▊| 9856/10000 [02:21<00:01, 83.57it/s]Processing train dataset:  82%|████████▏ | 8247/10000 [02:18<00:24, 71.74it/s]Processing train dataset:  95%|█████████▌| 9529/10000 [02:20<00:06, 71.35it/s]Processing train dataset:  98%|█████████▊| 9821/10000 [02:24<00:03, 55.87it/s]Processing train dataset:  99%|█████████▊| 9865/10000 [02:21<00:01, 79.75it/s]Processing train dataset:  83%|████████▎ | 8256/10000 [02:18<00:23, 75.65it/s]Processing train dataset:  95%|█████████▌| 9537/10000 [02:20<00:06, 71.48it/s]Processing train dataset:  98%|█████████▊| 9827/10000 [02:24<00:03, 55.26it/s]Processing train dataset:  99%|█████████▉| 9876/10000 [02:21<00:01, 85.37it/s]Processing train dataset:  83%|████████▎ | 8266/10000 [02:18<00:21, 81.82it/s]Processing train dataset:  95%|█████████▌| 9546/10000 [02:21<00:05, 76.01it/s]Processing train dataset:  98%|█████████▊| 9834/10000 [02:24<00:03, 55.18it/s]Processing train dataset:  99%|█████████▉| 9886/10000 [02:21<00:01, 88.02it/s]Processing train dataset:  83%|████████▎ | 8276/10000 [02:18<00:20, 85.52it/s]Processing train dataset:  96%|█████████▌| 9555/10000 [02:21<00:05, 78.13it/s]Processing train dataset:  99%|█████████▉| 9895/10000 [02:21<00:01, 87.49it/s]Processing train dataset:  98%|█████████▊| 9840/10000 [02:24<00:03, 51.08it/s]Processing train dataset:  83%|████████▎ | 8285/10000 [02:19<00:20, 83.88it/s]Processing train dataset:  96%|█████████▌| 9563/10000 [02:21<00:05, 73.29it/s]Processing train dataset:  98%|█████████▊| 9848/10000 [02:25<00:02, 54.83it/s]Processing train dataset:  99%|█████████▉| 9904/10000 [02:21<00:01, 78.35it/s]Processing train dataset:  83%|████████▎ | 8294/10000 [02:19<00:22, 75.80it/s]Processing train dataset:  96%|█████████▌| 9572/10000 [02:21<00:05, 75.75it/s]Processing train dataset:  99%|█████████▊| 9858/10000 [02:25<00:02, 63.10it/s]Processing train dataset:  99%|█████████▉| 9913/10000 [02:21<00:01, 77.93it/s]Processing train dataset:  96%|█████████▌| 9580/10000 [02:21<00:05, 76.72it/s]Processing train dataset:  83%|████████▎ | 8302/10000 [02:19<00:23, 72.78it/s]Processing train dataset:  99%|█████████▉| 9922/10000 [02:21<00:00, 80.55it/s]Processing train dataset:  96%|█████████▌| 9592/10000 [02:21<00:04, 86.84it/s]Processing train dataset:  99%|█████████▊| 9865/10000 [02:25<00:02, 60.17it/s]Processing train dataset:  83%|████████▎ | 8310/10000 [02:19<00:23, 72.01it/s]Processing train dataset:  99%|█████████▉| 9933/10000 [02:21<00:00, 82.97it/s]Processing train dataset:  96%|█████████▌| 9602/10000 [02:21<00:04, 89.28it/s]Processing train dataset:  99%|█████████▊| 9872/10000 [02:25<00:02, 60.87it/s]Processing train dataset:  83%|████████▎ | 8318/10000 [02:19<00:23, 72.53it/s]Processing train dataset:  96%|█████████▌| 9612/10000 [02:21<00:04, 90.21it/s]Processing train dataset:  99%|█████████▉| 9942/10000 [02:22<00:00, 78.73it/s]Processing train dataset:  99%|█████████▉| 9879/10000 [02:25<00:02, 58.88it/s]Processing train dataset:  83%|████████▎ | 8326/10000 [02:19<00:24, 67.08it/s]Processing train dataset:  96%|█████████▌| 9622/10000 [02:21<00:04, 86.42it/s]Processing train dataset: 100%|█████████▉| 9950/10000 [02:22<00:00, 76.45it/s]Processing train dataset:  99%|█████████▉| 9885/10000 [02:25<00:01, 57.68it/s]Processing train dataset:  83%|████████▎ | 8337/10000 [02:19<00:21, 76.34it/s]Processing train dataset:  96%|█████████▋| 9633/10000 [02:22<00:04, 91.28it/s]Processing train dataset: 100%|█████████▉| 9960/10000 [02:22<00:00, 80.91it/s]Processing train dataset:  99%|█████████▉| 9892/10000 [02:25<00:01, 59.35it/s]Processing train dataset:  83%|████████▎ | 8347/10000 [02:19<00:20, 81.64it/s]Processing train dataset:  96%|█████████▋| 9643/10000 [02:22<00:03, 91.46it/s]Processing train dataset: 100%|█████████▉| 9969/10000 [02:22<00:00, 81.89it/s]Processing train dataset:  99%|█████████▉| 9898/10000 [02:25<00:01, 57.15it/s]Processing train dataset:  84%|████████▎ | 8356/10000 [02:20<00:21, 78.04it/s]Processing train dataset: 100%|█████████▉| 9978/10000 [02:22<00:00, 82.24it/s]Processing train dataset:  97%|█████████▋| 9657/10000 [02:22<00:03, 102.08it/s]Processing train dataset:  99%|█████████▉| 9904/10000 [02:26<00:01, 56.14it/s]Processing train dataset:  84%|████████▎ | 8364/10000 [02:20<00:23, 70.50it/s]Processing train dataset:  97%|█████████▋| 9668/10000 [02:22<00:03, 102.25it/s]Processing train dataset: 100%|█████████▉| 9987/10000 [02:22<00:00, 81.76it/s]Processing train dataset:  99%|█████████▉| 9911/10000 [02:26<00:01, 58.53it/s]Processing train dataset:  84%|████████▎ | 8372/10000 [02:20<00:23, 69.79it/s]Processing train dataset: 100%|█████████▉| 9996/10000 [02:22<00:00, 83.58it/s]Processing train dataset:  97%|█████████▋| 9679/10000 [02:22<00:03, 100.17it/s]Processing train dataset:  99%|█████████▉| 9917/10000 [02:26<00:01, 58.58it/s]Processing train dataset: 100%|██████████| 10000/10000 [02:22<00:00, 70.03it/s]Processing train dataset:  84%|████████▍ | 8380/10000 [02:20<00:24, 66.57it/s]Processing train dataset:  99%|█████████▉| 9926/10000 [02:26<00:01, 63.86it/s]Processing train dataset:  97%|█████████▋| 9690/10000 [02:22<00:03, 93.17it/s] Processing train dataset:  84%|████████▍ | 8387/10000 [02:20<00:25, 62.77it/s]Processing train dataset:  99%|█████████▉| 9933/10000 [02:26<00:01, 61.87it/s]Processing train dataset:  97%|█████████▋| 9700/10000 [02:22<00:03, 82.82it/s]Processing train dataset:  84%|████████▍ | 8394/10000 [02:20<00:25, 63.75it/s]Processing train dataset:  99%|█████████▉| 9940/10000 [02:26<00:00, 62.49it/s]Processing train dataset:  97%|█████████▋| 9709/10000 [02:22<00:03, 76.56it/s]Processing train dataset:  84%|████████▍ | 8401/10000 [02:20<00:24, 64.62it/s]Processing train dataset:  99%|█████████▉| 9947/10000 [02:26<00:00, 61.28it/s]Processing train dataset:  84%|████████▍ | 8408/10000 [02:20<00:25, 63.00it/s]Processing train dataset: 100%|█████████▉| 9954/10000 [02:26<00:00, 60.88it/s]Processing train dataset:  97%|█████████▋| 9717/10000 [02:23<00:04, 64.17it/s]Processing train dataset:  84%|████████▍ | 8416/10000 [02:20<00:24, 64.69it/s]Processing train dataset: 100%|█████████▉| 9962/10000 [02:26<00:00, 64.72it/s]Processing train dataset:  97%|█████████▋| 9724/10000 [02:23<00:04, 64.54it/s]Processing train dataset:  84%|████████▍ | 8423/10000 [02:21<00:24, 64.38it/s]Processing train dataset: 100%|█████████▉| 9970/10000 [02:27<00:00, 66.68it/s]Processing train dataset:  97%|█████████▋| 9731/10000 [02:23<00:04, 63.96it/s]Processing train dataset:  84%|████████▍ | 8430/10000 [02:21<00:24, 65.14it/s]Processing train dataset: 100%|█████████▉| 9977/10000 [02:27<00:00, 58.33it/s]Processing train dataset:  97%|█████████▋| 9738/10000 [02:23<00:04, 57.91it/s]Processing train dataset:  84%|████████▍ | 8439/10000 [02:21<00:22, 69.12it/s]Processing train dataset: 100%|█████████▉| 9984/10000 [02:27<00:00, 58.90it/s]Processing train dataset:  97%|█████████▋| 9744/10000 [02:23<00:04, 56.15it/s]Processing train dataset:  84%|████████▍ | 8446/10000 [02:21<00:22, 69.24it/s]Processing train dataset: 100%|█████████▉| 9991/10000 [02:27<00:00, 61.44it/s]Processing train dataset:  85%|████████▍ | 8453/10000 [02:21<00:23, 67.25it/s]Processing train dataset:  98%|█████████▊| 9750/10000 [02:23<00:04, 50.35it/s]Processing train dataset: 100%|█████████▉| 9998/10000 [02:27<00:00, 62.65it/s]Processing train dataset: 100%|██████████| 10000/10000 [02:27<00:00, 67.77it/s]Processing train dataset:  85%|████████▍ | 8460/10000 [02:21<00:23, 64.98it/s]Processing train dataset:  98%|█████████▊| 9756/10000 [02:23<00:04, 51.07it/s]Processing train dataset:  85%|████████▍ | 8468/10000 [02:21<00:22, 68.90it/s]Processing train dataset:  98%|█████████▊| 9762/10000 [02:23<00:04, 49.92it/s]Processing train dataset:  85%|████████▍ | 8475/10000 [02:21<00:22, 68.56it/s]Processing train dataset:  98%|█████████▊| 9768/10000 [02:24<00:04, 52.41it/s]Processing train dataset:  85%|████████▍ | 8485/10000 [02:21<00:20, 75.23it/s]Processing train dataset:  98%|█████████▊| 9777/10000 [02:24<00:03, 58.84it/s]Processing train dataset:  85%|████████▍ | 8493/10000 [02:22<00:19, 76.42it/s]Processing train dataset:  98%|█████████▊| 9784/10000 [02:24<00:03, 59.68it/s]Processing train dataset:  85%|████████▌ | 8502/10000 [02:22<00:18, 78.98it/s]Processing train dataset:  98%|█████████▊| 9791/10000 [02:24<00:03, 57.41it/s]Processing train dataset:  85%|████████▌ | 8510/10000 [02:22<00:19, 75.65it/s]Processing train dataset:  85%|████████▌ | 8521/10000 [02:22<00:17, 84.48it/s]Processing train dataset:  98%|█████████▊| 9799/10000 [02:24<00:03, 57.87it/s]Processing train dataset:  85%|████████▌ | 8530/10000 [02:22<00:17, 82.08it/s]Processing train dataset:  98%|█████████▊| 9806/10000 [02:24<00:03, 58.29it/s]Processing train dataset:  85%|████████▌ | 8539/10000 [02:22<00:20, 71.35it/s]Processing train dataset:  98%|█████████▊| 9812/10000 [02:24<00:04, 43.76it/s]Processing train dataset:  85%|████████▌ | 8547/10000 [02:22<00:20, 69.39it/s]Processing train dataset:  86%|████████▌ | 8556/10000 [02:22<00:20, 72.04it/s]Processing train dataset:  98%|█████████▊| 9817/10000 [02:25<00:05, 34.69it/s]Processing train dataset:  86%|████████▌ | 8568/10000 [02:23<00:17, 80.73it/s]Processing train dataset:  86%|████████▌ | 8577/10000 [02:23<00:17, 81.46it/s]Processing train dataset:  98%|█████████▊| 9822/10000 [02:25<00:05, 32.20it/s]Processing train dataset:  86%|████████▌ | 8586/10000 [02:23<00:17, 82.01it/s]Processing train dataset:  98%|█████████▊| 9827/10000 [02:25<00:05, 32.96it/s]Processing train dataset:  86%|████████▌ | 8596/10000 [02:23<00:16, 84.31it/s]Processing train dataset:  98%|█████████▊| 9832/10000 [02:25<00:04, 35.89it/s]Processing train dataset:  86%|████████▌ | 8608/10000 [02:23<00:15, 92.33it/s]Processing train dataset:  98%|█████████▊| 9837/10000 [02:25<00:04, 38.57it/s]Processing train dataset:  86%|████████▌ | 8618/10000 [02:23<00:15, 90.40it/s]Processing train dataset:  98%|█████████▊| 9844/10000 [02:25<00:03, 42.12it/s]Processing train dataset:  86%|████████▋ | 8628/10000 [02:23<00:15, 85.75it/s]Processing train dataset:  98%|█████████▊| 9849/10000 [02:25<00:03, 40.80it/s]Processing train dataset:  86%|████████▋ | 8637/10000 [02:23<00:15, 86.26it/s]Processing train dataset:  86%|████████▋ | 8646/10000 [02:23<00:16, 80.76it/s]Processing train dataset:  99%|█████████▊| 9854/10000 [02:26<00:04, 36.23it/s]Processing train dataset:  87%|████████▋ | 8655/10000 [02:24<00:16, 82.57it/s]Processing train dataset:  99%|█████████▊| 9860/10000 [02:26<00:03, 39.71it/s]Processing train dataset:  87%|████████▋ | 8665/10000 [02:24<00:16, 82.90it/s]Processing train dataset:  99%|█████████▊| 9865/10000 [02:26<00:03, 39.66it/s]
  0%|          | 0/1000 [00:00<?, ?it/s]Processing val dataset:   0%|          | 0/1000 [00:00<?, ?it/s]Processing train dataset:  87%|████████▋ | 8674/10000 [02:24<00:19, 69.54it/s]Processing train dataset:  99%|█████████▊| 9872/10000 [02:26<00:02, 45.49it/s]Processing train dataset:  99%|█████████▉| 9878/10000 [02:26<00:02, 46.79it/s]Processing train dataset:  87%|████████▋ | 8686/10000 [02:24<00:17, 73.26it/s]Processing train dataset:  99%|█████████▉| 9883/10000 [02:26<00:02, 40.98it/s]Processing val dataset:   0%|          | 1/1000 [00:00<05:39,  2.94it/s]Processing train dataset:  87%|████████▋ | 8694/10000 [02:24<00:23, 56.74it/s]Processing val dataset:   1%|          | 7/1000 [00:00<00:50, 19.79it/s]Processing train dataset:  99%|█████████▉| 9888/10000 [02:26<00:02, 41.35it/s]Processing val dataset:   2%|▏         | 15/1000 [00:00<00:26, 37.53it/s]Processing train dataset:  87%|████████▋ | 8701/10000 [02:24<00:23, 54.63it/s]Processing train dataset:  99%|█████████▉| 9894/10000 [02:27<00:02, 42.42it/s]Processing val dataset:   3%|▎         | 26/1000 [00:00<00:16, 57.50it/s]Processing train dataset:  99%|█████████▉| 9899/10000 [02:27<00:02, 43.13it/s]Processing train dataset:  87%|████████▋ | 8707/10000 [02:25<00:26, 48.67it/s]Processing val dataset:   4%|▎         | 37/1000 [00:00<00:13, 71.84it/s]Processing train dataset:  99%|█████████▉| 9905/10000 [02:27<00:02, 45.24it/s]Processing train dataset:  87%|████████▋ | 8719/10000 [02:25<00:20, 61.58it/s]Processing val dataset:   5%|▍         | 49/1000 [00:00<00:11, 84.82it/s]Processing val dataset:   6%|▌         | 60/1000 [00:00<00:10, 91.41it/s]Processing train dataset:  99%|█████████▉| 9910/10000 [02:27<00:02, 38.33it/s]Processing train dataset:  87%|████████▋ | 8726/10000 [02:25<00:22, 55.57it/s]Processing val dataset:   7%|▋         | 70/1000 [00:01<00:10, 92.75it/s]Processing train dataset:  99%|█████████▉| 9919/10000 [02:27<00:01, 48.37it/s]Processing train dataset:  87%|████████▋ | 8734/10000 [02:25<00:20, 60.55it/s]Processing val dataset:   8%|▊         | 80/1000 [00:01<00:10, 91.79it/s]Processing train dataset:  87%|████████▋ | 8741/10000 [02:25<00:20, 62.56it/s]Processing train dataset:  99%|█████████▉| 9929/10000 [02:27<00:01, 56.60it/s]Processing val dataset:   9%|▉         | 90/1000 [00:01<00:09, 92.09it/s]Processing train dataset:  99%|█████████▉| 9935/10000 [02:27<00:01, 55.24it/s]Processing train dataset:  87%|████████▋ | 8748/10000 [02:25<00:21, 58.36it/s]Processing val dataset:  10%|█         | 100/1000 [00:01<00:09, 90.97it/s]Processing train dataset:  99%|█████████▉| 9941/10000 [02:27<00:01, 53.46it/s]Processing val dataset:  11%|█         | 110/1000 [00:01<00:10, 82.54it/s]Processing train dataset:  88%|████████▊ | 8755/10000 [02:25<00:29, 42.27it/s]Processing val dataset:  12%|█▏        | 120/1000 [00:01<00:10, 86.15it/s]Processing train dataset:  99%|█████████▉| 9947/10000 [02:28<00:01, 44.74it/s]Processing val dataset:  13%|█▎        | 134/1000 [00:01<00:08, 97.09it/s]Processing train dataset: 100%|█████████▉| 9955/10000 [02:28<00:00, 51.55it/s]Processing train dataset:  88%|████████▊ | 8761/10000 [02:26<00:33, 36.56it/s]Processing val dataset:  14%|█▍        | 144/1000 [00:01<00:09, 94.09it/s]Processing train dataset: 100%|█████████▉| 9963/10000 [02:28<00:00, 52.00it/s]Processing val dataset:  15%|█▌        | 154/1000 [00:01<00:09, 90.94it/s]Processing train dataset: 100%|█████████▉| 9969/10000 [02:28<00:00, 50.65it/s]Processing val dataset:  16%|█▋        | 164/1000 [00:02<00:09, 92.03it/s]Processing train dataset:  88%|████████▊ | 8766/10000 [02:26<00:41, 29.53it/s]Processing train dataset: 100%|█████████▉| 9975/10000 [02:28<00:00, 50.81it/s]Processing val dataset:  18%|█▊        | 175/1000 [00:02<00:08, 94.76it/s]Processing train dataset:  88%|████████▊ | 8774/10000 [02:26<00:32, 37.79it/s]Processing train dataset: 100%|█████████▉| 9981/10000 [02:28<00:00, 51.26it/s]Processing val dataset:  19%|█▊        | 186/1000 [00:02<00:08, 98.94it/s]Processing train dataset: 100%|█████████▉| 9989/10000 [02:28<00:00, 57.81it/s]Processing val dataset:  20%|█▉        | 199/1000 [00:02<00:07, 107.70it/s]Processing train dataset:  88%|████████▊ | 8779/10000 [02:26<00:34, 35.30it/s]Processing val dataset:  21%|██        | 210/1000 [00:02<00:07, 107.22it/s]Processing train dataset: 100%|█████████▉| 9995/10000 [02:28<00:00, 53.48it/s]Processing train dataset:  88%|████████▊ | 8784/10000 [02:26<00:33, 36.13it/s]Processing val dataset:  22%|██▏       | 221/1000 [00:02<00:07, 106.46it/s]Processing train dataset: 100%|██████████| 10000/10000 [02:29<00:00, 67.06it/s]Processing train dataset:  88%|████████▊ | 8789/10000 [02:27<00:34, 35.14it/s]Processing val dataset:  23%|██▎       | 232/1000 [00:02<00:08, 92.87it/s] Processing train dataset:  88%|████████▊ | 8793/10000 [02:27<00:33, 36.09it/s]Processing val dataset:  24%|██▍       | 242/1000 [00:02<00:08, 91.41it/s]Processing train dataset:  88%|████████▊ | 8799/10000 [02:27<00:29, 40.09it/s]Processing val dataset:  25%|██▌       | 254/1000 [00:02<00:07, 97.78it/s]Processing val dataset:  26%|██▋       | 265/1000 [00:03<00:07, 100.31it/s]Processing val dataset:  28%|██▊       | 276/1000 [00:03<00:07, 96.10it/s] Processing train dataset:  88%|████████▊ | 8804/10000 [02:27<00:47, 24.93it/s]Processing val dataset:  29%|██▉       | 291/1000 [00:03<00:06, 109.62it/s]Processing val dataset:  30%|███       | 305/1000 [00:03<00:06, 115.09it/s]Processing val dataset:  32%|███▏      | 318/1000 [00:03<00:06, 111.07it/s]Processing train dataset:  88%|████████▊ | 8808/10000 [02:27<00:57, 20.83it/s]Processing val dataset:  33%|███▎      | 332/1000 [00:03<00:05, 114.57it/s]Processing val dataset:  34%|███▍      | 344/1000 [00:03<00:05, 114.86it/s]Processing train dataset:  88%|████████▊ | 8811/10000 [02:28<01:02, 18.94it/s]Processing val dataset:  36%|███▌      | 357/1000 [00:03<00:05, 117.52it/s]Processing train dataset:  88%|████████▊ | 8814/10000 [02:28<00:57, 20.62it/s]Processing val dataset:  37%|███▋      | 370/1000 [00:03<00:05, 120.90it/s]Processing val dataset:  38%|███▊      | 383/1000 [00:04<00:05, 117.20it/s]Processing train dataset:  88%|████████▊ | 8817/10000 [02:28<01:01, 19.11it/s]Processing val dataset:  40%|███▉      | 395/1000 [00:04<00:05, 116.01it/s]Processing train dataset:  88%|████████▊ | 8820/10000 [02:28<00:57, 20.38it/s]Processing val dataset:  41%|████      | 412/1000 [00:04<00:04, 130.07it/s]Processing val dataset:  43%|████▎     | 428/1000 [00:04<00:04, 137.90it/s]Processing train dataset:  88%|████████▊ | 8823/10000 [02:28<01:01, 18.98it/s]Processing val dataset:  44%|████▍     | 443/1000 [00:04<00:03, 140.85it/s]Processing train dataset:  88%|████████▊ | 8826/10000 [02:28<00:57, 20.53it/s]Processing val dataset:  46%|████▌     | 458/1000 [00:04<00:04, 134.85it/s]Processing train dataset:  88%|████████▊ | 8829/10000 [02:29<01:00, 19.27it/s]Processing val dataset:  47%|████▋     | 472/1000 [00:04<00:04, 125.33it/s]Processing train dataset:  88%|████████▊ | 8833/10000 [02:29<00:52, 22.36it/s]Processing val dataset:  49%|████▉     | 488/1000 [00:04<00:03, 133.47it/s]Processing train dataset:  88%|████████▊ | 8836/10000 [02:29<00:50, 23.04it/s]Processing val dataset:  50%|█████     | 503/1000 [00:04<00:03, 136.64it/s]Processing val dataset:  52%|█████▏    | 517/1000 [00:05<00:03, 128.32it/s]Processing train dataset:  88%|████████▊ | 8839/10000 [02:29<00:53, 21.62it/s]Processing train dataset:  88%|████████▊ | 8844/10000 [02:29<00:41, 27.77it/s]Processing val dataset:  53%|█████▎    | 531/1000 [00:05<00:03, 121.28it/s]
  0%|          | 0/1000 [00:00<?, ?it/s]Processing val dataset:   0%|          | 0/1000 [00:00<?, ?it/s]Processing val dataset:  54%|█████▍    | 544/1000 [00:05<00:03, 121.51it/s]Processing train dataset:  88%|████████▊ | 8848/10000 [02:29<00:45, 25.57it/s]Processing val dataset:   0%|          | 1/1000 [00:00<03:38,  4.56it/s]Processing train dataset:  89%|████████▊ | 8855/10000 [02:29<00:33, 34.14it/s]Processing val dataset:  56%|█████▌    | 557/1000 [00:05<00:04, 97.52it/s] Processing val dataset:   1%|          | 9/1000 [00:00<00:30, 32.83it/s]Processing train dataset:  89%|████████▊ | 8862/10000 [02:29<00:27, 41.76it/s]Processing val dataset:  57%|█████▋    | 568/1000 [00:05<00:04, 95.78it/s]Processing val dataset:   2%|▏         | 20/1000 [00:00<00:16, 58.30it/s]Processing train dataset:  89%|████████▊ | 8868/10000 [02:30<00:27, 41.38it/s]Processing val dataset:  58%|█████▊    | 579/1000 [00:05<00:04, 93.74it/s]Processing val dataset:   3%|▎         | 30/1000 [00:00<00:13, 70.65it/s]Processing train dataset:  89%|████████▊ | 8873/10000 [02:30<00:28, 39.87it/s]Processing val dataset:  59%|█████▉    | 589/1000 [00:05<00:04, 88.25it/s]Processing val dataset:   4%|▍         | 39/1000 [00:00<00:14, 66.10it/s]Processing train dataset:  89%|████████▉ | 8878/10000 [02:30<00:27, 40.98it/s]Processing val dataset:  60%|█████▉    | 599/1000 [00:06<00:04, 86.53it/s]Processing val dataset:   5%|▍         | 49/1000 [00:00<00:12, 74.37it/s]Processing train dataset:  89%|████████▉ | 8883/10000 [02:30<00:26, 42.62it/s]Processing val dataset:  61%|██████    | 609/1000 [00:06<00:04, 88.48it/s]Processing val dataset:   6%|▌         | 58/1000 [00:00<00:12, 78.40it/s]Processing val dataset:  62%|██████▏   | 620/1000 [00:06<00:04, 92.67it/s]Processing val dataset:   7%|▋         | 67/1000 [00:01<00:11, 79.54it/s]Processing train dataset:  89%|████████▉ | 8888/10000 [02:30<00:29, 38.18it/s]Processing val dataset:  63%|██████▎   | 630/1000 [00:06<00:03, 94.32it/s]Processing val dataset:   8%|▊         | 76/1000 [00:01<00:11, 78.22it/s]Processing train dataset:  89%|████████▉ | 8892/10000 [02:30<00:32, 34.56it/s]Processing val dataset:  64%|██████▍   | 640/1000 [00:06<00:03, 93.02it/s]Processing val dataset:   8%|▊         | 85/1000 [00:01<00:11, 78.88it/s]Processing train dataset:  89%|████████▉ | 8898/10000 [02:30<00:28, 39.20it/s]Processing val dataset:  65%|██████▌   | 650/1000 [00:06<00:03, 88.34it/s]Processing val dataset:   9%|▉         | 94/1000 [00:01<00:12, 74.26it/s]Processing train dataset:  89%|████████▉ | 8904/10000 [02:30<00:24, 44.09it/s]Processing val dataset:  66%|██████▌   | 661/1000 [00:06<00:03, 93.92it/s]Processing val dataset:  10%|█         | 102/1000 [00:01<00:12, 70.75it/s]Processing train dataset:  89%|████████▉ | 8913/10000 [02:31<00:19, 54.72it/s]Processing val dataset:  11%|█         | 112/1000 [00:01<00:11, 77.16it/s]Processing val dataset:  67%|██████▋   | 671/1000 [00:06<00:04, 79.93it/s]Processing train dataset:  89%|████████▉ | 8919/10000 [02:31<00:20, 52.49it/s]Processing val dataset:  12%|█▏        | 122/1000 [00:01<00:10, 82.96it/s]Processing val dataset:  68%|██████▊   | 680/1000 [00:07<00:04, 70.33it/s]Processing train dataset:  89%|████████▉ | 8925/10000 [02:31<00:23, 46.34it/s]Processing val dataset:  14%|█▎        | 136/1000 [00:01<00:09, 93.79it/s]Processing val dataset:  69%|██████▉   | 688/1000 [00:07<00:04, 68.97it/s]Processing train dataset:  89%|████████▉ | 8930/10000 [02:31<00:24, 44.19it/s]Processing val dataset:  15%|█▍        | 146/1000 [00:02<00:11, 72.56it/s]Processing train dataset:  89%|████████▉ | 8935/10000 [02:31<00:23, 44.83it/s]Processing val dataset:  70%|██████▉   | 696/1000 [00:07<00:04, 61.40it/s]Processing val dataset:  70%|███████   | 704/1000 [00:07<00:04, 62.46it/s]Processing val dataset:  16%|█▌        | 155/1000 [00:02<00:13, 63.21it/s]Processing train dataset:  89%|████████▉ | 8940/10000 [02:31<00:28, 37.60it/s]Processing val dataset:  71%|███████   | 712/1000 [00:07<00:04, 64.52it/s]Processing val dataset:  16%|█▋        | 164/1000 [00:02<00:12, 68.59it/s]Processing train dataset:  89%|████████▉ | 8946/10000 [02:31<00:24, 42.37it/s]Processing val dataset:  72%|███████▏  | 721/1000 [00:07<00:03, 70.41it/s]Processing val dataset:  18%|█▊        | 175/1000 [00:02<00:10, 76.24it/s]Processing train dataset:  90%|████████▉ | 8954/10000 [02:32<00:20, 50.85it/s]Processing val dataset:  73%|███████▎  | 730/1000 [00:07<00:03, 74.27it/s]Processing val dataset:  18%|█▊        | 185/1000 [00:02<00:10, 81.02it/s]Processing val dataset:  74%|███████▍  | 740/1000 [00:07<00:03, 79.01it/s]Processing train dataset:  90%|████████▉ | 8962/10000 [02:32<00:22, 46.74it/s]Processing val dataset:  19%|█▉        | 194/1000 [00:02<00:10, 79.79it/s]Processing val dataset:  75%|███████▍  | 749/1000 [00:07<00:03, 78.62it/s]Processing train dataset:  90%|████████▉ | 8970/10000 [02:32<00:19, 53.38it/s]Processing val dataset:  20%|██        | 205/1000 [00:02<00:09, 85.98it/s]Processing val dataset:  76%|███████▌  | 762/1000 [00:08<00:02, 91.75it/s]Processing train dataset:  90%|████████▉ | 8982/10000 [02:32<00:14, 68.73it/s]Processing val dataset:  22%|██▏       | 220/1000 [00:02<00:07, 101.46it/s]Processing val dataset:  77%|███████▋  | 773/1000 [00:08<00:02, 95.79it/s]Processing train dataset:  90%|████████▉ | 8990/10000 [02:32<00:15, 64.29it/s]Processing val dataset:  23%|██▎       | 231/1000 [00:03<00:08, 91.43it/s] Processing val dataset:  78%|███████▊  | 783/1000 [00:08<00:02, 92.56it/s]Processing val dataset:  24%|██▍       | 241/1000 [00:03<00:08, 85.98it/s]Processing train dataset:  90%|████████▉ | 8997/10000 [02:32<00:17, 56.43it/s]Processing val dataset:  79%|███████▉  | 793/1000 [00:08<00:02, 92.68it/s]Processing val dataset:  25%|██▌       | 250/1000 [00:03<00:08, 86.91it/s]Processing val dataset:  80%|████████  | 803/1000 [00:08<00:02, 93.76it/s]Processing train dataset:  90%|█████████ | 9004/10000 [02:32<00:20, 48.10it/s]Processing val dataset:  81%|████████▏ | 813/1000 [00:08<00:01, 94.90it/s]Processing val dataset:  26%|██▌       | 259/1000 [00:03<00:08, 84.71it/s]Processing train dataset:  90%|█████████ | 9010/10000 [02:33<00:20, 47.56it/s]Processing val dataset:  82%|████████▏ | 823/1000 [00:08<00:01, 89.71it/s]Processing val dataset:  27%|██▋       | 268/1000 [00:03<00:09, 79.43it/s]Processing val dataset:  83%|████████▎ | 833/1000 [00:08<00:01, 89.08it/s]Processing val dataset:  28%|██▊       | 277/1000 [00:03<00:10, 72.00it/s]Processing val dataset:  84%|████████▍ | 842/1000 [00:08<00:01, 86.29it/s]Processing val dataset:  29%|██▉       | 290/1000 [00:03<00:08, 84.33it/s]Processing val dataset:  85%|████████▌ | 852/1000 [00:09<00:01, 89.13it/s]Processing val dataset:  30%|███       | 303/1000 [00:03<00:07, 95.56it/s]Processing train dataset:  90%|█████████ | 9016/10000 [02:33<00:31, 30.86it/s]Processing val dataset:  86%|████████▋ | 864/1000 [00:09<00:01, 95.76it/s]Processing val dataset:  32%|███▏      | 315/1000 [00:03<00:06, 100.15it/s]Processing train dataset:  90%|█████████ | 9022/10000 [02:33<00:28, 34.13it/s]Processing val dataset:  88%|████████▊ | 877/1000 [00:09<00:01, 103.87it/s]Processing val dataset:  33%|███▎      | 326/1000 [00:04<00:06, 101.17it/s]Processing train dataset:  90%|█████████ | 9027/10000 [02:33<00:27, 35.96it/s]Processing val dataset:  89%|████████▉ | 890/1000 [00:09<00:00, 111.21it/s]Processing val dataset:  34%|███▍      | 340/1000 [00:04<00:05, 110.39it/s]Processing val dataset:  90%|█████████ | 904/1000 [00:09<00:00, 116.84it/s]Processing train dataset:  90%|█████████ | 9033/10000 [02:33<00:25, 37.51it/s]Processing val dataset:  35%|███▌      | 352/1000 [00:04<00:05, 112.56it/s]Processing val dataset:  92%|█████████▏| 916/1000 [00:09<00:00, 115.59it/s]Processing train dataset:  90%|█████████ | 9040/10000 [02:33<00:22, 43.12it/s]Processing val dataset:  36%|███▋      | 364/1000 [00:04<00:05, 111.33it/s]Processing val dataset:  93%|█████████▎| 930/1000 [00:09<00:00, 120.33it/s]Processing val dataset:  38%|███▊      | 377/1000 [00:04<00:05, 115.32it/s]Processing train dataset:  90%|█████████ | 9046/10000 [02:34<00:21, 43.87it/s]Processing val dataset:  94%|█████████▍| 943/1000 [00:09<00:00, 118.85it/s]Processing val dataset:  39%|███▉      | 389/1000 [00:04<00:05, 113.25it/s]Processing train dataset:  91%|█████████ | 9054/10000 [02:34<00:19, 48.10it/s]Processing val dataset:  96%|█████████▌| 956/1000 [00:09<00:00, 119.18it/s]Processing val dataset:  40%|████      | 404/1000 [00:04<00:04, 121.34it/s]Processing train dataset:  91%|█████████ | 9060/10000 [02:34<00:19, 47.04it/s]Processing val dataset:  97%|█████████▋| 969/1000 [00:10<00:00, 120.40it/s]Processing val dataset:  42%|████▏     | 417/1000 [00:04<00:04, 120.85it/s]Processing train dataset:  91%|█████████ | 9067/10000 [02:34<00:18, 51.73it/s]Processing val dataset:  98%|█████████▊| 982/1000 [00:10<00:00, 121.42it/s]Processing val dataset:  43%|████▎     | 430/1000 [00:04<00:04, 122.76it/s]Processing val dataset: 100%|█████████▉| 995/1000 [00:10<00:00, 120.95it/s]Processing train dataset:  91%|█████████ | 9074/10000 [02:34<00:17, 53.84it/s]Processing val dataset: 100%|██████████| 1000/1000 [00:10<00:00, 97.14it/s]Processing val dataset:  44%|████▍     | 444/1000 [00:05<00:04, 123.90it/s]Processing train dataset:  91%|█████████ | 9080/10000 [02:34<00:17, 51.36it/s]Processing val dataset:  46%|████▌     | 457/1000 [00:05<00:05, 106.90it/s]Processing val dataset:  47%|████▋     | 469/1000 [00:05<00:05, 103.35it/s]
  0%|          | 0/1000 [00:00<?, ?it/s]Processing val dataset:   0%|          | 0/1000 [00:00<?, ?it/s]Processing train dataset:  91%|█████████ | 9086/10000 [02:34<00:25, 35.97it/s]Processing val dataset:  48%|████▊     | 480/1000 [00:05<00:05, 101.89it/s]Processing val dataset:  49%|████▉     | 493/1000 [00:05<00:04, 108.37it/s]Processing train dataset:  91%|█████████ | 9091/10000 [02:35<00:25, 35.24it/s]Processing val dataset:  50%|█████     | 505/1000 [00:05<00:05, 90.52it/s] Processing train dataset:  91%|█████████ | 9096/10000 [02:35<00:27, 32.52it/s]Processing val dataset:   0%|          | 1/1000 [00:00<07:03,  2.36it/s]Processing val dataset:  52%|█████▏    | 515/1000 [00:05<00:05, 91.87it/s]Processing val dataset:   0%|          | 3/1000 [00:00<02:29,  6.67it/s]Processing train dataset:  91%|█████████ | 9105/10000 [02:35<00:20, 43.13it/s]Processing val dataset:  53%|█████▎    | 528/1000 [00:05<00:04, 98.91it/s]Processing val dataset:   1%|          | 7/1000 [00:00<01:06, 14.98it/s]Processing train dataset:  91%|█████████ | 9113/10000 [02:35<00:17, 50.27it/s]Processing val dataset:   1%|          | 12/1000 [00:00<00:41, 23.91it/s]Processing val dataset:  54%|█████▍    | 539/1000 [00:06<00:04, 92.88it/s]Processing train dataset:  91%|█████████ | 9121/10000 [02:35<00:16, 53.92it/s]Processing val dataset:  55%|█████▌    | 553/1000 [00:06<00:04, 103.66it/s]Processing val dataset:   2%|▏         | 16/1000 [00:00<00:36, 27.17it/s]Processing train dataset:  91%|█████████▏| 9131/10000 [02:35<00:13, 64.47it/s]Processing val dataset:  56%|█████▋    | 564/1000 [00:06<00:04, 101.07it/s]Processing train dataset:  91%|█████████▏| 9140/10000 [02:35<00:12, 70.69it/s]Processing val dataset:   2%|▏         | 21/1000 [00:00<00:31, 30.98it/s]Processing val dataset:  57%|█████▊    | 575/1000 [00:06<00:04, 101.53it/s]Processing train dataset:  92%|█████████▏| 9150/10000 [02:35<00:10, 77.38it/s]Processing val dataset:   3%|▎         | 27/1000 [00:01<00:27, 36.02it/s]Processing val dataset:  59%|█████▊    | 587/1000 [00:06<00:03, 104.53it/s]Processing train dataset:  92%|█████████▏| 9159/10000 [02:36<00:10, 80.62it/s]Processing val dataset:   3%|▎         | 32/1000 [00:01<00:24, 39.16it/s]Processing val dataset:  60%|██████    | 600/1000 [00:06<00:03, 110.85it/s]Processing train dataset:  92%|█████████▏| 9168/10000 [02:36<00:11, 74.90it/s]Processing val dataset:   4%|▎         | 37/1000 [00:01<00:23, 40.63it/s]Processing val dataset:  61%|██████    | 612/1000 [00:06<00:03, 109.00it/s]Processing train dataset:  92%|█████████▏| 9176/10000 [02:36<00:11, 73.04it/s]Processing val dataset:   4%|▍         | 42/1000 [00:01<00:22, 41.97it/s]
  0%|          | 0/1000 [00:00<?, ?it/s]Processing test dataset:   0%|          | 0/1000 [00:00<?, ?it/s]Processing train dataset:  92%|█████████▏| 9186/10000 [02:36<00:10, 79.78it/s]Processing val dataset:   5%|▍         | 48/1000 [00:01<00:21, 45.13it/s]Processing test dataset:   0%|          | 2/1000 [00:00<01:20, 12.33it/s]Processing val dataset:  62%|██████▏   | 624/1000 [00:07<00:04, 78.10it/s] Processing train dataset:  92%|█████████▏| 9195/10000 [02:36<00:10, 79.55it/s]Processing val dataset:   5%|▌         | 53/1000 [00:01<00:20, 46.34it/s]Processing test dataset:   1%|          | 12/1000 [00:00<00:19, 51.53it/s]Processing val dataset:  63%|██████▎   | 634/1000 [00:07<00:04, 82.63it/s]Processing val dataset:   6%|▌         | 61/1000 [00:01<00:16, 55.29it/s]Processing train dataset:  92%|█████████▏| 9204/10000 [02:36<00:10, 78.39it/s]Processing test dataset:   2%|▏         | 21/1000 [00:00<00:15, 63.77it/s]Processing val dataset:   7%|▋         | 72/1000 [00:01<00:13, 69.23it/s]Processing val dataset:  64%|██████▍   | 644/1000 [00:07<00:04, 78.79it/s]Processing train dataset:  92%|█████████▏| 9212/10000 [02:36<00:11, 67.24it/s]Processing test dataset:   3%|▎         | 30/1000 [00:00<00:13, 70.45it/s]Processing val dataset:   8%|▊         | 80/1000 [00:02<00:13, 66.06it/s]Processing val dataset:  65%|██████▌   | 653/1000 [00:07<00:04, 78.63it/s]Processing train dataset:  92%|█████████▏| 9220/10000 [02:36<00:12, 62.72it/s]Processing test dataset:   4%|▍         | 38/1000 [00:00<00:13, 68.98it/s]Processing val dataset:   9%|▊         | 87/1000 [00:02<00:14, 63.19it/s]Processing val dataset:  66%|██████▌   | 662/1000 [00:07<00:04, 76.31it/s]Processing test dataset:   5%|▍         | 46/1000 [00:00<00:13, 71.20it/s]Processing train dataset:  92%|█████████▏| 9227/10000 [02:37<00:13, 58.11it/s]Processing val dataset:   9%|▉         | 94/1000 [00:02<00:14, 63.51it/s]Processing val dataset:  67%|██████▋   | 673/1000 [00:07<00:04, 81.43it/s]Processing test dataset:   6%|▌         | 55/1000 [00:00<00:12, 74.58it/s]Processing train dataset:  92%|█████████▏| 9236/10000 [02:37<00:11, 65.60it/s]Processing val dataset:  10%|█         | 101/1000 [00:02<00:14, 61.96it/s]Processing val dataset:  68%|██████▊   | 683/1000 [00:07<00:03, 85.22it/s]Processing test dataset:   6%|▋         | 64/1000 [00:00<00:12, 77.30it/s]Processing train dataset:  92%|█████████▏| 9243/10000 [02:37<00:11, 65.25it/s]Processing val dataset:  69%|██████▉   | 694/1000 [00:07<00:03, 89.26it/s]Processing val dataset:  11%|█         | 108/1000 [00:02<00:14, 60.71it/s]Processing test dataset:   7%|▋         | 73/1000 [00:01<00:11, 78.75it/s]Processing val dataset:  70%|███████   | 704/1000 [00:07<00:03, 91.24it/s]Processing train dataset:  92%|█████████▎| 9250/10000 [02:37<00:12, 59.10it/s]Processing val dataset:  12%|█▏        | 115/1000 [00:02<00:14, 59.11it/s]Processing test dataset:   8%|▊         | 83/1000 [00:01<00:11, 81.89it/s]Processing train dataset:  93%|█████████▎| 9257/10000 [02:37<00:12, 60.14it/s]Processing val dataset:  12%|█▏        | 123/1000 [00:02<00:13, 64.55it/s]Processing val dataset:  71%|███████▏  | 714/1000 [00:08<00:03, 84.38it/s]Processing test dataset:   9%|▉         | 92/1000 [00:01<00:11, 81.20it/s]Processing val dataset:  13%|█▎        | 131/1000 [00:02<00:12, 68.40it/s]Processing train dataset:  93%|█████████▎| 9264/10000 [02:37<00:12, 60.52it/s]Processing val dataset:  72%|███████▏  | 723/1000 [00:08<00:03, 83.92it/s]Processing test dataset:  10%|█         | 101/1000 [00:01<00:11, 80.27it/s]Processing val dataset:  14%|█▍        | 138/1000 [00:02<00:12, 67.41it/s]Processing val dataset:  73%|███████▎  | 732/1000 [00:08<00:03, 84.57it/s]Processing train dataset:  93%|█████████▎| 9271/10000 [02:37<00:12, 60.20it/s]Processing test dataset:  11%|█         | 110/1000 [00:01<00:10, 81.25it/s]Processing val dataset:  14%|█▍        | 145/1000 [00:03<00:12, 67.22it/s]Processing val dataset:  74%|███████▍  | 742/1000 [00:08<00:02, 87.25it/s]Processing test dataset:  12%|█▏        | 120/1000 [00:01<00:10, 82.88it/s]Processing train dataset:  93%|█████████▎| 9278/10000 [02:37<00:13, 54.70it/s]Processing val dataset:  75%|███████▌  | 751/1000 [00:08<00:02, 87.56it/s]Processing val dataset:  15%|█▌        | 152/1000 [00:03<00:13, 64.07it/s]Processing train dataset:  93%|█████████▎| 9284/10000 [02:38<00:12, 55.38it/s]Processing test dataset:  13%|█▎        | 129/1000 [00:01<00:10, 82.26it/s]Processing val dataset:  76%|███████▌  | 762/1000 [00:08<00:02, 93.30it/s]Processing val dataset:  16%|█▌        | 159/1000 [00:03<00:12, 64.75it/s]Processing train dataset:  93%|█████████▎| 9292/10000 [02:38<00:11, 60.67it/s]Processing test dataset:  14%|█▍        | 138/1000 [00:01<00:10, 80.38it/s]Processing val dataset:  77%|███████▋  | 773/1000 [00:08<00:02, 95.71it/s]Processing val dataset:  17%|█▋        | 167/1000 [00:03<00:12, 67.75it/s]Processing train dataset:  93%|█████████▎| 9299/10000 [02:38<00:11, 60.82it/s]Processing test dataset:  15%|█▍        | 147/1000 [00:01<00:10, 80.53it/s]Processing val dataset:  78%|███████▊  | 783/1000 [00:08<00:02, 95.57it/s]Processing val dataset:  18%|█▊        | 176/1000 [00:03<00:11, 72.46it/s]Processing test dataset:  16%|█▌        | 156/1000 [00:02<00:10, 79.71it/s]Processing train dataset:  93%|█████████▎| 9306/10000 [02:38<00:11, 58.64it/s]Processing val dataset:  19%|█▊        | 186/1000 [00:03<00:10, 78.86it/s]Processing val dataset:  79%|███████▉  | 793/1000 [00:08<00:02, 90.90it/s]Processing train dataset:  93%|█████████▎| 9312/10000 [02:38<00:11, 58.55it/s]Processing test dataset:  16%|█▋        | 165/1000 [00:02<00:10, 79.45it/s]Processing val dataset:  80%|████████  | 803/1000 [00:09<00:02, 93.02it/s]Processing val dataset:  20%|█▉        | 195/1000 [00:03<00:10, 79.74it/s]Processing test dataset:  17%|█▋        | 174/1000 [00:02<00:10, 81.35it/s]Processing train dataset:  93%|█████████▎| 9318/10000 [02:38<00:12, 55.10it/s]Processing val dataset:  21%|██        | 206/1000 [00:03<00:09, 87.94it/s]Processing val dataset:  81%|████████▏ | 813/1000 [00:09<00:02, 88.76it/s]Processing test dataset:  18%|█▊        | 184/1000 [00:02<00:09, 84.64it/s]Processing val dataset:  22%|██▏       | 219/1000 [00:03<00:07, 97.88it/s]Processing train dataset:  93%|█████████▎| 9325/10000 [02:38<00:11, 56.50it/s]Processing val dataset:  82%|████████▏ | 822/1000 [00:09<00:02, 87.18it/s]Processing test dataset:  19%|█▉        | 193/1000 [00:02<00:09, 85.34it/s]Processing val dataset:  23%|██▎       | 230/1000 [00:03<00:07, 98.67it/s]Processing train dataset:  93%|█████████▎| 9331/10000 [02:38<00:12, 53.88it/s]Processing val dataset:  83%|████████▎ | 831/1000 [00:09<00:02, 82.38it/s]Processing test dataset:  20%|██        | 202/1000 [00:02<00:09, 85.43it/s]Processing val dataset:  24%|██▍       | 240/1000 [00:04<00:07, 97.56it/s]Processing train dataset:  93%|█████████▎| 9339/10000 [02:39<00:11, 55.77it/s]Processing val dataset:  84%|████████▍ | 840/1000 [00:09<00:01, 80.72it/s]Processing test dataset:  21%|██        | 211/1000 [00:02<00:09, 83.23it/s]Processing val dataset:  25%|██▌       | 250/1000 [00:04<00:08, 90.24it/s]Processing train dataset:  93%|█████████▎| 9345/10000 [02:39<00:11, 56.50it/s]Processing val dataset:  85%|████████▍ | 849/1000 [00:09<00:01, 81.06it/s]Processing test dataset:  22%|██▏       | 220/1000 [00:02<00:09, 82.87it/s]Processing train dataset:  94%|█████████▎| 9351/10000 [02:39<00:11, 56.51it/s]Processing val dataset:  26%|██▌       | 260/1000 [00:04<00:08, 83.90it/s]Processing val dataset:  86%|████████▌ | 858/1000 [00:09<00:01, 79.39it/s]Processing test dataset:  23%|██▎       | 229/1000 [00:02<00:09, 83.36it/s]Processing train dataset:  94%|█████████▎| 9359/10000 [02:39<00:10, 59.17it/s]Processing val dataset:  87%|████████▋ | 866/1000 [00:09<00:01, 78.69it/s]Processing val dataset:  27%|██▋       | 269/1000 [00:04<00:08, 82.76it/s]Processing test dataset:  24%|██▍       | 238/1000 [00:03<00:09, 80.02it/s]Processing val dataset:  88%|████████▊ | 875/1000 [00:09<00:01, 80.74it/s]Processing train dataset:  94%|█████████▎| 9366/10000 [02:39<00:10, 60.62it/s]Processing val dataset:  28%|██▊       | 278/1000 [00:04<00:09, 76.15it/s]Processing test dataset:  25%|██▍       | 247/1000 [00:03<00:09, 80.48it/s]Processing train dataset:  94%|█████████▎| 9373/10000 [02:39<00:09, 63.17it/s]Processing val dataset:  88%|████████▊ | 885/1000 [00:10<00:01, 83.85it/s]Processing val dataset:  29%|██▉       | 288/1000 [00:04<00:08, 81.86it/s]Processing test dataset:  26%|██▌       | 256/1000 [00:03<00:09, 75.91it/s]Processing train dataset:  94%|█████████▍| 9381/10000 [02:39<00:09, 67.52it/s]Processing val dataset:  89%|████████▉ | 894/1000 [00:10<00:01, 82.30it/s]Processing val dataset:  30%|██▉       | 297/1000 [00:04<00:08, 81.88it/s]Processing test dataset:  26%|██▋       | 264/1000 [00:03<00:09, 74.94it/s]Processing train dataset:  94%|█████████▍| 9390/10000 [02:39<00:08, 72.13it/s]Processing val dataset:  90%|█████████ | 905/1000 [00:10<00:01, 88.10it/s]Processing val dataset:  31%|███       | 306/1000 [00:04<00:08, 81.88it/s]Processing test dataset:  27%|██▋       | 273/1000 [00:03<00:09, 77.86it/s]Processing train dataset:  94%|█████████▍| 9398/10000 [02:39<00:08, 73.98it/s]Processing val dataset:  92%|█████████▏| 915/1000 [00:10<00:00, 90.58it/s]Processing val dataset:  32%|███▏      | 315/1000 [00:05<00:08, 80.26it/s]Processing test dataset:  28%|██▊       | 282/1000 [00:03<00:09, 79.49it/s]Processing train dataset:  94%|█████████▍| 9406/10000 [02:40<00:08, 73.53it/s]Processing val dataset:  92%|█████████▎| 925/1000 [00:10<00:00, 89.79it/s]Processing val dataset:  32%|███▏      | 324/1000 [00:05<00:08, 78.82it/s]Processing test dataset:  29%|██▉       | 291/1000 [00:03<00:08, 79.57it/s]Processing train dataset:  94%|█████████▍| 9414/10000 [02:40<00:07, 74.06it/s]Processing val dataset:  94%|█████████▎| 935/1000 [00:10<00:00, 91.38it/s]Processing val dataset:  33%|███▎      | 332/1000 [00:05<00:08, 79.03it/s]Processing test dataset:  30%|███       | 303/1000 [00:03<00:07, 89.78it/s]Processing train dataset:  94%|█████████▍| 9423/10000 [02:40<00:07, 76.29it/s]Processing val dataset:  94%|█████████▍| 945/1000 [00:10<00:00, 90.29it/s]Processing val dataset:  34%|███▍      | 341/1000 [00:05<00:08, 80.09it/s]Processing test dataset:  32%|███▏      | 315/1000 [00:03<00:07, 95.11it/s]Processing train dataset:  94%|█████████▍| 9432/10000 [02:40<00:07, 74.87it/s]Processing val dataset:  96%|█████████▌| 955/1000 [00:10<00:00, 88.15it/s]Processing val dataset:  35%|███▌      | 350/1000 [00:05<00:08, 77.12it/s]Processing test dataset:  32%|███▎      | 325/1000 [00:04<00:07, 92.42it/s]Processing train dataset:  94%|█████████▍| 9440/10000 [02:40<00:07, 76.05it/s]Processing val dataset:  96%|█████████▋| 964/1000 [00:10<00:00, 88.41it/s]Processing val dataset:  36%|███▌      | 358/1000 [00:05<00:09, 70.79it/s]Processing train dataset:  94%|█████████▍| 9449/10000 [02:40<00:06, 79.32it/s]Processing test dataset:  34%|███▎      | 335/1000 [00:04<00:07, 85.61it/s]Processing val dataset:  97%|█████████▋| 973/1000 [00:11<00:00, 81.72it/s]Processing train dataset:  95%|█████████▍| 9457/10000 [02:40<00:06, 78.87it/s]Processing val dataset:  37%|███▋      | 366/1000 [00:05<00:08, 70.85it/s]Processing test dataset:  34%|███▍      | 344/1000 [00:04<00:07, 83.98it/s]Processing val dataset:  98%|█████████▊| 982/1000 [00:11<00:00, 81.54it/s]Processing train dataset:  95%|█████████▍| 9465/10000 [02:40<00:06, 78.02it/s]Processing val dataset:  37%|███▋      | 374/1000 [00:05<00:08, 71.53it/s]Processing test dataset:  35%|███▌      | 354/1000 [00:04<00:07, 85.83it/s]Processing val dataset:  99%|█████████▉| 992/1000 [00:11<00:00, 84.95it/s]Processing train dataset:  95%|█████████▍| 9473/10000 [02:40<00:06, 78.54it/s]Processing val dataset:  38%|███▊      | 382/1000 [00:05<00:08, 71.49it/s]Processing test dataset:  37%|███▋      | 366/1000 [00:04<00:06, 93.97it/s]Processing val dataset: 100%|██████████| 1000/1000 [00:11<00:00, 87.98it/s]Processing train dataset:  95%|█████████▍| 9481/10000 [02:40<00:06, 77.34it/s]Processing val dataset:  39%|███▉      | 390/1000 [00:06<00:08, 71.29it/s]Processing test dataset:  38%|███▊      | 376/1000 [00:04<00:07, 85.63it/s]Processing train dataset:  95%|█████████▍| 9489/10000 [02:41<00:06, 77.28it/s]Processing val dataset:  40%|████      | 400/1000 [00:06<00:07, 78.79it/s]Processing test dataset:  38%|███▊      | 385/1000 [00:04<00:07, 84.14it/s]Processing train dataset:  95%|█████████▍| 9497/10000 [02:41<00:06, 75.14it/s]Processing val dataset:  41%|████      | 409/1000 [00:06<00:07, 81.83it/s]Processing test dataset:  40%|███▉      | 396/1000 [00:04<00:06, 89.99it/s]Processing train dataset:  95%|█████████▌| 9505/10000 [02:41<00:06, 75.83it/s]Processing val dataset:  42%|████▏     | 418/1000 [00:06<00:07, 79.43it/s]Processing test dataset:  41%|████      | 408/1000 [00:04<00:06, 97.49it/s]Processing train dataset:  95%|█████████▌| 9515/10000 [02:41<00:06, 80.45it/s]Processing test dataset:  42%|████▏     | 420/1000 [00:05<00:05, 100.29it/s]Processing val dataset:  43%|████▎     | 427/1000 [00:06<00:09, 59.68it/s]
  0%|          | 0/1000 [00:00<?, ?it/s]Processing val dataset:   0%|          | 0/1000 [00:00<?, ?it/s]Processing train dataset:  95%|█████████▌| 9524/10000 [02:41<00:07, 64.07it/s]Processing val dataset:  43%|████▎     | 434/1000 [00:06<00:09, 61.88it/s]Processing test dataset:  43%|████▎     | 431/1000 [00:05<00:06, 81.64it/s] Processing train dataset:  95%|█████████▌| 9531/10000 [02:41<00:08, 57.25it/s]Processing val dataset:  44%|████▍     | 442/1000 [00:06<00:08, 62.86it/s]Processing test dataset:  44%|████▍     | 440/1000 [00:05<00:07, 70.32it/s]Processing val dataset:   0%|          | 1/1000 [00:00<04:47,  3.47it/s]Processing train dataset:  95%|█████████▌| 9539/10000 [02:41<00:07, 61.05it/s]Processing val dataset:  45%|████▌     | 452/1000 [00:06<00:07, 71.23it/s]Processing test dataset:  45%|████▍     | 449/1000 [00:05<00:07, 73.70it/s]Processing val dataset:   1%|          | 7/1000 [00:00<00:45, 21.69it/s]Processing val dataset:  46%|████▌     | 460/1000 [00:07<00:07, 70.11it/s]Processing train dataset:  95%|█████████▌| 9546/10000 [02:42<00:07, 58.82it/s]Processing test dataset:  46%|████▌     | 459/1000 [00:05<00:06, 79.28it/s]Processing val dataset:   2%|▏         | 15/1000 [00:00<00:26, 36.60it/s]Processing val dataset:  47%|████▋     | 468/1000 [00:07<00:07, 67.26it/s]Processing train dataset:  96%|█████████▌| 9553/10000 [02:42<00:07, 56.85it/s]Processing test dataset:  47%|████▋     | 468/1000 [00:05<00:07, 75.40it/s]Processing val dataset:   2%|▏         | 23/1000 [00:00<00:19, 49.08it/s]Processing val dataset:  48%|████▊     | 478/1000 [00:07<00:07, 73.51it/s]Processing train dataset:  96%|█████████▌| 9560/10000 [02:42<00:08, 54.44it/s]Processing test dataset:  48%|████▊     | 476/1000 [00:05<00:06, 76.42it/s]Processing val dataset:   3%|▎         | 31/1000 [00:00<00:16, 57.96it/s]Processing val dataset:  49%|████▊     | 487/1000 [00:07<00:06, 75.62it/s]Processing train dataset:  96%|█████████▌| 9569/10000 [02:42<00:06, 61.98it/s]Processing val dataset:   4%|▍         | 39/1000 [00:00<00:14, 64.18it/s]Processing test dataset:  49%|████▊     | 487/1000 [00:06<00:06, 83.57it/s]Processing val dataset:  50%|████▉     | 495/1000 [00:07<00:06, 73.16it/s]Processing val dataset:   5%|▍         | 47/1000 [00:00<00:14, 66.29it/s]Processing test dataset:  50%|████▉     | 496/1000 [00:06<00:06, 81.41it/s]Processing train dataset:  96%|█████████▌| 9576/10000 [02:42<00:07, 57.23it/s]Processing val dataset:  50%|█████     | 504/1000 [00:07<00:06, 71.89it/s]Processing val dataset:   6%|▌         | 55/1000 [00:01<00:14, 65.55it/s]Processing test dataset:  50%|█████     | 505/1000 [00:06<00:06, 76.64it/s]Processing train dataset:  96%|█████████▌| 9582/10000 [02:42<00:07, 54.29it/s]Processing val dataset:  51%|█████▏    | 514/1000 [00:07<00:06, 78.07it/s]Processing val dataset:   6%|▌         | 62/1000 [00:01<00:15, 59.59it/s]Processing test dataset:  51%|█████▏    | 513/1000 [00:06<00:06, 71.89it/s]Processing train dataset:  96%|█████████▌| 9588/10000 [02:42<00:08, 51.29it/s]Processing val dataset:  52%|█████▏    | 522/1000 [00:07<00:06, 72.61it/s]Processing val dataset:   7%|▋         | 70/1000 [00:01<00:14, 64.70it/s]Processing test dataset:  52%|█████▏    | 522/1000 [00:06<00:06, 75.32it/s]Processing train dataset:  96%|█████████▌| 9594/10000 [02:42<00:08, 50.23it/s]Processing val dataset:  53%|█████▎    | 530/1000 [00:08<00:06, 71.71it/s]Processing val dataset:   8%|▊         | 78/1000 [00:01<00:13, 66.72it/s]Processing test dataset:  53%|█████▎    | 532/1000 [00:06<00:05, 80.68it/s]Processing val dataset:  54%|█████▍    | 540/1000 [00:08<00:05, 78.77it/s]Processing val dataset:   8%|▊         | 85/1000 [00:01<00:13, 66.29it/s]Processing test dataset:  54%|█████▍    | 541/1000 [00:06<00:05, 80.94it/s]Processing train dataset:  96%|█████████▌| 9604/10000 [02:43<00:08, 45.37it/s]Processing val dataset:   9%|▉         | 92/1000 [00:01<00:14, 64.55it/s]Processing val dataset:  55%|█████▍    | 549/1000 [00:08<00:06, 69.09it/s]Processing test dataset:  55%|█████▌    | 550/1000 [00:06<00:05, 79.14it/s]Processing train dataset:  96%|█████████▌| 9609/10000 [02:43<00:08, 46.19it/s]Processing val dataset:  10%|█         | 101/1000 [00:01<00:12, 69.88it/s]Processing val dataset:  56%|█████▌    | 558/1000 [00:08<00:05, 74.17it/s]Processing test dataset:  56%|█████▌    | 558/1000 [00:06<00:05, 77.05it/s]Processing train dataset:  96%|█████████▌| 9615/10000 [02:43<00:07, 49.29it/s]Processing val dataset:  11%|█         | 109/1000 [00:01<00:12, 72.21it/s]Processing val dataset:  57%|█████▋    | 567/1000 [00:08<00:05, 76.85it/s]Processing test dataset:  57%|█████▋    | 569/1000 [00:07<00:05, 84.77it/s]Processing train dataset:  96%|█████████▌| 9621/10000 [02:43<00:07, 48.78it/s]Processing val dataset:  12%|█▏        | 117/1000 [00:01<00:11, 74.21it/s]Processing val dataset:  58%|█████▊    | 576/1000 [00:08<00:05, 78.44it/s]Processing test dataset:  58%|█████▊    | 578/1000 [00:07<00:04, 85.14it/s]Processing val dataset:  13%|█▎        | 129/1000 [00:02<00:10, 85.16it/s]Processing train dataset:  96%|█████████▋| 9627/10000 [02:43<00:07, 46.92it/s]Processing test dataset:  59%|█████▉    | 588/1000 [00:07<00:04, 89.16it/s]Processing val dataset:  58%|█████▊    | 585/1000 [00:08<00:05, 73.44it/s]Processing train dataset:  96%|█████████▋| 9635/10000 [02:43<00:06, 54.46it/s]Processing test dataset:  60%|█████▉    | 598/1000 [00:07<00:04, 90.45it/s]Processing val dataset:  14%|█▍        | 138/1000 [00:02<00:10, 79.77it/s]Processing val dataset:  59%|█████▉    | 593/1000 [00:08<00:05, 74.89it/s]Processing train dataset:  96%|█████████▋| 9646/10000 [02:43<00:05, 68.29it/s]Processing test dataset:  61%|██████    | 608/1000 [00:07<00:04, 90.87it/s]
  0%|          | 0/1000 [00:00<?, ?it/s]Processing test dataset:   0%|          | 0/1000 [00:00<?, ?it/s]Processing train dataset:  97%|█████████▋| 9659/10000 [02:43<00:04, 77.22it/s]Processing val dataset:  60%|██████    | 601/1000 [00:09<00:06, 59.33it/s]Processing test dataset:  62%|██████▏   | 618/1000 [00:07<00:04, 86.00it/s]Processing val dataset:  15%|█▍        | 147/1000 [00:02<00:14, 59.22it/s]Processing test dataset:   0%|          | 1/1000 [00:00<02:16,  7.32it/s]Processing train dataset:  97%|█████████▋| 9669/10000 [02:44<00:04, 80.92it/s]Processing val dataset:  61%|██████    | 609/1000 [00:09<00:06, 63.32it/s]Processing test dataset:  63%|██████▎   | 629/1000 [00:07<00:04, 79.85it/s]Processing val dataset:  15%|█▌        | 154/1000 [00:02<00:15, 55.45it/s]Processing test dataset:   1%|          | 8/1000 [00:00<00:27, 36.35it/s]Processing val dataset:  62%|██████▏   | 616/1000 [00:09<00:06, 59.87it/s]Processing train dataset:  97%|█████████▋| 9678/10000 [02:44<00:04, 69.89it/s]Processing test dataset:  64%|██████▍   | 638/1000 [00:07<00:04, 77.57it/s]Processing test dataset:   1%|▏         | 14/1000 [00:00<00:24, 40.85it/s]Processing val dataset:  62%|██████▏   | 623/1000 [00:09<00:06, 57.95it/s]Processing val dataset:  16%|█▌        | 161/1000 [00:02<00:17, 47.97it/s]Processing test dataset:  65%|██████▍   | 646/1000 [00:08<00:04, 73.66it/s]Processing train dataset:  97%|█████████▋| 9686/10000 [02:44<00:04, 65.82it/s]Processing test dataset:   2%|▏         | 20/1000 [00:00<00:20, 46.83it/s]Processing val dataset:  63%|██████▎   | 633/1000 [00:09<00:05, 65.89it/s]Processing val dataset:  17%|█▋        | 167/1000 [00:02<00:17, 48.30it/s]Processing test dataset:  66%|██████▌   | 656/1000 [00:08<00:04, 79.69it/s]Processing train dataset:  97%|█████████▋| 9694/10000 [02:44<00:04, 68.62it/s]Processing test dataset:   3%|▎         | 27/1000 [00:00<00:18, 52.01it/s]Processing val dataset:  64%|██████▍   | 640/1000 [00:09<00:05, 64.05it/s]Processing val dataset:  17%|█▋        | 173/1000 [00:03<00:17, 47.61it/s]Processing test dataset:  66%|██████▋   | 665/1000 [00:08<00:04, 79.19it/s]Processing train dataset:  97%|█████████▋| 9702/10000 [02:44<00:04, 65.59it/s]Processing test dataset:   4%|▎         | 36/1000 [00:00<00:15, 61.23it/s]Processing val dataset:  65%|██████▍   | 647/1000 [00:09<00:05, 65.37it/s]Processing val dataset:  18%|█▊        | 180/1000 [00:03<00:15, 51.56it/s]Processing test dataset:  67%|██████▋   | 674/1000 [00:08<00:04, 78.30it/s]Processing train dataset:  97%|█████████▋| 9709/10000 [02:44<00:04, 63.74it/s]Processing test dataset:   4%|▍         | 43/1000 [00:00<00:15, 61.42it/s]Processing val dataset:  65%|██████▌   | 654/1000 [00:09<00:05, 63.56it/s]Processing val dataset:  19%|█▊        | 186/1000 [00:03<00:15, 51.84it/s]Processing test dataset:  68%|██████▊   | 682/1000 [00:08<00:04, 76.81it/s]Processing train dataset:  97%|█████████▋| 9717/10000 [02:44<00:04, 66.69it/s]Processing test dataset:   5%|▌         | 50/1000 [00:00<00:15, 62.87it/s]Processing test dataset:  69%|██████▉   | 690/1000 [00:08<00:04, 76.17it/s]Processing val dataset:  66%|██████▌   | 661/1000 [00:10<00:05, 58.18it/s]Processing val dataset:  19%|█▉        | 192/1000 [00:03<00:16, 48.81it/s]Processing test dataset:   6%|▌         | 57/1000 [00:01<00:15, 61.42it/s]Processing train dataset:  97%|█████████▋| 9724/10000 [02:45<00:04, 61.53it/s]Processing test dataset:  70%|██████▉   | 698/1000 [00:08<00:03, 76.24it/s]Processing val dataset:  67%|██████▋   | 670/1000 [00:10<00:05, 63.19it/s]Processing val dataset:  20%|█▉        | 199/1000 [00:03<00:15, 53.25it/s]Processing test dataset:   6%|▋         | 64/1000 [00:01<00:15, 61.76it/s]Processing train dataset:  97%|█████████▋| 9731/10000 [02:45<00:04, 58.42it/s]Processing test dataset:  71%|███████   | 706/1000 [00:08<00:03, 74.66it/s]Processing val dataset:  68%|██████▊   | 677/1000 [00:10<00:05, 60.13it/s]Processing test dataset:   7%|▋         | 71/1000 [00:01<00:14, 63.76it/s]Processing val dataset:  20%|██        | 205/1000 [00:03<00:15, 50.07it/s]Processing test dataset:  71%|███████▏  | 714/1000 [00:08<00:03, 74.84it/s]Processing train dataset:  97%|█████████▋| 9738/10000 [02:45<00:04, 52.95it/s]Processing val dataset:  21%|██        | 211/1000 [00:03<00:16, 49.01it/s]Processing test dataset:   8%|▊         | 78/1000 [00:01<00:16, 56.38it/s]Processing test dataset:  72%|███████▏  | 722/1000 [00:09<00:03, 73.05it/s]Processing val dataset:  68%|██████▊   | 684/1000 [00:10<00:06, 45.46it/s]Processing val dataset:  22%|██▏       | 219/1000 [00:03<00:14, 55.36it/s]Processing test dataset:   8%|▊         | 85/1000 [00:01<00:15, 57.95it/s]Processing test dataset:  73%|███████▎  | 730/1000 [00:09<00:03, 73.97it/s]Processing val dataset:  22%|██▎       | 225/1000 [00:04<00:14, 54.50it/s]Processing val dataset:  69%|██████▉   | 690/1000 [00:10<00:06, 45.25it/s]Processing test dataset:  74%|███████▍  | 739/1000 [00:09<00:03, 76.92it/s]Processing test dataset:   9%|▉         | 92/1000 [00:01<00:15, 58.02it/s]Processing train dataset:  97%|█████████▋| 9744/10000 [02:45<00:07, 34.76it/s]Processing val dataset:  23%|██▎       | 232/1000 [00:04<00:13, 57.36it/s]Processing test dataset:  10%|▉         | 98/1000 [00:01<00:15, 58.06it/s]Processing test dataset:  75%|███████▍  | 747/1000 [00:09<00:03, 75.93it/s]Processing val dataset:  70%|██████▉   | 695/1000 [00:10<00:06, 43.70it/s]Processing train dataset:  98%|█████████▊| 9750/10000 [02:45<00:06, 38.26it/s]Processing val dataset:  24%|██▍       | 239/1000 [00:04<00:12, 59.73it/s]Processing test dataset:  10%|█         | 105/1000 [00:01<00:14, 60.97it/s]Processing test dataset:  76%|███████▌  | 757/1000 [00:09<00:02, 81.96it/s]Processing val dataset:  70%|███████   | 702/1000 [00:10<00:06, 46.80it/s]Processing train dataset:  98%|█████████▊| 9757/10000 [02:45<00:05, 44.06it/s]Processing val dataset:  25%|██▍       | 246/1000 [00:04<00:13, 56.99it/s]Processing test dataset:  11%|█         | 112/1000 [00:01<00:14, 61.04it/s]Processing test dataset:  77%|███████▋  | 766/1000 [00:09<00:02, 79.48it/s]Processing val dataset:  71%|███████   | 708/1000 [00:11<00:06, 48.45it/s]Processing train dataset:  98%|█████████▊| 9764/10000 [02:45<00:04, 48.11it/s]Processing val dataset:  26%|██▌       | 255/1000 [00:04<00:11, 65.09it/s]Processing test dataset:  12%|█▏        | 120/1000 [00:02<00:13, 64.55it/s]Processing test dataset:  78%|███████▊  | 775/1000 [00:09<00:02, 82.15it/s]Processing train dataset:  98%|█████████▊| 9774/10000 [02:46<00:03, 60.05it/s]Processing val dataset:  71%|███████▏  | 714/1000 [00:11<00:06, 45.81it/s]Processing test dataset:  13%|█▎        | 127/1000 [00:02<00:13, 66.04it/s]Processing val dataset:  26%|██▋       | 263/1000 [00:04<00:10, 67.15it/s]Processing test dataset:  78%|███████▊  | 784/1000 [00:09<00:02, 82.56it/s]Processing train dataset:  98%|█████████▊| 9784/10000 [02:46<00:03, 68.84it/s]Processing test dataset:  13%|█▎        | 134/1000 [00:02<00:12, 66.90it/s]Processing val dataset:  72%|███████▏  | 721/1000 [00:11<00:05, 47.50it/s]Processing val dataset:  27%|██▋       | 271/1000 [00:04<00:10, 68.71it/s]Processing test dataset:  79%|███████▉  | 793/1000 [00:09<00:02, 82.76it/s]Processing train dataset:  98%|█████████▊| 9792/10000 [02:46<00:02, 71.05it/s]Processing val dataset:  73%|███████▎  | 730/1000 [00:11<00:04, 56.15it/s]Processing test dataset:  14%|█▍        | 141/1000 [00:02<00:13, 64.91it/s]Processing test dataset:  80%|████████  | 802/1000 [00:09<00:02, 84.53it/s]Processing val dataset:  28%|██▊       | 279/1000 [00:04<00:10, 69.85it/s]Processing train dataset:  98%|█████████▊| 9800/10000 [02:46<00:02, 68.70it/s]Processing val dataset:  74%|███████▍  | 738/1000 [00:11<00:04, 61.70it/s]Processing test dataset:  15%|█▍        | 149/1000 [00:02<00:12, 67.42it/s]Processing val dataset:  29%|██▉       | 288/1000 [00:04<00:09, 74.76it/s]Processing test dataset:  81%|████████  | 811/1000 [00:10<00:02, 83.40it/s]Processing train dataset:  98%|█████████▊| 9808/10000 [02:46<00:02, 70.69it/s]Processing val dataset:  75%|███████▍  | 746/1000 [00:11<00:03, 66.41it/s]Processing val dataset:  30%|██▉       | 296/1000 [00:05<00:09, 75.35it/s]Processing test dataset:  82%|████████▏ | 821/1000 [00:10<00:02, 84.61it/s]Processing test dataset:  16%|█▌        | 156/1000 [00:02<00:13, 63.41it/s]Processing train dataset:  98%|█████████▊| 9816/10000 [02:46<00:02, 68.94it/s]Processing val dataset:  30%|███       | 304/1000 [00:05<00:09, 74.25it/s]Processing test dataset:  83%|████████▎ | 830/1000 [00:10<00:01, 85.84it/s]Processing test dataset:  16%|█▋        | 163/1000 [00:02<00:13, 62.97it/s]Processing val dataset:  75%|███████▌  | 754/1000 [00:11<00:04, 61.23it/s]Processing train dataset:  98%|█████████▊| 9825/10000 [02:46<00:02, 73.02it/s]Processing val dataset:  31%|███       | 312/1000 [00:05<00:09, 72.52it/s]Processing test dataset:  84%|████████▍ | 839/1000 [00:10<00:01, 83.27it/s]Processing test dataset:  17%|█▋        | 170/1000 [00:02<00:13, 63.76it/s]Processing val dataset:  76%|███████▌  | 761/1000 [00:11<00:04, 55.61it/s]Processing train dataset:  98%|█████████▊| 9836/10000 [02:46<00:02, 81.46it/s]Processing test dataset:  18%|█▊        | 178/1000 [00:02<00:12, 67.86it/s]Processing val dataset:  32%|███▏      | 320/1000 [00:05<00:09, 70.76it/s]Processing test dataset:  85%|████████▍ | 848/1000 [00:10<00:01, 80.74it/s]Processing val dataset:  77%|███████▋  | 767/1000 [00:12<00:04, 50.93it/s]Processing train dataset:  98%|█████████▊| 9845/10000 [02:47<00:02, 73.52it/s]Processing test dataset:  19%|█▊        | 187/1000 [00:03<00:11, 71.98it/s]Processing val dataset:  33%|███▎      | 328/1000 [00:05<00:09, 71.64it/s]Processing test dataset:  86%|████████▌ | 857/1000 [00:10<00:01, 78.40it/s]Processing train dataset:  99%|█████████▊| 9854/10000 [02:47<00:01, 77.40it/s]Processing test dataset:  20%|█▉        | 197/1000 [00:03<00:10, 76.91it/s]Processing val dataset:  34%|███▎      | 337/1000 [00:05<00:08, 74.42it/s]Processing test dataset:  86%|████████▋ | 865/1000 [00:10<00:01, 77.42it/s]Processing val dataset:  77%|███████▋  | 773/1000 [00:12<00:04, 46.19it/s]Processing val dataset:  35%|███▍      | 346/1000 [00:05<00:08, 78.68it/s]Processing test dataset:  21%|██        | 206/1000 [00:03<00:10, 78.22it/s]Processing test dataset:  87%|████████▋ | 873/1000 [00:10<00:01, 75.71it/s]Processing train dataset:  99%|█████████▊| 9863/10000 [02:47<00:01, 71.51it/s]Processing val dataset:  78%|███████▊  | 780/1000 [00:12<00:04, 51.13it/s]Processing val dataset:  35%|███▌      | 354/1000 [00:05<00:08, 77.99it/s]Processing test dataset:  21%|██▏       | 214/1000 [00:03<00:10, 75.36it/s]Processing test dataset:  88%|████████▊ | 881/1000 [00:11<00:01, 73.76it/s]Processing train dataset:  99%|█████████▊| 9871/10000 [02:47<00:01, 71.13it/s]Processing val dataset:  79%|███████▊  | 786/1000 [00:12<00:04, 52.84it/s]Processing val dataset:  36%|███▌      | 362/1000 [00:05<00:08, 75.51it/s]Processing test dataset:  89%|████████▉ | 889/1000 [00:11<00:01, 74.43it/s]Processing test dataset:  22%|██▏       | 222/1000 [00:03<00:10, 71.17it/s]Processing val dataset:  79%|███████▉  | 792/1000 [00:12<00:04, 49.86it/s]Processing val dataset:  37%|███▋      | 370/1000 [00:06<00:08, 73.89it/s]Processing train dataset:  99%|█████████▉| 9879/10000 [02:47<00:02, 58.85it/s]Processing test dataset:  90%|████████▉ | 898/1000 [00:11<00:01, 76.68it/s]Processing test dataset:  23%|██▎       | 230/1000 [00:03<00:11, 67.00it/s]Processing val dataset:  80%|███████▉  | 798/1000 [00:12<00:03, 50.61it/s]Processing val dataset:  38%|███▊      | 378/1000 [00:06<00:08, 74.43it/s]Processing test dataset:  91%|█████████ | 906/1000 [00:11<00:01, 76.45it/s]Processing train dataset:  99%|█████████▉| 9886/10000 [02:47<00:02, 55.58it/s]Processing test dataset:  24%|██▎       | 237/1000 [00:03<00:11, 65.83it/s]Processing val dataset:  80%|████████  | 804/1000 [00:12<00:03, 49.16it/s]Processing val dataset:  39%|███▊      | 386/1000 [00:06<00:08, 73.83it/s]Processing test dataset:  92%|█████████▏| 915/1000 [00:11<00:01, 77.50it/s]Processing test dataset:  24%|██▍       | 245/1000 [00:03<00:10, 69.51it/s]Processing train dataset:  99%|█████████▉| 9892/10000 [02:47<00:01, 54.06it/s]Processing val dataset:  81%|████████  | 810/1000 [00:12<00:03, 51.16it/s]Processing val dataset:  39%|███▉      | 394/1000 [00:06<00:08, 73.59it/s]Processing test dataset:  92%|█████████▏| 923/1000 [00:11<00:01, 76.80it/s]Processing test dataset:  25%|██▌       | 253/1000 [00:03<00:10, 71.06it/s]Processing train dataset:  99%|█████████▉| 9899/10000 [02:47<00:01, 56.85it/s]Processing val dataset:  82%|████████▏ | 816/1000 [00:13<00:03, 51.05it/s]Processing val dataset:  41%|████      | 406/1000 [00:06<00:07, 83.94it/s]Processing test dataset:  93%|█████████▎| 931/1000 [00:11<00:00, 73.65it/s]Processing test dataset:  26%|██▌       | 261/1000 [00:04<00:10, 70.25it/s]Processing train dataset:  99%|█████████▉| 9905/10000 [02:48<00:01, 51.33it/s]Processing val dataset:  82%|████████▏ | 822/1000 [00:13<00:03, 49.17it/s]Processing val dataset:  42%|████▏     | 415/1000 [00:06<00:07, 79.90it/s]Processing test dataset:  94%|█████████▍| 939/1000 [00:11<00:00, 75.35it/s]Processing test dataset:  27%|██▋       | 269/1000 [00:04<00:10, 68.35it/s]Processing train dataset:  99%|█████████▉| 9911/10000 [02:48<00:01, 49.97it/s]Processing val dataset:  83%|████████▎ | 828/1000 [00:13<00:03, 50.24it/s]Processing test dataset:  95%|█████████▍| 948/1000 [00:11<00:00, 79.33it/s]Processing val dataset:  42%|████▏     | 424/1000 [00:06<00:07, 81.23it/s]Processing test dataset:  28%|██▊       | 276/1000 [00:04<00:11, 63.73it/s]Processing train dataset:  99%|█████████▉| 9917/10000 [02:48<00:01, 50.71it/s]Processing test dataset:  96%|█████████▌| 957/1000 [00:11<00:00, 80.93it/s]Processing val dataset:  83%|████████▎ | 834/1000 [00:13<00:03, 51.68it/s]Processing val dataset:  43%|████▎     | 434/1000 [00:06<00:06, 84.04it/s]Processing test dataset:  28%|██▊       | 283/1000 [00:04<00:11, 64.76it/s]Processing val dataset:  84%|████████▍ | 840/1000 [00:13<00:03, 52.71it/s]Processing val dataset:  44%|████▍     | 443/1000 [00:06<00:06, 84.30it/s]Processing test dataset:  97%|█████████▋| 966/1000 [00:12<00:00, 79.00it/s]Processing train dataset:  99%|█████████▉| 9923/10000 [02:48<00:01, 49.63it/s]Processing test dataset:  29%|██▉       | 291/1000 [00:04<00:10, 68.48it/s]Processing test dataset:  98%|█████████▊| 975/1000 [00:12<00:00, 79.51it/s]Processing val dataset:  45%|████▌     | 452/1000 [00:07<00:06, 80.61it/s]Processing train dataset:  99%|█████████▉| 9929/10000 [02:48<00:01, 50.38it/s]Processing val dataset:  85%|████████▍ | 846/1000 [00:13<00:03, 47.98it/s]Processing test dataset:  30%|███       | 301/1000 [00:04<00:09, 75.50it/s]Processing test dataset:  98%|█████████▊| 984/1000 [00:12<00:00, 82.06it/s]Processing train dataset:  99%|█████████▉| 9937/10000 [02:48<00:01, 56.75it/s]Processing val dataset:  46%|████▌     | 461/1000 [00:07<00:06, 77.93it/s]Processing val dataset:  85%|████████▌ | 853/1000 [00:13<00:02, 50.19it/s]Processing test dataset:  31%|███       | 309/1000 [00:04<00:09, 70.83it/s]Processing train dataset:  99%|█████████▉| 9945/10000 [02:48<00:00, 59.56it/s]Processing val dataset:  47%|████▋     | 469/1000 [00:07<00:07, 74.54it/s]Processing test dataset:  99%|█████████▉| 993/1000 [00:12<00:00, 72.76it/s]Processing val dataset:  86%|████████▌ | 860/1000 [00:13<00:02, 53.33it/s]Processing test dataset:  32%|███▏      | 317/1000 [00:04<00:10, 65.75it/s]Processing train dataset: 100%|█████████▉| 9952/10000 [02:48<00:00, 62.19it/s]Processing val dataset:  48%|████▊     | 477/1000 [00:07<00:07, 74.48it/s]Processing test dataset: 100%|██████████| 1000/1000 [00:12<00:00, 79.61it/s]Processing val dataset:  87%|████████▋ | 866/1000 [00:14<00:02, 53.58it/s]Processing test dataset:  32%|███▏      | 324/1000 [00:05<00:10, 63.75it/s]Processing train dataset: 100%|█████████▉| 9959/10000 [02:49<00:00, 59.41it/s]Processing val dataset:  48%|████▊     | 485/1000 [00:07<00:07, 70.04it/s]Processing val dataset:  87%|████████▋ | 872/1000 [00:14<00:02, 48.52it/s]Processing test dataset:  33%|███▎      | 331/1000 [00:05<00:10, 63.76it/s]Processing train dataset: 100%|█████████▉| 9966/10000 [02:49<00:00, 58.63it/s]Processing val dataset:  49%|████▉     | 493/1000 [00:07<00:07, 70.04it/s]Processing val dataset:  88%|████████▊ | 878/1000 [00:14<00:02, 49.58it/s]Processing test dataset:  34%|███▍      | 338/1000 [00:05<00:10, 63.94it/s]Processing train dataset: 100%|█████████▉| 9972/10000 [02:49<00:00, 55.44it/s]Processing val dataset:  88%|████████▊ | 884/1000 [00:14<00:02, 48.28it/s]Processing train dataset: 100%|█████████▉| 9979/10000 [02:49<00:00, 59.08it/s]Processing val dataset:  89%|████████▉ | 890/1000 [00:14<00:02, 50.94it/s]Processing val dataset:  50%|█████     | 501/1000 [00:07<00:10, 47.45it/s]Processing train dataset: 100%|█████████▉| 9987/10000 [02:49<00:00, 63.53it/s]Processing test dataset:  34%|███▍      | 345/1000 [00:05<00:15, 42.09it/s]Processing val dataset:  90%|████████▉ | 896/1000 [00:14<00:01, 52.65it/s]Processing val dataset:  51%|█████     | 510/1000 [00:08<00:08, 55.03it/s]Processing train dataset: 100%|█████████▉| 9994/10000 [02:49<00:00, 62.28it/s]Processing test dataset:  35%|███▌      | 351/1000 [00:05<00:14, 45.63it/s]Processing train dataset: 100%|██████████| 10000/10000 [02:49<00:00, 58.93it/s]Processing val dataset:  90%|█████████ | 903/1000 [00:14<00:01, 53.73it/s]Processing val dataset:  52%|█████▏    | 520/1000 [00:08<00:07, 62.56it/s]Processing test dataset:  36%|███▌      | 358/1000 [00:05<00:12, 50.07it/s]Processing val dataset:  53%|█████▎    | 529/1000 [00:08<00:06, 68.69it/s]Processing val dataset:  91%|█████████ | 909/1000 [00:14<00:01, 52.72it/s]Processing test dataset:  36%|███▋      | 365/1000 [00:05<00:11, 54.40it/s]Processing val dataset:  54%|█████▍    | 539/1000 [00:08<00:06, 75.28it/s]Processing test dataset:  37%|███▋      | 374/1000 [00:06<00:09, 62.82it/s]Processing val dataset:  92%|█████████▏| 915/1000 [00:15<00:01, 43.41it/s]Processing val dataset:  55%|█████▌    | 551/1000 [00:08<00:05, 86.49it/s]Processing test dataset:  38%|███▊      | 384/1000 [00:06<00:08, 71.88it/s]Processing val dataset:  56%|█████▌    | 561/1000 [00:08<00:05, 76.45it/s]Processing test dataset:  39%|███▉      | 392/1000 [00:06<00:09, 62.26it/s]Processing val dataset:  92%|█████████▏| 920/1000 [00:15<00:02, 34.22it/s]Processing val dataset:  57%|█████▋    | 571/1000 [00:08<00:05, 80.48it/s]Processing test dataset:  40%|████      | 400/1000 [00:06<00:09, 64.91it/s]Processing val dataset:  92%|█████████▏| 924/1000 [00:15<00:02, 33.74it/s]Processing val dataset:  58%|█████▊    | 582/1000 [00:08<00:04, 86.99it/s]Processing test dataset:  41%|████      | 409/1000 [00:06<00:08, 70.13it/s]Processing val dataset:  93%|█████████▎| 930/1000 [00:15<00:01, 39.04it/s]Processing val dataset:  59%|█████▉    | 593/1000 [00:08<00:04, 92.79it/s]Processing test dataset:  42%|████▏     | 417/1000 [00:06<00:08, 67.92it/s]Processing val dataset:  94%|█████████▍| 940/1000 [00:15<00:01, 50.68it/s]Processing val dataset:  60%|██████    | 603/1000 [00:09<00:04, 92.02it/s]Processing test dataset:  43%|████▎     | 426/1000 [00:06<00:08, 70.28it/s]Processing val dataset:  95%|█████████▌| 952/1000 [00:15<00:00, 65.41it/s]Processing val dataset:  62%|██████▏   | 615/1000 [00:09<00:03, 97.16it/s]Processing val dataset:  97%|█████████▋| 966/1000 [00:15<00:00, 82.93it/s]Processing test dataset:  44%|████▎     | 435/1000 [00:06<00:07, 73.78it/s]Processing val dataset:  63%|██████▎   | 626/1000 [00:09<00:03, 99.00it/s]Processing test dataset:  44%|████▍     | 445/1000 [00:06<00:06, 80.20it/s]Processing val dataset:  98%|█████████▊| 984/1000 [00:16<00:00, 106.67it/s]Processing val dataset:  64%|██████▍   | 639/1000 [00:09<00:03, 105.16it/s]Processing test dataset:  46%|████▌     | 455/1000 [00:07<00:06, 83.35it/s]Processing val dataset: 100%|█████████▉| 996/1000 [00:16<00:00, 104.92it/s]Processing val dataset:  65%|██████▌   | 650/1000 [00:09<00:03, 105.06it/s]Processing val dataset: 100%|██████████| 1000/1000 [00:16<00:00, 61.88it/s]Processing test dataset:  46%|████▋     | 464/1000 [00:07<00:06, 83.82it/s]Processing val dataset:  66%|██████▌   | 661/1000 [00:09<00:03, 100.31it/s]Processing test dataset:  47%|████▋     | 473/1000 [00:07<00:06, 82.83it/s]Processing val dataset:  67%|██████▋   | 672/1000 [00:09<00:03, 100.82it/s]Processing test dataset:  48%|████▊     | 484/1000 [00:07<00:05, 88.24it/s]Processing val dataset:  68%|██████▊   | 684/1000 [00:09<00:03, 103.87it/s]Processing test dataset:  49%|████▉     | 494/1000 [00:07<00:05, 89.55it/s]Processing val dataset:  70%|██████▉   | 695/1000 [00:09<00:02, 103.68it/s]Processing test dataset:  50%|█████     | 505/1000 [00:07<00:05, 92.87it/s]Processing val dataset:  71%|███████   | 707/1000 [00:10<00:02, 106.43it/s]Processing test dataset:  52%|█████▏    | 517/1000 [00:07<00:04, 99.55it/s]Processing val dataset:  72%|███████▏  | 718/1000 [00:10<00:02, 105.49it/s]Processing test dataset:  53%|█████▎    | 532/1000 [00:07<00:04, 113.07it/s]Processing test dataset:  55%|█████▍    | 547/1000 [00:07<00:03, 122.76it/s]Processing val dataset:  73%|███████▎  | 729/1000 [00:10<00:03, 83.88it/s] Processing test dataset:  56%|█████▌    | 562/1000 [00:08<00:03, 129.22it/s]Processing val dataset:  74%|███████▍  | 743/1000 [00:10<00:02, 96.29it/s]
  0%|          | 0/1000 [00:00<?, ?it/s]Processing test dataset:   0%|          | 0/1000 [00:00<?, ?it/s]Processing test dataset:  57%|█████▊    | 575/1000 [00:08<00:03, 123.10it/s]Processing val dataset:  75%|███████▌  | 754/1000 [00:10<00:02, 98.38it/s]Processing test dataset:   0%|          | 2/1000 [00:00<01:09, 14.46it/s]Processing val dataset:  77%|███████▋  | 766/1000 [00:10<00:02, 101.91it/s]Processing test dataset:  59%|█████▉    | 588/1000 [00:08<00:03, 121.58it/s]Processing test dataset:   1%|          | 6/1000 [00:00<00:39, 24.89it/s]Processing val dataset:  78%|███████▊  | 779/1000 [00:10<00:02, 109.29it/s]Processing test dataset:  60%|██████    | 601/1000 [00:08<00:03, 123.10it/s]Processing test dataset:  62%|██████▏   | 616/1000 [00:08<00:02, 130.07it/s]Processing val dataset:  79%|███████▉  | 791/1000 [00:10<00:01, 108.46it/s]Processing test dataset:   1%|          | 11/1000 [00:00<00:34, 28.83it/s]Processing test dataset:  63%|██████▎   | 630/1000 [00:08<00:02, 129.26it/s]Processing val dataset:  80%|████████  | 804/1000 [00:10<00:01, 112.15it/s]Processing test dataset:   2%|▏         | 15/1000 [00:00<00:31, 31.05it/s]Processing test dataset:  64%|██████▍   | 643/1000 [00:08<00:02, 129.09it/s]Processing val dataset:  82%|████████▏ | 816/1000 [00:11<00:01, 113.13it/s]Processing test dataset:   2%|▏         | 21/1000 [00:00<00:26, 37.33it/s]Processing test dataset:  66%|██████▌   | 656/1000 [00:08<00:03, 109.94it/s]Processing val dataset:  83%|████████▎ | 828/1000 [00:11<00:01, 97.19it/s] Processing val dataset:  84%|████████▍ | 839/1000 [00:11<00:01, 97.47it/s]Processing test dataset:  67%|██████▋   | 668/1000 [00:08<00:03, 103.01it/s]Processing test dataset:   2%|▎         | 25/1000 [00:00<00:38, 25.65it/s]Processing test dataset:  68%|██████▊   | 681/1000 [00:09<00:03, 102.07it/s]Processing val dataset:  85%|████████▌ | 852/1000 [00:11<00:01, 94.68it/s]Processing test dataset:   3%|▎         | 29/1000 [00:01<00:36, 26.84it/s]Processing test dataset:  69%|██████▉   | 692/1000 [00:09<00:03, 102.13it/s]Processing val dataset:  86%|████████▌ | 862/1000 [00:11<00:01, 89.39it/s]Processing test dataset:   3%|▎         | 33/1000 [00:01<00:34, 28.03it/s]Processing test dataset:  70%|███████   | 703/1000 [00:09<00:02, 99.07it/s] Processing val dataset:  87%|████████▋ | 872/1000 [00:11<00:01, 85.45it/s]Processing test dataset:   4%|▎         | 37/1000 [00:01<00:34, 27.93it/s]Processing test dataset:  71%|███████▏  | 714/1000 [00:09<00:03, 93.14it/s]Processing val dataset:  88%|████████▊ | 881/1000 [00:11<00:01, 83.09it/s]Processing test dataset:   4%|▍         | 40/1000 [00:01<00:34, 27.57it/s]Processing test dataset:  72%|███████▏  | 724/1000 [00:09<00:03, 84.61it/s]Processing val dataset:  89%|████████▉ | 890/1000 [00:11<00:01, 77.06it/s]Processing test dataset:   4%|▍         | 43/1000 [00:01<00:38, 24.94it/s]Processing val dataset:  90%|████████▉ | 898/1000 [00:12<00:01, 77.53it/s]Processing test dataset:  73%|███████▎  | 733/1000 [00:09<00:03, 81.28it/s]Processing test dataset:   5%|▍         | 46/1000 [00:01<00:42, 22.39it/s]Processing val dataset:  91%|█████████ | 907/1000 [00:12<00:01, 79.19it/s]Processing test dataset:  74%|███████▍  | 742/1000 [00:09<00:03, 83.33it/s]Processing val dataset:  92%|█████████▏| 915/1000 [00:12<00:01, 75.07it/s]Processing test dataset:  75%|███████▌  | 751/1000 [00:09<00:03, 75.33it/s]Processing test dataset:   5%|▍         | 49/1000 [00:01<00:46, 20.41it/s]Processing val dataset:  92%|█████████▎| 925/1000 [00:12<00:00, 80.78it/s]Processing test dataset:  77%|███████▋  | 766/1000 [00:10<00:02, 92.99it/s]Processing test dataset:   6%|▌         | 57/1000 [00:02<00:29, 32.25it/s]Processing val dataset:  93%|█████████▎| 934/1000 [00:12<00:00, 78.42it/s]Processing test dataset:  78%|███████▊  | 778/1000 [00:10<00:02, 99.97it/s]Processing val dataset:  94%|█████████▍| 945/1000 [00:12<00:00, 85.60it/s]Processing test dataset:  79%|███████▉  | 789/1000 [00:10<00:02, 94.79it/s]Processing test dataset:   6%|▌         | 62/1000 [00:02<00:33, 27.70it/s]Processing test dataset:  80%|████████  | 800/1000 [00:10<00:02, 97.21it/s]Processing val dataset:  95%|█████████▌| 954/1000 [00:12<00:00, 77.27it/s]Processing test dataset:   7%|▋         | 66/1000 [00:02<00:31, 29.59it/s]Processing val dataset:  97%|█████████▋| 967/1000 [00:12<00:00, 89.34it/s]Processing test dataset:  81%|████████▏ | 813/1000 [00:10<00:01, 100.62it/s]Processing test dataset:   7%|▋         | 72/1000 [00:02<00:25, 36.05it/s]Processing val dataset:  98%|█████████▊| 978/1000 [00:13<00:00, 93.36it/s]Processing test dataset:  82%|████████▏ | 824/1000 [00:10<00:01, 101.40it/s]Processing test dataset:   8%|▊         | 77/1000 [00:02<00:24, 38.15it/s]Processing test dataset:   8%|▊         | 83/1000 [00:02<00:21, 43.38it/s]Processing test dataset:  84%|████████▎ | 835/1000 [00:10<00:01, 98.03it/s] Processing val dataset:  99%|█████████▉| 988/1000 [00:13<00:00, 85.45it/s]Processing test dataset:  85%|████████▍ | 847/1000 [00:10<00:01, 93.84it/s]Processing val dataset: 100%|█████████▉| 997/1000 [00:13<00:00, 78.43it/s]Processing test dataset:   9%|▉         | 88/1000 [00:02<00:23, 38.94it/s]Processing val dataset: 100%|██████████| 1000/1000 [00:13<00:00, 75.08it/s]Processing test dataset:   9%|▉         | 93/1000 [00:02<00:22, 40.63it/s]Processing test dataset:  86%|████████▌ | 857/1000 [00:11<00:01, 84.19it/s]Processing test dataset:  10%|▉         | 99/1000 [00:03<00:20, 43.64it/s]Processing test dataset:  87%|████████▋ | 866/1000 [00:11<00:01, 78.50it/s]Processing test dataset:  10%|█         | 105/1000 [00:03<00:19, 46.24it/s]Processing test dataset:  88%|████████▊ | 875/1000 [00:11<00:01, 71.49it/s]Processing test dataset:  88%|████████▊ | 883/1000 [00:11<00:01, 69.29it/s]Processing test dataset:  90%|████████▉ | 899/1000 [00:11<00:01, 90.35it/s]Processing test dataset:  11%|█         | 110/1000 [00:03<00:31, 28.50it/s]Processing test dataset:  92%|█████████▏| 922/1000 [00:11<00:00, 122.52it/s]Processing test dataset:  11%|█▏        | 114/1000 [00:03<00:29, 30.49it/s]Processing test dataset:  94%|█████████▍| 941/1000 [00:11<00:00, 134.45it/s]Processing test dataset:  96%|█████████▌| 962/1000 [00:11<00:00, 149.71it/s]Processing test dataset:  12%|█▏        | 118/1000 [00:03<00:35, 25.06it/s]Processing test dataset:  98%|█████████▊| 982/1000 [00:12<00:00, 162.21it/s]Processing test dataset:  12%|█▏        | 122/1000 [00:04<00:34, 25.55it/s]Processing test dataset: 100%|█████████▉| 999/1000 [00:12<00:00, 156.75it/s]Processing test dataset: 100%|██████████| 1000/1000 [00:12<00:00, 82.34it/s]Processing test dataset:  13%|█▎        | 126/1000 [00:04<00:32, 27.08it/s]Processing test dataset:  13%|█▎        | 130/1000 [00:04<00:30, 28.16it/s]Processing test dataset:  14%|█▎        | 135/1000 [00:04<00:26, 32.14it/s]Processing test dataset:  14%|█▍        | 142/1000 [00:04<00:20, 41.00it/s]Processing test dataset:  15%|█▌        | 150/1000 [00:04<00:16, 50.74it/s]Processing test dataset:  16%|█▌        | 158/1000 [00:04<00:14, 57.54it/s]Processing test dataset:  17%|█▋        | 172/1000 [00:04<00:10, 79.32it/s]Processing test dataset:  19%|█▉        | 192/1000 [00:04<00:07, 112.53it/s]Processing test dataset:  22%|██▏       | 215/1000 [00:05<00:05, 145.09it/s]
  0%|          | 0/1000 [00:00<?, ?it/s]Processing test dataset:   0%|          | 0/1000 [00:00<?, ?it/s]Processing test dataset:  24%|██▎       | 236/1000 [00:05<00:04, 154.12it/s]Processing test dataset:   0%|          | 2/1000 [00:00<00:56, 17.59it/s]Processing test dataset:   0%|          | 4/1000 [00:00<00:56, 17.64it/s]Processing test dataset:   1%|          | 9/1000 [00:00<00:33, 29.47it/s]Processing test dataset:  25%|██▌       | 252/1000 [00:05<00:08, 87.19it/s] Processing test dataset:   1%|          | 12/1000 [00:00<00:38, 25.93it/s]Processing test dataset:   2%|▏         | 17/1000 [00:00<00:32, 30.06it/s]
Done!
Processing test dataset:  26%|██▋       | 265/1000 [00:05<00:10, 70.37it/s]Processing test dataset:   2%|▏         | 21/1000 [00:00<00:36, 26.73it/s]Processing test dataset:   3%|▎         | 28/1000 [00:00<00:28, 34.63it/s]Processing test dataset:  28%|██▊       | 275/1000 [00:06<00:11, 60.72it/s]Processing test dataset:  28%|██▊       | 285/1000 [00:06<00:11, 65.00it/s]Processing test dataset:  29%|██▉       | 294/1000 [00:06<00:10, 66.55it/s]Processing test dataset:  30%|███       | 302/1000 [00:06<00:10, 64.49it/s]Processing test dataset:  31%|███       | 310/1000 [00:06<00:10, 64.45it/s]Processing test dataset:   3%|▎         | 32/1000 [00:01<01:00, 16.04it/s]Processing test dataset:  32%|███▏      | 318/1000 [00:06<00:10, 65.25it/s]Processing test dataset:   4%|▎         | 35/1000 [00:01<00:57, 16.79it/s]Processing test dataset:  32%|███▎      | 325/1000 [00:06<00:10, 63.30it/s]Processing test dataset:   4%|▍         | 38/1000 [00:01<00:51, 18.67it/s]Processing test dataset:  34%|███▎      | 335/1000 [00:06<00:09, 71.97it/s]Processing test dataset:   4%|▍         | 42/1000 [00:01<00:43, 22.01it/s]
  0%|          | 0/1000 [00:00<?, ?it/s]Processing val dataset:   0%|          | 0/1000 [00:00<?, ?it/s]Processing test dataset:  35%|███▍      | 346/1000 [00:07<00:08, 79.76it/s]Processing test dataset:   5%|▌         | 51/1000 [00:02<00:27, 34.65it/s]Processing test dataset:   6%|▌         | 56/1000 [00:02<00:25, 36.73it/s]Processing test dataset:  36%|███▌      | 355/1000 [00:07<00:09, 65.09it/s]Processing test dataset:   6%|▌         | 62/1000 [00:02<00:22, 41.80it/s]Processing val dataset:   0%|          | 1/1000 [00:00<04:45,  3.50it/s]Processing test dataset:  36%|███▋      | 365/1000 [00:07<00:08, 72.37it/s]Processing test dataset:   7%|▋         | 68/1000 [00:02<00:20, 45.16it/s]Processing val dataset:   1%|          | 9/1000 [00:00<00:35, 27.62it/s]Processing test dataset:  37%|███▋      | 373/1000 [00:07<00:08, 74.23it/s]Processing test dataset:   8%|▊         | 85/1000 [00:02<00:11, 76.80it/s]Processing val dataset:   2%|▏         | 15/1000 [00:00<00:26, 37.70it/s]Processing test dataset:  38%|███▊      | 381/1000 [00:07<00:08, 73.97it/s]Processing test dataset:  10%|▉         | 98/1000 [00:02<00:10, 89.62it/s]Processing val dataset:   2%|▏         | 21/1000 [00:00<00:23, 42.37it/s]Processing test dataset:  39%|███▉      | 390/1000 [00:07<00:07, 76.92it/s]Processing test dataset:  11%|█         | 109/1000 [00:02<00:09, 92.07it/s]Processing test dataset:  40%|███▉      | 399/1000 [00:07<00:07, 79.53it/s]Processing val dataset:   3%|▎         | 29/1000 [00:00<00:18, 51.38it/s]Processing test dataset:  41%|████      | 409/1000 [00:07<00:07, 77.33it/s]Processing test dataset:  42%|████▏     | 417/1000 [00:08<00:08, 72.54it/s]Processing val dataset:   4%|▎         | 35/1000 [00:01<00:27, 34.70it/s]Processing test dataset:  42%|████▎     | 425/1000 [00:08<00:07, 73.87it/s]Processing val dataset:   4%|▍         | 40/1000 [00:01<00:27, 34.98it/s]Processing val dataset:   4%|▍         | 45/1000 [00:01<00:25, 36.94it/s]Processing test dataset:  43%|████▎     | 433/1000 [00:08<00:09, 60.75it/s]Processing val dataset:   5%|▌         | 53/1000 [00:01<00:21, 44.06it/s]Processing test dataset:  44%|████▍     | 440/1000 [00:08<00:09, 59.47it/s]
Done!
Processing val dataset:   6%|▌         | 58/1000 [00:01<00:25, 37.31it/s]Processing test dataset:  45%|████▍     | 447/1000 [00:08<00:11, 48.77it/s]Processing val dataset:   6%|▋         | 63/1000 [00:01<00:26, 35.27it/s]Processing val dataset:   7%|▋         | 68/1000 [00:01<00:24, 37.97it/s]Processing test dataset:  12%|█▏        | 119/1000 [00:03<00:36, 23.97it/s]Processing val dataset:   7%|▋         | 73/1000 [00:01<00:23, 39.38it/s]Processing test dataset:  45%|████▌     | 453/1000 [00:09<00:16, 32.55it/s]Processing val dataset:   8%|▊         | 82/1000 [00:02<00:17, 51.49it/s]Processing val dataset:   9%|▉         | 89/1000 [00:02<00:16, 55.30it/s]Processing val dataset:  10%|▉         | 95/1000 [00:02<00:20, 44.93it/s]Processing test dataset:  46%|████▌     | 458/1000 [00:09<00:22, 23.62it/s]Processing val dataset:  10%|█         | 103/1000 [00:02<00:17, 51.67it/s]Processing test dataset:  47%|████▋     | 468/1000 [00:09<00:15, 33.47it/s]Processing val dataset:  11%|█         | 112/1000 [00:02<00:14, 60.72it/s]Processing test dataset:  48%|████▊     | 479/1000 [00:09<00:11, 45.58it/s]Processing val dataset:  12%|█▏        | 122/1000 [00:02<00:12, 68.75it/s]Processing test dataset:  49%|████▉     | 492/1000 [00:09<00:08, 59.81it/s]Processing val dataset:  13%|█▎        | 130/1000 [00:02<00:15, 56.54it/s]Processing test dataset:  50%|█████     | 501/1000 [00:09<00:09, 54.31it/s]Processing val dataset:  14%|█▍        | 140/1000 [00:03<00:13, 65.92it/s]Processing test dataset:  51%|█████     | 510/1000 [00:10<00:08, 61.16it/s]Processing val dataset:  15%|█▌        | 152/1000 [00:03<00:10, 78.13it/s]Processing test dataset:  52%|█████▏    | 522/1000 [00:10<00:06, 73.27it/s]Processing val dataset:  16%|█▋        | 163/1000 [00:03<00:09, 85.68it/s]Processing test dataset:  54%|█████▎    | 536/1000 [00:10<00:05, 87.94it/s]Processing val dataset:  18%|█▊        | 175/1000 [00:03<00:08, 94.53it/s]Processing test dataset:  55%|█████▌    | 550/1000 [00:10<00:04, 99.07it/s]Processing val dataset:  18%|█▊        | 185/1000 [00:03<00:09, 90.05it/s]Processing test dataset:  56%|█████▌    | 562/1000 [00:10<00:04, 96.65it/s]Processing test dataset:  13%|█▎        | 127/1000 [00:05<01:12, 12.01it/s]Processing val dataset:  20%|█▉        | 196/1000 [00:03<00:08, 94.62it/s]Processing test dataset:  57%|█████▋    | 573/1000 [00:10<00:04, 95.17it/s]Processing val dataset:  21%|██        | 206/1000 [00:03<00:08, 90.33it/s]Processing test dataset:  58%|█████▊    | 585/1000 [00:10<00:04, 101.50it/s]Processing val dataset:  22%|██▏       | 216/1000 [00:03<00:09, 83.45it/s]Processing test dataset:  60%|█████▉    | 596/1000 [00:10<00:04, 92.80it/s] Processing val dataset:  23%|██▎       | 227/1000 [00:03<00:08, 86.03it/s]Processing test dataset:  61%|██████    | 606/1000 [00:10<00:04, 92.61it/s]Processing test dataset:  13%|█▎        | 133/1000 [00:06<01:13, 11.86it/s]Processing val dataset:  24%|██▍       | 238/1000 [00:04<00:09, 83.06it/s]Processing test dataset:  62%|██████▏   | 616/1000 [00:11<00:04, 79.78it/s]Processing val dataset:  25%|██▍       | 247/1000 [00:04<00:09, 77.85it/s]Processing test dataset:  62%|██████▎   | 625/1000 [00:11<00:05, 71.33it/s]Processing val dataset:  26%|██▌       | 258/1000 [00:04<00:08, 85.39it/s]Processing test dataset:  63%|██████▎   | 633/1000 [00:11<00:05, 67.33it/s]Processing val dataset:  27%|██▋       | 267/1000 [00:04<00:08, 83.07it/s]Processing test dataset:  14%|█▎        | 137/1000 [00:06<01:16, 11.24it/s]Processing val dataset:  28%|██▊       | 276/1000 [00:04<00:11, 65.18it/s]Processing test dataset:  14%|█▍        | 140/1000 [00:06<01:12, 11.85it/s]Processing test dataset:  64%|██████▍   | 641/1000 [00:11<00:07, 48.88it/s]Processing val dataset:  28%|██▊       | 284/1000 [00:04<00:10, 65.29it/s]Processing val dataset:  29%|██▉       | 292/1000 [00:04<00:10, 66.60it/s]Processing test dataset:  14%|█▍        | 143/1000 [00:06<01:12, 11.88it/s]Processing test dataset:  65%|██████▍   | 647/1000 [00:12<00:09, 39.10it/s]Processing val dataset:  30%|███       | 305/1000 [00:04<00:08, 80.90it/s]Processing val dataset:  31%|███▏      | 314/1000 [00:05<00:08, 81.21it/s]Processing test dataset:  66%|██████▌   | 659/1000 [00:12<00:06, 49.69it/s]Processing val dataset:  32%|███▏      | 323/1000 [00:05<00:09, 72.35it/s]Processing test dataset:  15%|█▍        | 146/1000 [00:07<01:17, 11.07it/s]Processing test dataset:  66%|██████▋   | 665/1000 [00:12<00:07, 43.95it/s]Processing val dataset:  33%|███▎      | 331/1000 [00:05<00:09, 72.34it/s]Processing test dataset:  67%|██████▋   | 671/1000 [00:12<00:07, 44.51it/s]Processing test dataset:  15%|█▍        | 148/1000 [00:07<01:15, 11.21it/s]Processing val dataset:  34%|███▍      | 339/1000 [00:05<00:09, 70.05it/s]Processing test dataset:  68%|██████▊   | 676/1000 [00:12<00:07, 44.96it/s]Processing val dataset:  35%|███▍      | 349/1000 [00:05<00:08, 74.99it/s]Processing test dataset:  15%|█▌        | 150/1000 [00:07<01:16, 11.04it/s]Processing test dataset:  68%|██████▊   | 683/1000 [00:12<00:06, 49.10it/s]Processing val dataset:  36%|███▌      | 359/1000 [00:05<00:07, 80.30it/s]Processing test dataset:  69%|██████▉   | 690/1000 [00:12<00:05, 52.33it/s]Processing val dataset:  37%|███▋      | 368/1000 [00:05<00:08, 72.59it/s]Processing test dataset:  70%|██████▉   | 696/1000 [00:12<00:06, 49.93it/s]Processing test dataset:  15%|█▌        | 152/1000 [00:07<01:26,  9.78it/s]Processing val dataset:  38%|███▊      | 379/1000 [00:05<00:07, 81.83it/s]Processing test dataset:  71%|███████   | 707/1000 [00:13<00:04, 62.00it/s]Processing val dataset:  39%|███▉      | 388/1000 [00:06<00:07, 81.84it/s]Processing test dataset:  15%|█▌        | 154/1000 [00:08<01:22, 10.21it/s]Processing test dataset:  72%|███████▏  | 717/1000 [00:13<00:04, 67.03it/s]Processing val dataset:  40%|████      | 400/1000 [00:06<00:06, 90.84it/s]Processing test dataset:  72%|███████▎  | 725/1000 [00:13<00:03, 70.16it/s]Processing val dataset:  41%|████      | 410/1000 [00:06<00:06, 90.97it/s]Processing test dataset:  16%|█▌        | 156/1000 [00:08<01:26,  9.75it/s]Processing test dataset:  74%|███████▎  | 735/1000 [00:13<00:03, 76.88it/s]Processing val dataset:  42%|████▏     | 420/1000 [00:06<00:06, 91.74it/s]Processing test dataset:  16%|█▌        | 158/1000 [00:08<01:16, 10.94it/s]Processing test dataset:  74%|███████▍  | 745/1000 [00:13<00:03, 78.36it/s]Processing val dataset:  43%|████▎     | 432/1000 [00:06<00:05, 94.69it/s]Processing test dataset:  75%|███████▌  | 753/1000 [00:13<00:03, 74.02it/s]Processing test dataset:  16%|█▌        | 160/1000 [00:08<01:14, 11.26it/s]Processing val dataset:  44%|████▍     | 443/1000 [00:06<00:05, 95.13it/s]Processing val dataset:  45%|████▌     | 453/1000 [00:06<00:05, 94.93it/s]Processing test dataset:  76%|███████▌  | 761/1000 [00:13<00:03, 64.80it/s]Processing val dataset:  46%|████▋     | 463/1000 [00:06<00:05, 91.55it/s]Processing test dataset:  77%|███████▋  | 768/1000 [00:13<00:03, 61.51it/s]Processing test dataset:  16%|█▌        | 162/1000 [00:08<01:27,  9.55it/s]Processing val dataset:  47%|████▋     | 473/1000 [00:06<00:05, 90.19it/s]Processing test dataset:  78%|███████▊  | 776/1000 [00:14<00:03, 63.08it/s]Processing val dataset:  48%|████▊     | 483/1000 [00:07<00:06, 84.20it/s]Processing test dataset:  78%|███████▊  | 783/1000 [00:14<00:03, 63.64it/s]Processing val dataset:  49%|████▉     | 492/1000 [00:07<00:06, 76.79it/s]Processing test dataset:  79%|███████▉  | 790/1000 [00:14<00:04, 50.21it/s]Processing val dataset:  50%|█████     | 500/1000 [00:07<00:06, 73.65it/s]Processing test dataset:  16%|█▋        | 164/1000 [00:09<01:59,  7.00it/s]Processing test dataset:  80%|███████▉  | 797/1000 [00:14<00:03, 54.53it/s]Processing test dataset:  17%|█▋        | 170/1000 [00:09<01:01, 13.41it/s]Processing val dataset:  51%|█████     | 508/1000 [00:07<00:07, 69.15it/s]Processing test dataset:  80%|████████  | 803/1000 [00:14<00:03, 50.28it/s]Processing test dataset:  18%|█▊        | 175/1000 [00:09<00:45, 18.15it/s]Processing val dataset:  52%|█████▏    | 515/1000 [00:07<00:07, 61.44it/s]Processing test dataset:  81%|████████  | 809/1000 [00:14<00:04, 46.27it/s]Processing test dataset:  18%|█▊        | 178/1000 [00:09<00:41, 19.64it/s]Processing val dataset:  52%|█████▏    | 522/1000 [00:07<00:07, 61.67it/s]Processing test dataset:  82%|████████▏ | 817/1000 [00:14<00:03, 53.09it/s]Processing test dataset:  18%|█▊        | 182/1000 [00:09<00:35, 23.31it/s]Processing val dataset:  53%|█████▎    | 530/1000 [00:07<00:07, 64.61it/s]Processing test dataset:  82%|████████▎ | 825/1000 [00:14<00:03, 57.57it/s]Processing val dataset:  54%|█████▎    | 537/1000 [00:07<00:07, 65.70it/s]Processing test dataset:  84%|████████▎ | 835/1000 [00:15<00:02, 65.83it/s]Processing test dataset:  19%|█▊        | 186/1000 [00:10<00:38, 20.96it/s]Processing val dataset:  55%|█████▍    | 548/1000 [00:08<00:05, 76.57it/s]Processing test dataset:  84%|████████▍ | 844/1000 [00:15<00:02, 70.84it/s]Processing test dataset:  19%|█▉        | 189/1000 [00:10<00:35, 22.57it/s]Processing val dataset:  56%|█████▌    | 557/1000 [00:08<00:05, 75.13it/s]Processing val dataset:  56%|█████▋    | 565/1000 [00:08<00:05, 75.11it/s]Processing test dataset:  19%|█▉        | 192/1000 [00:10<00:38, 21.15it/s]Processing test dataset:  85%|████████▌ | 852/1000 [00:15<00:02, 61.10it/s]Processing val dataset:  57%|█████▋    | 573/1000 [00:08<00:05, 73.28it/s]Processing test dataset:  20%|█▉        | 196/1000 [00:10<00:34, 23.15it/s]Processing val dataset:  58%|█████▊    | 585/1000 [00:08<00:04, 85.73it/s]Processing test dataset:  86%|████████▌ | 859/1000 [00:15<00:02, 51.81it/s]Processing val dataset:  59%|█████▉    | 594/1000 [00:08<00:04, 86.84it/s]Processing test dataset:  20%|█▉        | 199/1000 [00:10<00:38, 20.59it/s]Processing test dataset:  86%|████████▋ | 865/1000 [00:15<00:02, 47.08it/s]Processing val dataset:  60%|██████    | 603/1000 [00:08<00:04, 80.27it/s]Processing test dataset:  87%|████████▋ | 871/1000 [00:15<00:02, 44.95it/s]Processing val dataset:  61%|██████    | 612/1000 [00:08<00:04, 81.31it/s]Processing test dataset:  20%|██        | 203/1000 [00:10<00:42, 18.75it/s]Processing test dataset:  88%|████████▊ | 879/1000 [00:16<00:02, 51.27it/s]Processing val dataset:  62%|██████▏   | 621/1000 [00:09<00:05, 74.03it/s]Processing test dataset:  89%|████████▊ | 886/1000 [00:16<00:02, 53.55it/s]Processing val dataset:  63%|██████▎   | 629/1000 [00:09<00:05, 71.23it/s]Processing test dataset:  89%|████████▉ | 893/1000 [00:16<00:01, 57.50it/s]Processing val dataset:  64%|██████▍   | 640/1000 [00:09<00:04, 80.92it/s]Processing test dataset:  21%|██        | 206/1000 [00:11<00:55, 14.21it/s]Processing test dataset:  90%|█████████ | 902/1000 [00:16<00:01, 62.86it/s]Processing test dataset:  21%|██        | 208/1000 [00:11<00:52, 15.08it/s]Processing val dataset:  65%|██████▍   | 649/1000 [00:09<00:04, 74.49it/s]Processing test dataset:  91%|█████████ | 909/1000 [00:16<00:01, 60.98it/s]Processing val dataset:  66%|██████▌   | 657/1000 [00:09<00:05, 62.55it/s]Processing test dataset:  92%|█████████▏| 916/1000 [00:16<00:01, 55.35it/s]Processing test dataset:  92%|█████████▏| 924/1000 [00:16<00:01, 60.99it/s]Processing val dataset:  67%|██████▋   | 666/1000 [00:09<00:04, 67.68it/s]Processing test dataset:  21%|██        | 210/1000 [00:11<01:11, 11.09it/s]Processing test dataset:  93%|█████████▎| 931/1000 [00:16<00:01, 63.28it/s]Processing val dataset:  68%|██████▊   | 677/1000 [00:09<00:04, 76.71it/s]Processing test dataset:  94%|█████████▍| 938/1000 [00:16<00:01, 59.99it/s]Processing val dataset:  69%|██████▊   | 686/1000 [00:09<00:04, 74.96it/s]Processing test dataset:  95%|█████████▌| 952/1000 [00:17<00:00, 79.73it/s]Processing test dataset:  21%|██        | 212/1000 [00:11<01:21,  9.61it/s]Processing val dataset:  70%|██████▉   | 698/1000 [00:10<00:03, 79.52it/s]Processing test dataset:  22%|██▏       | 216/1000 [00:12<01:00, 12.87it/s]Processing val dataset:  71%|███████   | 707/1000 [00:10<00:04, 72.29it/s]Processing test dataset:  96%|█████████▌| 961/1000 [00:17<00:00, 66.61it/s]Processing test dataset:  22%|██▏       | 218/1000 [00:12<01:02, 12.55it/s]Processing test dataset:  97%|█████████▋| 969/1000 [00:17<00:00, 54.61it/s]Processing val dataset:  72%|███████▏  | 715/1000 [00:10<00:05, 56.89it/s]Processing test dataset:  22%|██▏       | 220/1000 [00:12<00:59, 13.16it/s]Processing val dataset:  72%|███████▏  | 722/1000 [00:10<00:05, 55.33it/s]Processing test dataset:  98%|█████████▊| 976/1000 [00:17<00:00, 51.12it/s]Processing val dataset:  73%|███████▎  | 732/1000 [00:10<00:04, 63.87it/s]Processing test dataset:  99%|█████████▊| 987/1000 [00:17<00:00, 62.44it/s]Processing test dataset:  22%|██▏       | 223/1000 [00:12<01:04, 12.14it/s]Processing val dataset:  74%|███████▍  | 744/1000 [00:10<00:03, 75.38it/s]Processing test dataset: 100%|█████████▉| 998/1000 [00:17<00:00, 72.76it/s]Processing test dataset: 100%|██████████| 1000/1000 [00:17<00:00, 56.01it/s]Processing val dataset:  76%|███████▌  | 755/1000 [00:10<00:02, 82.46it/s]Processing test dataset:  23%|██▎       | 226/1000 [00:12<00:56, 13.82it/s]Processing val dataset:  76%|███████▋  | 764/1000 [00:11<00:02, 83.63it/s]Processing val dataset:  77%|███████▋  | 773/1000 [00:11<00:03, 73.27it/s]Processing test dataset:  23%|██▎       | 228/1000 [00:13<01:07, 11.35it/s]Processing val dataset:  78%|███████▊  | 785/1000 [00:11<00:02, 81.33it/s]Processing val dataset:  80%|███████▉  | 797/1000 [00:11<00:02, 89.12it/s]Processing test dataset:  23%|██▎       | 230/1000 [00:13<01:13, 10.45it/s]Processing val dataset:  81%|████████  | 807/1000 [00:11<00:02, 78.89it/s]Processing val dataset:  82%|████████▏ | 817/1000 [00:11<00:02, 83.93it/s]Processing val dataset:  83%|████████▎ | 830/1000 [00:11<00:01, 94.92it/s]Processing val dataset:  84%|████████▍ | 840/1000 [00:12<00:02, 68.27it/s]Processing test dataset:  23%|██▎       | 232/1000 [00:14<01:55,  6.64it/s]Processing val dataset:  86%|████████▌ | 857/1000 [00:12<00:01, 89.28it/s]Processing val dataset:  87%|████████▋ | 871/1000 [00:12<00:01, 95.60it/s]Processing test dataset:  23%|██▎       | 233/1000 [00:14<02:02,  6.25it/s]Processing val dataset:  88%|████████▊ | 882/1000 [00:12<00:01, 97.70it/s]Processing test dataset:  23%|██▎       | 234/1000 [00:14<02:03,  6.18it/s]Processing val dataset:  89%|████████▉ | 893/1000 [00:12<00:01, 80.29it/s]
Done!
Processing val dataset:  90%|█████████ | 903/1000 [00:12<00:01, 72.90it/s]Processing test dataset:  24%|██▎       | 236/1000 [00:14<02:02,  6.22it/s]Processing test dataset:  24%|██▍       | 238/1000 [00:14<01:34,  8.03it/s]Processing val dataset:  91%|█████████ | 912/1000 [00:12<00:01, 63.81it/s]Processing test dataset:  24%|██▍       | 240/1000 [00:14<01:26,  8.80it/s]Processing val dataset:  92%|█████████▏| 920/1000 [00:13<00:01, 52.88it/s]Processing test dataset:  24%|██▍       | 242/1000 [00:15<01:29,  8.46it/s]Processing val dataset:  93%|█████████▎| 926/1000 [00:13<00:01, 43.34it/s]Processing test dataset:  24%|██▍       | 244/1000 [00:15<01:15, 10.00it/s]Processing val dataset:  93%|█████████▎| 931/1000 [00:13<00:01, 44.21it/s]Processing test dataset:  25%|██▍       | 246/1000 [00:15<01:07, 11.24it/s]Processing val dataset:  94%|█████████▎| 937/1000 [00:13<00:01, 45.86it/s]Processing test dataset:  25%|██▍       | 248/1000 [00:15<01:05, 11.45it/s]Processing val dataset:  94%|█████████▍| 944/1000 [00:13<00:01, 50.38it/s]Processing val dataset:  95%|█████████▌| 950/1000 [00:13<00:00, 50.05it/s]Processing test dataset:  25%|██▌       | 250/1000 [00:15<01:11, 10.46it/s]Processing val dataset:  96%|█████████▌| 956/1000 [00:14<00:00, 44.70it/s]Processing test dataset:  25%|██▌       | 253/1000 [00:16<00:55, 13.35it/s]Processing val dataset:  96%|█████████▋| 965/1000 [00:14<00:00, 51.56it/s]Processing test dataset:  26%|██▌       | 257/1000 [00:16<00:59, 12.51it/s]Processing val dataset:  97%|█████████▋| 971/1000 [00:14<00:00, 35.72it/s]Processing val dataset:  98%|█████████▊| 979/1000 [00:14<00:00, 43.51it/s]Processing val dataset:  98%|█████████▊| 985/1000 [00:14<00:00, 46.66it/s]Processing val dataset:  99%|█████████▉| 992/1000 [00:14<00:00, 51.28it/s]Processing val dataset: 100%|█████████▉| 998/1000 [00:14<00:00, 47.23it/s]Processing val dataset: 100%|██████████| 1000/1000 [00:15<00:00, 66.49it/s]Processing test dataset:  26%|██▌       | 259/1000 [00:17<01:52,  6.61it/s]Processing test dataset:  26%|██▌       | 261/1000 [00:17<01:57,  6.30it/s]Processing test dataset:  26%|██▌       | 262/1000 [00:17<01:53,  6.51it/s]Processing test dataset:  26%|██▋       | 264/1000 [00:17<01:33,  7.90it/s]Processing test dataset:  27%|██▋       | 267/1000 [00:17<01:08, 10.68it/s]Processing test dataset:  28%|██▊       | 275/1000 [00:18<00:33, 21.41it/s]
  0%|          | 0/1000 [00:00<?, ?it/s]Processing test dataset:   0%|          | 0/1000 [00:00<?, ?it/s]Processing test dataset:  28%|██▊       | 281/1000 [00:18<00:25, 28.11it/s]Processing test dataset:   0%|          | 5/1000 [00:00<00:21, 45.65it/s]Processing test dataset:   1%|          | 10/1000 [00:00<00:23, 42.15it/s]Processing test dataset:  28%|██▊       | 285/1000 [00:18<00:28, 25.01it/s]Processing test dataset:   2%|▏         | 15/1000 [00:00<00:28, 34.75it/s]Processing test dataset:  29%|██▉       | 289/1000 [00:18<00:28, 25.05it/s]Processing test dataset:   2%|▏         | 19/1000 [00:00<00:31, 31.04it/s]Processing test dataset:  29%|██▉       | 293/1000 [00:18<00:28, 24.70it/s]Processing test dataset:   2%|▏         | 23/1000 [00:00<00:39, 25.02it/s]Processing test dataset:  30%|██▉       | 296/1000 [00:18<00:35, 19.82it/s]Processing test dataset:   3%|▎         | 27/1000 [00:00<00:39, 24.43it/s]Processing test dataset:  30%|██▉       | 299/1000 [00:19<00:35, 19.82it/s]Processing test dataset:   3%|▎         | 31/1000 [00:01<00:36, 26.22it/s]Processing test dataset:   4%|▎         | 36/1000 [00:01<00:33, 28.54it/s]Processing test dataset:  30%|███       | 302/1000 [00:19<00:44, 15.66it/s]Processing test dataset:   4%|▍         | 39/1000 [00:01<00:34, 28.10it/s]Processing test dataset:   4%|▍         | 45/1000 [00:01<00:31, 30.16it/s]Processing test dataset:  30%|███       | 304/1000 [00:19<00:53, 13.03it/s]Processing test dataset:   5%|▍         | 49/1000 [00:01<00:34, 27.25it/s]Processing test dataset:  31%|███       | 306/1000 [00:19<00:52, 13.22it/s]Processing test dataset:   5%|▌         | 54/1000 [00:01<00:29, 31.71it/s]Processing test dataset:  31%|███       | 310/1000 [00:19<00:38, 17.70it/s]Processing test dataset:   6%|▌         | 60/1000 [00:01<00:27, 33.70it/s]Processing test dataset:  31%|███▏      | 314/1000 [00:20<00:34, 19.96it/s]Processing test dataset:  32%|███▏      | 317/1000 [00:20<00:35, 19.31it/s]Processing test dataset:   6%|▋         | 64/1000 [00:02<00:32, 28.85it/s]Processing test dataset:  32%|███▏      | 323/1000 [00:20<00:25, 26.52it/s]Processing test dataset:   7%|▋         | 68/1000 [00:02<00:35, 26.26it/s]Processing test dataset:  33%|███▎      | 327/1000 [00:20<00:24, 27.08it/s]Processing test dataset:   7%|▋         | 72/1000 [00:02<00:32, 28.19it/s]Processing test dataset:  33%|███▎      | 332/1000 [00:20<00:20, 32.12it/s]Processing test dataset:   8%|▊         | 78/1000 [00:02<00:27, 33.89it/s]Processing test dataset:  34%|███▍      | 339/1000 [00:20<00:17, 36.96it/s]Processing test dataset:   8%|▊         | 82/1000 [00:02<00:26, 34.66it/s]Processing test dataset:   9%|▊         | 86/1000 [00:02<00:30, 29.76it/s]Processing test dataset:   9%|▉         | 90/1000 [00:03<00:31, 28.84it/s]Processing test dataset:   9%|▉         | 94/1000 [00:03<00:34, 26.42it/s]Processing test dataset:  10%|▉         | 98/1000 [00:03<00:32, 28.05it/s]Processing test dataset:  10%|█         | 101/1000 [00:03<00:31, 28.26it/s]Processing test dataset:  10%|█         | 104/1000 [00:03<00:33, 26.76it/s]Processing test dataset:  34%|███▍      | 343/1000 [00:21<00:52, 12.45it/s]Processing test dataset:  11%|█         | 109/1000 [00:03<00:27, 32.08it/s]Processing test dataset:  11%|█▏        | 113/1000 [00:03<00:38, 23.02it/s]Processing test dataset:  12%|█▏        | 116/1000 [00:04<00:38, 23.12it/s]Processing test dataset:  12%|█▏        | 119/1000 [00:04<00:41, 21.42it/s]Processing test dataset:  35%|███▍      | 346/1000 [00:22<01:11,  9.18it/s]Processing test dataset:  12%|█▏        | 122/1000 [00:04<00:46, 18.85it/s]Processing test dataset:  13%|█▎        | 127/1000 [00:04<00:35, 24.33it/s]Processing test dataset:  13%|█▎        | 130/1000 [00:04<00:35, 24.56it/s]Processing test dataset:  14%|█▎        | 135/1000 [00:04<00:30, 28.52it/s]Processing test dataset:  35%|███▍      | 349/1000 [00:22<01:28,  7.32it/s]Processing test dataset:  14%|█▍        | 139/1000 [00:05<00:36, 23.39it/s]Processing test dataset:  35%|███▌      | 351/1000 [00:23<01:26,  7.50it/s]Processing test dataset:  15%|█▌        | 152/1000 [00:05<00:20, 40.71it/s]Processing test dataset:  35%|███▌      | 353/1000 [00:23<01:21,  7.91it/s]Processing test dataset:  16%|█▌        | 157/1000 [00:05<00:23, 36.59it/s]Processing test dataset:  17%|█▋        | 168/1000 [00:05<00:16, 50.76it/s]Processing test dataset:  36%|███▌      | 355/1000 [00:23<01:17,  8.28it/s]Processing test dataset:  18%|█▊        | 179/1000 [00:05<00:13, 59.59it/s]Processing test dataset:  36%|███▌      | 357/1000 [00:23<01:19,  8.12it/s]Processing test dataset:  19%|█▊        | 186/1000 [00:05<00:17, 46.25it/s]Processing test dataset:  19%|█▉        | 192/1000 [00:06<00:17, 44.99it/s]Processing test dataset:  20%|█▉        | 198/1000 [00:06<00:20, 38.49it/s]Processing test dataset:  36%|███▌      | 359/1000 [00:24<01:36,  6.64it/s]Processing test dataset:  20%|██        | 203/1000 [00:06<00:20, 38.40it/s]Processing test dataset:  36%|███▌      | 360/1000 [00:24<01:44,  6.14it/s]Processing test dataset:  21%|██        | 208/1000 [00:06<00:25, 30.55it/s]Processing test dataset:  36%|███▌      | 361/1000 [00:24<01:50,  5.76it/s]Processing test dataset:  21%|██▏       | 213/1000 [00:06<00:25, 30.61it/s]Processing test dataset:  36%|███▋      | 363/1000 [00:24<01:25,  7.42it/s]Processing test dataset:  22%|██▏       | 217/1000 [00:06<00:25, 30.21it/s]Processing test dataset:  22%|██▏       | 223/1000 [00:07<00:22, 35.26it/s]Processing test dataset:  36%|███▋      | 365/1000 [00:25<01:22,  7.67it/s]Processing test dataset:  23%|██▎       | 227/1000 [00:07<00:21, 35.39it/s]Processing test dataset:  37%|███▋      | 366/1000 [00:25<01:24,  7.49it/s]Processing test dataset:  23%|██▎       | 232/1000 [00:07<00:23, 33.39it/s]Processing test dataset:  37%|███▋      | 369/1000 [00:25<00:56, 11.21it/s]Processing test dataset:  24%|██▎       | 236/1000 [00:07<00:22, 33.82it/s]Processing test dataset:  24%|██▍       | 243/1000 [00:07<00:19, 38.39it/s]Processing test dataset:  37%|███▋      | 371/1000 [00:25<01:07,  9.36it/s]Processing test dataset:  25%|██▍       | 247/1000 [00:07<00:23, 32.07it/s]Processing test dataset:  37%|███▋      | 373/1000 [00:26<01:15,  8.30it/s]Processing test dataset:  25%|██▌       | 251/1000 [00:08<00:31, 23.97it/s]Processing test dataset:  38%|███▊      | 375/1000 [00:26<01:05,  9.57it/s]Processing test dataset:  26%|██▌       | 255/1000 [00:08<00:28, 25.98it/s]Processing test dataset:  38%|███▊      | 378/1000 [00:26<00:48, 12.88it/s]Processing test dataset:  26%|██▌       | 258/1000 [00:08<00:28, 26.44it/s]Processing test dataset:  38%|███▊      | 384/1000 [00:26<00:31, 19.65it/s]Processing test dataset:  26%|██▌       | 261/1000 [00:08<00:31, 23.65it/s]Processing test dataset:  39%|███▊      | 387/1000 [00:26<00:29, 20.82it/s]Processing test dataset:  26%|██▋       | 264/1000 [00:08<00:31, 23.18it/s]Processing test dataset:  39%|███▉      | 393/1000 [00:26<00:21, 28.84it/s]Processing test dataset:  40%|███▉      | 397/1000 [00:26<00:23, 25.40it/s]Processing test dataset:  27%|██▋       | 267/1000 [00:08<00:37, 19.65it/s]Processing test dataset:  40%|████      | 401/1000 [00:26<00:21, 28.15it/s]Processing test dataset:  40%|████      | 405/1000 [00:27<00:23, 25.57it/s]Processing test dataset:  27%|██▋       | 270/1000 [00:09<00:46, 15.76it/s]Processing test dataset:  41%|████      | 408/1000 [00:27<00:22, 26.12it/s]Processing test dataset:  27%|██▋       | 272/1000 [00:09<00:46, 15.76it/s]Processing test dataset:  41%|████      | 412/1000 [00:27<00:25, 22.97it/s]Processing test dataset:  27%|██▋       | 274/1000 [00:09<00:52, 13.95it/s]Processing test dataset:  42%|████▏     | 421/1000 [00:27<00:15, 36.39it/s]Processing test dataset:  28%|██▊       | 278/1000 [00:09<00:47, 15.29it/s]Processing test dataset:  43%|████▎     | 426/1000 [00:27<00:16, 34.80it/s]Processing test dataset:  28%|██▊       | 280/1000 [00:09<00:51, 13.96it/s]Processing test dataset:  43%|████▎     | 430/1000 [00:27<00:18, 31.58it/s]Processing test dataset:  28%|██▊       | 284/1000 [00:10<00:44, 16.00it/s]Processing test dataset:  29%|██▉       | 288/1000 [00:10<00:36, 19.64it/s]Processing test dataset:  29%|██▉       | 293/1000 [00:10<00:29, 23.57it/s]Processing test dataset:  30%|██▉       | 298/1000 [00:10<00:29, 24.02it/s]Processing test dataset:  30%|███       | 302/1000 [00:10<00:26, 26.17it/s]Processing test dataset:  43%|████▎     | 434/1000 [00:28<00:42, 13.29it/s]Processing test dataset:  31%|███       | 311/1000 [00:10<00:17, 39.68it/s]Processing test dataset:  32%|███▏      | 319/1000 [00:10<00:14, 48.56it/s]Processing test dataset:  32%|███▎      | 325/1000 [00:11<00:15, 43.21it/s]Processing test dataset:  33%|███▎      | 330/1000 [00:11<00:15, 43.08it/s]Processing test dataset:  34%|███▍      | 339/1000 [00:11<00:12, 53.78it/s]Processing test dataset:  44%|████▎     | 437/1000 [00:29<00:58,  9.59it/s]Processing test dataset:  34%|███▍      | 345/1000 [00:11<00:13, 48.29it/s]Processing test dataset:  44%|████▍     | 439/1000 [00:29<01:09,  8.02it/s]Processing test dataset:  35%|███▌      | 351/1000 [00:11<00:20, 31.27it/s]Processing test dataset:  36%|███▌      | 356/1000 [00:11<00:19, 33.58it/s]Processing test dataset:  36%|███▌      | 361/1000 [00:12<00:21, 29.52it/s]Processing test dataset:  44%|████▍     | 441/1000 [00:30<01:16,  7.35it/s]Processing test dataset:  36%|███▋      | 365/1000 [00:12<00:21, 29.08it/s]Processing test dataset:  37%|███▋      | 369/1000 [00:12<00:20, 30.97it/s]Processing test dataset:  37%|███▋      | 373/1000 [00:12<00:25, 24.17it/s]Processing test dataset:  44%|████▍     | 443/1000 [00:30<01:30,  6.14it/s]Processing test dataset:  38%|███▊      | 376/1000 [00:12<00:25, 24.63it/s]Processing test dataset:  39%|███▉      | 388/1000 [00:12<00:13, 43.80it/s]Processing test dataset:  44%|████▍     | 445/1000 [00:30<01:30,  6.11it/s]Processing test dataset:  40%|████      | 404/1000 [00:13<00:10, 54.77it/s]Processing test dataset:  45%|████▍     | 446/1000 [00:31<01:29,  6.18it/s]Processing test dataset:  41%|████      | 410/1000 [00:13<00:11, 52.48it/s]Processing test dataset:  45%|████▍     | 447/1000 [00:31<01:26,  6.38it/s]Processing test dataset:  42%|████▏     | 416/1000 [00:13<00:11, 52.19it/s]Processing test dataset:  45%|████▍     | 448/1000 [00:31<01:28,  6.23it/s]Processing test dataset:  42%|████▏     | 423/1000 [00:13<00:11, 51.44it/s]Processing test dataset:  43%|████▎     | 431/1000 [00:13<00:09, 57.82it/s]Processing test dataset:  45%|████▍     | 449/1000 [00:31<01:31,  5.99it/s]Processing test dataset:  44%|████▍     | 442/1000 [00:13<00:08, 66.14it/s]Processing test dataset:  45%|████▌     | 452/1000 [00:13<00:07, 73.44it/s]Processing test dataset:  45%|████▌     | 451/1000 [00:31<01:18,  6.99it/s]Processing test dataset:  46%|████▌     | 460/1000 [00:13<00:07, 71.50it/s]Processing test dataset:  45%|████▌     | 452/1000 [00:31<01:16,  7.13it/s]Processing test dataset:  47%|████▋     | 468/1000 [00:14<00:07, 68.27it/s]Processing test dataset:  46%|████▌     | 456/1000 [00:32<00:46, 11.74it/s]Processing test dataset:  48%|████▊     | 476/1000 [00:14<00:09, 56.43it/s]Processing test dataset:  46%|████▌     | 460/1000 [00:32<00:34, 15.59it/s]Processing test dataset:  46%|████▌     | 462/1000 [00:32<00:34, 15.79it/s]Processing test dataset:  46%|████▋     | 465/1000 [00:32<00:30, 17.69it/s]Processing test dataset:  48%|████▊     | 483/1000 [00:14<00:12, 42.30it/s]Processing test dataset:  47%|████▋     | 467/1000 [00:32<00:32, 16.37it/s]Processing test dataset:  49%|████▉     | 488/1000 [00:14<00:14, 34.76it/s]Processing test dataset:  47%|████▋     | 469/1000 [00:32<00:31, 17.11it/s]Processing test dataset:  47%|████▋     | 473/1000 [00:32<00:23, 22.39it/s]Processing test dataset:  49%|████▉     | 493/1000 [00:14<00:15, 33.13it/s]Processing test dataset:  48%|████▊     | 477/1000 [00:32<00:20, 25.96it/s]Processing test dataset:  48%|████▊     | 485/1000 [00:33<00:13, 37.79it/s]Processing test dataset:  50%|████▉     | 497/1000 [00:15<00:18, 27.62it/s]Processing test dataset:  49%|████▉     | 489/1000 [00:33<00:14, 34.38it/s]Processing test dataset:  50%|█████     | 504/1000 [00:15<00:14, 33.37it/s]Processing test dataset:  49%|████▉     | 493/1000 [00:33<00:14, 34.44it/s]Processing test dataset:  51%|█████     | 508/1000 [00:15<00:14, 34.46it/s]Processing test dataset:  51%|█████     | 512/1000 [00:15<00:14, 33.49it/s]Processing test dataset:  50%|████▉     | 497/1000 [00:33<00:19, 25.73it/s]Processing test dataset:  52%|█████▏    | 522/1000 [00:15<00:09, 47.88it/s]Processing test dataset:  50%|█████     | 504/1000 [00:33<00:14, 33.21it/s]Processing test dataset:  53%|█████▎    | 533/1000 [00:15<00:07, 58.59it/s]Processing test dataset:  51%|█████     | 511/1000 [00:33<00:12, 39.96it/s]Processing test dataset:  54%|█████▍    | 540/1000 [00:15<00:07, 59.73it/s]Processing test dataset:  52%|█████▏    | 517/1000 [00:33<00:11, 43.39it/s]Processing test dataset:  55%|█████▍    | 547/1000 [00:15<00:07, 59.62it/s]Processing test dataset:  56%|█████▌    | 561/1000 [00:16<00:05, 80.07it/s]Processing test dataset:  57%|█████▋    | 571/1000 [00:16<00:05, 78.62it/s]Processing test dataset:  58%|█████▊    | 580/1000 [00:16<00:05, 72.99it/s]Processing test dataset:  52%|█████▏    | 522/1000 [00:34<00:22, 21.28it/s]Processing test dataset:  59%|█████▉    | 588/1000 [00:16<00:06, 63.80it/s]Processing test dataset:  60%|█████▉    | 595/1000 [00:16<00:06, 60.46it/s]Processing test dataset:  60%|██████    | 605/1000 [00:16<00:05, 68.06it/s]Processing test dataset:  61%|██████▏   | 613/1000 [00:16<00:05, 70.95it/s]Processing test dataset:  62%|██████▏   | 621/1000 [00:16<00:05, 72.15it/s]Processing test dataset:  63%|██████▎   | 632/1000 [00:17<00:04, 80.65it/s]Processing test dataset:  64%|██████▍   | 641/1000 [00:17<00:05, 70.58it/s]Processing test dataset:  53%|█████▎    | 526/1000 [00:35<00:40, 11.65it/s]Processing test dataset:  65%|██████▍   | 649/1000 [00:17<00:05, 67.56it/s]Processing test dataset:  66%|██████▋   | 663/1000 [00:17<00:04, 84.22it/s]Processing test dataset:  67%|██████▋   | 673/1000 [00:17<00:03, 87.57it/s]Processing test dataset:  68%|██████▊   | 684/1000 [00:17<00:03, 92.00it/s]Processing test dataset:  53%|█████▎    | 529/1000 [00:35<00:45, 10.36it/s]Processing test dataset:  69%|██████▉   | 694/1000 [00:17<00:03, 89.02it/s]Processing test dataset:  70%|███████   | 704/1000 [00:17<00:03, 84.09it/s]Processing test dataset:  72%|███████▏  | 719/1000 [00:18<00:02, 100.86it/s]Processing test dataset:  74%|███████▍  | 738/1000 [00:18<00:02, 124.01it/s]Processing test dataset:  76%|███████▌  | 758/1000 [00:18<00:01, 143.38it/s]Processing test dataset:  53%|█████▎    | 532/1000 [00:36<00:56,  8.25it/s]Processing test dataset:  77%|███████▋  | 773/1000 [00:18<00:02, 76.06it/s] Processing test dataset:  53%|█████▎    | 534/1000 [00:36<01:06,  7.02it/s]Processing test dataset:  78%|███████▊  | 785/1000 [00:19<00:04, 47.94it/s]Processing test dataset:  54%|█████▎    | 536/1000 [00:37<01:18,  5.95it/s]Processing test dataset:  79%|███████▉  | 794/1000 [00:19<00:04, 45.97it/s]Processing test dataset:  80%|████████  | 802/1000 [00:19<00:04, 45.95it/s]Processing test dataset:  54%|█████▎    | 537/1000 [00:37<01:28,  5.20it/s]Processing test dataset:  54%|█████▍    | 538/1000 [00:38<01:30,  5.12it/s]Processing test dataset:  81%|████████  | 809/1000 [00:20<00:05, 34.42it/s]Processing test dataset:  54%|█████▍    | 541/1000 [00:38<01:01,  7.46it/s]Processing test dataset:  54%|█████▍    | 543/1000 [00:38<00:52,  8.75it/s]Processing test dataset:  82%|████████▏ | 815/1000 [00:20<00:05, 31.81it/s]Processing test dataset:  55%|█████▍    | 545/1000 [00:38<00:45,  9.99it/s]Processing test dataset:  82%|████████▏ | 820/1000 [00:20<00:05, 31.41it/s]Processing test dataset:  82%|████████▎ | 825/1000 [00:20<00:05, 33.09it/s]Processing test dataset:  83%|████████▎ | 829/1000 [00:20<00:05, 34.10it/s]Processing test dataset:  55%|█████▍    | 547/1000 [00:38<00:57,  7.87it/s]Processing test dataset:  83%|████████▎ | 833/1000 [00:20<00:04, 34.99it/s]Processing test dataset:  84%|████████▎ | 837/1000 [00:20<00:05, 29.40it/s]Processing test dataset:  55%|█████▍    | 549/1000 [00:39<00:55,  8.07it/s]Processing test dataset:  84%|████████▍ | 841/1000 [00:21<00:05, 30.73it/s]Processing test dataset:  55%|█████▌    | 551/1000 [00:39<00:49,  9.16it/s]Processing test dataset:  84%|████████▍ | 845/1000 [00:21<00:05, 29.34it/s]Processing test dataset:  55%|█████▌    | 553/1000 [00:39<00:42, 10.63it/s]Processing test dataset:  56%|█████▌    | 556/1000 [00:39<00:31, 14.14it/s]Processing test dataset:  56%|█████▌    | 561/1000 [00:39<00:21, 20.41it/s]Processing test dataset:  57%|█████▋    | 566/1000 [00:39<00:18, 22.87it/s]Processing test dataset:  85%|████████▍ | 849/1000 [00:21<00:08, 17.81it/s]Processing test dataset:  57%|█████▋    | 571/1000 [00:39<00:15, 28.46it/s]Processing test dataset:  86%|████████▌ | 855/1000 [00:21<00:06, 23.40it/s]Processing test dataset:  58%|█████▊    | 581/1000 [00:39<00:09, 43.15it/s]Processing test dataset:  86%|████████▌ | 859/1000 [00:21<00:05, 25.27it/s]Processing test dataset:  59%|█████▉    | 588/1000 [00:40<00:11, 35.59it/s]Processing test dataset:  86%|████████▋ | 863/1000 [00:22<00:06, 19.94it/s]Processing test dataset:  59%|█████▉    | 593/1000 [00:40<00:12, 33.67it/s]Processing test dataset:  87%|████████▋ | 866/1000 [00:22<00:06, 19.29it/s]Processing test dataset:  60%|█████▉    | 598/1000 [00:40<00:10, 36.75it/s]Processing test dataset:  60%|██████    | 603/1000 [00:40<00:10, 38.48it/s]Processing test dataset:  87%|████████▋ | 869/1000 [00:22<00:06, 19.15it/s]Processing test dataset:  61%|██████    | 611/1000 [00:40<00:08, 47.75it/s]Processing test dataset:  87%|████████▋ | 872/1000 [00:22<00:06, 20.89it/s]Processing test dataset:  88%|████████▊ | 883/1000 [00:22<00:03, 38.76it/s]Processing test dataset:  89%|████████▉ | 890/1000 [00:22<00:02, 44.53it/s]Processing test dataset:  62%|██████▏   | 617/1000 [00:40<00:10, 34.85it/s]Processing test dataset:  90%|█████████ | 900/1000 [00:23<00:01, 56.23it/s]Processing test dataset:  91%|█████████ | 912/1000 [00:23<00:01, 71.22it/s]Processing test dataset:  92%|█████████▏| 920/1000 [00:23<00:01, 62.03it/s]Processing test dataset:  93%|█████████▎| 928/1000 [00:23<00:01, 65.29it/s]Processing test dataset:  94%|█████████▎| 936/1000 [00:23<00:00, 66.36it/s]Processing test dataset:  62%|██████▏   | 622/1000 [00:41<00:20, 18.76it/s]Processing test dataset:  95%|█████████▍| 949/1000 [00:23<00:00, 58.39it/s]Processing test dataset:  63%|██████▎   | 626/1000 [00:41<00:22, 16.62it/s]Processing test dataset:  96%|█████████▌| 956/1000 [00:23<00:00, 60.20it/s]Processing test dataset:  63%|██████▎   | 629/1000 [00:42<00:21, 16.93it/s]Processing test dataset:  96%|█████████▋| 963/1000 [00:24<00:00, 53.57it/s]Processing test dataset:  63%|██████▎   | 633/1000 [00:42<00:19, 18.93it/s]Processing test dataset:  97%|█████████▋| 969/1000 [00:24<00:00, 43.52it/s]Processing test dataset:  64%|██████▎   | 636/1000 [00:42<00:21, 16.58it/s]Processing test dataset:  97%|█████████▋| 974/1000 [00:24<00:00, 38.43it/s]Processing test dataset:  98%|█████████▊| 983/1000 [00:24<00:00, 46.88it/s]Processing test dataset:  64%|██████▍   | 639/1000 [00:42<00:25, 14.12it/s]Processing test dataset:  99%|█████████▉| 989/1000 [00:24<00:00, 37.40it/s]Processing test dataset:  64%|██████▍   | 641/1000 [00:42<00:24, 14.71it/s]Processing test dataset: 100%|█████████▉| 996/1000 [00:24<00:00, 42.58it/s]Processing test dataset: 100%|██████████| 1000/1000 [00:25<00:00, 39.97it/s]Processing test dataset:  64%|██████▍   | 643/1000 [00:43<00:28, 12.58it/s]Processing test dataset:  64%|██████▍   | 645/1000 [00:43<00:31, 11.39it/s]Processing test dataset:  65%|██████▍   | 647/1000 [00:43<00:39,  8.97it/s]Processing test dataset:  65%|██████▌   | 650/1000 [00:43<00:29, 11.87it/s]Processing test dataset:  65%|██████▌   | 654/1000 [00:43<00:22, 15.47it/s]Processing test dataset:  66%|██████▌   | 659/1000 [00:44<00:16, 21.05it/s]Processing test dataset:  66%|██████▌   | 662/1000 [00:44<00:17, 19.26it/s]Processing test dataset:  66%|██████▋   | 665/1000 [00:44<00:17, 18.66it/s]Processing test dataset:  67%|██████▋   | 673/1000 [00:44<00:11, 29.43it/s]Processing test dataset:  69%|██████▊   | 686/1000 [00:44<00:06, 48.56it/s]Processing test dataset:  69%|██████▉   | 693/1000 [00:44<00:05, 53.15it/s]Processing test dataset:  70%|███████   | 700/1000 [00:45<00:07, 42.40it/s]Processing test dataset:  71%|███████   | 706/1000 [00:45<00:07, 39.45it/s]Processing test dataset:  72%|███████▏  | 717/1000 [00:45<00:05, 53.51it/s]Processing test dataset:  72%|███████▏  | 724/1000 [00:45<00:05, 50.32it/s]Processing test dataset:  73%|███████▎  | 730/1000 [00:45<00:07, 37.14it/s]Processing test dataset:  74%|███████▎  | 735/1000 [00:45<00:07, 33.34it/s]Processing test dataset:  75%|███████▍  | 746/1000 [00:46<00:05, 45.90it/s]Processing test dataset:  75%|███████▌  | 752/1000 [00:46<00:05, 45.79it/s]Processing test dataset:  78%|███████▊  | 783/1000 [00:46<00:02, 97.53it/s]Processing test dataset:  80%|███████▉  | 798/1000 [00:46<00:01, 107.13it/s]Processing test dataset:  81%|████████  | 811/1000 [00:46<00:02, 91.36it/s] Processing test dataset:  85%|████████▍ | 848/1000 [00:46<00:01, 151.62it/s]
Done!
Processing test dataset:  88%|████████▊ | 883/1000 [00:46<00:00, 197.82it/s]Processing test dataset:  91%|█████████ | 907/1000 [00:46<00:00, 181.96it/s]Processing test dataset:  93%|█████████▎| 928/1000 [00:47<00:00, 88.94it/s] Processing test dataset:  95%|█████████▍| 947/1000 [00:47<00:00, 102.81it/s]Processing test dataset:  96%|█████████▋| 964/1000 [00:47<00:00, 94.62it/s] Processing test dataset:  98%|█████████▊| 983/1000 [00:48<00:00, 97.49it/s]Processing test dataset: 100%|█████████▉| 996/1000 [00:48<00:00, 69.44it/s]Processing test dataset: 100%|██████████| 1000/1000 [00:48<00:00, 20.63it/s]
Done!
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230308_014203-wk2io7c4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_41
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/wk2io7c4
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230308_014203-dcalt2lv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_41
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/dcalt2lv
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230308_014203-95i102lh
wandb: Run `wandb offline` to turn off syncing.
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230308_014203-5wyz08m2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_41
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/95i102lh
wandb: Syncing run ResGatedGraphConv_41
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5wyz08m2
wandb: Waiting for W&B process to finish... (failed 255). Press Control-C to abort syncing.
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 46, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 80, in run
    model.train()
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 19, in train
    loss = (model(data).squeeze() - y).abs().mean()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 88, in forward
    x = gnn(x, edge_index, e)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/gnn.py", line 31, in forward
    x = layer(x, edge_index, edge_attr)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/pyg_gnn_wrapper.py", line 60, in forward
    return self.layer(x, edge_index, edge_attr)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/nn/conv/transformer_conv.py", line 176, in forward
    out = self.propagate(edge_index, query=query, key=key, value=value,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 437, in propagate
    out = self.message(**msg_kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/nn/conv/transformer_conv.py", line 216, in message
    alpha = softmax(alpha, index, ptr, size_i)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/utils/softmax.py", line 62, in softmax
    src_max = scatter(src, index, dim, dim_size=N, reduce='max')
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_scatter/scatter.py", line 160, in scatter
    return scatter_max(src, index, dim, out, dim_size)[0]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_scatter/scatter.py", line 72, in scatter_max
    return torch.ops.torch_scatter.scatter_max(src, index, dim, out, dim_size)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/_ops.py", line 143, in __call__
    return self._op(*args, **kwargs or {})
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py", line 187, in _teardown
    result = self._service.join()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/service/service.py", line 216, in join
      File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/subprocess.py", line 1083, in wait
    return self._wait(timeout=timeout)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/subprocess.py", line 1806, in _wait
    (pid, sts) = self._try_wait(0)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/subprocess.py", line 1764, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
wandb: 
wandb: Run history:
wandb:  test perf ▁▄▄▇▇▇▇▇▇▇▇████████████████████████
wandb: train loss ▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███▇█▇█████
wandb: train perf █▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▂▁▂▁▁▁▁▁
wandb: valid perf ▄▆▅▇▆▇▄▇▄▂▇█▁▇▇█▇▆▇▄▆▇▇█▇▇█▆▇▄▇██▆▅
wandb: 
wandb: Run summary:
wandb:  test perf -0.28729
wandb: train loss -0.26848
wandb: train perf 0.26848
wandb: valid perf -0.59124
wandb: 
wandb: 🚀 View run TransformerConv_41 at: https://wandb.ai/eddy26/graph-MLPMixer/runs/dcalt2lv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230308_014203-dcalt2lv/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▆▇▇▇▇▇▇▇▇▇██████████████████████████
wandb: train loss ▁▂▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb: train perf █▇▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▅▇▇▇▆▇▇█▇██████████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.13761
wandb: train loss -0.04375
wandb: train perf 0.04375
wandb: valid perf -0.17949
wandb: 
wandb: 🚀 View run GCNConv_41 at: https://wandb.ai/eddy26/graph-MLPMixer/runs/wk2io7c4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230308_014203-wk2io7c4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230308_030036-w7l0oyoy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_95
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/w7l0oyoy
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▃▅▆▆▆▆▇▇▇▇▇▇██████████████████████████
wandb: train loss ▁▃▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇████████████████████
wandb: train perf █▆▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▃▆▄▇▅▇▇▇▇▇▆▇███████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.07812
wandb: train loss -0.02579
wandb: train perf 0.02579
wandb: valid perf -0.11569
wandb: 
wandb: 🚀 View run GINEConv_41 at: https://wandb.ai/eddy26/graph-MLPMixer/runs/95i102lh
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230308_014203-95i102lh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230308_031829-czm19eq2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_95
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/czm19eq2
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.135 MB of 0.135 MB uploaded (0.000 MB deduped)wandb: | 0.135 MB of 0.135 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▅▆▆▆▇▇▇▇▇▇▇▇▇█████████████████████████
wandb: train loss ▁▃▄▄▅▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████████████████
wandb: train perf █▆▅▅▄▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▆▆▆▇▄▇▇▇▇▇▇▇▇▇███▇███████████████████▇█
wandb: 
wandb: Run summary:
wandb:  test perf -0.12418
wandb: train loss -0.02928
wandb: train perf 0.02928
wandb: valid perf -0.15573
wandb: 
wandb: 🚀 View run ResGatedGraphConv_41 at: https://wandb.ai/eddy26/graph-MLPMixer/runs/5wyz08m2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230308_014203-5wyz08m2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230308_032621-8yt0xke5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_95
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8yt0xke5
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▆▆▆▇▆▆▇▇▇▇██████████████████████████
wandb: train loss ▁▂▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████████
wandb: train perf █▇▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▂▅▅▅▅▆▆▇▆▆▇▇▆▇▆██▇██▇██████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.07396
wandb: train loss -0.0253
wandb: train perf 0.0253
wandb: valid perf -0.10415
wandb: 
wandb: 🚀 View run GINEConv_95 at: https://wandb.ai/eddy26/graph-MLPMixer/runs/czm19eq2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230308_031829-czm19eq2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230308_044902-arpqr9c6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_12
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/arpqr9c6
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 3, in <module>
    from core.train_helper import run
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 11, in <module>
    import wandb
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/__init__.py", line 26, in <module>
    from wandb import sdk as wandb_sdk
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/__init__.py", line 7, in <module>
    from .wandb_init import _attach, init  # noqa: F401
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/wandb_init.py", line 31, in <module>
    from .backend.backend import Backend
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/backend/backend.py", line 20, in <module>
    from ..internal.internal import wandb_internal
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/internal/internal.py", line 34, in <module>
    from . import context, handler, internal_util, sender, settings_static, writer
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/internal/sender.py", line 31, in <module>
    from wandb.filesync.dir_watcher import DirWatcher
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/filesync/dir_watcher.py", line 29, in <module>
    wd_polling = util.vendor_import("wandb_watchdog.observers.polling")
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/util.py", line 333, in vendor_import
    module = import_module(name)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/observers/__init__.py", line 63, in <module>
    from .inotify import InotifyObserver as Observer
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/observers/inotify.py", line 74, in <module>
    from .inotify_buffer import InotifyBuffer
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/observers/inotify_buffer.py", line 19, in <module>
    from wandb_watchdog.utils.delayed_queue import DelayedQueue
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 971, in get_code
  File "<frozen importlib._bootstrap_external>", line 640, in _compile_bytecode
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 46, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 49, in run
    model = create_model(cfg).to(cfg.device)
  File "/home/shpark/graph-MLPMixer/core/get_model.py", line 68, in create_model
    return GraphMLPMixer(nfeat_node=nfeat_node,
  File "/home/shpark/graph-MLPMixer/core/model.py", line 59, in __init__
    self.mlp_mixer = MLPMixer(
  File "/home/shpark/graph-MLPMixer/core/model_utils/mlp_mixer.py", line 61, in __init__
    [MixerBlock(nhid, self.n_patches, nhid*4, nhid//2, dropout=dropout) for _ in range(nlayer)])
  File "/home/shpark/graph-MLPMixer/core/model_utils/mlp_mixer.py", line 61, in <listcomp>
    [MixerBlock(nhid, self.n_patches, nhid*4, nhid//2, dropout=dropout) for _ in range(nlayer)])
TypeError: __init__() missing 1 required positional argument: 'channel_mix'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 46, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 49, in run
    model = create_model(cfg).to(cfg.device)
  File "/home/shpark/graph-MLPMixer/core/get_model.py", line 68, in create_model
    return GraphMLPMixer(nfeat_node=nfeat_node,
  File "/home/shpark/graph-MLPMixer/core/model.py", line 59, in __init__
    self.mlp_mixer = MLPMixer(
  File "/home/shpark/graph-MLPMixer/core/model_utils/mlp_mixer.py", line 61, in __init__
    [MixerBlock(nhid, self.n_patches, nhid*4, nhid//2, dropout=dropout) for _ in range(nlayer)])
  File "/home/shpark/graph-MLPMixer/core/model_utils/mlp_mixer.py", line 61, in <listcomp>
    [MixerBlock(nhid, self.n_patches, nhid*4, nhid//2, dropout=dropout) for _ in range(nlayer)])
TypeError: __init__() missing 1 required positional argument: 'channel_mix'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 46, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 49, in run
    model = create_model(cfg).to(cfg.device)
  File "/home/shpark/graph-MLPMixer/core/get_model.py", line 68, in create_model
    return GraphMLPMixer(nfeat_node=nfeat_node,
  File "/home/shpark/graph-MLPMixer/core/model.py", line 59, in __init__
    self.mlp_mixer = MLPMixer(
  File "/home/shpark/graph-MLPMixer/core/model_utils/mlp_mixer.py", line 61, in __init__
    [MixerBlock(nhid, self.n_patches, nhid*4, nhid//2, dropout=dropout) for _ in range(nlayer)])
  File "/home/shpark/graph-MLPMixer/core/model_utils/mlp_mixer.py", line 61, in <listcomp>
    [MixerBlock(nhid, self.n_patches, nhid*4, nhid//2, dropout=dropout) for _ in range(nlayer)])
TypeError: __init__() missing 1 required positional argument: 'channel_mix'
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_065038-iy2v9i7t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_41
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/iy2v9i7t
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_065038-0jp8y8lc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_41
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0jp8y8lc
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_065038-a39qqcr9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_41
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/a39qqcr9
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_065039-pk7di8y9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_41
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/pk7di8y9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇████████████████████████
wandb: train loss ▁▂▃▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇█▇██████████████
wandb: train perf █▇▆▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▂▁▁▁▂▅▅▆▆▆▆▇▇▇▇▇▇█▇█▇███████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.08323
wandb: train loss -0.02889
wandb: train perf 0.02889
wandb: valid perf -0.10817
wandb: 
wandb: 🚀 View run TransformerConv_41 at: https://wandb.ai/eddy26/graph-MLPMixer/runs/iy2v9i7t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_065038-iy2v9i7t/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_081813-4rtvz1c8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_95
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/4rtvz1c8
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▅▇▆▆▇▇▇▇▇▇▇▇▇▇██████████████████████
wandb: train loss ▁▃▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇███▇█████████████████
wandb: train perf █▆▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▄▆▄▂▅▆▇▇▇▆▇██▇▇▇███████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.07488
wandb: train loss -0.02367
wandb: train perf 0.02367
wandb: valid perf -0.11134
wandb: 
wandb: 🚀 View run GINEConv_41 at: https://wandb.ai/eddy26/graph-MLPMixer/runs/pk7di8y9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_065039-pk7di8y9/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_083318-0xj5hb9z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_95
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0xj5hb9z
wandb: Waiting for W&B process to finish... (failed 255). Press Control-C to abort syncing.
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 46, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 81, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 19, in train
    loss = (model(data).squeeze() - y).abs().mean()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 96, in forward
    mixer_x = self.mlp_mixer(mixer_x, coarsen_adj)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/mlp_mixer.py", line 79, in forward
    x = mixer_block(x, coarsen_adj)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/mlp_mixer.py", line 43, in forward
    x = x + self.channel_mix(x)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1125, in _call_impl
    forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py", line 187, in _teardown
    result = self._service.join()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/service/service.py", line 216, in join
    ret = self._internal_proc.wait()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/subprocess.py", line 1083, in wait
    return self._wait(timeout=timeout)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/subprocess.py", line 1806, in _wait
    (pid, sts) = self._try_wait(0)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/subprocess.py", line 1764, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_111630-3dq5rrgp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/3dq5rrgp
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_111630-1kiu6fa0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1kiu6fa0
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_111630-g0qeezm2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/g0qeezm2
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_111630-tmlnc29m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/tmlnc29m
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 46, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 52, in run
    wandb.init(
TypeError: init() got an unexpected keyword argument 'tag'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 46, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 52, in run
    wandb.init(
TypeError: init() got an unexpected keyword argument 'tag'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 46, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 52, in run
    wandb.init(
TypeError: init() got an unexpected keyword argument 'tag'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 46, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 52, in run
    wandb.init(
TypeError: init() got an unexpected keyword argument 'tag'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 46, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 52, in run
    wandb.init(
TypeError: init() got an unexpected keyword argument 'tag'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 46, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 52, in run
    wandb.init(
TypeError: init() got an unexpected keyword argument 'tag'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 46, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 52, in run
    wandb.init(
TypeError: init() got an unexpected keyword argument 'tag'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 46, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 52, in run
    wandb.init(
TypeError: init() got an unexpected keyword argument 'tag'
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_112359-8zzte6y1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8zzte6y1
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_112359-yry4rm5g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/yry4rm5g
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_112359-hfdxbs5n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/hfdxbs5n
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_112359-573yphjc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/573yphjc
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_112735-hs1s38v2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/hs1s38v2
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_112735-d581p9si
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/d581p9si
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_112735-5ja92mac
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5ja92mac
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_112735-wtawehdm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/wtawehdm
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▆▅▆▆▇▆▇▇▇▇▇▇██████████████████████████
wandb: train loss ▁▂▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████
wandb: train perf █▇▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▂▆▆▅▇▆▆▆▇▇▇▇▅█▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.15103
wandb: train loss -0.05283
wandb: train perf 0.05283
wandb: valid perf -0.18841
wandb: 
wandb: 🚀 View run GCNConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/573yphjc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_112359-573yphjc/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_124204-forxjh3y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/forxjh3y
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▅▆▆▇▇▇▇█▇▇▇▇██████████████████████████
wandb: train loss ▁▂▃▄▄▅▅▅▅▅▆▅▆▆▆▇▇▇▇▇▇▇██████████████████
wandb: train perf █▇▆▅▅▄▄▄▄▄▃▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▃▃▂▆▆▆▇▅▆▇▇▇▇▇▇█▇██████████▇███████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.15914
wandb: train loss -0.03985
wandb: train perf 0.03985
wandb: valid perf -0.18539
wandb: 
wandb: 🚀 View run ResGatedGraphConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/yry4rm5g
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_112359-yry4rm5g/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Network error (ReadTimeout), entering retry loop.
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/wandb_init.py", line 1144, in init
    run = wi.init()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/wandb_init.py", line 773, in init
    raise error
wandb.errors.CommError: Error communicating with wandb process, exiting...
For more info see: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
wandb: ERROR Abnormal program exit
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/wandb_init.py", line 1144, in init
    run = wi.init()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/wandb_init.py", line 773, in init
    raise error
wandb.errors.CommError: Error communicating with wandb process, exiting...
For more info see: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 46, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 52, in run
    wandb.init(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/wandb_init.py", line 1181, in init
    raise Exception("problem") from error_seen
Exception: problem
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.136 MB of 0.136 MB uploaded (0.000 MB deduped)wandb: / 0.136 MB of 0.136 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████████
wandb: train loss ▁▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇████████████████
wandb: train perf █▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▅▁▅▂▅▅▇▇▆▆▇▇▇▇▇█▇▇▇▇▇███████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.09703
wandb: train loss -0.03264
wandb: train perf 0.03264
wandb: valid perf -0.12156
wandb: 
wandb: 🚀 View run GINEConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/hfdxbs5n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_112359-hfdxbs5n/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_125519-nfv14bsl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/nfv14bsl
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▆▇▇▇▇▇▇▇▇▇▇█████████████████████████
wandb: train loss ▁▃▄▄▅▅▅▆▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇█████████████████
wandb: train perf █▆▅▅▄▄▄▃▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▅▆▆▆▇▇▇█▇▆▇▇▇▇██▇██▇███████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.12272
wandb: train loss -0.02467
wandb: train perf 0.02467
wandb: valid perf -0.14844
wandb: 
wandb: 🚀 View run ResGatedGraphConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/d581p9si
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_112735-d581p9si/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_131252-jc6ehrk7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/jc6ehrk7
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.158 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.158 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████
wandb: train loss ▁▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████████████
wandb: train perf █▆▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▅▆▇▇▇▇██▇█▇██████▇█████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.13822
wandb: train loss -0.03236
wandb: train perf 0.03236
wandb: valid perf -0.16916
wandb: 
wandb: 🚀 View run GCNConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/wtawehdm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_112735-wtawehdm/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_131834-6bmklobg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6bmklobg
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.011 MB of 0.154 MB uploaded (0.000 MB deduped)wandb: | 0.150 MB of 0.154 MB uploaded (0.000 MB deduped)wandb: / 0.154 MB of 0.154 MB uploaded (0.000 MB deduped)wandb: - 0.154 MB of 0.154 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▅▅▆▇▇▇▇▇▇▇▇▇▇█████████████████████████
wandb: train loss ▁▃▄▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇████████████████
wandb: train perf █▆▅▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▂▂▅▄▁▆▅▆▄▆▇▇▆▆▆▆█▇▇█▇██▇████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.07155
wandb: train loss -0.02226
wandb: train perf 0.02226
wandb: valid perf -0.10604
wandb: 
wandb: 🚀 View run GINEConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/5ja92mac
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_112735-5ja92mac/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_132202-2p1satak
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/2p1satak
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▂▅▅▇▇▇▇▇▇▇▇▇▇▇▇████████████████████████
wandb: train loss ▁▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████████████
wandb: train perf █▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▂▆▃▇▅▆▆▇▇▇▇▇▁▇▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.16562
wandb: train loss -0.05146
wandb: train perf 0.05146
wandb: valid perf -0.18861
wandb: 
wandb: 🚀 View run GCNConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/forxjh3y
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_124204-forxjh3y/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_135448-j6pywbvm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/j6pywbvm
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.204 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.204 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████████████████████
wandb: train loss ▁▃▄▄▄▅▅▅▅▅▅▆▆▅▆▆▆▇▇▇▇▇▇▇████████████████
wandb: train perf █▆▅▅▅▄▄▄▄▄▄▃▃▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▂▄▁▆▅▁▆▆▆▆▇▇▇▂▇▇▇▇███▇█▇████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.09553
wandb: train loss -0.03522
wandb: train perf 0.03522
wandb: valid perf -0.12478
wandb: 
wandb: 🚀 View run TransformerConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/8zzte6y1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_112359-8zzte6y1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_135533-x5pxrb29
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/x5pxrb29
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.204 MB uploaded (0.000 MB deduped)wandb: | 0.124 MB of 0.204 MB uploaded (0.000 MB deduped)wandb: / 0.124 MB of 0.204 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▆▇▇▇▇▇▇███████████████████████████████
wandb: train loss ▁▃▄▄▅▅▅▅▆▆▇▇▇▇▇▇▇█▇█████████████████████
wandb: train perf █▆▅▅▄▄▄▄▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▂▃▆▅▅▅▇▆▇▇█████▇█▇█████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.08255
wandb: train loss -0.02397
wandb: train perf 0.02397
wandb: valid perf -0.10699
wandb: 
wandb: 🚀 View run TransformerConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/hs1s38v2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_112735-hs1s38v2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_141532-4nfz154x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/4nfz154x
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: / 0.016 MB of 0.152 MB uploaded (0.000 MB deduped)wandb: - 0.016 MB of 0.152 MB uploaded (0.000 MB deduped)wandb: \ 0.016 MB of 0.152 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇███████████████
wandb: train loss ▁▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇███▇██████████████
wandb: train perf █▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▄▆▁▆▆▇▇▇▇▇▇▇█▇█▇▇▇█▇████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.09779
wandb: train loss -0.03047
wandb: train perf 0.03047
wandb: valid perf -0.12399
wandb: 
wandb: 🚀 View run GINEConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/nfv14bsl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_125519-nfv14bsl/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_143853-r0iv1lgl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/r0iv1lgl
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.130 MB of 0.130 MB uploaded (0.000 MB deduped)wandb: / 0.130 MB of 0.130 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▄▅▇▇▇▇▇▇██████████████████████████████
wandb: train loss ▁▂▃▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█████████████████
wandb: train perf █▇▆▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▄▄▁▇▂▇▇█▇▇▇███▇▇▇█▇████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.13402
wandb: train loss -0.02902
wandb: train perf 0.02902
wandb: valid perf -0.16408
wandb: 
wandb: 🚀 View run ResGatedGraphConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/jc6ehrk7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_131252-jc6ehrk7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_144620-22dzej66
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/22dzej66
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.152 MB of 0.152 MB uploaded (0.000 MB deduped)wandb: | 0.152 MB of 0.152 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▆▆▆▇▇▇▇█████████████████████████████
wandb: train loss ▁▃▃▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇████████████████
wandb: train perf █▆▆▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▄▁▅▆▄▇▇▅▇▇▇████████▇████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.14488
wandb: train loss -0.03489
wandb: train perf 0.03489
wandb: valid perf -0.17411
wandb: 
wandb: 🚀 View run GCNConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6bmklobg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_131834-6bmklobg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_150821-2vvv1hac
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/2vvv1hac
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.136 MB uploaded (0.000 MB deduped)wandb: | 0.135 MB of 0.136 MB uploaded (0.000 MB deduped)wandb: / 0.135 MB of 0.136 MB uploaded (0.000 MB deduped)wandb: - 0.135 MB of 0.136 MB uploaded (0.000 MB deduped)wandb: \ 0.135 MB of 0.136 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▆▇▇▇▇▇▇▇▇▇██████████████████████████
wandb: train loss ▁▃▃▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█████████████████
wandb: train perf █▆▆▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▂▄▆▁▆▅▅▆▃▇▆▃▆█▇█▇██████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.15215
wandb: train loss -0.04734
wandb: train perf 0.04734
wandb: valid perf -0.19748
wandb: 
wandb: 🚀 View run GCNConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/j6pywbvm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_135448-j6pywbvm/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_152508-2e1jdgk9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/2e1jdgk9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.186 MB uploaded (0.000 MB deduped)wandb: / 0.186 MB of 0.186 MB uploaded (0.000 MB deduped)wandb: - 0.186 MB of 0.186 MB uploaded (0.000 MB deduped)wandb: \ 0.186 MB of 0.186 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇██████████████████
wandb: train loss ▁▂▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb: train perf █▇▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▃▅▆▆▇▇▅▇▅▇▆▇▇▇▇▇▇▇▇▇█▇▇█▇██████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.07053
wandb: train loss -0.02025
wandb: train perf 0.02025
wandb: valid perf -0.09787
wandb: 
wandb: 🚀 View run GINEConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/2p1satak
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_132202-2p1satak/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_154633-pcb3z04v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/pcb3z04v
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.168 MB of 0.168 MB uploaded (0.000 MB deduped)wandb: / 0.168 MB of 0.168 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▆▇▇▇▇▇▇▇▆▆▇▇▇▇███▇███████████████████
wandb: train loss ▁▃▄▅▄▅▅▅▅▅▆▅▆▇▇▇▇▇▇▇▇▇▇█▇▇██████████████
wandb: train perf █▆▅▄▅▄▄▄▄▄▃▄▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▂▆▇▇▇██▇▇▇▅████████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.09451
wandb: train loss -0.03385
wandb: train perf 0.03385
wandb: valid perf -0.12815
wandb: 
wandb: 🚀 View run TransformerConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/x5pxrb29
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_135533-x5pxrb29/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_160119-kodakvy2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/kodakvy2
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.118 MB uploaded (0.000 MB deduped)wandb: | 0.118 MB of 0.118 MB uploaded (0.000 MB deduped)wandb: / 0.118 MB of 0.118 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▆▇▇▇▇▇▇▇▇▇▇▇▇██████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb: train loss ▁▂▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████████████
wandb: train perf █▇▆▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▃▅▁▆▇▆▆▇▇▄▇▇▇▆▇▇█▇█▇████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.14556
wandb: train loss -0.03403
wandb: train perf 0.03403
wandb: valid perf -0.16023
wandb: 
wandb: 🚀 View run ResGatedGraphConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/22dzej66
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_144620-22dzej66/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_161045-cm9r8rym
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/cm9r8rym
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████████████
wandb: train loss ▁▃▄▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████
wandb: train perf █▆▅▅▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▁▄▄▅▅▅▄▄▇▆▇▆▇█▇▇▇█▇▇███████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.0903
wandb: train loss -0.03117
wandb: train perf 0.03117
wandb: valid perf -0.11893
wandb: 
wandb: 🚀 View run GINEConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/r0iv1lgl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_143853-r0iv1lgl/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_162547-8rjtgw5k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8rjtgw5k
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.143 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.143 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▄▅▅▆▆▇▇▇▇▇▇▇▇█████████████████████████
wandb: train loss ▁▂▃▄▄▄▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████████████
wandb: train perf █▇▆▅▅▅▄▄▃▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▆▅▇▆▆▆▇▇▇▇▇▇█▇█████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.1321
wandb: train loss -0.03629
wandb: train perf 0.03629
wandb: valid perf -0.17685
wandb: 
wandb: 🚀 View run GCNConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/2vvv1hac
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_150821-2vvv1hac/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_164826-174azsr3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/174azsr3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.189 MB of 0.189 MB uploaded (0.000 MB deduped)wandb: | 0.189 MB of 0.189 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▆▇▇▇▇▇▇▇████████████████████████████
wandb: train loss ▁▂▃▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇█▇███████████████████
wandb: train perf █▇▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▂▃▆▅▃▆▇▅▆▇▇▇▇█▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.07678
wandb: train loss -0.02406
wandb: train perf 0.02406
wandb: valid perf -0.10785
wandb: 
wandb: 🚀 View run TransformerConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/4nfz154x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_141532-4nfz154x/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_165459-l9j77s8c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/l9j77s8c
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇█████████████████████████
wandb: train loss ▁▂▃▄▅▅▅▅▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇███████████████
wandb: train perf █▇▆▅▄▄▄▄▄▃▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▆▇▇▇▇▇▇▅██████▇▇███████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.1499
wandb: train loss -0.04433
wandb: train perf 0.04433
wandb: valid perf -0.19362
wandb: 
wandb: 🚀 View run GCNConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/2e1jdgk9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_152508-2e1jdgk9/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▄▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇███████████████████████
wandb: train loss ▁▃▄▄▄▅▄▅▅▅▅▆▆▆▇▆▇▇▇▆▇▇▇▇▇▇██████████████
wandb: train perf █▆▅▅▅▄▅▄▄▄▄▃▃▃▂▃▂▂▂▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▄▄▄▅▅▄▄▄▆▄▅▁▇▇▇▇▆▄▆█▇██████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.10129
wandb: train loss -0.03795
wandb: train perf 0.03795
wandb: valid perf -0.13155
wandb: 
wandb: 🚀 View run TransformerConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/kodakvy2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_160119-kodakvy2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_174051-6lfp7p23
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6lfp7p23
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▃▅▅▆▆▇▇▇▇▇▇▇▇██▇▇▇█████████████████████
wandb: train loss ▁▂▃▄▄▅▅▅▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇████████████████
wandb: train perf █▇▆▅▅▄▄▄▄▃▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▂▁▄▅▇▆▅▆▇▃▆▇▆▇▂▇█▆▇█████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.12611
wandb: train loss -0.02929
wandb: train perf 0.02929
wandb: valid perf -0.15483
wandb: 
wandb: 🚀 View run ResGatedGraphConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/cm9r8rym
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_161045-cm9r8rym/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▅▅▆▆▇▇▇▇▇▇▇▇▇▇█████████████████████████
wandb: train loss ▁▃▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████
wandb: train perf █▆▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▂▁▅▅▆▇▁▇▇▇▇▇█▇▇█████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.07805
wandb: train loss -0.02011
wandb: train perf 0.02011
wandb: valid perf -0.10597
wandb: 
wandb: 🚀 View run GINEConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/pcb3z04v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_154633-pcb3z04v/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_175959-x13ncei0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/x13ncei0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████████████
wandb: train loss ▁▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇██████████████████
wandb: train perf █▆▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▇▁▇▇▆▆▆█▇█▇██▇█▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.10319
wandb: train loss -0.03409
wandb: train perf 0.03409
wandb: valid perf -0.13086
wandb: 
wandb: 🚀 View run GINEConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/8rjtgw5k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_162547-8rjtgw5k/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.120 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.120 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▅▆▆▇▇▇▇▇▇▇▇▇███▇▇▇▇███████████████████
wandb: train loss ▁▂▃▄▄▅▅▅▅▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████
wandb: train perf █▇▆▅▅▄▄▄▄▃▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▁▇▆▇▇▇▇▇█▇█▇█▇█████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.13636
wandb: train loss -0.04061
wandb: train perf 0.04061
wandb: valid perf -0.16914
wandb: 
wandb: 🚀 View run GCNConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/174azsr3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_164826-174azsr3/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▅▅▆▆▇▇▇▇▇▇▇▇▇▇█████████████████████████
wandb: train loss ▁▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇███████████████
wandb: train perf █▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▃▅▁▃▅▆▅▆▇▇▆▇▇▇▇▇▇██████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.07376
wandb: train loss -0.02562
wandb: train perf 0.02562
wandb: valid perf -0.11189
wandb: 
wandb: 🚀 View run TransformerConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/l9j77s8c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_165459-l9j77s8c/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_190739-fg9ntepx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv__onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/fg9ntepx
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▆▇▇▇▇▇▇▇▇▇▇█████████████████████████
wandb: train loss ▁▂▃▄▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇██████████████████
wandb: train perf █▇▆▅▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▇▇▇▇▇████▇█████████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.08275
wandb: train loss -0.02376
wandb: train perf 0.02376
wandb: valid perf -0.10853
wandb: 
wandb: 🚀 View run GINEConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/x13ncei0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_175959-x13ncei0/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▆▆▆▇▇▇▇▇▆▆▆▇▇▇█▇▇█▇▇█████████████████
wandb: train loss ▁▂▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█▇███████████████
wandb: train perf █▇▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▇▇█▇▇███████▇██████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.09118
wandb: train loss -0.0326
wandb: train perf 0.0326
wandb: valid perf -0.12157
wandb: 
wandb: 🚀 View run TransformerConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6lfp7p23
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_174051-6lfp7p23/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████████████
wandb: train loss ▁▂▃▄▄▄▅▅▅▅▅▆▅▆▆▆▇▇▇▇▇▇▇▇████████████████
wandb: train perf █▇▆▅▅▅▄▄▄▄▄▃▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▇▆▇███▇██▇█▇███████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.07816
wandb: train loss -0.03339
wandb: train perf 0.03339
wandb: valid perf -0.10781
wandb: 
wandb: 🚀 View run TransformerConv__onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/fg9ntepx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_190739-fg9ntepx/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_234127-tyxzv95z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConvonlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/tyxzv95z
wandb: Waiting for W&B process to finish... (failed 255). Press Control-C to abort syncing.
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 46, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 83, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 20, in train
    loss.backward()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py", line 187, in _teardown
    result = self._service.join()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/service/service.py", line 216, in join
    ret = self._internal_proc.wait()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/subprocess.py", line 1083, in wait
    return self._wait(timeout=timeout)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/subprocess.py", line 1806, in _wait
    (pid, sts) = self._try_wait(0)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/subprocess.py", line 1764, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁
wandb: train loss ▁▆▇█
wandb: train perf █▃▂▁
wandb: valid perf █▅▁▇
wandb: 
wandb: Run summary:
wandb:  test perf -0.55361
wandb: train loss -0.43371
wandb: train perf 0.43371
wandb: valid perf -0.5721
wandb: 
wandb: 🚀 View run ResGatedGraphConvonlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/tyxzv95z
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_234127-tyxzv95z/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_234224-vzxhbhwm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/vzxhbhwm
wandb: Waiting for W&B process to finish... (failed 255). Press Control-C to abort syncing.
wandb: 
wandb: Run history:
wandb:  test perf ▁███
wandb: train loss ▁▆██
wandb: train perf █▃▁▁
wandb: valid perf ▁██▆
wandb: 
wandb: Run summary:
wandb:  test perf -0.50096
wandb: train loss -0.44233
wandb: train perf 0.44233
wandb: valid perf -0.74142
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/vzxhbhwm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_234224-vzxhbhwm/logs
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 46, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 83, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/zinc.py", line 11, in train
    if model.use_lap:
KeyboardInterrupt
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_234339-h6xebem0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/h6xebem0
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 245, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 245, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 245, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 245, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/moltox21.py", line 87, in <module>
    run(cfg, create_dataset, create_model, train, test, evaluator=evaluator)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 98, in create_dataset
    dataset = PygGraphPropPredDataset(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/ogb/graphproppred/dataset_pyg.py", line 55, in __init__
    if input('Will you update the dataset now? (y/N)\n').lower() == 'y':
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/moltox21.py", line 87, in <module>
    run(cfg, create_dataset, create_model, train, test, evaluator=evaluator)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 98, in create_dataset
    dataset = PygGraphPropPredDataset(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/ogb/graphproppred/dataset_pyg.py", line 55, in __init__
    if input('Will you update the dataset now? (y/N)\n').lower() == 'y':
EOFError: EOF when reading a line
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/moltox21.py", line 87, in <module>
    run(cfg, create_dataset, create_model, train, test, evaluator=evaluator)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 98, in create_dataset
    dataset = PygGraphPropPredDataset(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/ogb/graphproppred/dataset_pyg.py", line 55, in __init__
    if input('Will you update the dataset now? (y/N)\n').lower() == 'y':
EOFError: EOF when reading a line
  0%|          | 0/2 [00:00<?, ?it/s]Downloaded 0.00 GB:   0%|          | 0/2 [00:01<?, ?it/s]Downloaded 0.00 GB:  50%|█████     | 1/2 [00:01<00:01,  1.08s/it]Downloaded 0.00 GB:  50%|█████     | 1/2 [00:01<00:01,  1.08s/it]Downloaded 0.00 GB: 100%|██████████| 2/2 [00:01<00:00,  1.85it/s]
Processing...
  0%|          | 0/7831 [00:00<?, ?it/s]100%|██████████| 7831/7831 [00:00<00:00, 101794.41it/s]
  0%|          | 0/7831 [00:00<?, ?it/s] 32%|███▏      | 2488/7831 [00:00<00:00, 16303.37it/s]100%|██████████| 7831/7831 [00:00<00:00, 35789.50it/s]
Done!
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_234724-c4fhu53a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/c4fhu53a
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_234924-d8bqcuoi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/d8bqcuoi
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_234924-kc5flf7e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/kc5flf7e
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_234924-i0pl2j3b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/i0pl2j3b
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230309_234924-ui9n3o58
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ui9n3o58
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▅▆▆▆▆▇▇▇▇▇▇▇▇█████████████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb: valid perf ▁▄▅▆▇▇▇▇▇▇███████████▇▇▇█▇▇▇▇█▇▇▇▇▇▇▇▇▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.78741
wandb: train loss 0.12125
wandb: train perf 0.93828
wandb: valid perf 0.81164
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/d8bqcuoi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_234924-d8bqcuoi/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_003710-5pwsr8sg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5pwsr8sg
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▅▆▆▆▆▇▇▇▇▇███▇▇▇█████████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb: valid perf ▁▄▅▆▇▇▆▇▇▇▇▇█▇▇▇▇▇▇█████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.78841
wandb: train loss 0.11252
wandb: train perf 0.95064
wandb: valid perf 0.82431
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ui9n3o58
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_234924-ui9n3o58/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_003810-wx8sbn0s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/wx8sbn0s
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▆▆▆█▇▇▇███████████████████████████████
wandb: train loss █▇▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb: valid perf ▁▅▆▆▇▇█▇▇▇█▇█▇▇████▇██▇▇██▇▇▇▇█▇▇▇▇▇▇▇▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.78197
wandb: train loss 0.10296
wandb: train perf 0.95919
wandb: valid perf 0.80769
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/kc5flf7e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_234924-kc5flf7e/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_003847-xah8m0pm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xah8m0pm
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▃▅▆▆▆▇▇▇▇▇▇██▇███▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb: train loss █▇▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇████████████████
wandb: valid perf ▁▄▆▆▇▇▇▇▇▇▇▇▇▇██████▇██████▇███████▇████
wandb: 
wandb: Run summary:
wandb:  test perf 0.78749
wandb: train loss 0.11933
wandb: train perf 0.94207
wandb: valid perf 0.82482
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/i0pl2j3b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_234924-i0pl2j3b/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_004419-qgl0okmw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/qgl0okmw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▅▆▇▇▇▇▇▇▇▇▇▇▇██████████████████████████
wandb: train loss ▁▃▃▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇██████████████████
wandb: train perf █▆▆▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▃▅▄▇▅▆▆▇▃▅▆▆▇██████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.14169
wandb: train loss -0.04793
wandb: train perf 0.04793
wandb: valid perf -0.17973
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/h6xebem0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230309_234339-h6xebem0/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_005006-jjhwnm9w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/jjhwnm9w
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: \ 0.016 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.016 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb: valid perf ▁▄▆▆▇▇▇▇█▇▇▇█▇▇████▇█▇▇███████▇███▇▇████
wandb: 
wandb: Run summary:
wandb:  test perf 0.78731
wandb: train loss 0.12241
wandb: train perf 0.93642
wandb: valid perf 0.81857
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/5pwsr8sg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_003710-5pwsr8sg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_012505-rkq64qts
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/rkq64qts
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▅▆▇▇▇▇▇▇▇█▇██████████████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb: valid perf ▁▃▄▅▆▆▆▆▇▆▇▇▇███▇██▇███▇████▇█▇▇▇▇▇▇▇▇▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.78316
wandb: train loss 0.1117
wandb: train perf 0.95022
wandb: valid perf 0.8227
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/wx8sbn0s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_003810-wx8sbn0s/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_012707-wufhrkly
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/wufhrkly
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▅▆▆▆▇▇▇▇▇▇▇███████████████████████████
wandb: train loss █▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb: valid perf ▁▄▆▆▆▇▇▇▇▇▇▇▇▇████▇▇▇██████▇███▇████▇█▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.78569
wandb: train loss 0.09853
wandb: train perf 0.96307
wandb: valid perf 0.81534
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xah8m0pm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_003847-xah8m0pm/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_012746-1m6rwo5t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1m6rwo5t
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▅▆▆▆▆▆▆▆▇▇▇▇████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb: train loss █▇▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████████
wandb: valid perf ▁▄▅▆▇▇▇▇▇▇▇▇▇▇██▇▇███▇▇███▇▇▇▇▇████▇█▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 0.78192
wandb: train loss 0.11923
wandb: train perf 0.93961
wandb: valid perf 0.81814
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/qgl0okmw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_004419-qgl0okmw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_014010-ozyf3wpe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ozyf3wpe
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: \ 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: \ 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: \ 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: \ 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: \ 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb: valid perf ▁▃▅▆▆▆▇▇▇▇█▇▇▇▇▇▇████████████▇█████▇▇██▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.78132
wandb: train loss 0.12136
wandb: train perf 0.93845
wandb: valid perf 0.8127
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/rkq64qts
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_012505-rkq64qts/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_021302-va4bxb00
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/va4bxb00
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▂▅▆▆▆▇▇▇███████████████████████████████
wandb: train loss ▁▂▃▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇████████████████
wandb: train perf █▇▆▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▃▁▆▆▇▇▇█▇▇▇▇▇▆█▇█▇█████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.15523
wandb: train loss -0.04112
wandb: train perf 0.04112
wandb: valid perf -0.18153
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/jjhwnm9w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_005006-jjhwnm9w/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_021537-rratj1dw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/rratj1dw
wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▅▆▇▆▇▇▇▇▇▇▇▇▇████████████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb: valid perf ▁▄▅▅▆▆▇▇█▇█▇▇▇▇▇███▇███▇█▇▇█▇▇▇▇▇▇▇▇▇▇▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.78458
wandb: train loss 0.11733
wandb: train perf 0.94408
wandb: valid perf 0.80656
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/wufhrkly
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_012707-wufhrkly/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_021541-3nrzsg8a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/3nrzsg8a
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.016 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.016 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: \ 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▅▆▇▆▇▇▇▇▇▇▇▇▇▇███████████████████████
wandb: train loss █▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb: valid perf ▁▅▆▆▇▇▇██▇█▇▇███▇▇█▇█▇▇▇▇█▇▇█▇█▇▇▇▇▇▇▇▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.7858
wandb: train loss 0.09801
wandb: train perf 0.96244
wandb: valid perf 0.80853
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/1m6rwo5t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_012746-1m6rwo5t/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_021643-b6yl4v8x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/b6yl4v8x
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▆▇▇▇▇▇▇▇████████████████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb: valid perf ▁▄▅▆▆▆▇▇▇▇▇███▇▇█████▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.78379
wandb: train loss 0.1107
wandb: train perf 0.95033
wandb: valid perf 0.80862
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ozyf3wpe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_014010-ozyf3wpe/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_023501-29054rtr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/29054rtr
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▃▅▆▆▇▇▇▇████▇▇█████████████████████████
wandb: train loss █▇▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb: valid perf ▁▃▅▆▇▇▇▇▇▇█▇▇█▇██▇█▇███████▇███▇████▇██▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.77976
wandb: train loss 0.12187
wandb: train perf 0.93705
wandb: valid perf 0.81291
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/va4bxb00
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_021302-va4bxb00/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▅▅▆▆▆▆▇▇▇▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb: valid perf ▁▄▆▆▆▇▇▇▇▇▇███████▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.77353
wandb: train loss 0.11423
wandb: train perf 0.94636
wandb: valid perf 0.81187
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/3nrzsg8a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_021541-3nrzsg8a/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▅▇▇▇▇██▇█████████████████████████████
wandb: train loss █▇▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb: valid perf ▁▄▆▇▇▇▇▇█▇▇███▇███████▇████▇███▇▇█▇█▇▇█▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.79045
wandb: train loss 0.10286
wandb: train perf 0.95832
wandb: valid perf 0.81187
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/b6yl4v8x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_021643-b6yl4v8x/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇████████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb: valid perf ▁▃▅▆▆▇▇▇▇▇▇█▇▇████████████████████▇█████
wandb: 
wandb: Run summary:
wandb:  test perf 0.78621
wandb: train loss 0.1159
wandb: train perf 0.94353
wandb: valid perf 0.82674
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/29054rtr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_023501-29054rtr/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▅▅▆▆▆▇▆▆▆▇▆▆▆▇▇▇▇▇▇████████████████████
wandb: train loss ▁▃▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇█████████████████
wandb: train perf █▆▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▂▆▆▆▆▆▇▁████████▇███████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.14208
wandb: train loss -0.03609
wandb: train perf 0.03609
wandb: valid perf -0.18163
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/rratj1dw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_021537-rratj1dw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_035119-i5sf4qlp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMix
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/i5sf4qlp
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 244, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 244, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 244, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 244, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/peptides_func.py", line 97, in <module>
    run(cfg, create_dataset, create_model, train, test, evaluator=None)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 106, in create_dataset
    dataset = PeptidesFunctionalDataset(
  File "/home/shpark/graph-MLPMixer/core/data_utils/peptides_functional.py", line 55, in __init__
    if input("Will you update the dataset now? (y/N)\n").lower() == 'y':
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/peptides_func.py", line 97, in <module>
    run(cfg, create_dataset, create_model, train, test, evaluator=None)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 106, in create_dataset
    dataset = PeptidesFunctionalDataset(
  File "/home/shpark/graph-MLPMixer/core/data_utils/peptides_functional.py", line 55, in __init__
    if input("Will you update the dataset now? (y/N)\n").lower() == 'y':
EOFError: EOF when reading a line
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/peptides_func.py", line 97, in <module>
    run(cfg, create_dataset, create_model, train, test, evaluator=None)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 106, in create_dataset
    dataset = PeptidesFunctionalDataset(
  File "/home/shpark/graph-MLPMixer/core/data_utils/peptides_functional.py", line 55, in __init__
    if input("Will you update the dataset now? (y/N)\n").lower() == 'y':
EOFError: EOF when reading a line
Downloading https://www.dropbox.com/s/ol2v01usvaxbsr8/peptide_multi_class_dataset.csv.gz?dl=1
Downloading https://www.dropbox.com/s/j4zcnx2eipuo0xz/splits_random_stratified_peptide.pickle?dl=1
Processing...
  0%|          | 0/15535 [00:00<?, ?it/s]  0%|          | 32/15535 [00:00<00:48, 319.41it/s]  0%|          | 65/15535 [00:00<00:47, 323.97it/s]  1%|          | 105/15535 [00:00<00:43, 354.50it/s]  1%|          | 142/15535 [00:00<00:43, 357.08it/s]  1%|          | 181/15535 [00:00<00:41, 366.62it/s]  1%|▏         | 219/15535 [00:00<00:41, 368.98it/s]  2%|▏         | 258/15535 [00:00<00:40, 374.20it/s]  2%|▏         | 296/15535 [00:00<00:41, 363.35it/s]  2%|▏         | 336/15535 [00:00<00:41, 370.00it/s]  2%|▏         | 374/15535 [00:01<00:41, 363.97it/s]  3%|▎         | 411/15535 [00:01<00:42, 359.29it/s]  3%|▎         | 447/15535 [00:01<00:43, 348.53it/s]  3%|▎         | 484/15535 [00:01<00:42, 353.26it/s]  3%|▎         | 525/15535 [00:01<00:40, 366.39it/s]  4%|▎         | 565/15535 [00:01<00:39, 374.30it/s]  4%|▍         | 603/15535 [00:01<00:41, 358.46it/s]  4%|▍         | 640/15535 [00:01<00:42, 348.99it/s]  4%|▍         | 681/15535 [00:01<00:40, 365.89it/s]  5%|▍         | 718/15535 [00:01<00:40, 365.34it/s]  5%|▍         | 756/15535 [00:02<00:40, 366.32it/s]  5%|▌         | 797/15535 [00:02<00:39, 374.37it/s]  5%|▌         | 838/15535 [00:02<00:38, 382.30it/s]  6%|▌         | 877/15535 [00:02<00:39, 370.19it/s]  6%|▌         | 915/15535 [00:02<00:40, 360.45it/s]  6%|▌         | 957/15535 [00:02<00:39, 373.55it/s]  6%|▋         | 995/15535 [00:02<00:39, 369.71it/s]  7%|▋         | 1033/15535 [00:02<00:40, 357.38it/s]  7%|▋         | 1073/15535 [00:02<00:39, 367.08it/s]  7%|▋         | 1114/15535 [00:03<00:38, 379.06it/s]  7%|▋         | 1153/15535 [00:03<00:38, 372.47it/s]  8%|▊         | 1191/15535 [00:03<00:38, 370.95it/s]  8%|▊         | 1231/15535 [00:03<00:38, 375.87it/s]  8%|▊         | 1269/15535 [00:03<00:39, 363.30it/s]  8%|▊         | 1309/15535 [00:03<00:38, 372.45it/s]  9%|▊         | 1347/15535 [00:03<00:38, 370.04it/s]  9%|▉         | 1385/15535 [00:03<00:39, 359.28it/s]  9%|▉         | 1422/15535 [00:03<00:48, 289.63it/s]  9%|▉         | 1458/15535 [00:04<00:46, 306.00it/s] 10%|▉         | 1498/15535 [00:04<00:42, 329.20it/s] 10%|▉         | 1533/15535 [00:04<00:42, 331.95it/s] 10%|█         | 1568/15535 [00:04<00:42, 331.18it/s] 10%|█         | 1602/15535 [00:04<00:42, 327.56it/s] 11%|█         | 1638/15535 [00:04<00:41, 334.85it/s] 11%|█         | 1675/15535 [00:04<00:40, 343.79it/s] 11%|█         | 1710/15535 [00:04<00:40, 345.07it/s] 11%|█         | 1745/15535 [00:04<00:41, 332.97it/s] 11%|█▏        | 1779/15535 [00:05<00:42, 322.21it/s] 12%|█▏        | 1815/15535 [00:05<00:41, 332.61it/s] 12%|█▏        | 1849/15535 [00:05<00:41, 328.51it/s] 12%|█▏        | 1887/15535 [00:05<00:40, 341.00it/s] 12%|█▏        | 1929/15535 [00:05<00:37, 363.00it/s] 13%|█▎        | 1972/15535 [00:05<00:35, 377.63it/s] 13%|█▎        | 2011/15535 [00:05<00:35, 379.95it/s] 13%|█▎        | 2050/15535 [00:05<00:37, 355.60it/s] 13%|█▎        | 2088/15535 [00:05<00:37, 357.72it/s] 14%|█▎        | 2126/15535 [00:05<00:36, 363.01it/s] 14%|█▍        | 2165/15535 [00:06<00:36, 364.52it/s] 14%|█▍        | 2202/15535 [00:06<00:37, 356.34it/s] 14%|█▍        | 2241/15535 [00:06<00:36, 364.27it/s] 15%|█▍        | 2278/15535 [00:06<00:36, 364.58it/s] 15%|█▍        | 2315/15535 [00:06<00:37, 355.53it/s] 15%|█▌        | 2351/15535 [00:06<00:37, 354.15it/s] 15%|█▌        | 2388/15535 [00:06<00:36, 357.84it/s] 16%|█▌        | 2424/15535 [00:06<00:37, 348.94it/s] 16%|█▌        | 2459/15535 [00:06<00:38, 336.36it/s] 16%|█▌        | 2495/15535 [00:07<00:38, 340.57it/s] 16%|█▋        | 2535/15535 [00:07<00:36, 354.10it/s] 17%|█▋        | 2573/15535 [00:07<00:36, 357.51it/s] 17%|█▋        | 2609/15535 [00:07<00:36, 358.05it/s] 17%|█▋        | 2645/15535 [00:07<00:37, 346.12it/s] 17%|█▋        | 2680/15535 [00:07<00:37, 341.22it/s] 17%|█▋        | 2715/15535 [00:07<00:37, 339.65it/s] 18%|█▊        | 2753/15535 [00:07<00:36, 348.37it/s] 18%|█▊        | 2788/15535 [00:07<00:36, 347.83it/s] 18%|█▊        | 2833/15535 [00:07<00:33, 376.43it/s] 18%|█▊        | 2871/15535 [00:08<00:33, 375.40it/s] 19%|█▊        | 2909/15535 [00:08<00:33, 372.79it/s] 19%|█▉        | 2947/15535 [00:08<00:34, 360.96it/s] 19%|█▉        | 2984/15535 [00:08<00:35, 352.03it/s] 19%|█▉        | 3023/15535 [00:08<00:34, 362.25it/s] 20%|█▉        | 3060/15535 [00:08<00:34, 364.01it/s] 20%|█▉        | 3097/15535 [00:08<00:34, 361.88it/s] 20%|██        | 3134/15535 [00:08<00:36, 342.94it/s] 20%|██        | 3174/15535 [00:08<00:34, 357.38it/s] 21%|██        | 3214/15535 [00:09<00:33, 367.46it/s] 21%|██        | 3251/15535 [00:09<00:34, 354.28it/s] 21%|██        | 3287/15535 [00:09<00:34, 353.90it/s] 21%|██▏       | 3323/15535 [00:09<00:35, 347.32it/s] 22%|██▏       | 3358/15535 [00:09<00:35, 344.06it/s] 22%|██▏       | 3398/15535 [00:09<00:33, 358.04it/s] 22%|██▏       | 3434/15535 [00:09<00:35, 338.66it/s] 22%|██▏       | 3474/15535 [00:09<00:33, 355.67it/s] 23%|██▎       | 3510/15535 [00:09<00:34, 348.70it/s] 23%|██▎       | 3547/15535 [00:09<00:33, 352.84it/s] 23%|██▎       | 3586/15535 [00:10<00:33, 361.43it/s] 23%|██▎       | 3625/15535 [00:10<00:32, 365.83it/s] 24%|██▎       | 3662/15535 [00:10<00:34, 348.32it/s] 24%|██▍       | 3698/15535 [00:10<00:34, 341.29it/s] 24%|██▍       | 3733/15535 [00:10<00:34, 339.18it/s] 24%|██▍       | 3768/15535 [00:10<00:35, 334.46it/s] 24%|██▍       | 3802/15535 [00:10<00:36, 322.22it/s] 25%|██▍       | 3837/15535 [00:10<00:35, 328.92it/s] 25%|██▍       | 3871/15535 [00:10<00:35, 330.16it/s] 25%|██▌       | 3910/15535 [00:11<00:33, 343.66it/s] 25%|██▌       | 3945/15535 [00:11<00:34, 337.28it/s] 26%|██▌       | 3979/15535 [00:11<00:34, 337.00it/s] 26%|██▌       | 4013/15535 [00:11<00:35, 326.41it/s] 26%|██▌       | 4050/15535 [00:11<00:33, 338.34it/s] 26%|██▋       | 4091/15535 [00:11<00:32, 353.17it/s] 27%|██▋       | 4128/15535 [00:11<00:31, 358.03it/s] 27%|██▋       | 4164/15535 [00:11<00:32, 350.72it/s] 27%|██▋       | 4200/15535 [00:11<00:33, 339.84it/s] 27%|██▋       | 4235/15535 [00:12<00:33, 342.00it/s] 27%|██▋       | 4272/15535 [00:12<00:32, 348.58it/s] 28%|██▊       | 4307/15535 [00:12<00:32, 344.36it/s] 28%|██▊       | 4342/15535 [00:12<00:33, 332.38it/s] 28%|██▊       | 4379/15535 [00:12<00:32, 342.28it/s] 28%|██▊       | 4414/15535 [00:12<00:33, 331.73it/s] 29%|██▊       | 4449/15535 [00:12<00:33, 335.64it/s] 29%|██▉       | 4484/15535 [00:12<00:32, 338.66it/s] 29%|██▉       | 4518/15535 [00:12<00:35, 311.53it/s] 29%|██▉       | 4554/15535 [00:12<00:33, 324.72it/s] 30%|██▉       | 4591/15535 [00:13<00:32, 336.54it/s] 30%|██▉       | 4630/15535 [00:13<00:31, 351.26it/s] 30%|███       | 4666/15535 [00:13<00:31, 347.50it/s] 30%|███       | 4701/15535 [00:13<00:32, 335.30it/s] 30%|███       | 4738/15535 [00:13<00:31, 344.32it/s] 31%|███       | 4773/15535 [00:13<00:32, 336.26it/s] 31%|███       | 4811/15535 [00:13<00:31, 345.81it/s] 31%|███       | 4848/15535 [00:13<00:30, 351.42it/s] 31%|███▏      | 4884/15535 [00:13<00:30, 349.49it/s] 32%|███▏      | 4920/15535 [00:14<00:30, 348.93it/s] 32%|███▏      | 4955/15535 [00:14<00:33, 319.19it/s] 32%|███▏      | 4988/15535 [00:14<00:32, 319.75it/s] 32%|███▏      | 5025/15535 [00:14<00:31, 332.59it/s] 33%|███▎      | 5067/15535 [00:14<00:29, 356.72it/s] 33%|███▎      | 5103/15535 [00:14<00:29, 354.18it/s] 33%|███▎      | 5140/15535 [00:14<00:28, 358.76it/s] 33%|███▎      | 5177/15535 [00:14<00:28, 359.61it/s] 34%|███▎      | 5214/15535 [00:14<00:30, 338.31it/s] 34%|███▍      | 5249/15535 [00:14<00:30, 338.81it/s] 34%|███▍      | 5284/15535 [00:15<00:30, 332.91it/s] 34%|███▍      | 5319/15535 [00:15<00:30, 336.82it/s] 34%|███▍      | 5355/15535 [00:15<00:29, 342.34it/s] 35%|███▍      | 5390/15535 [00:15<00:30, 328.03it/s] 35%|███▍      | 5430/15535 [00:15<00:29, 345.43it/s] 35%|███▌      | 5465/15535 [00:15<00:29, 345.93it/s] 35%|███▌      | 5501/15535 [00:15<00:28, 349.37it/s] 36%|███▌      | 5537/15535 [00:15<00:28, 350.23it/s] 36%|███▌      | 5573/15535 [00:15<00:28, 351.46it/s] 36%|███▌      | 5609/15535 [00:16<00:28, 343.95it/s] 36%|███▋      | 5644/15535 [00:16<00:28, 342.16it/s] 37%|███▋      | 5679/15535 [00:16<00:29, 336.21it/s] 37%|███▋      | 5713/15535 [00:16<00:30, 322.23it/s] 37%|███▋      | 5749/15535 [00:16<00:29, 331.73it/s] 37%|███▋      | 5783/15535 [00:16<00:30, 321.43it/s] 37%|███▋      | 5816/15535 [00:16<00:30, 320.00it/s] 38%|███▊      | 5851/15535 [00:16<00:29, 328.17it/s] 38%|███▊      | 5891/15535 [00:16<00:27, 345.73it/s] 38%|███▊      | 5932/15535 [00:17<00:26, 359.98it/s] 38%|███▊      | 5972/15535 [00:17<00:25, 369.57it/s] 39%|███▊      | 6010/15535 [00:17<00:26, 362.83it/s] 39%|███▉      | 6047/15535 [00:17<00:26, 356.89it/s] 39%|███▉      | 6084/15535 [00:17<00:26, 358.49it/s] 39%|███▉      | 6120/15535 [00:17<00:40, 235.07it/s] 40%|███▉      | 6156/15535 [00:17<00:35, 260.92it/s] 40%|███▉      | 6187/15535 [00:17<00:34, 267.13it/s] 40%|████      | 6226/15535 [00:18<00:31, 296.73it/s] 40%|████      | 6262/15535 [00:18<00:29, 312.26it/s] 41%|████      | 6296/15535 [00:18<00:29, 312.62it/s] 41%|████      | 6331/15535 [00:18<00:28, 322.04it/s] 41%|████      | 6365/15535 [00:18<00:28, 317.33it/s] 41%|████      | 6406/15535 [00:18<00:26, 342.80it/s] 41%|████▏     | 6442/15535 [00:18<00:26, 337.32it/s][05:01:12] WARNING: not removing hydrogen atom without neighbors
[05:01:12] WARNING: not removing hydrogen atom without neighbors
 42%|████▏     | 6478/15535 [00:18<00:26, 340.85it/s] 42%|████▏     | 6513/15535 [00:18<00:28, 321.42it/s] 42%|████▏     | 6549/15535 [00:18<00:27, 330.81it/s] 42%|████▏     | 6584/15535 [00:19<00:26, 335.62it/s] 43%|████▎     | 6620/15535 [00:19<00:26, 342.33it/s] 43%|████▎     | 6655/15535 [00:19<00:26, 335.92it/s] 43%|████▎     | 6689/15535 [00:19<00:28, 314.70it/s] 43%|████▎     | 6729/15535 [00:19<00:26, 337.42it/s] 44%|████▎     | 6764/15535 [00:19<00:25, 340.35it/s] 44%|████▍     | 6799/15535 [00:19<00:25, 342.49it/s] 44%|████▍     | 6836/15535 [00:19<00:24, 350.33it/s] 44%|████▍     | 6872/15535 [00:19<00:25, 341.38it/s] 45%|████▍     | 6918/15535 [00:20<00:23, 372.13it/s] 45%|████▍     | 6956/15535 [00:20<00:23, 365.36it/s] 45%|████▌     | 6993/15535 [00:20<00:23, 360.17it/s] 45%|████▌     | 7030/15535 [00:20<00:24, 350.62it/s] 46%|████▌     | 7069/15535 [00:20<00:23, 359.69it/s] 46%|████▌     | 7106/15535 [00:20<00:24, 348.16it/s] 46%|████▌     | 7142/15535 [00:20<00:23, 350.81it/s] 46%|████▌     | 7178/15535 [00:20<00:24, 342.35it/s] 46%|████▋     | 7213/15535 [00:20<00:24, 343.62it/s] 47%|████▋     | 7248/15535 [00:20<00:24, 343.57it/s] 47%|████▋     | 7283/15535 [00:21<00:23, 344.31it/s] 47%|████▋     | 7319/15535 [00:21<00:23, 348.29it/s] 47%|████▋     | 7354/15535 [00:21<00:23, 343.90it/s] 48%|████▊     | 7393/15535 [00:21<00:22, 354.97it/s] 48%|████▊     | 7434/15535 [00:21<00:21, 370.08it/s] 48%|████▊     | 7472/15535 [00:21<00:23, 346.56it/s] 48%|████▊     | 7508/15535 [00:21<00:22, 350.27it/s] 49%|████▊     | 7544/15535 [00:21<00:23, 345.33it/s] 49%|████▉     | 7587/15535 [00:21<00:21, 369.21it/s] 49%|████▉     | 7625/15535 [00:22<00:21, 368.24it/s] 49%|████▉     | 7662/15535 [00:22<00:21, 364.60it/s] 50%|████▉     | 7699/15535 [00:22<00:22, 343.40it/s] 50%|████▉     | 7734/15535 [00:22<00:23, 335.94it/s] 50%|█████     | 7770/15535 [00:22<00:22, 342.16it/s] 50%|█████     | 7807/15535 [00:22<00:22, 345.56it/s] 50%|█████     | 7845/15535 [00:22<00:21, 353.58it/s] 51%|█████     | 7882/15535 [00:22<00:21, 355.91it/s] 51%|█████     | 7920/15535 [00:22<00:21, 362.31it/s] 51%|█████     | 7957/15535 [00:22<00:20, 362.51it/s] 51%|█████▏    | 7994/15535 [00:23<00:20, 364.35it/s] 52%|█████▏    | 8031/15535 [00:23<00:20, 360.63it/s] 52%|█████▏    | 8069/15535 [00:23<00:20, 365.23it/s] 52%|█████▏    | 8107/15535 [00:23<00:20, 365.79it/s] 52%|█████▏    | 8144/15535 [00:23<00:20, 361.50it/s] 53%|█████▎    | 8181/15535 [00:23<00:21, 347.98it/s] 53%|█████▎    | 8216/15535 [00:23<00:21, 343.14it/s] 53%|█████▎    | 8255/15535 [00:23<00:20, 355.29it/s] 53%|█████▎    | 8291/15535 [00:23<00:21, 331.77it/s] 54%|█████▎    | 8331/15535 [00:24<00:20, 348.73it/s] 54%|█████▍    | 8374/15535 [00:24<00:19, 368.76it/s] 54%|█████▍    | 8412/15535 [00:24<00:19, 361.89it/s] 54%|█████▍    | 8449/15535 [00:24<00:20, 346.54it/s] 55%|█████▍    | 8485/15535 [00:24<00:20, 348.32it/s] 55%|█████▍    | 8521/15535 [00:24<00:20, 338.46it/s] 55%|█████▌    | 8563/15535 [00:24<00:19, 360.53it/s] 55%|█████▌    | 8601/15535 [00:24<00:18, 365.17it/s] 56%|█████▌    | 8638/15535 [00:24<00:19, 355.56it/s] 56%|█████▌    | 8674/15535 [00:25<00:20, 341.11it/s] 56%|█████▌    | 8721/15535 [00:25<00:18, 373.52it/s] 56%|█████▋    | 8760/15535 [00:25<00:18, 376.07it/s] 57%|█████▋    | 8798/15535 [00:25<00:17, 377.02it/s] 57%|█████▋    | 8838/15535 [00:25<00:17, 383.48it/s] 57%|█████▋    | 8877/15535 [00:25<00:18, 360.45it/s] 57%|█████▋    | 8914/15535 [00:25<00:19, 347.37it/s] 58%|█████▊    | 8952/15535 [00:25<00:18, 356.07it/s] 58%|█████▊    | 8988/15535 [00:25<00:18, 351.70it/s] 58%|█████▊    | 9024/15535 [00:25<00:18, 348.47it/s] 58%|█████▊    | 9064/15535 [00:26<00:17, 363.23it/s] 59%|█████▊    | 9107/15535 [00:26<00:16, 380.78it/s] 59%|█████▉    | 9146/15535 [00:26<00:17, 364.03it/s] 59%|█████▉    | 9183/15535 [00:26<00:18, 348.63it/s] 59%|█████▉    | 9222/15535 [00:26<00:17, 357.26it/s] 60%|█████▉    | 9258/15535 [00:26<00:17, 357.16it/s] 60%|█████▉    | 9294/15535 [00:26<00:18, 340.39it/s] 60%|██████    | 9333/15535 [00:26<00:17, 353.16it/s] 60%|██████    | 9372/15535 [00:26<00:16, 363.29it/s] 61%|██████    | 9409/15535 [00:27<00:16, 361.64it/s] 61%|██████    | 9446/15535 [00:27<00:16, 363.67it/s] 61%|██████    | 9486/15535 [00:27<00:16, 373.94it/s] 61%|██████▏   | 9524/15535 [00:27<00:16, 366.79it/s] 62%|██████▏   | 9561/15535 [00:27<00:17, 349.78it/s] 62%|██████▏   | 9597/15535 [00:27<00:17, 347.26it/s] 62%|██████▏   | 9634/15535 [00:27<00:16, 353.19it/s] 62%|██████▏   | 9671/15535 [00:27<00:16, 357.05it/s] 62%|██████▏   | 9707/15535 [00:27<00:16, 347.81it/s] 63%|██████▎   | 9742/15535 [00:27<00:16, 344.37it/s] 63%|██████▎   | 9777/15535 [00:28<00:16, 340.66it/s] 63%|██████▎   | 9812/15535 [00:28<00:17, 336.13it/s] 63%|██████▎   | 9846/15535 [00:28<00:17, 331.17it/s] 64%|██████▎   | 9885/15535 [00:28<00:16, 346.88it/s] 64%|██████▍   | 9926/15535 [00:28<00:15, 364.42it/s] 64%|██████▍   | 9963/15535 [00:28<00:15, 360.21it/s] 64%|██████▍   | 10001/15535 [00:28<00:15, 363.03it/s] 65%|██████▍   | 10038/15535 [00:28<00:15, 357.91it/s] 65%|██████▍   | 10080/15535 [00:28<00:14, 374.97it/s] 65%|██████▌   | 10121/15535 [00:29<00:14, 384.80it/s] 65%|██████▌   | 10160/15535 [00:29<00:14, 379.01it/s] 66%|██████▌   | 10198/15535 [00:29<00:14, 360.21it/s] 66%|██████▌   | 10235/15535 [00:29<00:15, 344.88it/s] 66%|██████▌   | 10273/15535 [00:29<00:14, 353.67it/s] 66%|██████▋   | 10309/15535 [00:29<00:14, 353.76it/s] 67%|██████▋   | 10347/15535 [00:29<00:14, 357.83it/s] 67%|██████▋   | 10387/15535 [00:29<00:13, 369.94it/s] 67%|██████▋   | 10427/15535 [00:29<00:13, 376.05it/s] 67%|██████▋   | 10465/15535 [00:29<00:14, 361.28it/s] 68%|██████▊   | 10506/15535 [00:30<00:13, 374.53it/s] 68%|██████▊   | 10544/15535 [00:30<00:13, 367.83it/s] 68%|██████▊   | 10583/15535 [00:30<00:13, 371.62it/s] 68%|██████▊   | 10621/15535 [00:30<00:13, 366.10it/s] 69%|██████▊   | 10658/15535 [00:30<00:13, 362.24it/s] 69%|██████▉   | 10696/15535 [00:30<00:13, 364.60it/s] 69%|██████▉   | 10733/15535 [00:30<00:13, 358.54it/s] 69%|██████▉   | 10769/15535 [00:30<00:13, 353.11it/s] 70%|██████▉   | 10805/15535 [00:30<00:13, 339.49it/s] 70%|██████▉   | 10846/15535 [00:31<00:13, 357.36it/s] 70%|███████   | 10884/15535 [00:31<00:12, 363.51it/s] 70%|███████   | 10921/15535 [00:31<00:12, 358.40it/s] 71%|███████   | 10962/15535 [00:31<00:12, 372.94it/s] 71%|███████   | 11000/15535 [00:31<00:12, 370.80it/s] 71%|███████   | 11039/15535 [00:31<00:11, 376.33it/s] 71%|███████▏  | 11077/15535 [00:31<00:11, 371.85it/s] 72%|███████▏  | 11120/15535 [00:31<00:11, 388.84it/s] 72%|███████▏  | 11159/15535 [00:31<00:11, 370.44it/s] 72%|███████▏  | 11197/15535 [00:31<00:11, 366.25it/s] 72%|███████▏  | 11240/15535 [00:32<00:11, 381.86it/s] 73%|███████▎  | 11282/15535 [00:32<00:10, 388.95it/s] 73%|███████▎  | 11322/15535 [00:32<00:11, 374.10it/s] 73%|███████▎  | 11365/15535 [00:32<00:10, 388.48it/s] 73%|███████▎  | 11405/15535 [00:32<00:10, 380.79it/s] 74%|███████▎  | 11444/15535 [00:32<00:11, 365.06it/s] 74%|███████▍  | 11482/15535 [00:32<00:11, 365.85it/s] 74%|███████▍  | 11523/15535 [00:32<00:10, 377.63it/s] 74%|███████▍  | 11561/15535 [00:32<00:11, 360.07it/s] 75%|███████▍  | 11598/15535 [00:33<00:11, 357.34it/s] 75%|███████▍  | 11634/15535 [00:33<00:10, 355.10it/s] 75%|███████▌  | 11670/15535 [00:33<00:11, 345.98it/s] 75%|███████▌  | 11705/15535 [00:33<00:11, 339.10it/s] 76%|███████▌  | 11739/15535 [00:33<00:17, 218.11it/s] 76%|███████▌  | 11777/15535 [00:33<00:15, 249.53it/s] 76%|███████▌  | 11814/15535 [00:33<00:13, 276.80it/s] 76%|███████▋  | 11855/15535 [00:33<00:11, 308.43it/s] 77%|███████▋  | 11890/15535 [00:34<00:11, 315.40it/s] 77%|███████▋  | 11925/15535 [00:34<00:11, 318.89it/s] 77%|███████▋  | 11959/15535 [00:34<00:11, 317.39it/s] 77%|███████▋  | 11995/15535 [00:34<00:10, 328.70it/s] 77%|███████▋  | 12030/15535 [00:34<00:10, 330.52it/s] 78%|███████▊  | 12067/15535 [00:34<00:10, 341.21it/s] 78%|███████▊  | 12102/15535 [00:34<00:09, 343.41it/s] 78%|███████▊  | 12138/15535 [00:34<00:09, 348.25it/s] 78%|███████▊  | 12176/15535 [00:34<00:09, 354.58it/s] 79%|███████▊  | 12217/15535 [00:35<00:09, 365.07it/s] 79%|███████▉  | 12254/15535 [00:35<00:09, 348.22it/s] 79%|███████▉  | 12290/15535 [00:35<00:09, 344.20it/s] 79%|███████▉  | 12329/15535 [00:35<00:09, 355.47it/s] 80%|███████▉  | 12366/15535 [00:35<00:08, 358.11it/s] 80%|███████▉  | 12403/15535 [00:35<00:08, 360.98it/s] 80%|████████  | 12442/15535 [00:35<00:08, 367.89it/s] 80%|████████  | 12479/15535 [00:35<00:08, 366.46it/s] 81%|████████  | 12516/15535 [00:35<00:08, 353.70it/s] 81%|████████  | 12556/15535 [00:35<00:08, 364.69it/s] 81%|████████  | 12598/15535 [00:36<00:07, 379.61it/s] 81%|████████▏ | 12637/15535 [00:36<00:07, 379.71it/s] 82%|████████▏ | 12676/15535 [00:36<00:07, 365.70it/s] 82%|████████▏ | 12713/15535 [00:36<00:08, 344.45it/s] 82%|████████▏ | 12752/15535 [00:36<00:07, 355.56it/s] 82%|████████▏ | 12790/15535 [00:36<00:07, 361.61it/s] 83%|████████▎ | 12833/15535 [00:36<00:07, 376.39it/s] 83%|████████▎ | 12871/15535 [00:36<00:07, 377.04it/s] 83%|████████▎ | 12912/15535 [00:36<00:06, 383.98it/s] 83%|████████▎ | 12951/15535 [00:37<00:07, 363.03it/s] 84%|████████▎ | 12988/15535 [00:37<00:07, 340.42it/s] 84%|████████▍ | 13027/15535 [00:37<00:07, 348.81it/s] 84%|████████▍ | 13063/15535 [00:37<00:07, 342.97it/s] 84%|████████▍ | 13105/15535 [00:37<00:06, 362.03it/s] 85%|████████▍ | 13142/15535 [00:37<00:06, 360.11it/s] 85%|████████▍ | 13181/15535 [00:37<00:06, 364.93it/s] 85%|████████▌ | 13218/15535 [00:37<00:06, 362.21it/s] 85%|████████▌ | 13255/15535 [00:37<00:06, 351.20it/s] 86%|████████▌ | 13296/15535 [00:38<00:06, 366.49it/s] 86%|████████▌ | 13333/15535 [00:38<00:05, 367.02it/s] 86%|████████▌ | 13370/15535 [00:38<00:06, 360.32it/s] 86%|████████▋ | 13407/15535 [00:38<00:06, 344.17it/s] 87%|████████▋ | 13443/15535 [00:38<00:06, 346.68it/s] 87%|████████▋ | 13478/15535 [00:38<00:06, 326.17it/s] 87%|████████▋ | 13511/15535 [00:38<00:06, 321.06it/s] 87%|████████▋ | 13548/15535 [00:38<00:05, 332.77it/s] 87%|████████▋ | 13587/15535 [00:38<00:05, 347.28it/s] 88%|████████▊ | 13622/15535 [00:38<00:05, 346.39it/s] 88%|████████▊ | 13658/15535 [00:39<00:05, 348.10it/s] 88%|████████▊ | 13694/15535 [00:39<00:05, 349.78it/s] 88%|████████▊ | 13733/15535 [00:39<00:05, 357.75it/s] 89%|████████▊ | 13770/15535 [00:39<00:04, 357.12it/s] 89%|████████▉ | 13806/15535 [00:39<00:04, 354.78it/s] 89%|████████▉ | 13842/15535 [00:39<00:04, 340.90it/s] 89%|████████▉ | 13881/15535 [00:39<00:04, 354.56it/s] 90%|████████▉ | 13917/15535 [00:39<00:04, 339.42it/s] 90%|████████▉ | 13955/15535 [00:39<00:04, 349.14it/s] 90%|█████████ | 13991/15535 [00:40<00:04, 334.20it/s] 90%|█████████ | 14028/15535 [00:40<00:04, 342.42it/s] 91%|█████████ | 14065/15535 [00:40<00:04, 348.31it/s] 91%|█████████ | 14101/15535 [00:40<00:04, 347.72it/s] 91%|█████████ | 14143/15535 [00:40<00:03, 367.32it/s] 91%|█████████▏| 14180/15535 [00:40<00:03, 366.90it/s] 92%|█████████▏| 14217/15535 [00:40<00:03, 355.10it/s] 92%|█████████▏| 14255/15535 [00:40<00:03, 360.75it/s] 92%|█████████▏| 14292/15535 [00:40<00:03, 354.41it/s] 92%|█████████▏| 14332/15535 [00:40<00:03, 366.33it/s] 93%|█████████▎| 14377/15535 [00:41<00:02, 390.51it/s] 93%|█████████▎| 14417/15535 [00:41<00:02, 372.72it/s] 93%|█████████▎| 14455/15535 [00:41<00:02, 364.02it/s] 93%|█████████▎| 14492/15535 [00:41<00:02, 359.70it/s] 94%|█████████▎| 14529/15535 [00:41<00:02, 338.03it/s] 94%|█████████▎| 14564/15535 [00:41<00:02, 332.42it/s] 94%|█████████▍| 14599/15535 [00:41<00:02, 336.63it/s] 94%|█████████▍| 14633/15535 [00:41<00:02, 330.42it/s] 94%|█████████▍| 14670/15535 [00:41<00:02, 340.83it/s] 95%|█████████▍| 14705/15535 [00:42<00:02, 326.30it/s] 95%|█████████▍| 14744/15535 [00:42<00:02, 343.78it/s] 95%|█████████▌| 14780/15535 [00:42<00:02, 346.32it/s] 95%|█████████▌| 14815/15535 [00:42<00:02, 333.67it/s] 96%|█████████▌| 14853/15535 [00:42<00:01, 346.42it/s] 96%|█████████▌| 14888/15535 [00:42<00:01, 343.59it/s] 96%|█████████▌| 14927/15535 [00:42<00:01, 356.81it/s] 96%|█████████▋| 14963/15535 [00:42<00:01, 351.49it/s] 97%|█████████▋| 14999/15535 [00:42<00:01, 336.76it/s] 97%|█████████▋| 15038/15535 [00:43<00:01, 350.84it/s] 97%|█████████▋| 15074/15535 [00:43<00:01, 348.96it/s] 97%|█████████▋| 15110/15535 [00:43<00:01, 348.30it/s] 97%|█████████▋| 15146/15535 [00:43<00:01, 349.87it/s] 98%|█████████▊| 15182/15535 [00:43<00:01, 340.56it/s] 98%|█████████▊| 15223/15535 [00:43<00:00, 360.04it/s] 98%|█████████▊| 15260/15535 [00:43<00:00, 359.41it/s] 98%|█████████▊| 15299/15535 [00:43<00:00, 364.88it/s] 99%|█████████▊| 15337/15535 [00:43<00:00, 368.00it/s] 99%|█████████▉| 15374/15535 [00:43<00:00, 368.39it/s] 99%|█████████▉| 15413/15535 [00:44<00:00, 374.29it/s] 99%|█████████▉| 15451/15535 [00:44<00:00, 371.78it/s]100%|█████████▉| 15489/15535 [00:44<00:00, 358.42it/s]100%|█████████▉| 15525/15535 [00:44<00:00, 329.11it/s]100%|██████████| 15535/15535 [00:44<00:00, 349.54it/s]
Done!
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_050327-p5yazrvv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/p5yazrvv
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 244, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 244, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 244, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 244, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/exp.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 244, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/exp.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/exp.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 244, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/exp.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/exp.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 244, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/exp.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'rw_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/exp.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 244, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/exp.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 69, in forward
    x += self.rw_encoder(data.rw_pos_enc)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'rw_pos_enc'
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▆▇▆▆▇▆▇▇▇▇▇▇██████████████████████████
wandb: train loss ▁▃▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████████████
wandb: train perf █▆▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▅▆▅▂▆▇▇▇▇▅▇▆▆██▇███████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.13973
wandb: train loss -0.03641
wandb: train perf 0.03641
wandb: valid perf -0.17557
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMix at: https://wandb.ai/eddy26/graph-MLPMixer/runs/i5sf4qlp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_035119-i5sf4qlp/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_053027-8ew46hly
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8ew46hly
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_053027-7cdyxyrx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/7cdyxyrx
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_053027-tz4r18aw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/tz4r18aw
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_053027-4gpxdbx8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/4gpxdbx8
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/8ew46hly
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_053027-8ew46hly/logs
wandb: 🚀 View run TransformerConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/7cdyxyrx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_053027-7cdyxyrx/logs
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/tz4r18aw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_053027-tz4r18aw/logs
wandb: 🚀 View run ResGatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/4gpxdbx8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_053027-4gpxdbx8/logs
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'lap_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/sr25.py", line 54, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 83, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/sr25.py", line 14, in train
    batch_pos_enc = data.lap_pos_enc
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'lap_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'lap_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/sr25.py", line 54, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 83, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/sr25.py", line 14, in train
    batch_pos_enc = data.lap_pos_enc
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'lap_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'lap_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/sr25.py", line 54, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 83, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/sr25.py", line 14, in train
    batch_pos_enc = data.lap_pos_enc
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'lap_pos_enc'
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 62, in __getattr__
    return self[key]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 85, in __getitem__
    return self._mapping[key]
KeyError: 'lap_pos_enc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/sr25.py", line 54, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 83, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/sr25.py", line 14, in train
    batch_pos_enc = data.lap_pos_enc
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/data.py", line 428, in __getattr__
    return getattr(self._store, key)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/storage.py", line 64, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'lap_pos_enc'
Processing...
Done!
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_053238-k6bvy2e4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/k6bvy2e4
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_053238-ghcxhbii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ghcxhbii
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_053238-yzu2f767
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/yzu2f767
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_053238-r0r5do0p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GATConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/r0r5do0p
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_053255-pqzjx5tg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/pqzjx5tg
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_053313-8kv82w4n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8kv82w4n
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_053317-cnb8lv89
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/cnb8lv89
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_053317-lm696qkg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/lm696qkg
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.058 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.058 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▂▃▃▆▆▅▆▆▆██████████████████████▇▇███
wandb: train loss █▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▄▆▇███████████████████████████████████
wandb: valid perf ▁▁▁▂▁▂▅▆▆▅▇▆▇████████████████████▇▇▇████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.00066
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GATConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/r0r5do0p
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_053238-r0r5do0p/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▃▃▄▄▄▄▆▆▆▆▆▆▇▇▇▇▇█████████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███████████████████
wandb: valid perf ▁▂▃▃▄▄▄▄▅▆▆▅▆▆▅▇█▇▇█████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.68301
wandb: train loss 0.07414
wandb: train perf 0.91557
wandb: valid perf 0.7038
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/8kv82w4n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_053313-8kv82w4n/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_055921-gel2fhxf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/gel2fhxf
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▂▃▃▄▅▆▆▆▆▆▇▇▇▇▇▇██████████████████████
wandb: train loss █▇▆▆▆▅▅▅▄▄▄▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇███████████████████
wandb: valid perf ▁▃▂▃▃▃▃▅▅▆▅▆▅▇▇▆▇▇██████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.68726
wandb: train loss 0.07221
wandb: train perf 0.91972
wandb: valid perf 0.7014
wandb: 
wandb: 🚀 View run TransformerConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/pqzjx5tg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_053255-pqzjx5tg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_055931-6dr0fh39
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6dr0fh39
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.107 MB of 0.107 MB uploaded (0.000 MB deduped)wandb: - 0.107 MB of 0.107 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▆▇█████████████████████████████████████
wandb: train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁███████████████████████████████████████
wandb: valid perf ▁▃▆██████████████▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb: 
wandb: Run summary:
wandb:  test perf 0.65
wandb: train loss 8e-05
wandb: train perf 1.0
wandb: valid perf 0.57895
wandb: 
wandb: 🚀 View run GatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/k6bvy2e4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_053238-k6bvy2e4/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▄▅▆▆▆▆▆▆▆▇▇▇▇▇███████████████████████
wandb: train loss █▇▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇███████████████████
wandb: valid perf ▁▂▅▄▄▆▅▄▅▆▅▆▇▇██████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.69323
wandb: train loss 0.06069
wandb: train perf 0.93564
wandb: valid perf 0.69691
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/cnb8lv89
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_053317-cnb8lv89/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_060930-hazpl6ac
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/hazpl6ac
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▅▅▅▆▆▆▇▆▇▇███████████████████████████
wandb: train loss █▇▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇████████████████████
wandb: valid perf ▁▄▅▅▅▆▆▆▇▆▇▇▇██▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.68704
wandb: train loss 0.05945
wandb: train perf 0.94238
wandb: valid perf 0.70432
wandb: 
wandb: 🚀 View run ResGatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/lm696qkg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_053317-lm696qkg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_061153-oj1eh3a8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/oj1eh3a8
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▃▄▅▅▄▆▆▆▆▇▇▇▇███████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb: train loss █▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂
wandb: train perf ▁▅▇█████████████████████████████████████
wandb: valid perf ▁▃▅▆▆▇▆▇███████████████████████████████▆
wandb: 
wandb: Run summary:
wandb:  test perf 0.6
wandb: train loss 0.02494
wandb: train perf 1.0
wandb: valid perf 0.68421
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ghcxhbii
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_053238-ghcxhbii/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▃▆▆▆▆▇▇███████████████████████████████
wandb: train loss █▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅██████████████████████████████████████
wandb: valid perf ▁▂▅▆▆▆▇█████████████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.85
wandb: train loss 9e-05
wandb: train perf 1.0
wandb: valid perf 0.89474
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/yzu2f767
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_053238-yzu2f767/logs
Processing...
Done!
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_071618-1uhjn23c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1uhjn23c
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▃▄▅▅▅▅▅▅▇▇▇▇▇▇████████████████████████
wandb: train loss █▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇███████████████████
wandb: valid perf ▁▄▄▅▅▄▆▆▅▅▇▇▇▇▇█████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.68207
wandb: train loss 0.07794
wandb: train perf 0.90665
wandb: valid perf 0.69928
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/hazpl6ac
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_060930-hazpl6ac/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_072355-7sorp2r3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/7sorp2r3
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▂▄▄▄▅▆▆▆▇▇▇▇███████████████████████████
wandb: train loss █▇▆▆▆▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇██████████████████
wandb: valid perf ▁▂▁▃▄▆▆▆▆▆▆▇▇█▇▇▇▇██████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.67815
wandb: train loss 0.0719
wandb: train perf 0.92186
wandb: valid perf 0.70447
wandb: 
wandb: 🚀 View run TransformerConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6dr0fh39
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_055931-6dr0fh39/logs
wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇███████████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███████████████████
wandb: valid perf ▁▃▄▃▅▃▄▆▄▅▆▅▆▆▇▅▅▇██▇███████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.68685
wandb: train loss 0.06897
wandb: train perf 0.9249
wandb: valid perf 0.69978
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/gel2fhxf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_055921-gel2fhxf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_072443-m18hwxsk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/m18hwxsk
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_072445-vfmwtezt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/vfmwtezt
Processing...
Done!
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_072917-p4truvkm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/p4truvkm
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▄▄▅▆▆▇▇▇▇████████████████████████████
wandb: train loss █▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇▇▇▇▇▇██████████████████
wandb: valid perf ▁▃▄▄▄▅▅▅▅▇▆▆▇▆█▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.66188
wandb: train loss 0.05862
wandb: train perf 0.94205
wandb: valid perf 0.70662
wandb: 
wandb: 🚀 View run ResGatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/oj1eh3a8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_061153-oj1eh3a8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_073232-r06nj24v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/r06nj24v
Processing...
Done!
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_074748-lu1ojz27
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/lu1ojz27
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.018 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 🚀 View run GatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/lu1ojz27
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_074748-lu1ojz27/logs
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 57, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 83, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 334, in forward
    x = gnn(x, edge_index, e)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/gnn.py", line 31, in forward
    x = layer(x, edge_index, edge_attr)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/pyg_gnn_wrapper.py", line 84, in forward
    return self.layer(x, edge_index)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/nn/conv/gated_graph_conv.py", line 81, in forward
    x = self.rnn(m, x)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/rnn.py", line 1279, in forward
    ret = _VF.gru_cell(
RuntimeError: CUDA out of memory. Tried to allocate 158.00 MiB (GPU 7; 23.70 GiB total capacity; 22.45 GiB already allocated; 135.69 MiB free; 22.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Processing...
Done!
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_082240-txwopto5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GATConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/txwopto5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▃▃▄▅▆▆▆▆▆▆▇▇▇▇█████████████████████████
wandb: train loss █▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇███████████████████
wandb: valid perf ▁▃▃▅▅▆▆▅▆▇▅▇▆▇▇█████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.67997
wandb: train loss 0.08878
wandb: train perf 0.88988
wandb: valid perf 0.69204
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/vfmwtezt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_072445-vfmwtezt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_083652-xf6u90jj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xf6u90jj
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▂▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇██████████████████████
wandb: train loss █▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▄▅▅▅▅▆▆▇▇▇▇▇▇▇▇▇██████████████████
wandb: valid perf ▁▂▃▃▂▅▄▃▅▅▂▆▇▇▇▆▇▇▇█████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.68624
wandb: train loss 0.06453
wandb: train perf 0.93172
wandb: valid perf 0.70333
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/7sorp2r3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_072355-7sorp2r3/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_084323-jsk1g2f3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/jsk1g2f3
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▂▅▆▇▇▇▇████████████████████████████████
wandb: train loss █▇▃▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▅▆▇▇▇█████████████████████████████████
wandb: valid perf ▁▂▅▆▇▇▅▇████████████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.0
wandb: train perf 1.0
wandb: valid perf 0.99984
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/1uhjn23c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_071618-1uhjn23c/logs
wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▄▆▆▆▆▆▇▇▇▇▇▇▇████████████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███████████████████
wandb: valid perf ▁▂▅▅▆▅▆▇▇▆▇▇▇▆▇█████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.68423
wandb: train loss 0.06714
wandb: train perf 0.92751
wandb: valid perf 0.69652
wandb: 
wandb: 🚀 View run TransformerConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/m18hwxsk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_072443-m18hwxsk/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_084921-butbugkj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/butbugkj
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.033 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.033 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇██████████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇████████████████████
wandb: valid perf ▁▂▄▁▅▆▅▆▅▆▇▆▇█▇▇███▇████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.6913
wandb: train loss 0.06032
wandb: train perf 0.93871
wandb: valid perf 0.69961
wandb: 
wandb: 🚀 View run ResGatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/r06nj24v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_073232-r06nj24v/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_085655-2zu9rk6m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/2zu9rk6m
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_090423-rl4tl9pc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/rl4tl9pc
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: 🚀 View run GatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/rl4tl9pc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_090423-rl4tl9pc/logs
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 57, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 83, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 334, in forward
    x = gnn(x, edge_index, e)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/gnn.py", line 31, in forward
    x = layer(x, edge_index, edge_attr)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/pyg_gnn_wrapper.py", line 84, in forward
    return self.layer(x, edge_index)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/nn/conv/gated_graph_conv.py", line 81, in forward
    x = self.rnn(m, x)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/rnn.py", line 1279, in forward
    ret = _VF.gru_cell(
RuntimeError: CUDA out of memory. Tried to allocate 158.00 MiB (GPU 7; 23.70 GiB total capacity; 22.46 GiB already allocated; 115.69 MiB free; 22.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_093408-8onj85gk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8onj85gk
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_095107-ht1l70wr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ht1l70wr
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_095934-1d3ommdr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GATConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1d3ommdr
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▅▅▆▇▇▇▇▇▇▇▇▇█████████████████████████
wandb: train loss █▇▇▆▆▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▂▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇███████████████████
wandb: valid perf ▁▂▄▅▄▅▄▆▇▆█▇▇█▆▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.64562
wandb: train loss 0.06868
wandb: train perf 0.92656
wandb: valid perf 0.66227
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xf6u90jj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_083652-xf6u90jj/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▂▄▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇█████████████████████
wandb: train loss █▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇███████████████████
wandb: valid perf ▁▁▄▃▄▆▅▆▆▆▆▆▇▇▇▇▇█▇█████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.69321
wandb: train loss 0.05855
wandb: train perf 0.94223
wandb: valid perf 0.70088
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/jsk1g2f3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_084323-jsk1g2f3/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▅▅▆▆▆▆▇▇▆▇▇▇▇▇▇██████████████████████
wandb: train loss █▇▆▆▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇████████████████████
wandb: valid perf ▁▃▃▄▅▆▆▆▆▇▆▆▇▇▇▇▇▇██████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.67909
wandb: train loss 0.07058
wandb: train perf 0.92306
wandb: valid perf 0.7013
wandb: 
wandb: 🚀 View run TransformerConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/butbugkj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_084921-butbugkj/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.033 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.033 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▄▄▄▄▅▅▆▆▆▇▇▇▇▇▇███████████████████████
wandb: train loss █▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇▇▇▇▇████████████████████
wandb: valid perf ▁▂▄▄▄▃▆▄▆▆▆▇▇█▇▇▇███████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.68435
wandb: train loss 0.0654
wandb: train perf 0.92799
wandb: valid perf 0.69292
wandb: 
wandb: 🚀 View run ResGatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/2zu9rk6m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_085655-2zu9rk6m/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_104332-rpj23fdt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/rpj23fdt
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_104337-fbv5l8h5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GATConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/fbv5l8h5
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.018 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 🚀 View run GatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/rpj23fdt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_104332-rpj23fdt/logs
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 57, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 83, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 334, in forward
    x = gnn(x, edge_index, e)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/gnn.py", line 31, in forward
    x = layer(x, edge_index, edge_attr)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/pyg_gnn_wrapper.py", line 84, in forward
    return self.layer(x, edge_index)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/nn/conv/gated_graph_conv.py", line 81, in forward
    x = self.rnn(m, x)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/rnn.py", line 1279, in forward
    ret = _VF.gru_cell(
RuntimeError: CUDA out of memory. Tried to allocate 158.00 MiB (GPU 7; 23.70 GiB total capacity; 22.47 GiB already allocated; 115.69 MiB free; 22.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_105136-inb41x0j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/inb41x0j
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▂▂▂▂▂▂▂▃▃▅▅▆▇▇███████████████████████
wandb: train loss ███▇▇▇▆▆▆▆▅▅▄▃▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▁▁▂▂▂▂▂▂▂▃▄▄▆▆▇▇█▇█████████████████████
wandb: valid perf ▁▁▁▂▂▂▂▂▂▂▃▃▅▅▆▇▇███████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.00042
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GATConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/1d3ommdr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_095934-1d3ommdr/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▆▇▇▇█████████████████████████████████
wandb: train loss █▇▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁██▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁
wandb: train perf ▁▁▂▅▆▇███████████▁▁▅▇███████████████▄███
wandb: valid perf ▁▁▁▅▃▇▇██████████▁▂▅▇███████████████▆███
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.00017
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/p4truvkm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_072917-p4truvkm/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▂▃▄▅▅▆▆▆▆▇▇▇▇▇███████████████████████
wandb: train loss █▇▇▆▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▁▂▃▄▅▆▆▇▇▇▇▇█▇█████████████████████████
wandb: valid perf ▁▁▁▂▃▄▄▅▅▆▆▆▆▇▇▆▇▇██████▇███████████████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.00013
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GATConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/txwopto5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_082240-txwopto5/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▂▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb: train loss █▇▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▁▁▂▃▄▅▅▅▆▆▆▆▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇██▇█████████
wandb: valid perf ▁▁▁▁▂▂▄▂▄▃▄▂▅▅▂▇▆▆▅▅▆▇▄▄▅▇▇███▇█████████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.01132
wandb: train perf 0.99813
wandb: valid perf 0.99996
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ht1l70wr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_095107-ht1l70wr/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_115014-quz9v30y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GATConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/quz9v30y
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_115455-eco0mhih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/eco0mhih
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▁▁▃▅▇███████████████████████████████
wandb: train loss █▇▇▆▆▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▁▁▂▂▂▃▅████████████████████████████████
wandb: valid perf ▁▁▁▁▁▁▃▅▇███████████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.0
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/8onj85gk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_093408-8onj85gk/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▂▂▃▄▆▆▆▆▆▆▇▇████████████████████████
wandb: train loss ███▇▇▇▆▄▄▄▂▇▄▂▃▁▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▁▁▁▂▂▃▄▄▄▇▂▄▆▆▇▅▅██████████████████████
wandb: valid perf ▁▁▁▁▁▂▃▄▁▄▅▂▂▆▆▇▁▆██████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.00022
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/inb41x0j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_105136-inb41x0j/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_120513-2vczbr04
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/2vczbr04
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_121144-grmj0ohc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/grmj0ohc
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_121314-r5260xnq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/r5260xnq
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.018 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 🚀 View run GatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/r5260xnq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_121314-r5260xnq/logs
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 57, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 83, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 334, in forward
    x = gnn(x, edge_index, e)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/gnn.py", line 31, in forward
    x = layer(x, edge_index, edge_attr)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/pyg_gnn_wrapper.py", line 84, in forward
    return self.layer(x, edge_index)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/nn/conv/gated_graph_conv.py", line 81, in forward
    x = self.rnn(m, x)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/rnn.py", line 1279, in forward
    ret = _VF.gru_cell(
RuntimeError: CUDA out of memory. Tried to allocate 158.00 MiB (GPU 7; 23.70 GiB total capacity; 22.48 GiB already allocated; 93.69 MiB free; 22.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.020 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.020 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▆▆▇███████
wandb: train loss ████████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▃▃▃▂▂▁▁▁▁▁▁
wandb: train perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▄▄▄▄▅▅▆▆▇███████
wandb: valid perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▃▆▄▇█▇█████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.01124
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/2vczbr04
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_120513-2vczbr04/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▁▁▂▂▂▂▃▃▃▄▅▆▇▇▇▇▇▇▇█████████████████
wandb: train loss ████▇▇▇▇▇▆▅▆▆▄▃▂▂▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▁▁▁▁▂▂▂▂▂▃▂▂▄▅▆▇▆▇▇▇▆▇█████████████████
wandb: valid perf ▁▁▁▁▁▁▂▂▂▂▃▂▃▄▅▆▇▆▇▇▇▆▇█████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.00097
wandb: train perf 1.0
wandb: valid perf 0.99996
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/eco0mhih
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_115455-eco0mhih/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▇███████
wandb: train loss ███████████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▂▁▁▁▁▁▁▁
wandb: train perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▇███████
wandb: valid perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▇███████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.06417
wandb: train perf 1.0
wandb: valid perf 0.99996
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/grmj0ohc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_121144-grmj0ohc/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_125750-6kc1u6wd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6kc1u6wd
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_125919-11hau6y0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GATConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/11hau6y0
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_132559-xbxx4k6f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xbxx4k6f
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: 🚀 View run GatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xbxx4k6f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_132559-xbxx4k6f/logs
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 57, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 83, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 334, in forward
    x = gnn(x, edge_index, e)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/gnn.py", line 31, in forward
    x = layer(x, edge_index, edge_attr)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/pyg_gnn_wrapper.py", line 84, in forward
    return self.layer(x, edge_index)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/nn/conv/gated_graph_conv.py", line 81, in forward
    x = self.rnn(m, x)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/rnn.py", line 1279, in forward
    ret = _VF.gru_cell(
RuntimeError: CUDA out of memory. Tried to allocate 158.00 MiB (GPU 7; 23.70 GiB total capacity; 22.49 GiB already allocated; 93.69 MiB free; 22.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_133434-3itpm61l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/3itpm61l
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▄▅▆▆▇▇████████
wandb: train loss ███▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▃▃▂▂▂▁▁▃▂▂▁▁
wandb: train perf ▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▆▆▇▇██▆▇▇██
wandb: valid perf ▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▂▃▃▃▄▅▆▆▇▇███▆▇▆██
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.01956
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GATConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/11hau6y0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_125919-11hau6y0/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▁▂▂▅▆▇██████████████████████████████
wandb: train loss ████▇▇▇▄▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▁▁▁▁▂▂▅▄▆██████████████████████████████
wandb: valid perf ▁▁▁▁▁▂▂▅▆▇██████████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 3e-05
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6kc1u6wd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_125750-6kc1u6wd/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_140122-6fw7q6nv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GATConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6fw7q6nv
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: / 0.017 MB of 0.017 MB uploaded (0.000 MB deduped)wandb: 🚀 View run GATConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6fw7q6nv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_140122-6fw7q6nv/logs
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 57, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 83, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 347, in forward
    x = scatter(x, data.subgraphs_nodes_mapper, dim=0, reduce=self.pooling)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_scatter/scatter.py", line 156, in scatter
    return scatter_mean(src, index, dim, out, dim_size)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_scatter/scatter.py", line 41, in scatter_mean
    out = scatter_sum(src, index, dim, out, dim_size)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_scatter/scatter.py", line 19, in scatter_sum
    size[dim] = int(index.max()) + 1
RuntimeError: CUDA out of memory. Tried to allocate 210.00 MiB (GPU 4; 23.70 GiB total capacity; 6.97 GiB already allocated; 133.69 MiB free; 7.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.021 MB of 0.021 MB uploaded (0.000 MB deduped)wandb: - 0.021 MB of 0.021 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▄▅▆▆▇▇██████████████
wandb: train loss ████████▇▇▇▇▇▇▇▇▇▇▇▆▅▄▃▂▂▂▁▃▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▄▄▅▆▇▇▇▆████████████
wandb: valid perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▃▅▅▆▇▆█▇████████████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.00189
wandb: train perf 1.0
wandb: valid perf 0.99988
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/3itpm61l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_133434-3itpm61l/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_140941-ipm8z6tv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ipm8z6tv
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.018 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 🚀 View run GatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ipm8z6tv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_140941-ipm8z6tv/logs
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 57, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 83, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 334, in forward
    x = gnn(x, edge_index, e)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/gnn.py", line 31, in forward
    x = layer(x, edge_index, edge_attr)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/pyg_gnn_wrapper.py", line 84, in forward
    return self.layer(x, edge_index)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/nn/conv/gated_graph_conv.py", line 81, in forward
    x = self.rnn(m, x)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/rnn.py", line 1279, in forward
    ret = _VF.gru_cell(
RuntimeError: CUDA out of memory. Tried to allocate 158.00 MiB (GPU 7; 23.70 GiB total capacity; 22.49 GiB already allocated; 73.69 MiB free; 22.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.037 MB of 0.037 MB uploaded (0.000 MB deduped)wandb: / 0.037 MB of 0.037 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▂▂▂▃▄▄▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████
wandb: train loss ██▇▇▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▁▂▁▁▁▁▁▁▁▁
wandb: train perf ▁▁▂▂▂▃▄▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇████████
wandb: valid perf ▁▁▂▂▂▃▄▄▄▄▄▄▅▄▆▆▆▅▅▆▆▆▆▆▆▆▆▆▆▇▇▆█▇████▅█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.00168
wandb: train perf 0.9999
wandb: valid perf 0.99996
wandb: 
wandb: 🚀 View run GATConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/quz9v30y
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_115014-quz9v30y/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_142618-snckvq6x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/snckvq6x
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230310_142703-pwsxymqg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/pwsxymqg
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▁▁▂▂▂▂▂▃▄▇██████████████████████████
wandb: train loss ███▇▇▇▇▇▇▆▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▁▁▁▁▁▂▂▂▂▃▃▄▇██████████████████████████
wandb: valid perf ▁▁▁▁▁▁▁▂▂▂▂▃▄▇██████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 8e-05
wandb: train perf 1.0
wandb: valid perf 0.99988
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/snckvq6x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_142618-snckvq6x/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▁▁▁▂▂▂▃▄▄▆██████████████████████████
wandb: train loss ███████▇▇▇▆▅▄▂▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁
wandb: train perf ▁▁▁▁▁▁▁▂▂▂▃▄▄▆▇█▇██▇███████████▄████████
wandb: valid perf ▁▁▁▁▁▁▁▂▁▂▃▄▃▆▅█▇██▇█▇█████████▃████████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.00093
wandb: train perf 1.0
wandb: valid perf 0.99996
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/pwsxymqg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_142703-pwsxymqg/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.102 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.102 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▆▇▇▇██████████████████████████████████
wandb: train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▇▇▇▇█████████████████████████████████
wandb: valid perf ▁▄▅▇▇▇█▅████████████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.00057
wandb: train perf 0.99988
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GATConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/fbv5l8h5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230310_104337-fbv5l8h5/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_040728-4njg4bqh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/4njg4bqh
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_040728-vfnzeodf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/vfnzeodf
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_040728-xp1o3hwn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xp1o3hwn
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_040728-r7bhehnk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/r7bhehnk
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_040741-qn7r946o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/qn7r946o
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_040741-lkizf7qw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/lkizf7qw
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_040741-q12ohknz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/q12ohknz
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_040741-v0xdy7z5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/v0xdy7z5
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇███████████████████████
wandb: train loss █▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇████████████████
wandb: valid perf ▁▃▅▅▅▅▆▆▇▆▆▆▇▆▅▆▅█▇▇▇███████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.67752
wandb: train loss 0.05876
wandb: train perf 0.94751
wandb: valid perf 0.6999
wandb: 
wandb: 🚀 View run ResGatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/qn7r946o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_040741-qn7r946o/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_043129-0unzw58y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0unzw58y
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇██████████████████████
wandb: train loss █▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████
wandb: valid perf ▁▂▃▄▅▅▄▅▅▅▆▆▄▅▆▇▆▆▇▇▇▇██████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.67487
wandb: train loss 0.08899
wandb: train perf 0.893
wandb: valid perf 0.69831
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/v0xdy7z5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_040741-v0xdy7z5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: 
wandb: Run history:
wandb:  test perf ▁▃▃▄▄▄▅▅▅▅▆▆▇▇▇▇▇▇▇▇▇███████████████████
wandb: train loss █▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇████████████████
wandb: valid perf ▁▃▃▄▃▃▃▅▅▃▆▅▄▅▄▆▇▇▇█▇▇██████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.6856
wandb: train loss 0.06049
wandb: train perf 0.93995
wandb: valid perf 0.70507
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/lkizf7qw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_040741-lkizf7qw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_043148-ecptepyj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ecptepyj
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_043150-31daal0z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/31daal0z
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▂▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇██████████████████
wandb: train loss █▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███████████████
wandb: valid perf ▁▁▂▂▄▃▄▄▅▅▅▆▇▆▆▅▆▅█▇▇▇██████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.68427
wandb: train loss 0.07498
wandb: train perf 0.9184
wandb: valid perf 0.70042
wandb: 
wandb: 🚀 View run TransformerConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/q12ohknz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_040741-q12ohknz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_043250-72xsko9c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/72xsko9c
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▅▅▆▆▆▆▆▇▆▆▇▇▇▇▇██████████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████
wandb: valid perf ▁▄▅▆▆▇▇▇▇▇▇▇▇█▇▇▇▇█▇███▇████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.78764
wandb: train loss 0.12442
wandb: train perf 0.93772
wandb: valid perf 0.81055
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/r7bhehnk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_040728-r7bhehnk/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_045240-75ta9zjq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/75ta9zjq
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▇▆▆▇▇▇█▇████████▇▇███████████████████
wandb: train loss █▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb: valid perf ▁▅▅▅▅▆▇▇▇▇▇███▇█▇█████▇▇█████▇█▇▇█▇▇▇▇▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.77362
wandb: train loss 0.10328
wandb: train perf 0.9612
wandb: valid perf 0.80652
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/vfnzeodf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_040728-vfnzeodf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_045400-hzrgn21a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/hzrgn21a
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▃▃▄▄▅▆▆▆▆▆▆▆▆▇████████████████████████
wandb: train loss █▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇█▇███████████████
wandb: valid perf ▂▁▂▃▅▃▅▅▆▆▆▄▆▇▆▆▇▇▇▇████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.67962
wandb: train loss 0.0601
wandb: train perf 0.94236
wandb: valid perf 0.70061
wandb: 
wandb: 🚀 View run ResGatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/0unzw58y
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_043129-0unzw58y/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_045520-dfao1nkv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/dfao1nkv
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▃▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█████████████████████
wandb: train loss █▇▇▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▂▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇█████████████████
wandb: valid perf ▁▄▂▅▄▅▄▅▅▆▆▄▇▆▆▇▇▇▇█▇███████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.68021
wandb: train loss 0.06774
wandb: train perf 0.92484
wandb: valid perf 0.70183
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/31daal0z
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_043150-31daal0z/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: 
wandb: Run history:
wandb:  test perf ▁▂▄▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█▇████████████████
wandb: train loss █▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇███████████████
wandb: valid perf ▂▁▄▃▄▅▄▄▄▆▄▆▆▅▆▆▇▇▇▇▇▇██████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.68433
wandb: train loss 0.08926
wandb: train perf 0.89154
wandb: valid perf 0.7118
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ecptepyj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_043148-ecptepyj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_045543-1aw6sbfm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1aw6sbfm
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_045546-vc8q9bka
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/vc8q9bka
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▄▄▅▆▅▆▆▇▇▇▇▇▇██▇▇█████████████████████
wandb: train loss █▇▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb: valid perf ▁▄▅▆▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇██▇▇▇█▇████▇███████
wandb: 
wandb: Run summary:
wandb:  test perf 0.77409
wandb: train loss 0.11448
wandb: train perf 0.94813
wandb: valid perf 0.8077
wandb: 
wandb: 🚀 View run ResGatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/4njg4bqh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_040728-4njg4bqh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_045702-xoaem5s9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xoaem5s9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████████████████
wandb: train loss █▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████
wandb: valid perf ▁▁▄▄▅▅▅▃▅▆▅▆▅▆▅▆▆▆▇▇▇▇▇▇████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.68144
wandb: train loss 0.07463
wandb: train perf 0.91803
wandb: valid perf 0.69645
wandb: 
wandb: 🚀 View run TransformerConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/72xsko9c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_043250-72xsko9c/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_045809-tvv0qewg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/tvv0qewg
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▅▅▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████
wandb: train loss █▇▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb: valid perf ▁▄▆▆▇▇▇▇▇▇█▇▇█▇█▇███▇▇▇▇█▇█▇█████████▇█▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.77977
wandb: train loss 0.11479
wandb: train perf 0.94834
wandb: valid perf 0.80328
wandb: 
wandb: 🚀 View run TransformerConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xp1o3hwn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_040728-xp1o3hwn/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_050101-iyg75hw7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/iyg75hw7
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▃▃▄▅▅▅▅▆▆▆▇▇▇▇▇▇██████████████████████
wandb: train loss █▇▇▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▂▃▃▄▄▄▅▅▅▅▅▆▆▇▇▇▇▇▇▇██████████████████
wandb: valid perf ▁▁▃▄▄▅▄▅▆▅▆▆▅▇▇▇▆▇██████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.6745
wandb: train loss 0.07163
wandb: train perf 0.91849
wandb: valid perf 0.70737
wandb: 
wandb: 🚀 View run ResGatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/dfao1nkv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_045520-dfao1nkv/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_051815-uzkpn3g7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/uzkpn3g7
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████████████████
wandb: train loss █▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇█████████████████
wandb: valid perf ▁▂▃▄▆▆▅▅▅▆▆▆▆▆▇▇▆▇▇███▇█████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.68259
wandb: train loss 0.0979
wandb: train perf 0.87606
wandb: valid perf 0.69919
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/vc8q9bka
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_045546-vc8q9bka/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_051941-t599c584
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/t599c584
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇█████████████████████
wandb: train loss █▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇████████████████
wandb: valid perf ▁▂▂▅▅▆▆▆▅▆▆▅▆▆▇▇▇▇▇█████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.68887
wandb: train loss 0.06284
wandb: train perf 0.93832
wandb: valid perf 0.69592
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/1aw6sbfm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_045543-1aw6sbfm/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_052002-nv4stapf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/nv4stapf
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▄▄▄▅▅▆▆▆▆▆▇▇▇████████████████████████
wandb: train loss █▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇████████████████
wandb: valid perf ▁▃▄▄▄▅▆▅▅▆▆▆▆▇▆▇█▇▇▇████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.68381
wandb: train loss 0.08447
wandb: train perf 0.89558
wandb: valid perf 0.70582
wandb: 
wandb: 🚀 View run TransformerConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/tvv0qewg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_045809-tvv0qewg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_052331-5zswleh5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5zswleh5
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████
wandb: train loss █▇▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb: valid perf ▁▄▅▆▆▆▇▇▇█▇▇██▇████████████▇█▇██▇█▇█▇█▇█
wandb: 
wandb: Run summary:
wandb:  test perf 0.7777
wandb: train loss 0.12068
wandb: train perf 0.94231
wandb: valid perf 0.80733
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/75ta9zjq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_045240-75ta9zjq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_053824-pfireobe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/pfireobe
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb: train loss █▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████
wandb: valid perf ▁▄▅▆▆▆▇▇▇▇▇▇▆▇█▇█▇▇▇▇▇████▇▇▇▇▇█▇▇▇▇▇▇▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.76707
wandb: train loss 0.10385
wandb: train perf 0.95861
wandb: valid perf 0.79746
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/hzrgn21a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_045400-hzrgn21a/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_054018-v1mepfhv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/v1mepfhv
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇██████████████████████
wandb: train loss █▇▇▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇██████████████████
wandb: valid perf ▁▂▃▃▃▅▅▅▆▅▆▅▆▇▇▇▇▇█▇████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.69071
wandb: train loss 0.06878
wandb: train perf 0.92496
wandb: valid perf 0.70789
wandb: 
wandb: 🚀 View run ResGatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/uzkpn3g7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_051815-uzkpn3g7/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▃▄▅▅▅▆▆▆▆▇▇▇▇▇▇███████████████████████
wandb: train loss █▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█████████████████
wandb: valid perf ▁▃▄▃▅▄▅▅▅▅▅▇▇▇▇▇▇█████▇█████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.67173
wandb: train loss 0.10165
wandb: train perf 0.86792
wandb: valid perf 0.70255
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/t599c584
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_051941-t599c584/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▃▄▄▅▅▅▅▅▆▆▆▇▇██▇▇▇▇███████████████████
wandb: train loss █▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇████████████████
wandb: valid perf ▁▃▃▅▄▄▅▅▆▅▅▅▆▆▆▇▇▇▇▇▇███████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.68528
wandb: train loss 0.05821
wandb: train perf 0.94652
wandb: valid perf 0.70828
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/nv4stapf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_052002-nv4stapf/logs
wandb: 
wandb: Run history:
wandb:  test perf ▁▃▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████████
wandb: train loss █▇▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb: valid perf ▁▄▅▆▆▆▇▇▇▇▇▇██████▇█████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.77757
wandb: train loss 0.12681
wandb: train perf 0.9349
wandb: valid perf 0.80793
wandb: 
wandb: 🚀 View run ResGatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xoaem5s9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_045702-xoaem5s9/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_054431-ekmq4npc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ekmq4npc
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▃▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████████████████████
wandb: train loss █▇▇▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▂▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇█████████████████
wandb: valid perf ▁▁▄▅▅▄▄▅▅▆▆▆▆▇▇▇▇▇▇█████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.67892
wandb: train loss 0.09179
wandb: train perf 0.88894
wandb: valid perf 0.69814
wandb: 
wandb: 🚀 View run TransformerConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/5zswleh5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_052331-5zswleh5/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▅▆▅▅▆▆▆▆▇▇▇▇▇▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████
wandb: train loss █▇▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb: valid perf ▁▄▅▅▆▆▆▇▇▆▇▇▇▆▇▆▇▇▇▇▇██▇█▇▇█▇███▇▇███▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 0.77962
wandb: train loss 0.11356
wandb: train perf 0.95019
wandb: valid perf 0.80901
wandb: 
wandb: 🚀 View run TransformerConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/iyg75hw7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_050101-iyg75hw7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_055432-ppymr2ip
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ppymr2ip
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▅▅▅▅▅▅▇▇▆▆▇▇██▇████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb: train loss █▇▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb: valid perf ▁▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇▇▇█▇▇▇▇▇▇▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.76835
wandb: train loss 0.12062
wandb: train perf 0.94243
wandb: valid perf 0.80857
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/pfireobe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_053824-pfireobe/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_062026-s7rwbg04
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/s7rwbg04
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▅▅▆▆▇▇▆▆▆▇▇▇▇▇▇▇▇▇████████████████████
wandb: train loss █▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb: valid perf ▁▄▅▅▆▆▆▇▇▇▇▇▇▇█▇▇████████▇█▇▇███████▇▇█▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.78387
wandb: train loss 0.09804
wandb: train perf 0.96433
wandb: valid perf 0.80156
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/v1mepfhv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_054018-v1mepfhv/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_062406-tr86blb1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/tr86blb1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▆▆▆▆▆▆▇▇▇▇▇██████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb: valid perf ▁▄▅▅▇▆▇▇▇▇▇▇▇▇▇█▇█▇█▇▇▇█▇▇▇▇▇█▇█▇▇▇████▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.77059
wandb: train loss 0.1199
wandb: train perf 0.94406
wandb: valid perf 0.80442
wandb: 
wandb: 🚀 View run ResGatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ekmq4npc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_054431-ekmq4npc/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_062732-d2f1bixl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/d2f1bixl
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▅▆▆▆▆▆▇▇▇▇▆▆▆▇▇▇▇▇███████████████████
wandb: train loss █▇▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████
wandb: valid perf ▁▃▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.77647
wandb: train loss 0.11223
wandb: train perf 0.95025
wandb: valid perf 0.81494
wandb: 
wandb: 🚀 View run TransformerConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ppymr2ip
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_055432-ppymr2ip/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230311_064207-u7u4kwsv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/u7u4kwsv
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▅▅▆▇▇▇▇█▇████████████████████████████
wandb: train loss █▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb: valid perf ▁▃▆▆▆▇▇▇▇▇▇▇██▇▇█▇▇█▇▇█▇▇▇█▇▇▇█▇▇███▇▇▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.76255
wandb: train loss 0.12061
wandb: train perf 0.94359
wandb: valid perf 0.79501
wandb: 
wandb: 🚀 View run GCNConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/s7rwbg04
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_062026-s7rwbg04/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▇▆▇▇▇▇▇███▇██████████████████████████
wandb: train loss █▇▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████
wandb: valid perf ▁▅▆▆▆▇▆▇▆▆▇▇▇██▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.76466
wandb: train loss 0.1027
wandb: train perf 0.96028
wandb: valid perf 0.80135
wandb: 
wandb: 🚀 View run GINEConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/tr86blb1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_062406-tr86blb1/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▃▅▆▅▆▆▆▆▆▆▇██▇▇▇▇▇▇▇▇▇████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb: valid perf ▁▃▅▆▆▆▆▇▇▇▇█▇▇▇▇▇███████▇█████▇▇█▇████▇█
wandb: 
wandb: Run summary:
wandb:  test perf 0.77208
wandb: train loss 0.1181
wandb: train perf 0.94531
wandb: valid perf 0.80619
wandb: 
wandb: 🚀 View run ResGatedGraphConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/d2f1bixl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_062732-d2f1bixl/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▅▄▅▅▆▆▇▆▆▆▆▆▆▇▇▇▇▇▇███████████████████
wandb: train loss █▇▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb: valid perf ▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇▇▇▇▇▇▇▇▇▇▆
wandb: 
wandb: Run summary:
wandb:  test perf 0.77403
wandb: train loss 0.11556
wandb: train perf 0.94787
wandb: valid perf 0.79745
wandb: 
wandb: 🚀 View run TransformerConv at: https://wandb.ai/eddy26/graph-MLPMixer/runs/u7u4kwsv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230311_064207-u7u4kwsv/logs
Downloading https://data.pyg.org/datasets/benchmarking-gnns/MNIST_v2.zip
Extracting dataset/MNIST/raw/MNIST_v2.zip
Processing...
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/mnist.py", line 62, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 89, in create_dataset
    train_dataset = GNNBenchmarkDataset(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 125, in __init__
    super().__init__(root, transform, pre_transform, pre_filter)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py", line 55, in __init__
    super().__init__(root, transform, pre_transform, pre_filter, log)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 94, in __init__
    self._process()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 211, in _process
    self.process()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 175, in process
    inputs = torch.load(self.raw_paths[0])
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/serialization.py", line 712, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/serialization.py", line 1049, in _load
    result = unpickler.load()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/serialization.py", line 1019, in persistent_load
    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/serialization.py", line 997, in load_tensor
    storage = zip_file.get_storage_from_record(name, numel, torch._UntypedStorage).storage()._untyped()
RuntimeError: PytorchStreamReader failed reading file data/2: invalid header or archive is corrupted
Downloading https://data.pyg.org/datasets/benchmarking-gnns/MNIST_v2.zip
Extracting dataset/MNIST/raw/MNIST_v2.zip
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/mnist.py", line 62, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 89, in create_dataset
    train_dataset = GNNBenchmarkDataset(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 125, in __init__
    super().__init__(root, transform, pre_transform, pre_filter)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py", line 55, in __init__
    super().__init__(root, transform, pre_transform, pre_filter, log)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 91, in __init__
    self._download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 185, in _download
    self.download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 167, in download
    extract_zip(path, self.raw_dir)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/extract.py", line 39, in extract_zip
    with zipfile.ZipFile(path, 'r') as f:
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/zipfile.py", line 1251, in __init__
    self.fp = io.open(file, filemode)
FileNotFoundError: [Errno 2] No such file or directory: 'dataset/MNIST/raw/MNIST_v2.zip'
Downloading https://data.pyg.org/datasets/benchmarking-gnns/MNIST_v2.zip
Extracting dataset/MNIST/raw/MNIST_v2.zip
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/mnist.py", line 62, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 89, in create_dataset
    train_dataset = GNNBenchmarkDataset(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 125, in __init__
    super().__init__(root, transform, pre_transform, pre_filter)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py", line 55, in __init__
    super().__init__(root, transform, pre_transform, pre_filter, log)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 91, in __init__
    self._download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 185, in _download
    self.download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 168, in download
    os.unlink(path)
FileNotFoundError: [Errno 2] No such file or directory: 'dataset/MNIST/raw/MNIST_v2.zip'
Downloading https://data.pyg.org/datasets/benchmarking-gnns/MNIST_v2.zip
Extracting dataset/MNIST/raw/MNIST_v2.zip
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/mnist.py", line 62, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 89, in create_dataset
    train_dataset = GNNBenchmarkDataset(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 125, in __init__
    super().__init__(root, transform, pre_transform, pre_filter)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py", line 55, in __init__
    super().__init__(root, transform, pre_transform, pre_filter, log)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 91, in __init__
    self._download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 185, in _download
    self.download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 168, in download
    os.unlink(path)
FileNotFoundError: [Errno 2] No such file or directory: 'dataset/MNIST/raw/MNIST_v2.zip'
Downloading https://data.pyg.org/datasets/benchmarking-gnns/CIFAR10_v2.zip
Extracting dataset/CIFAR10/raw/CIFAR10_v2.zip
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/cifar10.py", line 62, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 89, in create_dataset
    train_dataset = GNNBenchmarkDataset(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 125, in __init__
    super().__init__(root, transform, pre_transform, pre_filter)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py", line 55, in __init__
    super().__init__(root, transform, pre_transform, pre_filter, log)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 91, in __init__
    self._download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 185, in _download
    self.download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 168, in download
    os.unlink(path)
FileNotFoundError: [Errno 2] No such file or directory: 'dataset/CIFAR10/raw/CIFAR10_v2.zip'
Downloading https://data.pyg.org/datasets/benchmarking-gnns/CIFAR10_v2.zip
Extracting dataset/CIFAR10/raw/CIFAR10_v2.zip
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/cifar10.py", line 62, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 89, in create_dataset
    train_dataset = GNNBenchmarkDataset(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 125, in __init__
    super().__init__(root, transform, pre_transform, pre_filter)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py", line 55, in __init__
    super().__init__(root, transform, pre_transform, pre_filter, log)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 91, in __init__
    self._download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 185, in _download
    self.download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 168, in download
    os.unlink(path)
FileNotFoundError: [Errno 2] No such file or directory: 'dataset/CIFAR10/raw/CIFAR10_v2.zip'
Downloading https://data.pyg.org/datasets/benchmarking-gnns/CIFAR10_v2.zip
Extracting dataset/CIFAR10/raw/CIFAR10_v2.zip
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/cifar10.py", line 62, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 89, in create_dataset
    train_dataset = GNNBenchmarkDataset(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 125, in __init__
    super().__init__(root, transform, pre_transform, pre_filter)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py", line 55, in __init__
    super().__init__(root, transform, pre_transform, pre_filter, log)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 91, in __init__
    self._download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 185, in _download
    self.download()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 168, in download
    os.unlink(path)
FileNotFoundError: [Errno 2] No such file or directory: 'dataset/CIFAR10/raw/CIFAR10_v2.zip'
Processing...
Done!
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/mnist.py", line 62, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 93, in create_dataset
    test_dataset = GNNBenchmarkDataset(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 137, in __init__
    self.data, self.slices = torch.load(path)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/serialization.py", line 713, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/serialization.py", line 920, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
EOFError: Ran out of input
Processing...
Done!
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
Processing...
Done!
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_041508-f6m7vroe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/f6m7vroe
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_041508-r3gqou1r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/r3gqou1r
Processing...
Done!
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_041512-b8qd0jaq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/b8qd0jaq
Processing...
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/cifar10.py", line 62, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 89, in create_dataset
    train_dataset = GNNBenchmarkDataset(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 125, in __init__
    super().__init__(root, transform, pre_transform, pre_filter)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py", line 55, in __init__
    super().__init__(root, transform, pre_transform, pre_filter, log)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 94, in __init__
    self._process()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 211, in _process
    self.process()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 183, in process
    data_list = [self.pre_transform(d) for d in data_list]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/datasets/gnn_benchmark_dataset.py", line 183, in <listcomp>
    data_list = [self.pre_transform(d) for d in data_list]
  File "/home/shpark/graph-MLPMixer/core/transform.py", line 78, in __call__
    data = add_positional_encoding(data, self.rw_dim, self.lap_dim)
  File "/home/shpark/graph-MLPMixer/core/data_utils/pe.py", line 12, in add_positional_encoding
    data.lap_pos_enc = lap_positional_encoding(data, lap_dim)
  File "/home/shpark/graph-MLPMixer/core/data_utils/pe.py", line 54, in lap_positional_encoding
    EigVal, EigVec = np.linalg.eig(L.toarray())
  File "<__array_function__ internals>", line 180, in eig
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/numpy/linalg/linalg.py", line 1318, in eig
    w, vt = _umath_linalg.eig(a, signature=signature, extobj=extobj)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/resource_sharer.py", line 142, in _serve
    with self._listener.accept() as conn:
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 466, in accept
    answer_challenge(c, self._authkey)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/cifar10.py", line 62, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 32, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 165, in create_dataset
    test_dataset = [x for x in test_dataset]
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 165, in <listcomp>
    test_dataset = [x for x in test_dataset]
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/data/dataset.py", line 240, in __getitem__
    data = data if self.transform is None else self.transform(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/transforms/compose.py", line 24, in __call__
    data = transform(data)
  File "/home/shpark/graph-MLPMixer/core/transform.py", line 124, in __call__
    node_masks, edge_masks = metis_subgraph(
  File "/home/shpark/graph-MLPMixer/core/transform_utils/subgraph_extractors.py", line 50, in metis_subgraph
    cuts, membership = metis.part_graph(G, n_patches, recursive=True)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/metis.py", line 765, in part_graph
    graph = networkx_to_metis(graph)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/metis.py", line 543, in networkx_to_metis
    H = networkx.convert_node_labels_to_integers(G)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/networkx/relabel.py", line 277, in convert_node_labels_to_integers
    H = relabel_nodes(G, mapping)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/networkx/relabel.py", line 122, in relabel_nodes
    return _relabel_copy(G, m)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/networkx/relabel.py", line 215, in _relabel_copy
    H.add_edges_from(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/networkx/classes/graph.py", line 1035, in add_edges_from
    datadict = self._adj[u].get(v, self.edge_attr_dict_factory())
KeyboardInterrupt
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_041946-rq6pvlkv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/rq6pvlkv
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_041949-f24qv563
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/f24qv563
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_041953-27nrpa3j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/27nrpa3j
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_041956-2tiieibk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/2tiieibk
Downloading https://data.pyg.org/datasets/benchmarking-gnns/CIFAR10_v2.zip
Extracting dataset/CIFAR10/raw/CIFAR10_v2.zip
Processing...
Done!
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_042018-bzf8jdhd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/bzf8jdhd
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/resource_sharer.py", line 142, in _serve
    with self._listener.accept() as conn:
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 465, in accept
    deliver_challenge(c, self._authkey)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 740, in deliver_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_042024-0loxcmm7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0loxcmm7
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_042029-576at4o2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/576at4o2
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_042030-eun43bpl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/eun43bpl
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/resource_sharer.py", line 142, in _serve
    with self._listener.accept() as conn:
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 466, in accept
    answer_challenge(c, self._authkey)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 757, in answer_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_042329-zplmg1ay
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/zplmg1ay
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_042330-vqtojrut
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/vqtojrut
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_042330-iilxk23a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/iilxk23a
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_042334-h54lzgeh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/h54lzgeh
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_042414-6k7d24n5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6k7d24n5
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_042414-ydwc2beh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ydwc2beh
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_042416-97rzkw76
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/97rzkw76
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_042419-fttt7ixs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/fttt7ixs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▆▇▇▇▇▇▇████████████████████████████████
wandb: train loss █▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb: valid perf ▁▆▇▆▇▇▇▇█▇▇▇▇▇▇██▇██████▇███████▇███████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9531
wandb: train loss 0.03235
wandb: train perf 0.98816
wandb: valid perf 0.9518
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/h54lzgeh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_042334-h54lzgeh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_074521-72f9ch8u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/72f9ch8u
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▇▇▇▇▇▇▇█▇████████▇▇▇█████████████████
wandb: train loss █▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇▇▇███████████████████████████
wandb: valid perf ▁▄▆▇▇▇▇▇▇▇▇▇██▇██▇███▇█▇█▇██████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.981
wandb: train loss 0.00107
wandb: train perf 0.99969
wandb: valid perf 0.9822
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/vqtojrut
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_042330-vqtojrut/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_074755-b7u9tww6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/b7u9tww6
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▇▇▇▇▇▇█████████████████████████████████
wandb: train loss █▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇█████████████████████████████
wandb: valid perf ▁▅▆▇▇▇▇▇▇▇▇███▇█████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.985
wandb: train loss 0.00123
wandb: train perf 0.99965
wandb: valid perf 0.983
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/zplmg1ay
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_042329-zplmg1ay/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_075953-1vlfod4u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1vlfod4u
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▆▇▇██████████████████████████████████
wandb: train loss █▇▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██████████████████
wandb: valid perf ▁▄▅▆▇██████████████▇████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.5837
wandb: train loss 0.0346
wandb: train perf 0.98947
wandb: valid perf 0.6022
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/fttt7ixs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_042419-fttt7ixs/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_081029-om2e1k3y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/om2e1k3y
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▆▆▇▇▇█████████████████████████████████
wandb: train loss █▆▅▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇████████████████████████
wandb: valid perf ▁▄▆▆▇▇▇▇█▇█▇▇▇▇▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.6733
wandb: train loss 0.00753
wandb: train perf 0.99789
wandb: valid perf 0.695
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ydwc2beh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_042414-ydwc2beh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_082022-qlval1qi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/qlval1qi
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▆▇▇▇▇▇█▇██████████████████████████████
wandb: train loss █▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇███████████████████████
wandb: valid perf ▁▅▆▇▇▇█▇██▇█▇▇▇▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.7041
wandb: train loss 0.00687
wandb: train perf 0.99802
wandb: valid perf 0.7076
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/97rzkw76
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_042416-97rzkw76/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_082516-7npnw4os
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/7npnw4os
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▇▇▇▇▇▇▇██████████████████████████████
wandb: train loss █▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▁▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▇▇▇▇▇█▇▇▇▇▇▇▇▇███████
wandb: valid perf ▁▃▆▇▇▇█▇█▇█▇▇▇▆▇▇▅▇▃▇█████▇▅▇▇▅▆▆█▇▄█▄██
wandb: 
wandb: Run summary:
wandb:  test perf 0.9718
wandb: train loss 0.02809
wandb: train perf 0.99036
wandb: valid perf 0.974
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/iilxk23a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_042330-iilxk23a/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_083019-mzjt8s3f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/mzjt8s3f
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████████████
wandb: train loss █▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇███████████████████████
wandb: valid perf ▁▃▆▆▆▇▇▇▇▇▇▇▇█▇▇▇███████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.726
wandb: train loss 0.00823
wandb: train perf 0.99749
wandb: valid perf 0.7396
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6k7d24n5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_042414-6k7d24n5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_085134-4ze4m7xr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/4ze4m7xr
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████████████
wandb: train loss █▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb: valid perf ▁▁▅▆▇▇▇▇▆▇▇▇▇█▇▇███▇▇███████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9548
wandb: train loss 0.01928
wandb: train perf 0.99351
wandb: valid perf 0.9548
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/72f9ch8u
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_074521-72f9ch8u/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_110618-zexhrftl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/zexhrftl
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▆▇▇▇███████████████████████████████████
wandb: train loss █▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇▇████████████████████████████
wandb: valid perf ▁▆▇▇▇███████████████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9771
wandb: train loss 0.00089
wandb: train perf 0.99971
wandb: valid perf 0.9834
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/b7u9tww6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_074755-b7u9tww6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_111140-kqkvkba2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/kqkvkba2
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▇▇▇████████████████████████████████████
wandb: train loss █▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇▇████████████████████████████
wandb: valid perf ▁▆▇▇▇███████████████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9837
wandb: train loss 0.00084
wandb: train perf 0.99973
wandb: valid perf 0.9866
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/1vlfod4u
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_075953-1vlfod4u/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_113656-tgcb8g3c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/tgcb8g3c
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▆▇▇██████████████████████████████████
wandb: train loss █▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██████████████████
wandb: valid perf ▁▄▆▇▇███████████████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.5953
wandb: train loss 0.03439
wandb: train perf 0.98938
wandb: valid perf 0.5994
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/om2e1k3y
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_081029-om2e1k3y/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_115816-d9rljxuq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/d9rljxuq
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: \ 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▇▇▇██████████████████████████████████
wandb: train loss █▆▅▅▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▇▇▇▇▇▇████████████████████████
wandb: valid perf ▁▄▅▇▇█▇▇█▇█▇▇█▇▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.6702
wandb: train loss 0.00704
wandb: train perf 0.99771
wandb: valid perf 0.677
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/qlval1qi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_082022-qlval1qi/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_121532-z6lwmjbz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/z6lwmjbz
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▇▇██████████████████████████████████
wandb: train loss █▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇███████████████████████
wandb: valid perf ▁▄▅▆▇▇▇███▇▇▇▇▇▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.6954
wandb: train loss 0.00483
wandb: train perf 0.9986
wandb: valid perf 0.7092
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/7npnw4os
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_082516-7npnw4os/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_122356-0xsw6tnz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0xsw6tnz
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▆▇▇████████████████████████████████████
wandb: train loss █▄▃▃▂▂▂▂▂▂▂▂▂▂▂▃▃▃▄▂▂▂▂▂▂▁▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▆▆▆▅▇▇▇▇▇▇▇▇▇▇▇▇█████████
wandb: valid perf ▁▇▇▇▇▇███████▇█▅▃▆▃██▆▁▇▆▆▆▇▇▇███▇▇█▇██▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.9717
wandb: train loss 0.03439
wandb: train perf 0.98796
wandb: valid perf 0.9536
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/mzjt8s3f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_083019-mzjt8s3f/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_123753-8y3uz47i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8y3uz47i
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▆▇▇▇▇▇▇▇██████████████████████████████
wandb: train loss █▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███████████████████████
wandb: valid perf ▁▅▆▆▇▇▇▇▇▇▇▇██▇▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.7228
wandb: train loss 0.01228
wandb: train perf 0.99596
wandb: valid perf 0.7348
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/4ze4m7xr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_085134-4ze4m7xr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_131903-cbbggiah
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/cbbggiah
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▆▇▇▇▇▇▇▇▇█████████████████████████████
wandb: train loss █▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb: valid perf ▁▅▆▄▇▆▇▇▆▇▇▇█████████▇██████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9541
wandb: train loss 0.01452
wandb: train perf 0.99553
wandb: valid perf 0.9598
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/zexhrftl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_110618-zexhrftl/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_142755-2vw9k990
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/2vw9k990
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▇▇▇▇▇▇██████████████████████████████
wandb: train loss █▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇▇▇███████████████████████████
wandb: valid perf ▁▃▅▆▇▇▇▇▇▇█▇███▇█▇██▇█▇▇████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9795
wandb: train loss 0.00166
wandb: train perf 0.9994
wandb: valid perf 0.98
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/kqkvkba2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_111140-kqkvkba2/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_143541-bnxabewq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/bnxabewq
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▇▇▇██████████████████████████████████
wandb: train loss █▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇█████████████████████████████
wandb: valid perf ▁▄▆▆▇▇▇▇▇█▇▇▇▇▇█▇███████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9829
wandb: train loss 0.00274
wandb: train perf 0.99902
wandb: valid perf 0.9834
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/tgcb8g3c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_113656-tgcb8g3c/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_151427-iz583e9m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/iz583e9m
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▇▇██████████████████████████████████
wandb: train loss █▇▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██████████████████
wandb: valid perf ▁▄▅▆▇███████▇█▇▇█████▇█▇█▇████▇▇█████▇██
wandb: 
wandb: Run summary:
wandb:  test perf 0.6009
wandb: train loss 0.03502
wandb: train perf 0.98904
wandb: valid perf 0.593
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/d9rljxuq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_115816-d9rljxuq/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_154736-bt32q0p1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/bt32q0p1
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▆▇▇▇▇▇▇██████████████████████████████
wandb: train loss █▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇███████████████████████
wandb: valid perf ▁▄▆▇▇▇█▇███▇▇█▇▇▇███████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.6711
wandb: train loss 0.00706
wandb: train perf 0.99804
wandb: valid perf 0.6822
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/z6lwmjbz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_121532-z6lwmjbz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_161123-jnorjyv2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/jnorjyv2
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▅▆▇▇▇▇▇▇▇▇▇▇██▇███████████████████████
wandb: train loss █▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇███████████████████████
wandb: valid perf ▁▃▅▅▆▇▇▇▇▇▇█▇██▇▇███████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.7075
wandb: train loss 0.00816
wandb: train perf 0.99742
wandb: valid perf 0.718
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/0xsw6tnz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_122356-0xsw6tnz/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_162419-mm6n81ef
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/mm6n81ef
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▆▇▇▇▇██████████████████████████████████
wandb: train loss █▅▃▃▃▂▂▂▂▂▂▂▂▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▄▆▆▆▇▇▇▇▇▇▇▆▆▅▆▆▇▆▇▇▆▇▇▇▇▇▇████████████
wandb: valid perf ▁▆▆▇▇▇█▇█▇▇▇▇▇▆▆▇▇▃▇▇▇▇▇▇▇███████▇██████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9757
wandb: train loss 0.02033
wandb: train perf 0.99327
wandb: valid perf 0.9798
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/8y3uz47i
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_123753-8y3uz47i/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_164530-qpa4i1hs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/qpa4i1hs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████████████
wandb: train loss █▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇██████████████████████
wandb: valid perf ▁▄▆▆▇▇▇▇▇▇▇▇▇█▇▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.7243
wandb: train loss 0.01256
wandb: train perf 0.99591
wandb: valid perf 0.7296
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/cbbggiah
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_131903-cbbggiah/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230312_174614-pht8n14s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/pht8n14s
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▆▆▆▆▆▇▇▇▇▇█████████████████████████████
wandb: train loss █▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb: valid perf ▁▆▆▆▆▆▇▇▇▇█▇▇███▇██▇██████▇▇████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9542
wandb: train loss 0.02679
wandb: train perf 0.99031
wandb: valid perf 0.9592
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/2vw9k990
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_142755-2vw9k990/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▆▆▇▇▇▇▇▇███████████████████████████████
wandb: train loss █▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇▇▇███████████████████████████
wandb: valid perf ▁▅▆▇▆▇▇▇▇▇█▇▇████████▇██████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9792
wandb: train loss 0.00175
wandb: train perf 0.99944
wandb: valid perf 0.982
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/bnxabewq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_143541-bnxabewq/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▆▇▇▇███████████████████████████████████
wandb: train loss █▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇▇████████████████████████████
wandb: valid perf ▁▆▇▇▇▇▇█▇███▇███████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9832
wandb: train loss 0.00028
wandb: train perf 0.99993
wandb: valid perf 0.985
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/iz583e9m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_151427-iz583e9m/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▆▇▇██████████████████████████████████
wandb: train loss █▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█▇████████████████
wandb: valid perf ▁▄▆▆▇██████████▇▇▇█████▇███████████▇████
wandb: 
wandb: Run summary:
wandb:  test perf 0.6079
wandb: train loss 0.03446
wandb: train perf 0.9894
wandb: valid perf 0.6074
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/bt32q0p1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_154736-bt32q0p1/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▃▆▇▇▇██████████████████████████████████
wandb: train loss █▆▅▅▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▇▇▇▇▇▇████████████████████████
wandb: valid perf ▁▃▆▇▇█████▇███▇▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.6771
wandb: train loss 0.00731
wandb: train perf 0.99796
wandb: valid perf 0.6776
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/jnorjyv2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_161123-jnorjyv2/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▆▇▇▇█████████████████████████████████
wandb: train loss █▆▅▅▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇████████████████████████
wandb: valid perf ▁▄▅▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.7038
wandb: train loss 0.00526
wandb: train perf 0.99858
wandb: valid perf 0.7072
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/mm6n81ef
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_162419-mm6n81ef/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▇█████████████████████████████████████
wandb: train loss █▄▃▂▂▂▂▂▁▁▂▁▁▂▃▃▃▂▂▂▂▂▂▂▁▁▂▁▂▂▂▂▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▇▇▇▇▇██▇██▇▆▆▆▇▇▇▇▇▇▇██▇█▇▇▇▇████████
wandb: valid perf ▅▆▇███████████▅▆▆▅▄▆▁▆▅▆▄▇▇▇▇▅▆▇██▇▆▆▇▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.9692
wandb: train loss 0.055
wandb: train perf 0.9812
wandb: valid perf 0.932
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/qpa4i1hs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_164530-qpa4i1hs/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▃▆▇▆▇▇▇▇▇▇█████████████████████████████
wandb: train loss █▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇███████████████████████
wandb: valid perf ▁▃▅▇▆▇▇▇▇▇▇▇▇▇▇▇▇█████████▇█████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.7308
wandb: train loss 0.01018
wandb: train perf 0.99669
wandb: valid perf 0.7368
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/pht8n14s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230312_174614-pht8n14s/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_010506-s9i50deg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/s9i50deg
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_010510-xwlqqmcr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xwlqqmcr
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_010510-kijq2127
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/kijq2127
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_010510-84z2ii65
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/84z2ii65
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_010550-vsvko7ca
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/vsvko7ca
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_010552-8l4w6iuw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8l4w6iuw
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_010557-1cs2ozoe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1cs2ozoe
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_010601-gp4vtss9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/gp4vtss9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▆▇▇▇▇██████████████████████████████████
wandb: train loss █▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb: valid perf ▁▆▇▇▇▇█▇▇██▇██▇█▇███████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9544
wandb: train loss 0.02164
wandb: train perf 0.99267
wandb: valid perf 0.9588
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xwlqqmcr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_010510-xwlqqmcr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_042251-r8jxd4q1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/r8jxd4q1
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▇▇▇▇▇▇▇██████████████████████████████
wandb: train loss █▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇▇▇███████████████████████████
wandb: valid perf ▁▄▄▇▇▇▇▇▇▇█▇▇▇█▇▇▇▇█████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9803
wandb: train loss 0.00059
wandb: train perf 0.99982
wandb: valid perf 0.983
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/84z2ii65
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_010510-84z2ii65/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_042316-9cd2w5a1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/9cd2w5a1
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▆▆▇▇▇▇▇███████████████████████████████
wandb: train loss █▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇█████████████████████████████
wandb: valid perf ▁▄▆▆▆▆▇▇▇▇▇▇▇█▇▇███████▇█████▇██████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9803
wandb: train loss 0.00265
wandb: train perf 0.99913
wandb: valid perf 0.9832
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/kijq2127
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_010510-kijq2127/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_044121-6rstwob8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6rstwob8
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▇▇▇██████████████████████████████████
wandb: train loss █▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇████████████████████████
wandb: valid perf ▁▄▆▇▇▇▇▇█▇██████████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.6722
wandb: train loss 0.01106
wandb: train perf 0.99638
wandb: valid perf 0.6884
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/gp4vtss9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_010601-gp4vtss9/logs
wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▇▇▇█████████████████████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████████████
wandb: valid perf ▁▄▆▆▇▇██████████████████████▇███████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.6129
wandb: train loss 0.08994
wandb: train perf 0.9688
wandb: valid perf 0.6074
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/1cs2ozoe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_010557-1cs2ozoe/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_045633-43vbwjyt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/43vbwjyt
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_045637-rwe0cu9t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/rwe0cu9t
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.033 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.033 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▇▇▇▇█████████████████████████████████
wandb: train loss █▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇███████████████████████
wandb: valid perf ▁▅▆▇▇▇▇▇▇██▇▇▇▇▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.7036
wandb: train loss 0.00686
wandb: train perf 0.99809
wandb: valid perf 0.7146
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/vsvko7ca
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_010550-vsvko7ca/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_050254-mkdpagqp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/mkdpagqp
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▇▇▇███████████████████████████████████
wandb: train loss █▄▃▃▂▂▂▂▂▂▂▂▂▂▄▃▂▂▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇▇▇▇▅▆▇▇▆▇▇▇▇▇▇▇▇▇▇███████████
wandb: valid perf ▄▆▇▇███▇█▇█▇▇█▁▅▆▇▆▇▇▆▇█▇██▇▇███████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.974
wandb: train loss 0.03678
wandb: train perf 0.98745
wandb: valid perf 0.9738
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/s9i50deg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_010506-s9i50deg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_050518-bycq0ivf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/bycq0ivf
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▆▇▇▇▇▇▇▇▇████████████████████████████
wandb: train loss █▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇███████████████████████
wandb: valid perf ▁▅▆▆▇▇█▇▇▇▇█▇▇██████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.7179
wandb: train loss 0.01254
wandb: train perf 0.99613
wandb: valid perf 0.734
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/8l4w6iuw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_010552-8l4w6iuw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_052138-0kkt4z4u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0kkt4z4u
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▆▇▇▇▇█████████████████████████████████
wandb: train loss █▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████
wandb: valid perf ▁▅▄▄▅▇▆▇▇▇▇▇▇█▇▇████▇▇▇█▇▇██▇███████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9508
wandb: train loss 0.03087
wandb: train perf 0.98875
wandb: valid perf 0.9546
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/r8jxd4q1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_042251-r8jxd4q1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_081921-d8ftu8gz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/d8ftu8gz
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▆▇▇▇▇▇▇▇███████████████████████████████
wandb: train loss █▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇▇▇███████████████████████████
wandb: valid perf ▁▅▇▇▇▇█▇▇███████████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9807
wandb: train loss 0.00113
wandb: train perf 0.9996
wandb: valid perf 0.9838
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/9cd2w5a1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_042316-9cd2w5a1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_082055-6htrjn6z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6htrjn6z
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▇▇▇▇▇█████████████████████████████████
wandb: train loss █▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇▇▇███████████████████████████
wandb: valid perf ▁▅▇▅▇▇▇▇██▇██████▇██████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9841
wandb: train loss 0.00115
wandb: train perf 0.99962
wandb: valid perf 0.9848
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6rstwob8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_044121-6rstwob8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_085650-795m2vs4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/795m2vs4
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▇▇▇▇▇███████████████████████████████
wandb: train loss █▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███████████████████████
wandb: valid perf ▁▄▅▆▇▇▇▇██████▇█████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.6752
wandb: train loss 0.01234
wandb: train perf 0.99624
wandb: valid perf 0.6924
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/43vbwjyt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_045633-43vbwjyt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_093122-texiyn2k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/texiyn2k
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▇▇▇█████████████████████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇████████████
wandb: valid perf ▁▃▅▆▇▇▇████████████████████▇▇▇▇███▇▇█▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 0.6143
wandb: train loss 0.0879
wandb: train perf 0.96956
wandb: valid perf 0.6128
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/rwe0cu9t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_045637-rwe0cu9t/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_093134-ze9uzkwb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ze9uzkwb
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▆▇█████████████████████████████████████
wandb: train loss █▄▃▂▂▂▂▂▂▂▂▂▁▃▂▃▃▂▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁
wandb: train perf ▁▅▆▇▇▇▇▇▇▇▇▇█▆▇▆▆▇▆▇▇████████████▇██████
wandb: valid perf ▁▆▇▇▇████████▇▇▆▇▂▇██▇████████████▇█████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9719
wandb: train loss 0.04235
wandb: train perf 0.98464
wandb: valid perf 0.9736
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/bycq0ivf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_050518-bycq0ivf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_093405-g59w7nf4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/g59w7nf4
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▆▆▇▇▇▇████████████████████████████████
wandb: train loss █▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇██████████████████████
wandb: valid perf ▁▄▆▆▇▇█▇▇███████████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.6987
wandb: train loss 0.00628
wandb: train perf 0.9984
wandb: valid perf 0.7052
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/mkdpagqp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_050254-mkdpagqp/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_094356-mwe0kw2h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/mwe0kw2h
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.015 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: \ 0.015 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▆▆▇▇▇▇████████████████████████████████
wandb: train loss █▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇███████████████████████
wandb: valid perf ▁▅▆▇▇▇▇▇█▇█▇▇█▇▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.724
wandb: train loss 0.01309
wandb: train perf 0.99613
wandb: valid perf 0.7352
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/0kkt4z4u
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_052138-0kkt4z4u/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_101746-8adssla2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8adssla2
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▆▆▆▇▇▇▇▇▇▇█████████████████████████████
wandb: train loss █▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb: valid perf ▁▆▆▆▆▇▇▇▇▇▇▇▇█▇██▇████▇█████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9516
wandb: train loss 0.0205
wandb: train perf 0.99278
wandb: valid perf 0.9586
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/d8ftu8gz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_081921-d8ftu8gz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_114853-df5jd4jx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/df5jd4jx
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▆▇▇▇█▇▇████████████████████████████████
wandb: train loss █▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇▇▇▇██████████████████████████
wandb: valid perf ▁▄▇▇▇▇▇▇█▇██▇███████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9803
wandb: train loss 0.00162
wandb: train perf 0.99953
wandb: valid perf 0.9816
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6htrjn6z
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_082055-6htrjn6z/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_115022-b6v7otmj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/b6v7otmj
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▇▇▇▇▇█████████████████████████████████
wandb: train loss █▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▇▇▇▇▇▇▇▇█████████████████████████████
wandb: valid perf ▁▅▆▇▇▇▇▇▇█▇██▇██████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9843
wandb: train loss 0.00047
wandb: train perf 0.99991
wandb: valid perf 0.985
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/795m2vs4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_085650-795m2vs4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_124505-tnvch8u7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/tnvch8u7
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▅▆▇▇▇█████████████████████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████████
wandb: valid perf ▁▃▅▆▇▇▇▇███████████▇▇██▇██▇▇▇█▇█▇█▇▇▇██▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.6166
wandb: train loss 0.08859
wandb: train perf 0.97024
wandb: valid perf 0.6068
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ze9uzkwb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_093134-ze9uzkwb/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_132628-ir9uf8j0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ir9uf8j0
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▇▇▇▇████████████████████████████████
wandb: train loss █▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇██████████████████████
wandb: valid perf ▁▄▅▆▆▇▇██████████▇██████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.6871
wandb: train loss 0.01057
wandb: train perf 0.9968
wandb: valid perf 0.6898
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/texiyn2k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_093122-texiyn2k/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_132703-1y5sgyyl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1y5sgyyl
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▇▇▇██████████████████████████████████
wandb: train loss █▄▃▃▂▂▂▂▂▂▂▂▂▂▂▃▂▂▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▆▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇█████████
wandb: valid perf ▇▇▇█████████████▇██▁▇▇▇▇▇▆█▇█▄██████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.973
wandb: train loss 0.02607
wandb: train perf 0.99085
wandb: valid perf 0.9642
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/g59w7nf4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_093405-g59w7nf4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_133714-22m9hdzn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/22m9hdzn
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: - 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▇▇▇▇████████████████████████████████
wandb: train loss █▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇███████████████████████
wandb: valid perf ▁▄▅▆▇▇▇▇▇▇▇█▇▇▇▇▇███▇███▇███████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.7055
wandb: train loss 0.00709
wandb: train perf 0.99782
wandb: valid perf 0.7224
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/mwe0kw2h
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_094356-mwe0kw2h/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_134504-3aoh7pjz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/3aoh7pjz
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████████████
wandb: train loss █▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█████████████████████
wandb: valid perf ▁▄▆▆▇▇▇▇█▇▇▇█▇████▇█████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.7198
wandb: train loss 0.01284
wandb: train perf 0.99642
wandb: valid perf 0.7396
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/8adssla2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_101746-8adssla2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230313_143431-khedf715
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/khedf715
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▅▅▆▇▇▇▇▇▇▇▇███████████████████████████
wandb: train loss █▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb: valid perf ▂▁▆▆▆▇▇▇▇█▇▇██▇████▇█████▇█▇███▇████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9521
wandb: train loss 0.02899
wandb: train perf 0.98971
wandb: valid perf 0.9544
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/df5jd4jx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_114853-df5jd4jx/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.030 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.030 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▆▇▇▇▇▇████████████████████████████████
wandb: train loss █▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇▇████████████████████████████
wandb: valid perf ▁▁▆▇▇▇▇▇▇▇▇▇█████▇██████▇███████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9801
wandb: train loss 0.00133
wandb: train perf 0.9996
wandb: valid perf 0.9834
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/b6v7otmj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_115022-b6v7otmj/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████████████
wandb: train loss █▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇▇████████████████████████████
wandb: valid perf ▂▁▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇███████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.9849
wandb: train loss 0.00175
wandb: train perf 0.99933
wandb: valid perf 0.9826
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/tnvch8u7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_124505-tnvch8u7/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▅▆▇▇▇▇▇▇██████████████████████████████
wandb: train loss █▇▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████████
wandb: valid perf ▁▄▅▆▆▇█▇▇███████████████████▇███████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.6292
wandb: train loss 0.10527
wandb: train perf 0.96409
wandb: valid perf 0.6184
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ir9uf8j0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_132628-ir9uf8j0/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▅▆▇▇▇▇▇▇██████████████████████████████
wandb: train loss █▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███████████████████████
wandb: valid perf ▁▄▅▇▇▇▇█▇█████▇█████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.6836
wandb: train loss 0.01312
wandb: train perf 0.99589
wandb: valid perf 0.689
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/1y5sgyyl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_132703-1y5sgyyl/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▆▆▇▇▇▇▇███████████████████████████████
wandb: train loss █▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇███████████████████████
wandb: valid perf ▁▄▅▆▇▇▇▇▇█▇█▇██▇▇███████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.7121
wandb: train loss 0.0074
wandb: train perf 0.99791
wandb: valid perf 0.7144
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/3aoh7pjz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_134504-3aoh7pjz/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▆▇▇▇▇▇████████████████████████████████
wandb: train loss █▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇█████████
wandb: valid perf ▁▃▆▆▆▇▇▇▇▅█▇▆▇▇▇▆▇▅▇▄██▇▇▇▆▇▆▆▇██████▇██
wandb: 
wandb: Run summary:
wandb:  test perf 0.9722
wandb: train loss 0.03162
wandb: train perf 0.98927
wandb: valid perf 0.975
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/22m9hdzn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_133714-22m9hdzn/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▃▆▆▇▇▇▇▇▇██████████████████████████████
wandb: train loss █▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇██████████████████████
wandb: valid perf ▁▃▅▆▆▆▇▇▇▇▇▇▇▇▇█▇▇██████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.7176
wandb: train loss 0.01483
wandb: train perf 0.99578
wandb: valid perf 0.7394
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/khedf715
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230313_143431-khedf715/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/exp.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 242, in run_k_fold
    wandb.init(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/wandb_init.py", line 1166, in init
    raise e
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/wandb_init.py", line 1144, in init
    run = wi.init()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/wandb_init.py", line 744, in init
    result = run_init_handle.wait(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py", line 283, in wait
    found, abandoned = self._slot._get_and_clear(timeout=wait_timeout)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py", line 130, in _get_and_clear
    if self._wait(timeout=timeout):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py", line 126, in _wait
    return self._event.wait(timeout=timeout)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/threading.py", line 558, in wait
    signaled = self._cond.wait(timeout)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/threading.py", line 306, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/subprocess.py", line 1083, in wait
    return self._wait(timeout=timeout)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/subprocess.py", line 1806, in _wait
    (pid, sts) = self._try_wait(0)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/subprocess.py", line 1764, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py", line 187, in _teardown
    result = self._service.join()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/wandb/sdk/service/service.py", line 216, in join
    ret = self._internal_proc.wait()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/subprocess.py", line 1096, in wait
    self._wait(timeout=sigint_timeout)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/subprocess.py", line 1800, in _wait
    time.sleep(delay)
KeyboardInterrupt
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_003553-28jy0sui
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/28jy0sui
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_003553-8itdk6xr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8itdk6xr
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_003553-fujuo3as
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/fujuo3as
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_003553-5bz3z804
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5bz3z804
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_003554-vqele5q6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/vqele5q6
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_003554-th4rs6cm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/th4rs6cm
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_003554-yishu4ax
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/yishu4ax
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_004054-b1144i3s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/b1144i3s
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_004054-6r378jve
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6r378jve
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_004054-0lq2z4j8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0lq2z4j8
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_004054-ifsoj42o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ifsoj42o
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_004055-qnp3nma0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/qnp3nma0
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_004055-ezp8ft45
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ezp8ft45
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_004055-92w011qw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/92w011qw
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_004055-bcq97s06
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/bcq97s06
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.057 MB of 0.057 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁█▁█▄█▂█▁█▁█▅█▁█▆█▁█▂█▃█▁█▂█▇█▁█▄█▂█▇█▄█
wandb:        seconds ▄▃▁█▂▂▂▄▂▆▁▂▁▁▁▁▃▃▄▂▂▃▃▅▃▄▅█▅█▅▃▂▄▇▂▄▄▂▅
wandb:      test perf ▁█▁█▁█▂█▁█▁█▁█▁█▁█▁█▁█▁█▁█▂█▇█▁█▄█▂█▇█▁█
wandb:     train loss █▂▆▂▇▂▇▂▇▂▆▂▆▁█▁█▂█▁▇▁▅▁▆▁▃▁▂▁▃▁▃▁▃▁▂▁▂▁
wandb:     train perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.54391
wandb:      test perf 1.0
wandb:     train loss 0.00099
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/92w011qw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_004055-92w011qw/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.057 MB of 0.057 MB uploaded (0.000 MB deduped)wandb: | 0.057 MB of 0.057 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▄█▁█▁█▄█▁███▁█▁█▂█▁█▁█▁█▁███▁█▁█▅█▁█▇█▁█
wandb:        seconds ▂▂▅▃▂█▆▂▁▂▁▅▄▃▃▂▄▄▂▂▄▃▃▂▃▄▃▇▂▃▇▃▁▃▂▁▁▁▂▁
wandb:      test perf ▄█▁█▁█▄█▁███▁█▁█▁█▁█▁█▁█▁███▁█▁█▅█▁█▇█▁█
wandb:     train loss ▆▂▆▂█▂▄▂▆▂▆▂▇▂▆▁▇▂▆▁█▂▆▁▇▁▃▂▃▁▃▁▃▁▃▁▃▂▂▁
wandb:     train perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.7278
wandb:      test perf 1.0
wandb:     train loss 0.00087
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/qnp3nma0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_004055-qnp3nma0/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▆█▁█▁█▁█▁█▁█▁█▆█▁█▁█▁█▂█▄█▃███▁█▆█▇█████
wandb:        seconds ▄▃▃▄▃▄▃▄▃▄▃▃▃▃▃▄▃▃▂▃▃▃▇▂▅▄█▆▆▂▅▅▂▃▂▄▂▂▂▁
wandb:      test perf ▆█▁█▁█▁█▁█▁█▁█▃█▁█▁█▁█▁█▁█▃███▁█▁█▇█████
wandb:     train loss ▆▂▇▂▅▁▅▂▆▂▆▂▅▁▅▁█▁▅▁▅▁▆▁▅▁▃▁▃▁▂▁▂▁▃▁▃▁▃▁
wandb:     train perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.15634
wandb:      test perf 1.0
wandb:     train loss 0.0012
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/bcq97s06
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_004055-bcq97s06/logs
Processing...
Done!
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/sr25.py", line 54, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 35, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 134, in create_dataset
    dataset = SRDataset(root, pre_transform=pre_transform)
  File "/home/shpark/graph-MLPMixer/core/data_utils/sr25.py", line 11, in __init__
    self.data, self.slices = torch.load(self.processed_paths[0])
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/serialization.py", line 712, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/serialization.py", line 1049, in _load
    result = unpickler.load()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/serialization.py", line 1019, in persistent_load
    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/serialization.py", line 997, in load_tensor
    storage = zip_file.get_storage_from_record(name, numel, torch._UntypedStorage).storage()._untyped()
RuntimeError: PytorchStreamReader failed reading file data/1: file read failed
Processing...
Done!
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_010450-ky8av8tq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ky8av8tq
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_010451-8sooz9vd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8sooz9vd
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_010450-kue6oi15
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/kue6oi15
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_010515-iovxj9qs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/iovxj9qs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_010516-6rtbwvgi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6rtbwvgi
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_010542-3bjpsape
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/3bjpsape
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_010611-qnvlruf6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/qnvlruf6
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▅▆▆▆▆▆▆▆▇▇▇██████
wandb: train loss █▇▇█▇▆▆▇▆▆▅▇▇▆▅▄▇▄▄▄▄▄▄▄▄▄▃▃▂▃▂▂▂▁▁▁▁▁▁
wandb: train perf ▁▁▁▁▁▃▃▃▃▂▅▁▁▂▄▆▂▆▅▆▅▅▆▆▅▅▅▆█▅▆██████▇█
wandb: valid perf ▁▁▄▄▄▄▄▄▄▄▃▃▃▃▃▄▄▃▃▃▄▅▅▆▆▆▆▆▆▆▇▇▇██████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 1.09923
wandb: train perf 0.86667
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/8sooz9vd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_010451-8sooz9vd/logs
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▇█████████
wandb: train loss ██▅▆█▇▇▆▆▄▆▇▅▆▃▅▃▄▅▄▃▅▃▅▃▃▂▂▂▁▂▂▁▁▁▁
wandb: train perf ▁▁▅▃▁▂▃▃▄▅▁▂▃▃▆▂▆▄▂▄▆▄▇▄▅▆▆▇▆█▇▆██▇▇
wandb: valid perf ▁▁▁▁▂▂▂▂▃▃▂▂▂▂▂▄▄▄▄▅▅▅▅▅▆▆▇█████████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 1.18474
wandb: train perf 0.86667
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/kue6oi15
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_010450-kue6oi15/logs
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▂▂▂▂▂▂▄▅▅▅▅▅▆█████████████████████████
wandb: train loss ██▇▇▇█▆▇▇▆▇▆▅▇▅▇▅▄▅▄▅▄▅▄▃▄▃▄▂▃▂▃▂▁▃▂▁▁▂▁
wandb: train perf ▁▁▂▂▂▁▄▂▁▃▂▃▅▃▅▂▄▆▅▅▄▆▃▅▆▅▇▅█▇█▆▇█▆▆▇█▇█
wandb: valid perf ▁▂▁▁▁▁▁▁▄▅▅▅▅▅▆████▇▇▇▇▆▆▆▆▅▅▅▆▆▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.82085
wandb: train perf 0.93333
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ky8av8tq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_010450-ky8av8tq/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_010639-djj92amp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/djj92amp
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_010639-ioo08ly3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ioo08ly3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_010644-21fdnc1d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/21fdnc1d
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁█▁█▁█▁█▃█▁█▁█▃█▅█▁█▁█▁█▁█▁█▇█▁█▁█▁█▁█▁█
wandb:        seconds ▃▃▃▆▂▅▂▃▅▄▂▄▃▅▄▆▄▂▃▄▄▆▁█▂█▃▂▂▁▄▆▂▁▄▁▂▅▅▄
wandb:      test perf ▁█▁█▁█▁█▁█▁█▁█▃█▅█▁█▁█▁█▁█▁█▇█▁█▁█▁█▁█▁█
wandb:     train loss ▇▂▇▂▆▂▆▂▄▁▆▂▆▁▅▁▇▁▆▁▇▁▇▁█▁▂▁▃▁▂▁▃▂▃▁▃▁▃▂
wandb:     train perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 3.03173
wandb:      test perf 1.0
wandb:     train loss 0.00219
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ezp8ft45
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_004055-ezp8ft45/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇█
wandb: train loss █▆█▇▇▆▇▆▅▆▆▅▅▄▇▇▃▆▄▅▃▄▄▅▄▂▃▃▂▃▂▃▂▂▁
wandb: train perf ▁▃▁▁▃▃▃▅▅▃▄▅▅▆▁▂█▃▅▃▇▄▅▃▅██▇▇▆▇▆▆██
wandb: valid perf ▂▂▂▂▁▂▂▃▂▁▂▁▁▂▂▃▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 1.04335
wandb: train perf 0.93333
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/21fdnc1d
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_010644-21fdnc1d/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_010825-ja4q2x1e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ja4q2x1e
wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▄▄▄▅▅▅▅▅▅▅▅▅▆▇▇▇▇▇▇▇▇▇▇█
wandb: train loss ██▆▆▇▇█▇▇▇▇▅▆▇▇▆▅▅▄▄▅▄▄▃▄▃▄▃▃▂▃▂▂▃▂▂▂▁▁▁
wandb: train perf ▂▁▄▅▄▃▁▃▂▃▃▇▄▄▂▅▆▅▆▆▄▇▄▆▆▇▅▅▆█▆▇▇▇▇▆▇██▇
wandb: valid perf ▂▁▁▁▁▁▁▁▁▂▂▁▁▂▃▃▄▄▅▅▅▆▆▅▅▆▆▆▇▇▇▇▇███████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.8716
wandb: train perf 0.8
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ioo08ly3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_010639-ioo08ly3/logs
wandb: / 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████
wandb: train loss ███▇▇▇██▆▇▇▅▅▅▆▅▅▄▅▄▄▄▄▄▄▃▄▃▃▂▂▂▂▂▁▁▁▁▁▁
wandb: train perf ▁▂▁▂▁▂▁▂▃▂▂▄▅▅▄▃▅▅▄▇▆▇▆▆▆▇▅▇▆▇█▇█▇███▇██
wandb: valid perf ▁▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.78938
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/djj92amp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_010639-djj92amp/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_010835-qbj5tlb5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/qbj5tlb5
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_010836-k77tmdff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/k77tmdff
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▂▃▃▃▃▃▃▃▃▃▄▄▄▄▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██
wandb: train loss █▆█▇█▇▇▇▇▇▇▆▆▄▆▆▅▅▅▅▅▄▄▄▃▃▃▄▃▂▂▂▂▂▂▂▂▂▁
wandb: train perf ▁▅▂▃▁▄▂▂▂▂▂▃▃▅▁▄▃▅▅▄▄▇▅▇▆▆█▆▆▇▇█▇▇█████
wandb: valid perf ▁▁▁▁▂▃▃▂▂▃▂▂▃▃▄▄▄▄▆▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.65013
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ja4q2x1e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_010825-ja4q2x1e/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_011018-jehw3m5e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/jehw3m5e
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▂▂▂▂▂▂▂▃▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████
wandb: train loss █▇▅▇▆▇▇▆▆▇█▅▅▅▆▆▄▅▅▅▄▃▄▃▃▃▄▃▃▂▃▂▃▂▂▂▂▁▂▁
wandb: train perf ▁▂▇▂▅▃▂▃▃▃▂▅▆▅▄▃▆▅▅▄▅▆▅▇▆▆▅▆▆█▅▇▅█▇█▇█▇█
wandb: valid perf ▁▁▁▂▁▂▂▂▂▂▃▄▅▅▅▅▅▅▆▆▇▆▆▅▅▅▆▆▆▆▆▆▆▆▇▇████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.7851
wandb: train perf 0.86667
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/qbj5tlb5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_010835-qbj5tlb5/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_011039-0nviqciy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0nviqciy
wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█
wandb: train loss █████▇▇▇▇▇▇▇▇▆▇▆▅▆▆▅▅▄▄▄▄▄▃▄▃▃▃▂▃▃▂▂▂▁▂▁
wandb: train perf ▂▁▂▂▂▁▁▁▂▂▃▂▂▃▂▄▄▃▃▄▅▅▇▄▅▇▆▅▇▇▆█▇▆█▇████
wandb: valid perf ▂▁▁▂▂▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▅▅▄▅▅▅▆▇▇▇▇▇████████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.6595
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/k77tmdff
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_010836-k77tmdff/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_011047-035kiop4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/035kiop4
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▃▃▃▃▃▃▃▃▃▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████
wandb: train loss ███▇▇█▅▇▇█▇▇▇▆▆▆▅▆▅▄▅▃▃▅▅▄▃▂▂▃▂▂▃▂▁▁▂
wandb: train perf ▁▁▁▂▃▂▆▃▂▁▂▃▂▄▃▂▃▂▄▆▄▆█▄▅▅▆▇▇▆▆▇▄▅██▆
wandb: valid perf ▁▂▃▃▃▂▂▁▁▁▃▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 1.42476
wandb: train perf 0.66667
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/0nviqciy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_011039-0nviqciy/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▃▄▄▄▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇█████
wandb: train loss ██▇▇███▇▇▆▆▇▅▆▄▄▆▅▄▄▃▄▃▅▄▃▄▃▂▂▃▃▂▂▂▂▁▂▁▁
wandb: train perf ▁▁▂▂▁▂▁▂▂▄▃▂▅▃▅▅▃▅▆▅▇▆▆▃▅▆▆▇▇▇▆▆██▇▆████
wandb: valid perf ▁▁▁▁▂▂▁▁▁▁▂▂▂▂▂▂▃▄▄▄▃▃▃▄▅▅▅▆▆▆▆▇▇▇▇█████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.61459
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/jehw3m5e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_011018-jehw3m5e/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.020 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.020 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▆▆▆▆▇▇██████████████
wandb: train loss █▇█▇▇▇▇▇▇▇▆▆▅▆▆▄▆▅▅▅▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁
wandb: train perf ▁▁▁▁▂▁▂▂▃▂▂▄▅▄▄▇▃▄▅▄▇▆▇▅▇▇█▇▇█▇▇█████▇██
wandb: valid perf ▁▁▁▂▂▂▃▃▃▃▃▄▃▄▄▄▄▄▄▅▆▆▅▅▇▇██████████████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.60669
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/035kiop4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_011047-035kiop4/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████
wandb: train loss █▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train perf █▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb: valid perf ▄▄▆▄▅▄▃▄▁▅▅▆▇▆▇▇▆▇▇▆▆▇▇█▇▇██████▇███████
wandb: 
wandb: Run summary:
wandb:  test perf -0.24985
wandb: train loss 0.19955
wandb: train perf 0.19955
wandb: valid perf -0.24341
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/iovxj9qs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_010515-iovxj9qs/logs
wandb: \ 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: 
wandb: Run history:
wandb:  test perf ▁▄▄▄▄▆▆▆▆▆▆▆▇▇▇▇▇▇▇█████████████████████
wandb: train loss █▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: train perf █▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: valid perf ▃▁▄▅▄▅▅▇▆▆▇▆▅▇▇█▇▇▇█▇█▇▇████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.24944
wandb: train loss 0.19141
wandb: train perf 0.19141
wandb: valid perf -0.24479
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6rtbwvgi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_010516-6rtbwvgi/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_013529-iq4v53gq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/iq4v53gq
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_013531-02sihx9g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/02sihx9g
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▅▅▅▅▇▇▇▇▇▇▇▇▇█████████████████████████
wandb: train loss █▇▆▆▅▆▅▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb: train perf █▇▆▆▅▆▅▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▁▆▃▅▆▆▇▇▇▆▇▇▇██████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.24813
wandb: train loss 0.20966
wandb: train perf 0.20966
wandb: valid perf -0.24487
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/qnvlruf6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_010611-qnvlruf6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_013558-ops04zd9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ops04zd9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▂▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████████
wandb: train loss █▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf █▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▅▂▁▆▅▆▄▇▇▆▇▇▇▇▇▅███▇████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.24892
wandb: train loss 0.20884
wandb: train perf 0.20884
wandb: valid perf -0.24325
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/3bjpsape
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_010542-3bjpsape/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_013645-c27g3vud
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/c27g3vud
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▂▂▂▄▄▅▄▄▆▆▆▆▇▇▇▇▇█████████████████████
wandb: train loss █▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train perf █▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: valid perf ▅▁▆▅▄▅▆▃▆▆▆▆▆▆▇▇█▇▆▇▇█▇▇████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.24924
wandb: train loss 0.20691
wandb: train perf 0.20691
wandb: valid perf -0.2419
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/iq4v53gq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_013529-iq4v53gq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_020356-87mndmfn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/87mndmfn
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▃▅▅▅▅▆▆▆▆▆████████████████████████████
wandb: train loss █▇▇▆▆▆▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: train perf █▇▇▆▆▆▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: valid perf ▄▂▅▆▃▁▆▇▅▆▇▆▇█▇▇████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.24749
wandb: train loss 0.20862
wandb: train perf 0.20862
wandb: valid perf -0.24715
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/02sihx9g
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_013531-02sihx9g/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: 
wandb: Run history:
wandb:  test perf ▁▂▃▃▄▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████
wandb: train loss █▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb: train perf █▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb: valid perf ▆▁▆▅▇▇▇▆▅▆▆▇▇█▇▇█▇█████▇████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.25128
wandb: train loss 0.2059
wandb: train perf 0.2059
wandb: valid perf -0.24327
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ops04zd9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_013558-ops04zd9/logs
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_020423-n3idwdz3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/n3idwdz3
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_020426-36s7vksh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/36s7vksh
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████████
wandb: train loss █▇▇▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: train perf █▇▇▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: valid perf ▂▁▁▄▅▃▃▅▅▆▄▆▆▇▇▆▆▇▇▇▇████▇██████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.24773
wandb: train loss 0.20677
wandb: train perf 0.20677
wandb: valid perf -0.24233
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/c27g3vud
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_013645-c27g3vud/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_020639-b7cvo3xg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/b7cvo3xg
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▃▄▅▅▆▇▇▇▇▇▇██████▇▇▇▇█████████████████
wandb: train loss █▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: train perf █▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: valid perf ▁▄▅▂▁▆▆▅▆▇▅▇▆█▇███▇█████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.24706
wandb: train loss 0.20811
wandb: train perf 0.20811
wandb: valid perf -0.24082
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/87mndmfn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_020356-87mndmfn/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_023234-xwkedcvx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xwkedcvx
wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▆▆▇▇▇▇▇▇██████████████████████████████
wandb: train loss █▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁
wandb: train perf █▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁
wandb: valid perf ▁▃▆▄▆▂▆▆▇▇▇▇▇▆█▇█████▇██▇█▇█▇███████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.24832
wandb: train loss 0.20412
wandb: train perf 0.20412
wandb: valid perf -0.2444
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/36s7vksh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_020426-36s7vksh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_023242-zgmnshj9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/zgmnshj9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▅▅▆▇▇▇▇▇▇▇▇█████████████▇████████████
wandb: train loss █▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▃▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train perf █▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▃▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: valid perf ▂▁▄▄▅▅▆▄▆▇▇▇▇▇█████▇████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.25083
wandb: train loss 0.19809
wandb: train perf 0.19809
wandb: valid perf -0.24624
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/n3idwdz3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_020423-n3idwdz3/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_023302-x8ry9r33
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/x8ry9r33
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▄▄▄▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇███▇▇▇▇███████████
wandb: train loss █▇▆▆▆▆▆▅▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb: train perf █▇▆▆▆▆▆▅▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb: valid perf ▁▃▄▁▄▂▃▄▄▄▅▆▆▆▆▆▅▇▆▆▇▅▆▇▆▇▇▇▇███████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.25015
wandb: train loss 0.19668
wandb: train perf 0.19668
wandb: valid perf -0.24663
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/b7cvo3xg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_020639-b7cvo3xg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_023627-v33wqzny
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/v33wqzny
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.412 MB uploaded (0.000 MB deduped)wandb: / 0.412 MB of 0.412 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁█▁█▁▆▁█▂█▁█▂█▂█▁█▁█▁█▁█▂█▁█▃█▃█▂█▄█▃█▃█
wandb:        seconds ▃█▄▅▅▆▃▄▂▁▃▂▂▂▂▃▂▂▂▂▂▂▂▃▃▂▂▃▃▂▃▃▁▂▂▂▂▂▂▂
wandb:      test perf ▁█▁█▁▆▁█▁█▁█▁█▁█▁█▁█▁█▁█▁█▁█▃█▃█▂█▄█▃█▃█
wandb:     train loss ▃▁▅▁█▁▂▁▃▁▆▁▂▁▂▁▃▁▂▁▂▁▂▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁
wandb:     train perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.82701
wandb:      test perf 1.0
wandb:     train loss 0.01016
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6r378jve
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_004054-6r378jve/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.412 MB of 0.412 MB uploaded (0.000 MB deduped)wandb: | 0.412 MB of 0.412 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▂█▂█▂▇▂█▂█▂█▁█▂█▂█▂█▁█▂█▃█▁█▃█▃█▂█▄█▃█▂█
wandb:        seconds ▅█▆▅▅▃▃▆▂▃▂▂▂▂▂▄▂▂▃▃▂▂▂▁▃▃▃▃▃▂▄▃▂▂▃▂▂▂▃▃
wandb:      test perf ▁█▂█▁▇▁█▁█▁█▁█▁█▁█▂█▁█▁█▃█▁█▃█▃█▁█▄█▃█▂█
wandb:     train loss ▄▁▅▁█▁▂▁▄▁▆▁▂▁▂▁▃▁▂▁▂▁▃▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.7418
wandb:      test perf 1.0
wandb:     train loss 0.01047
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ifsoj42o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_004054-ifsoj42o/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.412 MB of 0.412 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁█▁█▂█▁█▂█▂█▂█▂█▂█▂█▂█▂█▂█▂█▃█▃█▂█▅█▃█▂█
wandb:        seconds ▂▆▂▂▂▄▁█▄▃▄▃▃▂▂▂▃▃▂▃▃▂▂▂▃▃▂▃▂▃▃▂▃▂▃▃▂▂▂▂
wandb:      test perf ▁█▁█▁█▁█▁█▁█▂█▁█▁█▂█▁█▂█▂█▁█▃█▃█▂█▅█▃█▂█
wandb:     train loss ▃▁▄▁█▁▂▁▃▁▄▁▂▁▂▁▃▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.6853
wandb:      test perf 1.0
wandb:     train loss 0.01025
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/b1144i3s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_004054-b1144i3s/logs
wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▃▄▄▄▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████████
wandb: train loss █▇▇▆▆▆▆▅▅▅▅▅▅▄▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: train perf █▇▇▆▆▆▆▅▅▅▅▅▅▄▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: valid perf ▇▁▅▇▇▇▇▇▇█▇▇▇▇▇▇▇███████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.24575
wandb: train loss 0.20439
wandb: train perf 0.20439
wandb: valid perf -0.24267
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/zgmnshj9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_023242-zgmnshj9/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▄▄▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇██▇▇█████████████████
wandb: train loss █▇▇▇▆▆▆▆▆▆▅▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▁▂▂▁▁▁
wandb: train perf █▇▇▇▆▆▆▆▆▆▅▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▁▂▂▁▁▁
wandb: valid perf ▁▃▅▃▆▇▆▆▄▇▆▇▇▇▆▇▇▇▇█▇▇▇▇▇█▇█████▇███████
wandb: 
wandb: Run summary:
wandb:  test perf -0.24692
wandb: train loss 0.19423
wandb: train perf 0.19423
wandb: valid perf -0.24194
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xwkedcvx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_023234-xwkedcvx/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▄▄▄▆▆▆▆▇▇▇███████████████████████████
wandb: train loss █▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁
wandb: train perf █▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁
wandb: valid perf ▅▁▄▄▆▃▆▆▇▄▇▇▇███▇███▇▇██████████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.24964
wandb: train loss 0.20162
wandb: train perf 0.20162
wandb: valid perf -0.24247
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/x8ry9r33
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_023302-x8ry9r33/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: \ 0.412 MB of 0.412 MB uploaded (0.000 MB deduped)wandb: | 0.412 MB of 0.412 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁█▁█▁▇▁█▁█▁█▁█▁█▁█▁█▁█▂█▂█▂█▃█▂█▁█▄█▃█▃█
wandb:        seconds ▂▃▂▂█▄▁▇▇▃▃▃▄▃▄▄▄▄▄▃▄▃▃▄▃▄▄▃▃▆▃▃▃▃▄▃▄▄▂▁
wandb:      test perf ▁█▁█▁▇▁█▁█▁█▁█▁█▁█▁█▁█▁█▂█▂█▃█▂█▁█▄█▃█▃█
wandb:     train loss ▃▁▅▁█▁▂▁▃▁▅▁▂▁▂▁▃▁▂▁▂▁▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.33898
wandb:      test perf 1.0
wandb:     train loss 0.01077
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/0lq2z4j8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_004054-0lq2z4j8/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▅▅▅▆▆▆▇▇▇▇▇███████████████████████████
wandb: train loss █▇▇▇▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: train perf █▇▇▇▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: valid perf ▁▁▅▄▃▅▆▆▆▃▇▇▆▇▇▇▆▇███████▇██████████████
wandb: 
wandb: Run summary:
wandb:  test perf -0.24953
wandb: train loss 0.2004
wandb: train perf 0.2004
wandb: valid perf -0.24362
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/v33wqzny
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_023627-v33wqzny/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_041507-ag35lcoh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ag35lcoh
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_041507-4dgz8ecc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/4dgz8ecc
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_041507-001agnlx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/001agnlx
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_041507-cykn59a9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/cykn59a9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▄▄▅▆▆▆▇██████████████████
wandb:        seconds ▂▁▄▂▆▆▃▄▃▃▅▄▁▁▃▂▃▄▂▂▂▄▃▄▃▃▅▄▅▆▇▄█▅▆▆▄▅▆▆
wandb:      test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▄▄▅▆▆▆▇██████████████████
wandb:     train loss █▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅▅█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.69884
wandb:      test perf 1.0
wandb:     train loss 0.0099
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/cykn59a9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_041507-cykn59a9/logs
wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▄▄▅▅▅▅▆▆█████████████████
wandb:        seconds ▁▅▄▄▅▃▄▄▄▅▃▄▂▃▄▄▄▃▄▄▃▃▄▄▅▅▁▄▄▆▇█▅▄▃▆▄▅▇▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▄▄▅▅▅▅▆▆█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.6063
wandb:      test perf 1.0
wandb:     train loss 0.01061
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/4dgz8ecc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_041507-4dgz8ecc/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_042031-kx40eo7q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/kx40eo7q
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_042034-zt3vkdmg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/zt3vkdmg
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▆▆▇██████████████████
wandb:        seconds ▄▂▃▃▃▅▂▅▅▄▅▂▁▂▃▄▄▃▄▄▂▃▄▄▅▆▃▆█▆▅▄▇▄█▁▅▄▅▃
wandb:      test perf ▁▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▄▄▅▆▆▇██████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.73811
wandb:      test perf 1.0
wandb:     train loss 0.01037
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ag35lcoh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_041507-ag35lcoh/logs
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_042118-ubwkfwi0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ubwkfwi0
wandb: / 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▅▆▇███████████████████
wandb:        seconds ▄▄▄▅▄▄▃▃▄▂▂▄▃▄▃▆▄▃▃▅▅▃▄▃▃▇▅▅▇█▅▇▅█▄▁▆▇▇▂
wandb:      test perf ▁▁▁▁▁▁▂▁▂▂▂▂▃▃▃▃▄▄▅▆▇███████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.6857
wandb:      test perf 1.0
wandb:     train loss 0.0107
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/001agnlx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_041507-001agnlx/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_042124-yasth04t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/yasth04t
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▄▅▆▇█████████████████
wandb:        seconds ▃█▇▅▇▃▃▃▇▄▅▂▂▂▄▄▄▃▃▇▁▃▂▁▃▃▄▂▄▅▃▃▂▃▄▃▂▄▂▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▄▅▆▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.42373
wandb:      test perf 1.0
wandb:     train loss 0.01036
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/kx40eo7q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_042031-kx40eo7q/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_042524-xw9ihy2m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xw9ihy2m
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▅▅▆▇█████████████████
wandb:        seconds ▅█▅▇▂▂▁▁▂▂▃▂▁▄▅▂▄▂▂▃▄▁▂▃▁▃▅▁▃▃▂▂▂▂▁▁▃▄▂▁
wandb:      test perf ▁▁▁▁▂▁▁▁▁▁▁▁▃▂▂▃▃▃▄▅▅▆▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.37379
wandb:      test perf 1.0
wandb:     train loss 0.01062
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/zt3vkdmg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_042034-zt3vkdmg/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_042532-0azu5ltp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0azu5ltp
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▄▄▄▆▆▆▆▇████████████████
wandb:        seconds ▅▆▇▇▆█▆▆█▅▅▆▇▆▆▅▆▆▅▄█▇▆▇▆▆▃▃▆█▁▃▂▃▃▄▂▃▂▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▄▄▄▆▆▆▆▇████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▆█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.56749
wandb:      test perf 1.0
wandb:     train loss 0.01041
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/yasth04t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_042124-yasth04t/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: 
wandb: Run history:
wandb: best test perf ▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▅▅▆▇███████████████████
wandb:        seconds ▅▅▅▇█▄▄▃▆▃▄▅▄▆▄▄▄▄▂▅▅▄▃▄▄▇▄▄▃▅▄▄▃▃▅▂▂▄▄▁
wandb:      test perf ▁▁▂▁▁▁▁▁▁▁▁▁▁▁▂▃▃▅▅▆▇███████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅▆▆████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.55582
wandb:      test perf 1.0
wandb:     train loss 0.00927
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ubwkfwi0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_042118-ubwkfwi0/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_042716-g9c245pu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/g9c245pu
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_042720-ab102v8s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ab102v8s
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▄▅▆▇███████████████████
wandb:        seconds ▂▂▅▆▅▄▃▃▃▅▄▄▃▃▄▂▃▅▃▆▇▅▄▅▆▇█▆▃▄▄▃▇▆▄▃▄▅▁▇
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▄▅▆▇███████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.51263
wandb:      test perf 1.0
wandb:     train loss 0.01054
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xw9ihy2m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_042524-xw9ihy2m/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_043020-l97nkygw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/l97nkygw
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▅▆▆▇█████████████████
wandb:        seconds ▅▆▅▂▂▃▁▅█▇▇▁█▃▄▃▃▄▃▄▄▇▄▇▆▃▂▇▅▁▆▄▁▃▃▄▇▇▅▇
wandb:      test perf ▁▁▁▁▁▁▂▁▁▁▁▁▂▃▃▃▃▄▄▅▆▆▇█████████████████
wandb:     train loss █▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.5626
wandb:      test perf 1.0
wandb:     train loss 0.01049
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/0azu5ltp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_042532-0azu5ltp/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_043038-5jav7fyt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5jav7fyt
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▂▃▃▃▃▃▃▃▃▃▄▅▅▅▇▇█████████████████
wandb:        seconds ▁▂▁▃▃▂▁▂▃▃▁▂▁▅▆▇▆▅▄▆▄▅▄▆▅▆▆▅▅▆▆▅▆▄▆▆▆█▅▇
wandb:      test perf ▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▄▅▅▅▇▇█████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.9536
wandb:      test perf 1.0
wandb:     train loss 0.01075
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/g9c245pu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_042716-g9c245pu/logs
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_043304-pj1qb8ht
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/pj1qb8ht
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▄▄▅▅▆▆█████████████████
wandb:        seconds ▆█▆▄▇▆██▇▄▆▆▆██▆▇▅▄▁▃▃█▅▂▂▁▃▂▃▄▃▆▅▇▁▅▃▃▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▄▄▅▅▆▆█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.61857
wandb:      test perf 1.0
wandb:     train loss 0.01065
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ab102v8s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_042720-ab102v8s/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_043309-q2u5w8y4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/q2u5w8y4
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▄▄▄▅▅▆▇▇█████████████████
wandb:        seconds ▅▂▁▅▅▃▃▃▃▄▅▅▅▄▅▆▃▄▃▆▅▄▄▄▃▄▆▂▅▆▇▅▇▄▂▄█▇▃▄
wandb:      test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▄▄▄▅▅▆▇▇█████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.50522
wandb:      test perf 1.0
wandb:     train loss 0.01108
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/l97nkygw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_043020-l97nkygw/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_043531-c48lcxkj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/c48lcxkj
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▄▄▄▆▆▆▇█████████████████
wandb:        seconds ▃▅▃▇▃▄▄▅▄▆▅▇▅▄▆▄▅█▄▄█▆▇▆▁▅▄█▆▇▅▅▇▇▄▆▂▇▆▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▄▄▄▆▆▆▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.51338
wandb:      test perf 1.0
wandb:     train loss 0.01015
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/5jav7fyt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_043038-5jav7fyt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_043602-xt32yenf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xt32yenf
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▄▄▄▅▅▅▆▆▇████████████████
wandb:        seconds ▄▅█▃▂▅▄▆▆▆▅▄▅▇▂▂▂▄▃▅▄▃▅▆▄▂▂▂▃▃▄▃▆▂▄▁▄▃▁▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▄▄▄▅▅▅▆▆▇████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.54953
wandb:      test perf 1.0
wandb:     train loss 0.01056
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/q2u5w8y4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_043309-q2u5w8y4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_043843-ph99b8et
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ph99b8et
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▅▆▇▇█████████████████
wandb:        seconds ▃▄▁▆▆▆▃▆▄▂▇▃▇▁▇▃▁▅▆▂▆▄▅▆▄▅▇▃▅▅▃▅▅▆▇▇█▃▇▇
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▅▆▇▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▃██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.9053
wandb:      test perf 1.0
wandb:     train loss 0.01046
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/pj1qb8ht
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_043304-pj1qb8ht/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_043909-0o0fod8k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0o0fod8k
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▄▅▆▆▆▇██████████████████
wandb:        seconds ▄█▅▄▅▇▄█▃▇▄▄▄▃▃▁▆▂▂▃▄▆▃▄▂▁▂▅▄▁▂▄▄▄▂▄▅▂▄▇
wandb:      test perf ▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▃▄▅▆▆▆▇██████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▃██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.58079
wandb:      test perf 1.0
wandb:     train loss 0.01029
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/c48lcxkj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_043531-c48lcxkj/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_044029-0nvcjy9n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0nvcjy9n
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▅▅▆███████████████████
wandb:        seconds ▆▄▄▅▃▅█▄▃▅▂▁▄▂▄▅▄▂▁▃▃▂▃▄▄▁▃▅▆▃▃▃▅█▄▂▇▆▅▆
wandb:      test perf ▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▅▅▆███████████████████
wandb:     train loss █▅▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▄▇▇████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.5756
wandb:      test perf 1.0
wandb:     train loss 0.01017
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xt32yenf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_043602-xt32yenf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_044106-958xqhto
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/958xqhto
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▅▅▆▆▇▇█████████████████
wandb:        seconds ▃▄▁▄▂▃▄▃▄▂█▆▄▂▄▅▅▃▂▇▆▅▄▄▃▄▅▂▂▄▃▄▁▂▃▃▄▂▆▅
wandb:      test perf ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▅▅▆▆▇▇█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.60123
wandb:      test perf 1.0
wandb:     train loss 0.01035
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ph99b8et
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_043843-ph99b8et/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_044403-awlsybxr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/awlsybxr
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: - 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▄▄▅▆▇▇▇█████████████████
wandb:        seconds ▃█▄▅▅▆▄▅▂▄▅▁▂▅▅▄▅▅▄▇▇▄▄▅▇▆▇▃█▂▄▄▂▅▂▆▅█▄▆
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▄▄▅▆▇▇▇█████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.87315
wandb:      test perf 1.0
wandb:     train loss 0.01139
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/0o0fod8k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_043909-0o0fod8k/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_044518-bj40htzs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/bj40htzs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▃▃▅▅▆▆▇█████████████████
wandb:        seconds ▄▄▅▄▄█▃▄▆▅▄▃▂▃▅▃▂▂▂▂▂▃▃▃▁▃▄▄▁▄▅▅█▃▃▅▅▄▄▅
wandb:      test perf ▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▃▃▅▅▆▆▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.55192
wandb:      test perf 1.0
wandb:     train loss 0.01016
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/0nvcjy9n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_044029-0nvcjy9n/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_044533-xddnib2i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xddnib2i
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▄▅▅▅▆▆█████████████████
wandb:        seconds █▅▇▇▅▃▂▃▃▂▂▃▄▂▁▁▁▃▂▅▂▄▄▄▃▆▃▂▃▅▅▄▄▄▅▇█▅▄▆
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▃▄▅▅▅▆▆█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.60234
wandb:      test perf 1.0
wandb:     train loss 0.01044
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/958xqhto
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_044106-958xqhto/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_044621-zzngszrc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/zzngszrc
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▅▆▆▆█████████████████
wandb:        seconds ▃▃▄▂▂▂▃▃▁▂▄▁▃▂▄▃▂▂█▄▅▆▄▅▇▅▅▆▅▅▇▇▄▅▅▅▅▂▄▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▃▃▄▄▅▆▆▆█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.49666
wandb:      test perf 1.0
wandb:     train loss 0.01099
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/awlsybxr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_044403-awlsybxr/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_044926-7tah7r9t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/7tah7r9t
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▃▄▅▅▅▆▆▆█████████████████
wandb:        seconds ▅█▂▂▂▂▄▅▃▄▆▃▅▄▅▆▆▅▃▅▃▆▄▅▄▃▃▃▃▅▁▄▄▄▂▄▄▆▆▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▃▄▅▅▅▆▆▆█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.44579
wandb:      test perf 1.0
wandb:     train loss 0.01038
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xddnib2i
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_044533-xddnib2i/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_045039-bxdylhhl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/bxdylhhl
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▄▄▄▅▆▇▇▇█████████████████
wandb:        seconds ▄▅▄▃▃▃▆▃▅█▃▂▁▄▂▄▃▂▃▄▃▃▂▂▃▃▁▃▂▅▅▁▄▄▁▄▆▁▄▂
wandb:      test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▄▄▄▅▆▇▇▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.74589
wandb:      test perf 1.0
wandb:     train loss 0.01107
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/bj40htzs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_044518-bj40htzs/logs
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▄▅▅▆▇█████████████████
wandb:        seconds ▆▄▃▅▄▃▃▄▄█▄▆▆▄▃▄▄▄▃▃▂▂▂▁▃▂▄▂▂▅▅▅▃▂▄▄▆▆▄▂
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▄▅▅▆▇█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.43372
wandb:      test perf 1.0
wandb:     train loss 0.01013
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/zzngszrc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_044621-zzngszrc/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_045133-6qnjzcry
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6qnjzcry
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_045136-1pvmzg4w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1pvmzg4w
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▄▄▄▅▅▅▆▆█████████████████
wandb:        seconds ▂▄▄▃▆▂▁▅▅▄▇▆▄▆▃▂▂▆▆▄▆▆▄▄▆▃▂▃▃▂▇▅▅█▅▅▃▂▃▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▄▄▄▅▅▅▆▆█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▃▆█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.49379
wandb:      test perf 1.0
wandb:     train loss 0.01039
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/7tah7r9t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_044926-7tah7r9t/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_045453-le09ryf4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/le09ryf4
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▄▄▄▅▅▅▅▆▆████████████████
wandb:        seconds ▅▅▅█▄▆▃▁▆▅▆▇▇▄▃▆▅▇▆▄▄▆▅▄▅▅▆▄▄▄▅▃▄▂▇▅▇▂▃▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▄▅▅▅▅▆▆████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.36435
wandb:      test perf 1.0
wandb:     train loss 0.01132
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/bxdylhhl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_045039-bxdylhhl/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_045544-1tz4wjv0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1tz4wjv0
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▅▆▆▇█████████████████
wandb:        seconds ▇▅▆▇█▅▅▄▅▃▄▅█▃▇▇▃▂▂▂▃▅▄▂▃▁▄▄▇▄▂▄▁▃▃▄▃▅▄▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▃▃▄▄▅▆▆▇█████████████████
wandb:     train loss █▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▆█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.46477
wandb:      test perf 1.0
wandb:     train loss 0.01077
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/1pvmzg4w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_045136-1pvmzg4w/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_045648-f52gwhi8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/f52gwhi8
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▅▆▇▇█████████████████
wandb:        seconds ▁▄▄▆▆█▄▄▆▅▅▃▆▆▇▃▆▄▅▅▂▁▂▅▅▄▅▂▂▅▆▅▇▅▄▃▂▆▇▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▅▆▇▇█████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.87476
wandb:      test perf 1.0
wandb:     train loss 0.01021
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6qnjzcry
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_045133-6qnjzcry/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_045741-5v91jpuv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5v91jpuv
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▄▄▄▄▆▆▇▇█████████████████
wandb:        seconds ▃▂▄▃▃▂▁▁▃▂▃▂▃▃█▄▅▅▄▆▂▃▅▄▃▄▆▅▅▃▄▂▂▇▅▄▅▃▅▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▄▄▄▄▆▆▇▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.69411
wandb:      test perf 1.0
wandb:     train loss 0.01057
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/le09ryf4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_045453-le09ryf4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_050023-6j3j4urd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6j3j4urd
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▆▇▇████████████████
wandb:        seconds ▃▃▃▃▃▆▂▂▁▇▄▄▄▃▂▁▃▃▃▄▄██▇▇▆▆▃▇▆▇█▆▅▂▆█▅▅▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▄▆▇▇████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.4298
wandb:      test perf 1.0
wandb:     train loss 0.01077
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/1tz4wjv0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_045544-1tz4wjv0/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_050048-kdnk8641
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/kdnk8641
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▅▅▅▆▆█████████████████
wandb:        seconds ▄▃▂▂▂▁▂▄▄▅▄▅▄▃▃▅▇▅▅▇▃▅▆█▆▅▆▂▇▃▄▃▅▄▂▆▃▂▄▁
wandb:      test perf ▁▁▁▁▁▁▁▁▁▂▃▃▃▃▃▃▄▄▅▅▅▆▆█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.39282
wandb:      test perf 1.0
wandb:     train loss 0.01062
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/f52gwhi8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_045648-f52gwhi8/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_050204-r1x109v0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/r1x109v0
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▄▄▅▅▅▆▆█████████████████
wandb:        seconds ▃▅▇▅▄▂▄▄▆▆▃▃▁▆▅▄▃▅▆▇▁▃▅█▂▅▃▄▃▂▄▅▄▃▂▃▃▃▄▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▄▄▅▅▅▆▆█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.85863
wandb:      test perf 1.0
wandb:     train loss 0.01012
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/5v91jpuv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_045741-5v91jpuv/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_050351-705fsi0c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/705fsi0c
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.010 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.010 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▄▄▅▆███████████████████
wandb:        seconds ▄▆▁▄▃▃▅▇▃▅▆▅▃▆▆▆█▅▅▅▄▆▆▆▃▅▄▃▄▃▃▄▃▃▃▂▃▄▄▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▄▄▅▆███████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.59574
wandb:      test perf 1.0
wandb:     train loss 0.00997
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6j3j4urd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_050023-6j3j4urd/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▃▄▅▅▅▆▇████████████████
wandb:        seconds ▇▆▄▅▅▄▃▇▆▃▅▄▆▄▆▆▇▃▁▄▆▇█▅█▄▄▄▃▄▄▃▄▄▃▅▇▅▃▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▃▄▅▅▅▆▇████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.43787
wandb:      test perf 1.0
wandb:     train loss 0.00968
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/kdnk8641
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_050048-kdnk8641/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_050555-dktp81fw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/dktp81fw
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_050559-gv7gha4h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/gv7gha4h
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▃▃▅▆▆▇▇██████████████████
wandb:        seconds ▇▄▄▅█▃▆▅▃▆▆▆▄▄▄▃▁▃▃▂▃▂▂▂▂▆▃▄▄▂▄▄▄▅▃▃▄▃▃▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▅▆▆▇▇██████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.45747
wandb:      test perf 1.0
wandb:     train loss 0.00954
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/r1x109v0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_050204-r1x109v0/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_050718-c2wctj9u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/c2wctj9u
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▄▅▆▆▆▆▇████████████████
wandb:        seconds ▇█▄▅▃▂▂▁▂▂▂▄▅▃▃▁▃▃▃▃▅▅▆▃▄▂▃▁▂▂▁▁▂▆▄▃▅▂▅▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▄▅▆▆▆▆▇████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.66907
wandb:      test perf 1.0
wandb:     train loss 0.01029
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/705fsi0c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_050351-705fsi0c/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_050912-bc97z0nn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/bc97z0nn
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▄▄▄▄▅▆▆▆█████████████████
wandb:        seconds ▁▃▃▂▃▅▄▅▂▁▂▂▃▂▃▂▄▄▅▅▅▅▂▅▂▂▄▅▄▄▃▆▆▅▇▅▃█▇▆
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▄▄▄▄▅▆▆▆█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.69828
wandb:      test perf 1.0
wandb:     train loss 0.01016
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/gv7gha4h
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_050559-gv7gha4h/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_051115-tpdcc7j2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/tpdcc7j2
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▆▆▆▆▇█████████████████
wandb:        seconds ▅▂▂▂▂▂▅▅▄▂▁▃▃▇▂▆▄▇█▇▆▅▆▅███▆█▇▇▆▄▇█▆▄▄▅▇
wandb:      test perf ▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▆▆▆▆▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.83081
wandb:      test perf 1.0
wandb:     train loss 0.01085
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/dktp81fw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_050555-dktp81fw/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_051141-965uyh1g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/965uyh1g
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▄▅▆▆▆▇████████████████
wandb:        seconds ▂▃▂▆▄▃▂▁▁▆▆▄▄▂▆▇█▇▆▇▆▇█▅▆▄▄▅▆▅▃▃▄▃▆▄▄▃▆▂
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▄▅▆▆▆▇████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.48636
wandb:      test perf 1.0
wandb:     train loss 0.01072
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/c2wctj9u
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_050718-c2wctj9u/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_051250-yfcybkvj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/yfcybkvj
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▄▄▄▆▆▇██████████████████
wandb:        seconds ▄▂▂▅▁▂▂▃▅▅▃▄▇▅▃▅▄█▅▆▇▅█▃▁▅▂▃▅▃▂▄▅▄▂▂▃▂▃▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▄▄▄▆▆▇██████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.58804
wandb:      test perf 1.0
wandb:     train loss 0.01019
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/bc97z0nn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_050912-bc97z0nn/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_051452-kr49099x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/kr49099x
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▆▆▇█████████████████
wandb:        seconds ▇█▃▃▇▆▃▃▄▆▄▁▄▆▅▄▅▇▆▅▃▄▃▃▅▂▃▂▅▅▅▄▃▄▃▃▄▃▃▃
wandb:      test perf ▁▁▁▁▁▁▂▂▁▂▂▂▂▂▃▃▃▄▄▄▆▆▇█████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.47105
wandb:      test perf 1.0
wandb:     train loss 0.00969
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/tpdcc7j2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_051115-tpdcc7j2/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_051629-i1hrzi2j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/i1hrzi2j
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▄▅▆▆▆▇████████████████
wandb:        seconds ▇▆█▅▅▅▄▄▅▄▅▅▅▇▅▆▅▂▃▃▃▂▁▁▄▅▄▃▂▃▂▃▃▃▄▁▃▄▃▆
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▄▅▆▆▆▇████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▃██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.7186
wandb:      test perf 1.0
wandb:     train loss 0.00987
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/965uyh1g
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_051141-965uyh1g/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_051709-jpuqgmda
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/jpuqgmda
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▅▆▆▆▆▇██████████████████
wandb:        seconds ▅▆▃▇▃▆▇▇▅█▆▄▃▃▂▃▇▄▇▄▄▃▃▃▄▃▅▄▂▃▅▃▅▁▂▄▂▂▂▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▅▆▆▆▆▇██████████████████
wandb:     train loss █▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.46456
wandb:      test perf 1.0
wandb:     train loss 0.01029
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/yfcybkvj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_051250-yfcybkvj/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_051759-ki7qxwfs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ki7qxwfs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▄▄▄▄▅▆▆▇█████████████████
wandb:        seconds ▃▄▄▆▄▃▃▁▁▂▂▄▃▄▅▄▄▃▃▅▃▃▂▂▂▇▆▆▅▂▂▃▅█▇▃▁▆▃▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▄▄▄▄▅▆▆▇█████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.45796
wandb:      test perf 1.0
wandb:     train loss 0.01058
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/kr49099x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_051452-kr49099x/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_052003-e8d8dh1j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/e8d8dh1j
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▄▄▄▅▅▆▇▇█████████████████
wandb:        seconds ▁▂▄▂▂▅▄▄▄▃▃▄▂▆▅▄▄▄▄▇▄▄▃▅▃▃▆▃▅▃▆▅▂▇▇▇█▅▆▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▄▄▄▅▅▆▇▇█████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.54433
wandb:      test perf 1.0
wandb:     train loss 0.01053
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/i1hrzi2j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_051629-i1hrzi2j/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_052142-lra1vlex
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/lra1vlex
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▅▅▅▆▆▆█████████████████
wandb:        seconds ▃▇▄▃▂▃▄▄▄▃▃▄▃▆▆▇▆▁▃▃▅▃█▅▇▃▇▄▄▇█▇▅▁█▅▆▄▅▆
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▅▅▅▆▆▆█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▄██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.65826
wandb:      test perf 1.0
wandb:     train loss 0.0103
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/jpuqgmda
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_051709-jpuqgmda/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_052239-if5fd69f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/if5fd69f
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▄▄▅▆▆▇██████████████████
wandb:        seconds ▁▅█▄▃▃▅▄▅▅▃▃▁▃▄▅▅▄▄▅▅▆▅▅▃▅▅▄▅▄▅▄▄▇▃▄▃▂▃▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▄▄▅▆▆▇██████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.60107
wandb:      test perf 1.0
wandb:     train loss 0.01063
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ki7qxwfs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_051759-ki7qxwfs/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_052323-t2jn4324
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/t2jn4324
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▆▆▆▆█████████████████
wandb:        seconds ▃▂▄▁▄█▅▄▅▅▅▆▄▄▁▅▅▃▃▃▅▂▅▂▁▂▃▄▃▆▂▂▅▂▄▆▄▃▁▁
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▆▆▆▆█████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.45066
wandb:      test perf 1.0
wandb:     train loss 0.0105
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/e8d8dh1j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_052003-e8d8dh1j/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_052527-bpssnt9c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/bpssnt9c
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: \ 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▄▄▄▄▅▆▆▇█████████████████
wandb:        seconds ▆█▇▄▃▄▄▂▃▇▅▄▁▄▂▄▄▃▃▆▄▃▄▄▇▄▄▄█▄▄▅▃▆▃▆▄▆▃▄
wandb:      test perf ▁▁▁▁▁▁▁▂▁▁▂▂▂▃▃▄▄▄▄▅▆▆▇█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁██▇████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.51809
wandb:      test perf 1.0
wandb:     train loss 0.01074
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/lra1vlex
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_052142-lra1vlex/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_052659-xexafe4p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xexafe4p
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▄▅▅▆▆▆▇█████████████████
wandb:        seconds ▂▅▆▃▃▁▃▂▄▄▃▃▅█▃▂▆▂▃▃▂▄▄▅▃▅▃▃▃▅▄▄▄▄█▃▃▃▄▄
wandb:      test perf ▁▂▁▁▁▁▁▁▁▁▁▁▁▂▂▃▄▅▅▆▆▆▇█████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.52907
wandb:      test perf 1.0
wandb:     train loss 0.00947
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/if5fd69f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_052239-if5fd69f/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_052759-1e0o8r1u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1e0o8r1u
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▄▅▅▆█████████████████
wandb:        seconds ▃▃▄▄▃▂▃▃▁▄▄▄▃▅▇▄▆▆▆▇▆▇▇▅▆█▅▆█▇▇▅▆▄▆▆▅▇▇▆
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▄▅▅▆█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.75663
wandb:      test perf 1.0
wandb:     train loss 0.01053
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/t2jn4324
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_052323-t2jn4324/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_052913-tz825pgm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/tz825pgm
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▆▆▆▇▇██████████████████
wandb:        seconds ▂▆▄▅▅▅█▃▄▅▆▄▆▅▄▄▅▃▂▁▃▂▃▄▄▆▄▄▂▅▃▅▄▄▂▂█▆▄▂
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▆▆▆▇▇██████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.38247
wandb:      test perf 1.0
wandb:     train loss 0.01178
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/bpssnt9c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_052527-bpssnt9c/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_053038-fn7lqijb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/fn7lqijb
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▃▄▄▆▆▆▆█████████████████
wandb:        seconds ▆█▇▄▅▅▃▃▃▄▄▄▄▅▃▇▃▁▆█▆▇▃▄▇▄▅▇▄▄▄▇▄▄▃▄▅▄▂▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▃▄▄▆▆▆▆█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.44098
wandb:      test perf 1.0
wandb:     train loss 0.00991
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xexafe4p
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_052659-xexafe4p/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_053211-i2qn9774
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/i2qn9774
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▄▄▄▅▅▆▆█████████████████
wandb:        seconds ▄▅▆▅▄▅▆▇▅▁▃▅▆█▄▃▆▅▁▃▄▁▄▇▂▄▄▂▂▃▂▄▃▃▅▄▅▃▄▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▄▄▄▅▅▆▆█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▄██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.50827
wandb:      test perf 1.0
wandb:     train loss 0.00957
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/1e0o8r1u
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_052759-1e0o8r1u/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_053309-uv9w8fc2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/uv9w8fc2
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▄▆▆▆▆█████████████████
wandb:        seconds ▅▄▅▄▅▆▅▆▆▃▆▃▅▆▅▄▆▆▅▄▄▆▅▄▆▂▆▆▄▅▅▅▆█▂▂▁▄▄▆
wandb:      test perf ▁▂▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▃▄▆▆▆▆█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.86347
wandb:      test perf 1.0
wandb:     train loss 0.01059
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/tz825pgm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_052913-tz825pgm/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_053517-mqd9mqqs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/mqd9mqqs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▅▅▅▅▅▆▆█████████████████
wandb:        seconds ▃▂▄▂▂▃▂▂▂▁▃▂▁▂▂▃▂▁▂▃▂▄▅▅▂▃▄▅▃▂▂▄▁▂▄▃▅██▇
wandb:      test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▅▅▅▅▅▆▆█████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁█▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.78698
wandb:      test perf 1.0
wandb:     train loss 0.01054
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/fn7lqijb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_053038-fn7lqijb/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_053550-ff3f2y1r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ff3f2y1r
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▄▄▄▅▆▇▇█████████████████
wandb:        seconds ▂▃▂▁▃▂▃▃▅▃▃▄▃▅▄▄▄▁▅▃▄▄▁▃▂▅▅▄▄▃▄▅▄▃▅▆▆██▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▄▄▄▅▆▇▇█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.57869
wandb:      test perf 1.0
wandb:     train loss 0.01071
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/i2qn9774
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_053211-i2qn9774/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_053733-1rllwu90
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1rllwu90
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▄▄▄▅▅▆▇█████████████████
wandb:        seconds ▃▄▄▄▅▅▃▅▂▃▅▂▄▅▄▄▄▅▅▃▅▅▆▁▃▃▃▄▃▆▄▅▄█▃▄▄▄▃▂
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▄▅▅▆▇█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.45555
wandb:      test perf 1.0
wandb:     train loss 0.01003
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/uv9w8fc2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_053309-uv9w8fc2/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_053829-2bfdtxzx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/2bfdtxzx
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: - 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▅▅▆▆██████████████████
wandb:        seconds ▃█▄▄▄▄▅▄▃▃▂▆▅▄▅▅▅▅▄▄▃▃▄▂▅▄▂▄▄▃▃▄▅▂▁▃▂▂▃▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▄▄▅▅▆▆██████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.4284
wandb:      test perf 1.0
wandb:     train loss 0.00983
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/mqd9mqqs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_053517-mqd9mqqs/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_054031-x66tohz3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/x66tohz3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▆▇██████████████████
wandb:        seconds ▃▃▆▆▄▆▅▆▅▆▄▂▇▅█▅▆▃▄▅▅▆▅▅▃▄▆█▅▃▃▁▄▆▅▅▅▂▁▃
wandb:      test perf ▁▁▁▁▁▁▂▁▁▁▁▁▂▂▃▃▃▃▄▄▆▇██████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.61556
wandb:      test perf 1.0
wandb:     train loss 0.01018
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ff3f2y1r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_053550-ff3f2y1r/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_054146-j7tqy3ba
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/j7tqy3ba
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▃▄▄▅▅▆▆█████████████████
wandb:        seconds ▅▇▆▂▂▂▂▃▁▁▂▃▂▂▂▁▃▄▂▂▁▂▃▃▆▅▄▇▃█▆▄▃▃▅▆▆█▃▁
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▃▄▄▅▅▆▆█████████████████
wandb:     train loss █▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.41057
wandb:      test perf 1.0
wandb:     train loss 0.00988
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/1rllwu90
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_053733-1rllwu90/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_054246-l14caavh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/l14caavh
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▄▄▄▄▅▅▆▇█████████████████
wandb:        seconds ▁▁▂▂▂▃▄▂▁▅▃▁▄▁▂▁▃█▅▄█▆▆▅▆▂▇▅▅█▄▅▂▂▅▃▂▅▂▇
wandb:      test perf ▁▁▁▁▁▁▂▂▁▁▁▁▂▃▃▄▄▄▄▅▅▆▇█████████████████
wandb:     train loss █▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.72
wandb:      test perf 1.0
wandb:     train loss 0.01032
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/2bfdtxzx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_053829-2bfdtxzx/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_054347-q8e40qvs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/q8e40qvs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▄▄▅▇▇██████████████████
wandb:        seconds ▅▃▆▄▄▄▃▆█▅▄▄▄▃▅▄▇▂▆▃▅▁▃▇▃▃▇▄▃█▃▂▇▇▂▃▂▃▃▂
wandb:      test perf ▂▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▄▄▆▇▇██████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.41798
wandb:      test perf 1.0
wandb:     train loss 0.01048
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/x66tohz3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_054031-x66tohz3/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_054546-t595piaq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/t595piaq
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▆▆▇▇▇█████████████████
wandb:        seconds ▅▆▇▅▇▃▂▄▅▆▃▅▅█▇▄█▄▄▆█▄▆▄▄▂▃▄▂▃▁▄▄▁▃▂▃▃▂▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▆▆▇▇▇█████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.43055
wandb:      test perf 1.0
wandb:     train loss 0.01105
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/j7tqy3ba
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_054146-j7tqy3ba/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_054656-vhbo4f55
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/vhbo4f55
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▅▅▆▆▇██████████████████
wandb:        seconds ▂▂▂▅▂▁▅▄▅▆▄▃▂▃▃▃▃▁▂▄▃▃▃▃▄▄▄▄▂▇▆▄▆▄███▃▅▇
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▅▆▆▇██████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.76604
wandb:      test perf 1.0
wandb:     train loss 0.01029
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/l14caavh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_054246-l14caavh/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_054814-2t96x258
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/2t96x258
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▃▄▄▅▅▆▆█████████████████
wandb:        seconds ▅█▆▅▂▅▄▄▃▃▄▂▂▄▁▃▄▅▆▄▂▃▁▁▃▃▅▅▃▃▃▄▅▃▂▅▂▄▅▇
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▃▄▄▅▅▆▆█████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.68737
wandb:      test perf 1.0
wandb:     train loss 0.01036
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/q8e40qvs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_054347-q8e40qvs/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_054900-okgzpqc6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/okgzpqc6
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▆▆▆▆█████████████████
wandb:        seconds ▃▅▃▂▃▃▃▃▁▆▂▂▄▂▃▃▆▂▁▂▁▄▃▄▅▄▅█▃▅█▅▆▂▆▇▄▃▆▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▂▂▃▃▃▃▃▃▄▆▆▆▆█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.46444
wandb:      test perf 1.0
wandb:     train loss 0.0102
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/t595piaq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_054546-t595piaq/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_055056-thjl1gn9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/thjl1gn9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▅▅▆▆▇▇█████████████████
wandb:        seconds ▂▃▄▂▃▂▃▂▄▂▄▁▄▃▅▅▂▇▆▄▆█▅▅▂█▇▃▄▁▃▃▄▄▇▄▃▅█▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▅▅▆▆▇▇█████████████████
wandb:     train loss █▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.56275
wandb:      test perf 1.0
wandb:     train loss 0.01029
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/vhbo4f55
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_054656-vhbo4f55/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_055208-irzpcphe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/irzpcphe
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▄▅▅▆▆▇██████████████████
wandb:        seconds ▅▂▆▃▂▁▂▆▆▄█▄▄▅▇▄▅▃▄▇▄▄▇▃▆▂▄▇▄▇▇▇▄▅▄▃▆▄▆▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▄▅▅▆▆▇██████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.7451
wandb:      test perf 1.0
wandb:     train loss 0.01027
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/2t96x258
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_054814-2t96x258/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▃▃▄▅▆▆▆▇█████████████████
wandb:        seconds ▅▅▄▄▆▅▃▂█▅▄▄▃▄▄▂▄▅▆▄▃█▂▁▅▄▃▂▄▂▅▄▄▅▃▆▅▅▅▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▅▆▆▆▇█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.54754
wandb:      test perf 1.0
wandb:     train loss 0.01
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/okgzpqc6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_054900-okgzpqc6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_055420-6krpbkha
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6krpbkha
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_055421-h5c9si9i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/h5c9si9i
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▅▆▆▇█████████████████
wandb:        seconds ▃▄▅▆▃▃▇▃▂▃▄▁▃▂▂▃▅▄▂▅▅▄▃▂▃▄▇▇█▇▄▁▄▄▂▄▃▄▂▅
wandb:      test perf ▁▁▁▁▁▂▂▁▁▁▂▂▂▃▃▃▄▄▄▅▆▆▇█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▃▆█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.57906
wandb:      test perf 1.0
wandb:     train loss 0.01062
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/thjl1gn9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_055056-thjl1gn9/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_055608-1buwdg56
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1buwdg56
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▅▆▆▆▇█████████████████
wandb:        seconds ▆▃▄▄▃▄▃▄▃▇▁▄▃▆▆▇▃▃▅█▃▄▅▅█▃▂█▅▃▃▄▆▆▆▄▆▄▄▆
wandb:      test perf ▁▁▁▂▁▁▁▁▁▁▁▁▃▃▃▃▄▄▅▆▆▆▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.58172
wandb:      test perf 1.0
wandb:     train loss 0.01076
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/irzpcphe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_055208-irzpcphe/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_055722-t2vlgi8c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/t2vlgi8c
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▃▃▅▆▇██████████████████
wandb:        seconds ▃▄▄▄▃▂▄▃▆▅▄▃▂▄▃▃▅▃▃▂▁▅▂▃▅▅▃▄▄▄▅▃▄▅▅██▆█▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▃▃▅▆▇██████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.65465
wandb:      test perf 1.0
wandb:     train loss 0.01104
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/h5c9si9i
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_055421-h5c9si9i/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_055948-02wwi7n1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/02wwi7n1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▄▆▆▆▆██████████████████
wandb:        seconds ▃▅▇▅▆▇▄▅▄▄▇▁▅▇▇▄▇▇▆▂▄▆▅▇▅▆▃▆██▅▆▄▅▄▅▃▆▃▄
wandb:      test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▄▆▆▆▆██████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.71242
wandb:      test perf 1.0
wandb:     train loss 0.01018
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6krpbkha
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_055420-6krpbkha/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: \ 0.010 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.010 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▄▄▅▅▆▇█████████████████
wandb:        seconds ▃▂▃▇▄▃▁▂▅▂▆▃▄▄▆▄▃▃▃▃▄▃▃▄▂▁█▅█▃▂▅▇▆▆▅▆▃▅▃
wandb:      test perf ▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▄▄▄▆▆▇▇█████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.50222
wandb:      test perf 1.0
wandb:     train loss 0.01052
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/1buwdg56
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_055608-1buwdg56/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▃▃▄▅▅▆▆▇████████████████
wandb:        seconds █▄▃▄▃▃▄▅▃▆▃▄▄▅▂▁▃▅▃▇▄▅▆▄▃▃▁▃▅▇▄▂▃▄▅▄▅▅▃▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▃▃▄▅▅▆▆▇████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.59818
wandb:      test perf 1.0
wandb:     train loss 0.01073
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/t2vlgi8c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_055722-t2vlgi8c/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_060237-xo4g271m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xo4g271m
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▆▆▆▇█████████████████
wandb:        seconds █▇▅▃▄▂▅▄▂▅▆▃▅▃▁▃▅▃▂▄▂▄▂▅▂▃▂▂▃▄▁▂▂▁▃▂▂▂▁▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▆▆▆▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.4345
wandb:      test perf 1.0
wandb:     train loss 0.01025
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/02wwi7n1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_055948-02wwi7n1/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▄▅▆▆▆███████████████████
wandb:        seconds ▅▆▄▆▅▆▆▇▆▆█▂▅▄▃▄▂▂▂▁▁▂▂▂▂▃▃▂▃▃▂▃▃▃▃▃▃▂▂▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▄▅▆▆▆███████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.37036
wandb:      test perf 1.0
wandb:     train loss 0.01077
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xo4g271m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_060237-xo4g271m/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_060730-1emfmoft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1emfmoft
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_060730-54rito7c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/54rito7c
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_060731-6p28kqi7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6p28kqi7
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_060731-dlw9zgwa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/dlw9zgwa
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▂▄▇▇███████████████
wandb:        seconds █▃▁▂▄▄▂▄▄▆▄▄▃▃▃▃▄▄▂▂
wandb:      test perf ▁▂▄▇▆███████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.84165
wandb:      test perf 1.0
wandb:     train loss 0.00091
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/dlw9zgwa
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_060731-dlw9zgwa/logs
wandb: - 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▇███████████
wandb:        seconds █▃▃▃▃▃▄▄▃▃▃▃▃▃▃▂▂▄▁▁
wandb:      test perf ▁▁▁▁▁▁▁▁▇███████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.76236
wandb:      test perf 1.0
wandb:     train loss 0.00124
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/54rito7c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_060730-54rito7c/logs
wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_060818-yre3xlu7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/yre3xlu7
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▃▇██████████
wandb:        seconds █▇▆▁▃▄▄▃▃▄▄▄▄▅▂▄▂▂▄▁
wandb:      test perf ▁▁▁▁▁▁▁▁▃▇██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.9222
wandb:      test perf 1.0
wandb:     train loss 0.0011
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6p28kqi7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_060731-6p28kqi7/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▅████████████
wandb:        seconds █▄▃▃▃▄▄▄▃▄▃▃▅▃▃▃▃▄▁▂
wandb:      test perf ▁▁▁▁▁▁▁▅████████████
wandb:     train loss █▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.88436
wandb:      test perf 1.0
wandb:     train loss 0.00081
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/1emfmoft
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_060730-1emfmoft/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_060820-q9ujjmo5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/q9ujjmo5
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_060824-0wz6pse9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0wz6pse9
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_060824-nanavwbd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/nanavwbd
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▂▂▂▂▅████████████
wandb:        seconds █▆▃▃▃▄▅▄▃▃▃▄▃▃▃▃▄▁▁▂
wandb:      test perf ▁▁▁▂▁▁▂▅████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.6344
wandb:      test perf 1.0
wandb:     train loss 0.0011
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/yre3xlu7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_060818-yre3xlu7/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_060902-n6mqvaq8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/n6mqvaq8
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▂▃███████████
wandb:        seconds ▃▅▇▆▆▄▅▂▃▄▄▃▃▁▃▁▃▂▂█
wandb:      test perf ▁▁▁▁▁▁▁▂▃███████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.12828
wandb:      test perf 1.0
wandb:     train loss 0.00105
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/q9ujjmo5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_060820-q9ujjmo5/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:        seconds ▇▇▆▄▇▆▅█▅▄▆▆▅▇▆▆▄▇▁▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.82927
wandb:      test perf 1.0
wandb:     train loss 0.00101
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/0wz6pse9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_060824-0wz6pse9/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▂▃▅▅▅████████████
wandb:        seconds ▄▅▅▃▅▅▅▅▄▅▅▅█▆▅▃▅▆▁▃
wandb:      test perf ▁▁▁▂▃▅▄▅████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.81659
wandb:      test perf 1.0
wandb:     train loss 0.00145
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/nanavwbd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_060824-nanavwbd/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_060908-69rcdnc0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/69rcdnc0
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_060913-0ul18994
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0ul18994
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_060915-eo6gu9ab
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/eo6gu9ab
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▂▅███████████
wandb:        seconds ▃▂▄█▂▂▂▂▂▂▂▃▂▂▃▂▂▃▂▁
wandb:      test perf ▁▁▁▁▁▁▁▂▅███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.55401
wandb:      test perf 1.0
wandb:     train loss 0.00133
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/n6mqvaq8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_060902-n6mqvaq8/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_060949-ytc6myd2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ytc6myd2
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▅████████████
wandb:        seconds █▁▂▂▂▂▂▂▂▂▂▁▁▁▂▂▁▁▁▄
wandb:      test perf ▁▁▁▁▁▁▂▅████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.22375
wandb:      test perf 1.0
wandb:     train loss 0.00112
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/69rcdnc0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_060908-69rcdnc0/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_060955-41mxqg3l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/41mxqg3l
wandb: \ 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:        seconds ▄▇▄▆▅▆▇██▇▅▆▇▄▃█▄▁▂▇
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.02974
wandb:      test perf 1.0
wandb:     train loss 0.00075
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/0ul18994
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_060913-0ul18994/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▃▃▃▃▃▃▇██████████
wandb:        seconds ▅▅▅▄▃▄▅▄█▄▄▄▃▄▅▄▁▄▅▁
wandb:      test perf ▁▁▁▃▃▂▁▂▃▇██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.64322
wandb:      test perf 1.0
wandb:     train loss 0.001
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/eo6gu9ab
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_060915-eo6gu9ab/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061003-f986jbr3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/f986jbr3
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061004-phzr67z3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/phzr67z3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:        seconds ▄▃▁▁▃█▃▁▂▁▂▂▃▃▃▂▂▃▂▂
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.6837
wandb:      test perf 1.0
wandb:     train loss 0.00149
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ytc6myd2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_060949-ytc6myd2/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061035-sv8k82jb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/sv8k82jb
wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▃▃▅▇█████████████
wandb:        seconds ▁▃█▂▂▂▂▂▃▃▃▂▂▂▃▂▂▂▁▄
wandb:      test perf ▁▁▁▃▂▅▇█████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.05099
wandb:      test perf 1.0
wandb:     train loss 0.00166
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/41mxqg3l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_060955-41mxqg3l/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061044-e0ln9rie
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/e0ln9rie
wandb: \ 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▃▃████████████
wandb:        seconds ▅▆▇▇▆▅▅▅▅▆▆▃▃▄▄▁▂▃█▆
wandb:      test perf ▁▁▁▁▁▂▃▃████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.97486
wandb:      test perf 1.0
wandb:     train loss 0.00118
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/f986jbr3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061003-f986jbr3/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:        seconds █▅▆▇▆▆▆▅▆▆▇▅▃▄▂▁▃▃█▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.82964
wandb:      test perf 1.0
wandb:     train loss 0.00107
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/phzr67z3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061004-phzr67z3/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061052-ymjfni0h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ymjfni0h
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061053-88prriw8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/88prriw8
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▃█████████
wandb:        seconds ▃▆▆▄▂▂█▅▂▄▆▂▃▅▆▅█▁▂▁
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▃█████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.67205
wandb:      test perf 1.0
wandb:     train loss 0.00112
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/sv8k82jb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061035-sv8k82jb/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061123-ix0bu8rj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ix0bu8rj
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▄▅▅▅▆████████████
wandb:        seconds ▂█▂▂▃▃▃▃▃▃▄▁▁▂▁▁▃▃▂▁
wandb:      test perf ▁▁▁▄▅▄▄▆████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.75087
wandb:      test perf 1.0
wandb:     train loss 0.00095
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/e0ln9rie
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061044-e0ln9rie/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061135-sit4vdjk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/sit4vdjk
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▆██████████
wandb:        seconds ▃██▇▄▄▃▆▇▅▃▁▆▁▄▆▃▄▆▃
wandb:      test perf ▂▁▁▁▁▁▁▁▂▆██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.07228
wandb:      test perf 1.0
wandb:     train loss 0.00108
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ymjfni0h
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061052-ymjfni0h/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▃▆████████████
wandb:        seconds ▂▆▆▄▃▅▂▆▃▂▁▂█▂▅▃▂▆▃▁
wandb:      test perf ▁▁▁▁▁▂▃▆████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.96424
wandb:      test perf 1.0
wandb:     train loss 0.00122
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/88prriw8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061053-88prriw8/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061144-siypshyx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/siypshyx
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061147-mv4xtoxv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/mv4xtoxv
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▄▅▇████████████
wandb:        seconds ▃▂▂▅▆▃▂▁▂▅█▅▃▃▃▄▃▂▃▃
wandb:      test perf ▁▁▁▁▂▄▅▇████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.67478
wandb:      test perf 1.0
wandb:     train loss 0.00107
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ix0bu8rj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061123-ix0bu8rj/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061211-i92xkzs2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/i92xkzs2
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▆██████████
wandb:        seconds ▁▁▃█▅▃▁▁▁▂▂▂▂▁▂▁▄█▅▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▆██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.87339
wandb:      test perf 1.0
wandb:     train loss 0.00126
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/sit4vdjk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061135-sit4vdjk/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061223-d3ytlf25
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/d3ytlf25
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▂▄███████████
wandb:        seconds ▁▆█▅▅▄▅▅▁▃▃▆▆▂▂▂▃▅▇▆
wandb:      test perf ▁▁▁▁▁▁▁▂▄███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.96439
wandb:      test perf 1.0
wandb:     train loss 0.00129
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/siypshyx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061144-siypshyx/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:        seconds ▄▄▆▅█▄▂▁▁▆▆▄▃▁▃▅█▃▁▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.82473
wandb:      test perf 1.0
wandb:     train loss 0.00097
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/mv4xtoxv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061147-mv4xtoxv/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061231-sgqq8g3e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/sgqq8g3e
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061235-8rmb54hq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8rmb54hq
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▅█████████
wandb:        seconds ▃▂▁▃█▁▃▃▂▂▅▇▃▃▃▂▅▄▄▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▅█████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.70946
wandb:      test perf 1.0
wandb:     train loss 0.00125
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/i92xkzs2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061211-i92xkzs2/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061257-uaah9p5j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/uaah9p5j
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▃▇███████████
wandb:        seconds ▁▁▄▃▄▂▂▃▂▂▂▂▂▁▁█▂▁▃▂
wandb:      test perf ▁▁▁▁▁▁▁▃▇███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.90403
wandb:      test perf 1.0
wandb:     train loss 0.00099
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/d3ytlf25
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061223-d3ytlf25/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061312-mek28v4w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/mek28v4w
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▂▃▇██████████
wandb:        seconds ▂▁▆▇▆▅▇▄▄▃▆▅▅█▆▅▃▃▆▆
wandb:      test perf ▂▂▂▂▂▁▂▃▄▇██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.05855
wandb:      test perf 1.0
wandb:     train loss 0.0011
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/sgqq8g3e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061231-sgqq8g3e/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:        seconds ▆▅▇█▆▄▄▄▅▅▄▆▇▅▅▇▅▅▁▁
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.76621
wandb:      test perf 1.0
wandb:     train loss 0.00127
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/8rmb54hq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061235-8rmb54hq/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061322-thaqhw2p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/thaqhw2p
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061326-zk0vc8jy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/zk0vc8jy
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▃▆████████████
wandb:        seconds ▃▄▅▃▁▇█▁▂▄▂▆▄▆▇▃▃▃▆▅
wandb:      test perf ▁▁▁▁▁▂▃▆████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.8236
wandb:      test perf 1.0
wandb:     train loss 0.00145
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/uaah9p5j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061257-uaah9p5j/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061343-fotjhrpq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/fotjhrpq
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▅████████████████
wandb:        seconds ▃▄▃▅▄▇▄▆▄▄▁▄▃▁██▂▅▃▃
wandb:      test perf ▁▁▁▅██▇▇▇███████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.79083
wandb:      test perf 1.0
wandb:     train loss 0.00171
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/mek28v4w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061312-mek28v4w/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061400-x29k1hwk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/x29k1hwk
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▅▅▅██████████████
wandb:        seconds ▁▅▇▅▅▁▁▂█▁▃▆▄▄▃▂▄▇▂▄
wandb:      test perf ▂▁▁▅▄▅██████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.90547
wandb:      test perf 1.0
wandb:     train loss 0.00107
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/thaqhw2p
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061322-thaqhw2p/logs
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▆▆▆▆▆▆▆▇██████████
wandb:        seconds ▆▇▇▄▃▁▆▆▃▄█▆▃▃▇▇▂▂▄▃
wandb:      test perf ▁▁▆▁▁▁▁▁▃▇██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.83216
wandb:      test perf 1.0
wandb:     train loss 0.00142
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/zk0vc8jy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061326-zk0vc8jy/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061412-9c4xaujd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/9c4xaujd
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061414-xl43cier
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xl43cier
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▇█████████████
wandb:        seconds ▂▅▄▃▆██▁▄▅▄▃▄▄▂▂▂▂▅▄
wandb:      test perf ▃▁▁▁▁▂▇█████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.94935
wandb:      test perf 1.0
wandb:     train loss 0.0015
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/fotjhrpq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061343-fotjhrpq/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061433-aht1nwyh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/aht1nwyh
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▅███████████████
wandb:        seconds █▄▂▆▇▅▃▃▄▅▃▃▂▁▂▃▆▃▅▅
wandb:      test perf ▁▁▁▁▅█▇▇████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.87028
wandb:      test perf 1.0
wandb:     train loss 0.00118
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/x29k1hwk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061400-x29k1hwk/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061447-iddezxh5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/iddezxh5
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▅█████████████
wandb:        seconds ▁▂▃▁▅▃▅▂▅▄▃▄▄▂▇▄▅█▄▅
wandb:      test perf ▁▁▁▁▁▁▅█████████████
wandb:     train loss █▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁█████▇█████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.24277
wandb:      test perf 1.0
wandb:     train loss 0.00079
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/9c4xaujd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061412-9c4xaujd/logs
wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▂▇███████████
wandb:        seconds ▄▃▃▅▃▂▂▃▃▁▄▄▇██▅▇▆▆▄
wandb:      test perf ▁▁▁▁▁▁▁▂▇███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.96653
wandb:      test perf 1.0
wandb:     train loss 0.00112
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xl43cier
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061414-xl43cier/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061504-nbrw3x3v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/nbrw3x3v
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061506-wdnppw44
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/wdnppw44
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▂▆██████████
wandb:        seconds ▄▂▂▂▆▄▂▃▂▂▃▃▂▁▁█▆▁▃▄
wandb:      test perf ▁▁▁▁▁▁▁▁▂▆██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.87816
wandb:      test perf 1.0
wandb:     train loss 0.00134
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/aht1nwyh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061433-aht1nwyh/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061520-mqonx3w8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/mqonx3w8
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:        seconds ▃▄▅▅▁▁▂▇█▂▂▆▃▂▂▃▇▃▄▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.95825
wandb:      test perf 1.0
wandb:     train loss 0.00107
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/iddezxh5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061447-iddezxh5/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061534-db9izgz6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/db9izgz6
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▅▆▆▆▆███████████
wandb:        seconds ▄▃▃▁▃█▆▁▅▅▂▂█▄▁▅▄▃▅▆
wandb:      test perf ▁▁▁▁▅▆▃▃▅███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.04069
wandb:      test perf 1.0
wandb:     train loss 0.00112
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/nbrw3x3v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061504-nbrw3x3v/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▂▄███████████
wandb:        seconds ▅▅▂▃▇▄▄▃▂▃▁▇█▂▄▄▄▅▅▃
wandb:      test perf ▁▁▁▁▁▁▁▂▄███████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.85454
wandb:      test perf 1.0
wandb:     train loss 0.00088
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/wdnppw44
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061506-wdnppw44/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061555-inj6ti4t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/inj6ti4t
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061557-2aaen5tl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/2aaen5tl
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:        seconds ▄▃▁▂▄▄▃▃▃▄▂▂▃▂▂▁▇█▂▁
wandb:      test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.56887
wandb:      test perf 1.0
wandb:     train loss 0.00118
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/mqonx3w8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061520-mqonx3w8/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061607-a7mm7ad8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/a7mm7ad8
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁███████████
wandb:        seconds ▃▃▃▂▃▁▁▁▄█▂▂▂▂▃▃▃▂▃▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁███████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.89709
wandb:      test perf 1.0
wandb:     train loss 0.00101
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/db9izgz6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061534-db9izgz6/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061624-zii3seq8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/zii3seq8
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▄▆███████████
wandb:        seconds ▃▂▃▇▄▃▂▂▁▁▂█▆▄▂▄▅▅▅▃
wandb:      test perf ▁▁▁▁▁▁▂▄▆███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.87022
wandb:      test perf 1.0
wandb:     train loss 0.00102
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/inj6ti4t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061555-inj6ti4t/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂██████████████
wandb:        seconds ▃▄▇█▄▄▅▇▃▃▁▇█▂▄▆▆▆▇▅
wandb:      test perf ▁▁▁▁▁▂██████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.90264
wandb:      test perf 1.0
wandb:     train loss 0.00117
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/2aaen5tl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061557-2aaen5tl/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061644-l13s4ol0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/l13s4ol0
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061646-suhwi075
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/suhwi075
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▃▃██████████
wandb:        seconds ▃▃▃▁▁▄██▅▃▄▄▅▄▅▄▂▃█▆
wandb:      test perf ▁▁▁▁▁▁▁▁▃▃██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.97784
wandb:      test perf 1.0
wandb:     train loss 0.00139
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/a7mm7ad8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061607-a7mm7ad8/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061653-lgnbv5c1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/lgnbv5c1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▃▄███████████
wandb:        seconds ▄▄▄▄▃▂▁▁█▆▂▂▅▄▃▃▃▂▃▃
wandb:      test perf ▁▁▁▁▁▁▁▃▄███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.80995
wandb:      test perf 1.0
wandb:     train loss 0.00122
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/zii3seq8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061624-zii3seq8/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061713-mmxxfei0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/mmxxfei0
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▄▄▄▄▄▄▄▇███████████
wandb:        seconds ▁▂█▃▄▆▄▄▅▂▃▂▆▇▃▃▅▄▄▄
wandb:      test perf ▁▄▂▁▁▁▂▃▇███████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.89597
wandb:      test perf 1.0
wandb:     train loss 0.00105
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/l13s4ol0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061644-l13s4ol0/logs
wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▃█████████
wandb:        seconds ▄█▁▂▆▅▄▆▃▅▄▅▇▂▇▅▄▆▆▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▃█████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.75485
wandb:      test perf 1.0
wandb:     train loss 0.00131
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/suhwi075
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061646-suhwi075/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061733-32ym70do
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/32ym70do
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061735-gevmplll
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/gevmplll
wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▃████████████
wandb:        seconds ▃▃▃▄▃▁▂▃█▇▅▅▄▃▄▄▃▂▅▆
wandb:      test perf ▁▁▁▁▁▁▁▃████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.15161
wandb:      test perf 1.0
wandb:     train loss 0.00108
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/lgnbv5c1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061653-lgnbv5c1/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061743-xoy7bk8f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xoy7bk8f
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁██████████████
wandb:        seconds ▂▃▁▁▄▃▂▃▅▅▃▄▆█▅▅▅▅▄▅
wandb:      test perf ▁▁▁▁▁▁██████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.03579
wandb:      test perf 1.0
wandb:     train loss 0.00133
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/mmxxfei0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061713-mmxxfei0/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061803-xbrpxpyx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xbrpxpyx
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:        seconds ▃▆▃▃▃▄▄▄▃▄▂▂█▆▂▁▄▃▃▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.94743
wandb:      test perf 1.0
wandb:     train loss 0.00125
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/gevmplll
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061735-gevmplll/logs
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▃▃██████████
wandb:        seconds ▃▇█▄▃▄▃▄▂▁▄▅▅▂▄▅▃▄▁▃
wandb:      test perf ▁▁▁▁▁▁▁▁▃▃██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.08484
wandb:      test perf 1.0
wandb:     train loss 0.00113
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/32ym70do
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061733-32ym70do/logs
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061823-wm1er6nm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/wm1er6nm
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▄▇█████████████
wandb:        seconds ▅▆▄▅▄▂▂▇█▃▁▃▂▅▆▆▃▁▂▄
wandb:      test perf ▁▁▁▁▂▄▇█████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.85554
wandb:      test perf 1.0
wandb:     train loss 0.0011
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xoy7bk8f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061743-xoy7bk8f/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061825-xl0w6vzc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xl0w6vzc
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061829-128x16ym
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/128x16ym
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▆██████████
wandb:        seconds ▇▅▃▄▅▃▂▄▇▁▁█▃▁▅▃▃▄▃▆
wandb:      test perf ▁▁▁▁▁▁▁▁▁▆██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.97643
wandb:      test perf 1.0
wandb:     train loss 0.00124
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xbrpxpyx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061803-xbrpxpyx/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061852-ozv0vwuz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ozv0vwuz
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▂███████████
wandb:        seconds ▁▆▅▆▅▆▄▃▇▁▂▆▆▁▃▄▇▇█▅
wandb:      test perf ▁▁▁▁▁▁▁▁▂███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.95928
wandb:      test perf 1.0
wandb:     train loss 0.0012
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/wm1er6nm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061823-wm1er6nm/logs
wandb: | 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▃▇██████████
wandb:        seconds ▄▁▄▃▄▃▃▄▂▂██▂▃▂▂▁▂▂▁
wandb:      test perf ▁▁▁▁▁▁▁▁▃▇██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.71932
wandb:      test perf 1.0
wandb:     train loss 0.00131
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xl0w6vzc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061825-xl0w6vzc/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▃███████████
wandb:        seconds ▃▃▂▂▂▄▄▂▁█▅▃▃▂▁▁▂▃▁▂
wandb:      test perf ▁▁▁▁▁▁▁▁▃███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.68131
wandb:      test perf 1.0
wandb:     train loss 0.00081
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/128x16ym
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061829-128x16ym/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061911-4cp2iwd5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/4cp2iwd5
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061914-uote02bs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/uote02bs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061915-olhrk8kk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/olhrk8kk
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▂▄▄▇██████████████
wandb:        seconds ▄▄▄▃▂▃▂▁▂█▅▁▃▄▅▃▂▃▂▃
wandb:      test perf ▁▁▂▄▄▇██████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.75708
wandb:      test perf 1.0
wandb:     train loss 0.00115
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ozv0vwuz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061852-ozv0vwuz/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061939-xckvhm47
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xckvhm47
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▄▇█████████
wandb:        seconds ▃▄▃▂▂▂▂▁▂▁▁▃█▃▄▅▆▃▃▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▄▇█████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.74486
wandb:      test perf 1.0
wandb:     train loss 0.00114
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/uote02bs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061914-uote02bs/logs
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃▇█████████
wandb:        seconds ▁▁▆▅▄▆█▃▅▁▂▆█▃▃▃▄▅▆▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃▇█████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.81259
wandb:      test perf 1.0
wandb:     train loss 0.00138
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/4cp2iwd5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061911-4cp2iwd5/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:        seconds ▄▄▂▂▂▄▂▁▂▂█▃▂▃▅▅▃▃▂▁
wandb:      test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.68479
wandb:      test perf 1.0
wandb:     train loss 0.00122
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/olhrk8kk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061915-olhrk8kk/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_061957-r7s1dc8x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/r7s1dc8x
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062001-85pb1iof
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/85pb1iof
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062001-8y7nvhx3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8y7nvhx3
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:        seconds ▄▅▅▃▃▂▁▂▄▇█▂▄▆▅▄▆▄▃▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.84241
wandb:      test perf 1.0
wandb:     train loss 0.00127
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xckvhm47
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061939-xckvhm47/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062028-9hj9sl5j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/9hj9sl5j
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▄▅▆████████████
wandb:        seconds ▁▁▁▅▁▂▁▂▁▂▃▃▃█▃▃▄▃▂▃
wandb:      test perf ▁▁▁▁▁▄▅▆████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.89511
wandb:      test perf 1.0
wandb:     train loss 0.00146
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/r7s1dc8x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_061957-r7s1dc8x/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:        seconds ▅▃▃▆▂▃▅▂▁▁▂█▄▂▄▂▄▃▂▁
wandb:      test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.7588
wandb:      test perf 1.0
wandb:     train loss 0.00106
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/8y7nvhx3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062001-8y7nvhx3/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062046-tlan0voo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/tlan0voo
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▆██████████
wandb:        seconds ▅▆▅▇▆█▇▅▄▄▁▇▄▅▄▄▄▆▅▁
wandb:      test perf ▁▁▁▁▁▁▁▁▁▆██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.72193
wandb:      test perf 1.0
wandb:     train loss 0.00138
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/85pb1iof
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062001-85pb1iof/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062048-kraav2ly
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/kraav2ly
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062052-c17zmyhg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/c17zmyhg
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▂▅██████████
wandb:        seconds ▃▂▄▂▁▂▂▁▂▆█▄▄▄▄▂▂▄▄▄
wandb:      test perf ▁▁▁▁▁▁▁▁▂▅██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.89482
wandb:      test perf 1.0
wandb:     train loss 0.00111
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/9hj9sl5j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062028-9hj9sl5j/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062118-97bmvtz2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/97bmvtz2
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▄▇▇▇▇███████████
wandb:        seconds ▆▁▂▃▄▄▃▅▄▃▃▂▃▂▄█▄▂▄▅
wandb:      test perf ▁▁▁▁▄▇▇▅▆███████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.93885
wandb:      test perf 1.0
wandb:     train loss 0.00096
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/tlan0voo
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062046-tlan0voo/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062133-q6hpbvqx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/q6hpbvqx
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:        seconds ▄▂▂▂▃▃▁▂▂▂▃█▃▄▂▁▃▁▃▇
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.10336
wandb:      test perf 1.0
wandb:     train loss 0.00149
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/c17zmyhg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062052-c17zmyhg/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▆█████████
wandb:        seconds ▁▄▂▃▄▅▅▄▃▂▃▇▅▃▄▆▄▃█▆
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▆█████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.26682
wandb:      test perf 1.0
wandb:     train loss 0.00071
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/kraav2ly
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062048-kraav2ly/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062140-5rr15xu1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5rr15xu1
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062142-5uvapzpb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5uvapzpb
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▃██████████████
wandb:        seconds ▄▄█▃▄█▁▂▂█▆▃▄▄▆▄▆▄▅▃
wandb:      test perf ▁▁▁▁▁▃██▇███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.77768
wandb:      test perf 1.0
wandb:     train loss 0.00126
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/97bmvtz2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062118-97bmvtz2/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062209-o0lz0m0t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/o0lz0m0t
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▂▆███████████
wandb:        seconds ▂▃▇▃▁▃▂▃▃▃▂▂▁▂▁▂▄█▅▂
wandb:      test perf ▁▁▁▁▁▁▁▂▆███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.69412
wandb:      test perf 1.0
wandb:     train loss 0.00106
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/q6hpbvqx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062133-q6hpbvqx/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062220-3penhmec
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/3penhmec
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▃███████████
wandb:        seconds ▅▇▅▅█▅▃▄▂▂▄▄▅▃▃▃▁▃▇▂
wandb:      test perf ▁▁▁▁▁▁▁▁▃███████████
wandb:     train loss █▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.73214
wandb:      test perf 1.0
wandb:     train loss 0.00142
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/5rr15xu1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062140-5rr15xu1/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▂▃▃▃▃▃▇██████████
wandb:        seconds ▄▃▃▃▃▃▃▃▃▂▇█▂▃▂▂▄▄▁▁
wandb:      test perf ▁▁▁▂▃▃▂▂▃▇██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.70869
wandb:      test perf 1.0
wandb:     train loss 0.00101
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/5uvapzpb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062142-5uvapzpb/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062230-b4ifhjcr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/b4ifhjcr
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062231-9b4sj565
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/9b4sj565
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▃▆▇██████████████
wandb:        seconds ▁▂▂▄▃▁▁▁█▅▂▃▂▃▂▃▂▃▃▃
wandb:      test perf ▁▁▁▃▆▇█▇████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.95665
wandb:      test perf 1.0
wandb:     train loss 0.00108
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/o0lz0m0t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062209-o0lz0m0t/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062259-gu67uf78
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/gu67uf78
wandb: \ 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▂██████████
wandb:        seconds ▃▂▇█▃▃▄▄▂▃▃▂▂▃▄▂▁▂▅▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▂██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.09391
wandb:      test perf 1.0
wandb:     train loss 0.00096
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/3penhmec
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062220-3penhmec/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▃████████████
wandb:        seconds ▂▇▄▄▄▅▅▃▅▁▃▄█▃▁▂▂▃▄▄
wandb:      test perf ▁▁▁▁▁▁▁▃████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.88779
wandb:      test perf 1.0
wandb:     train loss 0.00124
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/b4ifhjcr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062230-b4ifhjcr/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▅█████████████
wandb:        seconds ▆▆▅▄▇▄▄▆▄▁▂██▂▁▃▂▅▄▁
wandb:      test perf ▁▁▁▁▁▁▅█▇███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.73355
wandb:      test perf 1.0
wandb:     train loss 0.00146
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/9b4sj565
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062231-9b4sj565/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062318-k9657z6l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/k9657z6l
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062319-5ee95h8g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5ee95h8g
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▄▄▄▄▄▄▄▄▄██████████
wandb:        seconds ▃▄▄▄▅▃▂▃▆█▂▁▂▃▄▅▇▆▅▇
wandb:      test perf ▁▄▁▁▁▁▁▁▃▃██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.86212
wandb:      test perf 1.0
wandb:     train loss 0.0014
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/gu67uf78
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062259-gu67uf78/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062349-yxbievwr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/yxbievwr
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062349-rssax98a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/rssax98a
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062349-loyu8t58
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/loyu8t58
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062349-28niz0jf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/28niz0jf
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▆█████████████
wandb:        seconds ▁▂▁▂▃▃▃▂▂▂▂▂▂▂▂▁▂▅█▇
wandb:      test perf ▁▁▁▁▁▁▆█████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.27286
wandb:      test perf 1.0
wandb:     train loss 0.00132
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/k9657z6l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062318-k9657z6l/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▇███████████
wandb:        seconds ▂▂▃▂▁▂▃▃▂▂▂▂▃▃▂▂▃▅█▅
wandb:      test perf ▁▁▁▁▁▁▁▁▇███████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.11869
wandb:      test perf 1.0
wandb:     train loss 0.00117
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/5ee95h8g
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062319-5ee95h8g/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: / 0.008 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▃▃▃▃▃▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇█
wandb: train loss ██▇█▇▇▆▆▇▅▆▅▅▅▅▅▅▄▄▄▃▃▃▄▂▃▃▁▂▂▁▁▁▁▁
wandb: train perf ▁▂▂▁▁▂▃▃▂▃▃▃▄▂▄▄▄▅▄▆▇▅▆▅▇▅▆█▆▇██▇██
wandb: valid perf ▁▂▃▃▃▃▂▃▃▃▄▄▄▅▄▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.99932
wandb: train perf 0.93333
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/28niz0jf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062349-28niz0jf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: 
wandb: Run history:
wandb:  test perf ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb: train loss █▇█▇▇▆▆▇▅▆▄▆▆▅▆▅▄▅▄▅▃▄▃▃▄▃▃▄▃▂▃▂▂▂▂▁▁▁▁▁
wandb: train perf ▁▁▁▂▂▃▃▂▄▃▆▄▃▄▄▅▆▅▅▅▆▆▇▇▅▆▅▆▇█▇▇██▇▇███▇
wandb: valid perf ▂▃▂▁▁▁▁▂▂▂▃▃▃▃▂▂▃▃▄▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.80226
wandb: train perf 0.86667
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/rssax98a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062349-rssax98a/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062457-15q048wd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/15q048wd
wandb: - Waiting for wandb.init()...wandb: Waiting for W&B process to finish... (success).
wandb: \ Waiting for wandb.init()...wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062501-167ueprs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/167ueprs
wandb: | 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▂▂▂▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█
wandb: train loss █▇█▇▇▇▆▆▆▅▆▆▅▄▅▄▆▅▄▅▄▄▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▁▁▂
wandb: train perf ▁▂▁▂▂▂▃▃▃▅▂▃▃▅▃▅▃▄▅▄▅▆▆▇▆█▆▆████▇█▇▇███▇
wandb: valid perf ▂▁▂▃▃▃▃▂▂▂▃▃▃▂▂▂▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 1.0323
wandb: train perf 0.86667
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/yxbievwr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062349-yxbievwr/logs
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▂▂▂▃▃▃▃▃▃▃▃▃▃▃▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇██████
wandb: train loss ███▇▇█▇▅▇▇▅▆▆▆▅▅▄▅▅▄▃▄▃▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb: train perf ▁▁▁▂▂▁▂▇▂▃▅▂▃▃▅▅▆▅▅▆▇▅█▆█▇▆▆▇▇▇▇█▇▇█████
wandb: valid perf ▁▁▂▂▂▃▃▃▂▂▃▃▃▃▃▃▄▅▅▅▆▆▆▅▅▆▆▇▇▇▇▇▇▇██████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.61532
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/loyu8t58
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062349-loyu8t58/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062509-c3rbvgdc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/c3rbvgdc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062513-rgg22bwr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/rgg22bwr
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.013 MB of 0.020 MB uploaded (0.000 MB deduped)wandb: / 0.013 MB of 0.020 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▇▇▇▇▇▇▇▇▇▇▇█
wandb: train loss █▇█▇▇▆▇▇▇▆▆▆▅▅▆▅▅▄▄▄▄▃▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb: train perf ▁▂▁▁▂▄▂▁▃▄▃▃▅▅▃▄▄▇▅▆▄▆▅▅▇▆▆▅▆▆▇█▇▆▇▇▇███
wandb: valid perf ▂▁▁▂▃▃▃▂▄▄▄▄▄▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.8384
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/15q048wd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062457-15q048wd/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062613-261i6nmb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/261i6nmb
wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▅▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb: train loss ██▇█▇▇▆█▇▇▅▆▆▆▆▅▅▅▅▄▅▄▄▄▃▃▄▄▂▃▂▂▂▃▁▁▁
wandb: train perf ▁▁▃▁▂▃▃▂▄▃▆▂▄▃▄▆▄▄▄▆▅▆▆▆▇▇▅▅▇▆█▇▇▇███
wandb: valid perf ▁▁▁▁▂▂▂▂▁▂▁▂▃▃▃▃▄▄▅▅▅▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.82877
wandb: train perf 0.93333
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/c3rbvgdc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062509-c3rbvgdc/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062618-eosrqop9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/eosrqop9
wandb: 
wandb: Run history:
wandb:  test perf ▁▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▅▅▆▇▇▇▇▇▇▇▇▇▇███████
wandb: train loss ██▇▆▇▆▇▆█▄█▇▆▅▅▆▅▆▆▆▃▄▄▄▅▄▃▃▃▂▃▂▃▂▂▁▁▁▁▁
wandb: train perf ▁▁▃▄▂▄▃▅▁▇▂▂▄▅▆▂▃▃▃▃▇▆▅▆▅▆▇█▇█▇█▇█▇█████
wandb: valid perf ▁▂▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▅▅▆▇▇▇▇▇▇▇▇▇▇███████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.65159
wandb: train perf 0.93333
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/167ueprs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062501-167ueprs/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062629-p8bxrmd2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/p8bxrmd2
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▂▂▂▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb: train loss ▇▇██▇▆▆▆▅▇▅▆▄▅▄▅▄▄▄▄▄▃▃▃▃▃▃▂▂▃▂▂▂▁▂▁▁▁▁▁
wandb: train perf ▂▂▂▁▂▄▄▃▆▂▅▄▆▄▇▅▆▅▇▇▆▇▆▇▇▇▇▇▇▆▇███▇█████
wandb: valid perf ▁▁▂▂▂▆▆▇▇▇▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.41855
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/rgg22bwr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062513-rgg22bwr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062646-9lbus5r9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/9lbus5r9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.020 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.020 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▂▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb: train loss ██▇▆▇▇▆▇▇▆▇▆▅▆▄▄▅▅▄▄▃▃▄▃▄▄▃▃▂▃▂▃▂▂▂▁▂▁▁▁
wandb: train perf ▁▁▁▄▂▃▄▁▃▃▃▄▅▃█▆▆▄▇▆▇▇▆▇▆▆▆▆▇▇▇▆▇▇██████
wandb: valid perf ▁▂▂▃▄▄▅▅▅▆▅▅▅▆▇▇▇▇▇▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.52378
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/261i6nmb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062613-261i6nmb/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: 
wandb: Run history:
wandb:  test perf ▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇█
wandb: train loss ██▇▆▆▆▆▆▇▅▅▆▆▆▅▅▆▄▄▄▄▃▃▂▄▃▄▂▃▂▂▂▂▂▁▂▂▁▁▁
wandb: train perf ▁▂▁▅▃▃▅▄▁▅▆▃▃▄▅▅▄▅▆▅▅▆▆█▅▆▅▆▆▇█▇█▇█▇▇▇▇▇
wandb: valid perf ▂▁▂▂▂▂▂▃▃▃▃▃▄▃▃▃▃▃▃▃▃▄▄▄▄▅▅▆▆▆▆▆▆▆▆▆▇███
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.98225
wandb: train perf 0.73333
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/eosrqop9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062618-eosrqop9/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062734-b7lf62un
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/b7lf62un
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062738-4i2jqyn3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/4i2jqyn3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█
wandb: train loss █▇▇█▇▆█▆▇▇▇▅▇▆▅▄▅▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁
wandb: train perf ▂▁▂▂▂▃▂▃▂▁▃▆▃▅▅▆▆▇█▇▆▆▇▇▇▅▆▇▇▇▇▆▇▇████
wandb: valid perf ▂▁▂▂▂▂▃▃▃▃▃▄▄▅▅▄▅▆▆▅▅▅▆▆▆▆▆▆▇▆▆▆▆▆▇▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.68851
wandb: train perf 0.93333
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/9lbus5r9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062646-9lbus5r9/logs
wandb: \ 0.008 MB of 0.020 MB uploaded (0.000 MB deduped)wandb: - Waiting for wandb.init()...wandb: | 0.008 MB of 0.020 MB uploaded (0.000 MB deduped)wandb: \ Waiting for wandb.init()...wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▁▁▁▂▂▃▃▃▃▃▃▄▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█
wandb: train loss █▇▆█▅█▇▆▆▆▅▆▅▅▅▅▅▄▄▄▄▄▃▃▃▂▃▃▂▂▃▂▂▂▂▁▂▂▁▁
wandb: train perf ▁▁▂▁▄▁▁▃▃▁▅▅▃▄▅▄▄▆▄▅▅▅▇▅▆▇▅▇▆▆▆██▇▇█▇▇██
wandb: valid perf ▂▂▁▁▂▁▁▃▃▄▄▄▄▄▄▅▆▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.80232
wandb: train perf 0.93333
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/p8bxrmd2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062629-p8bxrmd2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062750-lbnej52e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/lbnej52e
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_062752-kfo3ylzn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_reproduce
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/kfo3ylzn
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▃▃▃▃▃▃▃▃▃▃▃▄▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████
wandb: train loss █████▇▇▇▇▆▆▅▄▆▅▆▄▅▄▅▄▃▄▃▄▃▂▃▃▂▃▂▂▂▁▁▁▁
wandb: train perf ▁▁▂▁▁▃▂▃▃▃▄▄▆▃▅▂▆▅▆▅▆▇▅▆▅▆▇▇▆█▇▆▇██▇██
wandb: valid perf ▁▂▃▃▂▂▂▂▂▂▃▃▃▄▆▇▇▇▇▇▇▇▇▇▆▆▇▇▇█████████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.78856
wandb: train perf 0.93333
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/b7lf62un
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062734-b7lf62un/logs
wandb: 
wandb: Run history:
wandb:  test perf ▁▂▂▃▃▃▃▃▃▃▃▃▃▃▄▅▅▅▅▅▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██
wandb: train loss █▇▆▆██▇▇▄▅▇▇▇▇▇▅▆▇▆▅▆▅▅▅▄▄▄▃▃▂▄▃▂▃▃▂▁▂▂▁
wandb: train perf ▁▂▄▄▂▂▃▂▆▃▃▂▁▂▃▅▃▂▃▃▃▃▂▃▅▆▅▅▇█▆▆▆▇▆█▇▆▇▇
wandb: valid perf ▁▂▂▃▃▂▂▂▂▂▂▂▃▃▄▅▅▅▅▅▅▇▇▇▇▇▇▆▆▆▆▆▆▆▆▇▇▇██
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 1.04754
wandb: train perf 0.86667
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/4i2jqyn3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062738-4i2jqyn3/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.019 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▁▁▂▂▂▃▃▃▄▅▅▅▅▅▅▅▅▅▅▆▆▆▇▇██████
wandb: train loss █████▇▇▇▇▇▆▇▆▅▄▆▆▆▄▃▃▂▄▅▄▃▃▄▃▄▂▃▂▁
wandb: train perf ▂▁▁▂▁▂▂▂▂▂▄▃▂▅▇▄▄▂▆█▇█▅▄▅▇▇▅▇▆█▅▆█
wandb: valid perf ▁▁▁▁▁▁▂▂▂▃▃▃▄▅▅▅▅▅▅▅▅▅▅▆▆▆▇▇██████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.80875
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/kfo3ylzn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062752-kfo3ylzn/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▂▂▂▃▃▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█
wandb: train loss █▇█▇█▅▇▇▇▆▇▅▆▆▅▄▅▄▅▄▄▅▄▃▃▃▃▃▃▂▃▃▂▂▃▂▃▂▂▁
wandb: train perf ▂▂▁▃▁█▂▃▃▅▃▅▃▄▅▆▅▅▅▆▅▃▆▆▆▅█▆▆█▇███▇▆▇███
wandb: valid perf ▂▁▁▂▂▃▃▄▄▃▃▄▄▄▄▄▅▅▅▅▆▇▇▇▇▇▇██▇▇▇▇▇▇▇████
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.62344
wandb: train perf 0.93333
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_reproduce at: https://wandb.ai/eddy26/graph-MLPMixer/runs/lbnej52e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_062750-lbnej52e/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_083044-9h2c2co1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/9h2c2co1
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_083044-prza8aop
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/prza8aop
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_083044-9t67v9a4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/9t67v9a4
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_083045-78l4zyt4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/78l4zyt4
wandb: Waiting for W&B process to finish... (failed 255). Press Control-C to abort syncing.
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 255, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 13, in train
    for data in train_loader:
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1077, in __init__
    w.start()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/popen_fork.py", line 70, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/util.py", line 357, in _exit_function
    p.join()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/process.py", line 147, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 255, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 13, in train
    for data in train_loader:
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1077, in __init__
    w.start()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/popen_fork.py", line 70, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/util.py", line 357, in _exit_function
    p.join()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/process.py", line 147, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 62, in <module>
    run_k_fold(cfg, create_dataset, create_model, train, test, k=5)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 255, in run_k_fold
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/csl.py", line 13, in train
    for data in train_loader:
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1359, in _next_data
    idx, data = self._get_data()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1325, in _get_data
    success, data = self._try_get_data()
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1163, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/queues.py", line 107, in get
    if not self._poll(timeout):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt
wandb: While tearing down the service manager. The following error has occurred: DataLoader worker (pid 826986) is killed by signal: Terminated. 
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▆▇▇██████████████
wandb:        seconds ▄▃▂▃▂▃▄▃▄▂▄▂▂▁▂▂▃▄▄▄▄▁▁▂▃▅▃▂▄▅▃▄▅▃▂▃▅▄██
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▄▄▄▄▆▇▇██████████████
wandb:     train loss █▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.72307
wandb:      test perf 1.0
wandb:     train loss 0.01393
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/78l4zyt4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_083045-78l4zyt4/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_083651-uyd5pwn9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/uyd5pwn9
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_083652-n8etgpci
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/n8etgpci
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_083652-y1rlgef4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/y1rlgef4
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_083652-5b444fvb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5b444fvb
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_083929-70yi9jlm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/70yi9jlm
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_083929-7fekg37r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/7fekg37r
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_083929-srnypbmd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/srnypbmd
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_083929-pxrpn04c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/pxrpn04c
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▂▂▂▂▂▂▂▂▃▄▅▅▅▆▆▆▇██████████████████
wandb:        seconds █▆▅▄▇▇▅▅▄▂▆▄▂▁▃▂▃▄▄▃▄▃▃▃▄▂▃▃▂▂▃▃▄▃▄▄▃▂▅▃
wandb:      test perf ▁▁▁▁▂▁▁▁▁▁▁▁▁▃▄▅▅▅▆▆▆▇██████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.36994
wandb:      test perf 1.0
wandb:     train loss 0.01041
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/7fekg37r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_083929-7fekg37r/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_084416-p9uyxhj3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/p9uyxhj3
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▄▄▅▆▆▆▆▇▇█████████████████
wandb:        seconds ▇▆▆▅▆▆▅▅▄▃▅▃▂▃▃▂▁▂▄▂▂▂▂▃▁▁▃▃▃▂▃▄▅▅▃▄█▇▃▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▄▄▅▆▆▆▆▇▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.39664
wandb:      test perf 1.0
wandb:     train loss 0.01119
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/70yi9jlm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_083929-70yi9jlm/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_084426-1jfma0ug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1jfma0ug
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▅▅▆████████████████████
wandb:        seconds ▁▃▃▆▄▄▆▄▄▄▃▅▃▅▃▄▄▄▅▄▃▅▄▃▅▃▅▅█▆▆▅▃▄▆▆▅▆█▆
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▅▅▆████████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.86646
wandb:      test perf 1.0
wandb:     train loss 0.01055
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/srnypbmd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_083929-srnypbmd/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_084531-jwndfh7r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/jwndfh7r
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▆▆▆▆▇████████████████
wandb:        seconds ▁▇▆▆▅▇▅▅▇▅▅▃▇▅▄▇▄▂▇▅▄▆▅▃▅▅▄▅█▇▃▃▅█▄█▆█▄▅
wandb:      test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▆▆▆▆▇████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅▆█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.82022
wandb:      test perf 1.0
wandb:     train loss 0.01016
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/pxrpn04c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_083929-pxrpn04c/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_084542-ka4l9yiy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ka4l9yiy
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▄▄▆▆▇███████████████████
wandb:        seconds ▅▇▆█▃▄▄▂▆▁▁▄▃▇▄▅▃▄▅▂▂▃▆▂▁▃▅▄▄▅▃▄▃▅▃▃▃▄▅▅
wandb:      test perf ▁▁▁▁▁▁▂▁▁▁▂▂▂▂▃▃▄▄▆▆▇███████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.48839
wandb:      test perf 1.0
wandb:     train loss 0.00986
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/p9uyxhj3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_084416-p9uyxhj3/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_084918-buws335k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/buws335k
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▄▅▆▆▇█████████████████
wandb:        seconds ▁▂▁▃▃▃▂▄▁▂▆▄▆▄▆▆▆▇▆▇▆▆▇█▅▅▆▅▄▆▄▄▆▆▅█▇▇█▇
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▄▅▆▆▇█████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.92027
wandb:      test perf 1.0
wandb:     train loss 0.01045
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/1jfma0ug
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_084426-1jfma0ug/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_085024-yh8je777
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/yh8je777
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▅▆▆▆▇▇█████████████████
wandb:        seconds ▃▃▆▃▄▅▂▇▅▃█▅▆▁▇▃▃▆▂▁▄▅▄▃▇▂▁█▂▄▆▃▄▃▆▂▂▅▂▃
wandb:      test perf ▁▁▁▁▁▁▂▁▁▁▁▁▃▃▃▃▄▅▆▆▆▇▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.62594
wandb:      test perf 1.0
wandb:     train loss 0.01084
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/jwndfh7r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_084531-jwndfh7r/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_085120-ryv3pfd1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ryv3pfd1
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▅▅▅▆▆█████████████████
wandb:        seconds █▃▇▇▃▅▂█▄▇▃▇▁▆▄▁▅▄▇▆▆▃▆▃▅▄▄▆▄▆▄▂▅▇▄▅▅▃▄▄
wandb:      test perf ▁▁▁▁▁▁▂▂▁▁▂▂▂▃▃▃▃▄▅▅▅▆▆█████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.70789
wandb:      test perf 1.0
wandb:     train loss 0.01074
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ka4l9yiy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_084542-ka4l9yiy/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_085143-tip174jv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/tip174jv
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▄▄▄▆▆▆▇█████████████████
wandb:        seconds █▆▄▄▂▆▂▁▁▇▃▄▁▃▅▅▅▂▃▃▄▇▄▅▇▅▅▆▄▃▄▃▆▂▅▂▄▃▄▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▄▄▆▆▆▇█████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.37605
wandb:      test perf 1.0
wandb:     train loss 0.01018
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/buws335k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_084918-buws335k/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_085404-t8xfzf09
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/t8xfzf09
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▄▄▅▅▅▆▇▇████████████████
wandb:        seconds ▅▇▅▆▆▂▅▆▃▂▁▅▅▅▆▆▅▅█▅▅▃▅▃▃▆▄▅▇▄▇▅▇▆▂▅▆█▅▇
wandb:      test perf ▁▁▁▁▁▁▁▂▂▁▁▂▂▂▃▃▄▄▅▅▅▆▇▇████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.89341
wandb:      test perf 1.0
wandb:     train loss 0.01018
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/yh8je777
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_085024-yh8je777/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_085632-xt838zb7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xt838zb7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▃▃▃▃▃▃▃▄▄▅▆▇▇▇██████████████████
wandb:        seconds ▇▇▄▆▄▆█▄▅▆▅▁█▂▆▄▇▄▄▄▄▁▇▆▇▅▅▄▂▃▇█▆▁▅▄▄▆▇█
wandb:      test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▄▄▅▆▇▇▇██████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇█▇████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.79183
wandb:      test perf 1.0
wandb:     train loss 0.01011
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ryv3pfd1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_085120-ryv3pfd1/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_085705-kn62zktv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/kn62zktv
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▄▆▆▆▇██████████████████
wandb:        seconds ▇▆▅▅▄▄▄▅▁▅▅▅▅▄▅▃█▆▆▁▄▅▂▅▄▄▃▃▅▃▆█▃▆▄▄▄▄▄▃
wandb:      test perf ▁▁▂▁▁▁▁▁▁▁▁▁▁▁▃▃▃▄▆▆▆▇██████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.63048
wandb:      test perf 1.0
wandb:     train loss 0.01021
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/tip174jv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_085143-tip174jv/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_085741-a25717eu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/a25717eu
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▅▅▅▆▇█████████████████
wandb:        seconds ▄▃▃▃▃▄▂▃▃▃▄▂▂▃▃▅▆▅▄▄▃▄▅▂▅▂▃▅▅▁▇▃▃▃▆█▄▂▂▂
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▅▅▅▆▇█████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.28513
wandb:      test perf 1.0
wandb:     train loss 0.01028
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/t8xfzf09
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_085404-t8xfzf09/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_085847-35syuzg4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/35syuzg4
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▃▄▄▄▄▄▅▅▆▆█████████████████
wandb:        seconds ▅▆█▄▅▆▄▂▂▂▃▁▁▂▅▂▄▁▂▃▄▃▅▃▂▁▃▆▂▁▄▃▄▃▂▃▄▅▄▄
wandb:      test perf ▁▁▁▁▁▁▂▁▁▁▂▂▂▃▄▄▄▄▄▅▅▆▆█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.53915
wandb:      test perf 1.0
wandb:     train loss 0.01015
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/kn62zktv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_085705-kn62zktv/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_090222-d1ta9yzj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/d1ta9yzj
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▅▅▅▆▇▇█████████████████
wandb:        seconds ▆▃▃▂▅▁▃▁▄▅▅▅▃▃▁▅█▅▅▅▅▆▄▅▅▄▁▅▅▃▃▃▆▂▃▅▃▅▄▄
wandb:      test perf ▁▁▁▁▁▁▂▂▁▁▁▁▃▃▃▃▃▅▄▅▆▇▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.80978
wandb:      test perf 1.0
wandb:     train loss 0.01113
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xt838zb7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_085632-xt838zb7/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_090243-wu8618q5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/wu8618q5
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.010 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.010 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▄▄▅▅▅▆▇████████████████
wandb:        seconds ▂▄▅▄▂▃▄▃▂▅▅▃▃▄▂▃▃▂▃▂▁▆▂▂▄▄▆▆▇▇▅█▅▅▃▆▅██▆
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▄▄▅▅▅▆▇████████████████
wandb:     train loss █▅▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.48411
wandb:      test perf 1.0
wandb:     train loss 0.01082
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/35syuzg4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_085847-35syuzg4/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_090339-q9ubp1uv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/q9ubp1uv
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▄▄▄▅▆▆▇█████████████████
wandb:        seconds ▄▃▆▇▅▅▁▂▆▄▅▇▅▃▆▆▅▄▂▇▆▄▆▆▇▆▇▄▅▇▃▅▆█▇▅▇▄▅▁
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▄▄▄▅▆▆▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.58682
wandb:      test perf 1.0
wandb:     train loss 0.01045
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/a25717eu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_085741-a25717eu/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_090346-wmdzmuul
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/wmdzmuul
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▄▄▅▆▆▆▇█████████████████
wandb:        seconds ▇▃▂▇▂▃▃▆▃▂▃▅▅▃▄▄▁▆▅▄▅▂▄▅▅▃▆▅▅▆▃█▃▅█▅▄▆▄▆
wandb:      test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▄▄▅▆▆▆▇█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.66465
wandb:      test perf 1.0
wandb:     train loss 0.01049
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/d1ta9yzj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_090222-d1ta9yzj/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_090754-cduhkx41
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/cduhkx41
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▄▅▆▆▆▆█████████████████
wandb:        seconds ▆▇██▅▄▅▅▆▆▅▆▆▄▂▁▁▁▁▁▃▂▂▂▁▃▂▄▃▂▃▂▄▅▃▂▃▁▁▂
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▄▅▆▆▆▆█████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇▇▇████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.50741
wandb:      test perf 1.0
wandb:     train loss 0.01086
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/wu8618q5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_090243-wu8618q5/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_090816-uyocp3qf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/uyocp3qf
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▄▅▅▅▆▆▇████████████████
wandb:        seconds ▂▁▂▃▂▃▅▃▃▃▂▂▂▂▂▃▄▄▂▃▃▅▃▂▃▄▇▇▇▇▆█▆▆▇▅▆▆▆▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▄▅▅▅▆▆▇████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.61208
wandb:      test perf 1.0
wandb:     train loss 0.01129
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/q9ubp1uv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_090339-q9ubp1uv/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_090856-ejj1xnxh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ejj1xnxh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▄▄▄▄▆▆███████████████████
wandb:        seconds ▇▆▅█▇▅▁▂▂▂▂▂▄▄▂▄▁▃▅▄▄▅▄▅▄▂▁▂▅▄▂▂▂▂▄▄▃▁▁▃
wandb:      test perf ▁▁▁▁▂▂▂▁▂▂▂▂▂▃▃▄▄▄▄▆▆███████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.51505
wandb:      test perf 1.0
wandb:     train loss 0.01007
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/wmdzmuul
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_090346-wmdzmuul/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_090907-5l6y8fkw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5l6y8fkw
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▄▄▄▅▆▇▇█████████████████
wandb:        seconds ▅▄▅▅▂▂▂▁▂▂▄▂▄▃▄▃▃▅▃▅▅▄▅▅▄▃▅▇▄█▄▄▃▄▇▅█▆▅▆
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▃▄▄▄▅▆▇▇█████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.70975
wandb:      test perf 1.0
wandb:     train loss 0.01033
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/cduhkx41
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_090754-cduhkx41/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_091324-jngf04ic
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/jngf04ic
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▄▄▄▄▆▆▆█████████████████
wandb:        seconds ▂▄▁▁▁▁▁▂▂▂▃▂▂▂▃▃▂▄▄▅▄▅▅▄▇█▆█▇▇▇▇▅▆▆▇▆▆▆▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▄▄▄▄▆▆▆█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.60011
wandb:      test perf 1.0
wandb:     train loss 0.01064
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/uyocp3qf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_090816-uyocp3qf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_091405-ou4mjf7k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ou4mjf7k
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▃▃▅▅▅▅█████████████████
wandb:        seconds ▂▃▁▃▂▃▂▁▄▂▄▃▁▄▃▃▂▅▆▅█▆▅▅▄▇▆▂▆▄▆▄▃▅▃▄▄▃▃▂
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▃▃▅▅▅▅█████████████████
wandb:     train loss █▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅▆█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.47374
wandb:      test perf 1.0
wandb:     train loss 0.01006
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/5l6y8fkw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_090907-5l6y8fkw/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_091430-kkyhqhc4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/kkyhqhc4
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▄▄▅▅▅▆▆█████████████████
wandb:        seconds ▅▅▃▅▄▆▅▅▇▃▄▅▇▇▄▄█▇▂▆▃▆▃▅▄▇▅▃▅▂▄▄▆▁▄▅▄▄▅▇
wandb:      test perf ▁▁▁▁▂▁▁▁▁▁▁▁▂▂▃▃▄▄▅▅▅▆▆█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.88827
wandb:      test perf 1.0
wandb:     train loss 0.00981
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ejj1xnxh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_090856-ejj1xnxh/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_091502-0om0zhcb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0om0zhcb
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▅▅▅▅▆▆█████████████████
wandb:        seconds ▅▃▃▄▂▆▂▁▃▂▃▂▁▂▄▄▃▃▆▅█▄▆▅▅▆▆▅▇▃▄▇▅▄▄▂▄▃▃▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▅▅▅▅▆▆█████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.46903
wandb:      test perf 1.0
wandb:     train loss 0.01027
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/jngf04ic
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_091324-jngf04ic/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_091836-2tjmgjue
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/2tjmgjue
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▅▆▆▆▆█████████████████
wandb:        seconds ▇█▅▇▇▇▆██▅█▇▄▃▃▄▅▄▄▂▃▂▂▂▄▂▂▃▃▂▂▁▅▁▃▃▃▂▂▂
wandb:      test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▅▆▆▆▆█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇▇▇████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.42954
wandb:      test perf 1.0
wandb:     train loss 0.01126
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ou4mjf7k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_091405-ou4mjf7k/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_091926-vjzvzdqb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/vjzvzdqb
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▄▄▄▅▆▆▆▆▇████████████████
wandb:        seconds ▄▃▂▁▂▃▂▂▃▁▄▄▃▄▆▄▅▅▄▅▃▅▅█▅▄▄▂▂▄▄▃▅▂▁▂▂▂▃▄
wandb:      test perf ▁▁▁▁▁▂▁▁▁▂▂▂▂▂▃▄▄▄▅▆▆▆▆▇████████████████
wandb:     train loss █▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.49821
wandb:      test perf 1.0
wandb:     train loss 0.00995
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/kkyhqhc4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_091430-kkyhqhc4/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_091934-yhchorae
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/yhchorae
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▄▄▄▄▆▆▆▆█████████████████
wandb:        seconds ▇▅▅▁▅▄▆▄▅▆▂▅▃▆▅▄▄▅▅█▅▄▄▄▇▄▆▆▄▃▂▅▄▄▅▄▁▄▇▅
wandb:      test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▄▄▄▄▆▆▆▆█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.78808
wandb:      test perf 1.0
wandb:     train loss 0.00987
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/0om0zhcb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_091502-0om0zhcb/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_092102-k1xtp9vs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/k1xtp9vs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▄▅▆▇▇▇██████████████████
wandb:        seconds ▂▂▄▃▃▄▁▂▂▅▆▃▃▃▅▅▁▆▄▆▅▅▅▅▇█▄▅▄▅▃▃▅▄▅▇▄▅▄▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▄▅▆▇▇▇██████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.55485
wandb:      test perf 1.0
wandb:     train loss 0.01075
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/2tjmgjue
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_091836-2tjmgjue/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_092403-o61u1xse
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/o61u1xse
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▄▅▆▇▇▇██████████████████
wandb:        seconds ▁▂▃▆▂▂▄▂▃▃▂▄▄▅▅▄▁█▄▂▄▅▅▂▃▂▂▅▄▆▃▅▄▃▄▂▂▃▅▂
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▄▅▆▇▇▇██████████████████
wandb:     train loss █▅▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▆▆████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.39991
wandb:      test perf 1.0
wandb:     train loss 0.01073
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/vjzvzdqb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_091926-vjzvzdqb/logs
wandb: \ 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▄▄▅▅▆▆█████████████████
wandb:        seconds ▅▄▅▅▅▆▅▃▅▅▄▇▅▆▅▅█▅▄▃▅▆▃▆▄▅▅▃▅▅▃▄▇▇▄▄▆▅▃▁
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▄▄▅▅▆▆█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▆█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.25118
wandb:      test perf 1.0
wandb:     train loss 0.01064
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/yhchorae
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_091934-yhchorae/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_092440-uxzzzep3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/uxzzzep3
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_092442-3a975r60
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/3a975r60
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: / 0.015 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: - 0.015 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: \ 0.015 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.015 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.015 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: - 0.015 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▄▅▆▆▆▇█████████████████
wandb:        seconds ▆▅▇▆▄▂█▇▆▄▇▆▆▅█▆▅▄▅▂▅▄▆▂▂▁▄▆▅▅▃▅▄▄▄▄▄▃▅▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▄▅▆▆▆▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.72585
wandb:      test perf 1.0
wandb:     train loss 0.00994
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/k1xtp9vs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_092102-k1xtp9vs/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_092713-lgrfjcbi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/lgrfjcbi
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▄▄▅▅▅▆▇█████████████████
wandb:        seconds ▄▃▇▇▁▂▃▄▃▄▆▇▇▅▇█▂▂▂▄▄▂▂▃▃▇▄▄▇▄▄▆▁▃▃▄▄▂▅█
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▄▄▅▅▅▆▇█████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.75301
wandb:      test perf 1.0
wandb:     train loss 0.01061
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/o61u1xse
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_092403-o61u1xse/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_092931-lmfo7848
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/lmfo7848
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▄▅▆▆▆██████████████████
wandb:        seconds ▃▂▄▂▂▄█▅▅▅▇▅▁▂▅▃▂▂▃▂▁▂▆▃▅▁▂▃▆▄▂▆▃▅▄▅▂▆▅▂
wandb:      test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▄▅▆▆▆██████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.38485
wandb:      test perf 1.0
wandb:     train loss 0.00963
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/3a975r60
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_092442-3a975r60/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▄▄▅▆▆▇█████████████████
wandb:        seconds ▂▃▃▄▃▄▆▃█▅▆▄▂▃▃▃▅▃▄▁▃▅▅▅▃▄▆▄▆▄▅▄▅▄▄▅▃▄▄▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▄▄▅▆▆▇█████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.46089
wandb:      test perf 1.0
wandb:     train loss 0.01093
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/uxzzzep3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_092440-uxzzzep3/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_092950-te5e7znz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/te5e7znz
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_092952-eu24y8aw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/eu24y8aw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▄▄▄▅▆▆▆██████████████████
wandb:        seconds ▃▃▂▃▄▄▄▃▃▄▄▂▃▄▁▄▂▁▆▇▄▄▇▄▃▂▆▁▃▄▂█▆▄▆▁▄▆▅▃
wandb:      test perf ▁▁▁▁▁▂▁▂▂▂▂▂▂▃▃▄▄▄▅▆▆▆██████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.73434
wandb:      test perf 1.0
wandb:     train loss 0.01062
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/lgrfjcbi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_092713-lgrfjcbi/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_093322-xrykvvsc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xrykvvsc
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▅▅▅▅▆▆█████████████████
wandb:        seconds ▁▃▃▃▅▃▂▃▂█▆▅▄▅▃▆▅▄▅▅▆▅▅▅▂▂▆▅▄▄▃▅▃▂▃▃▄▁▃▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▅▅▅▅▆▆█████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.55706
wandb:      test perf 1.0
wandb:     train loss 0.01013
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/lmfo7848
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_092931-lmfo7848/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_093451-bjuiieao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/bjuiieao
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▄▄▅▆▆▆▆█████████████████
wandb:        seconds ▂▃▂▂▃▃▂▅█▄▆▅▃▇▃▅▄▇▅▅▂▅▄▄▂▅▅▂▃▄▃▅▃▅▃▄▄▃▁▃
wandb:      test perf ▁▁▁▁▁▁▂▁▁▂▂▂▂▂▃▃▄▄▅▆▆▆▆█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.41083
wandb:      test perf 1.0
wandb:     train loss 0.01063
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/te5e7znz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_092950-te5e7znz/logs
wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▄▄▄▅▅▅▆▇█████████████████
wandb:        seconds ▂▄▁▅▂▂▅▃▃▄▃█▃▄█▄▅▅▅▂▇▄▄▁▅▄▁▄▄▂▃▄▂▂▂▃▂▃▂▁
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▄▄▄▅▅▅▆▇█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▇▇████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.36732
wandb:      test perf 1.0
wandb:     train loss 0.01071
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/eu24y8aw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_092952-eu24y8aw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_093500-kydbu5su
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/kydbu5su
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_093501-dqtlnh5e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/dqtlnh5e
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: - 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▆▆▇█████████████████
wandb:        seconds ▂▆▅▄▅▄▅▄▄▂▂▁▃▅▆▅▆▅▆▃█▂▇▄▃▆▅▆▄▇▇▅▅▃▇▆▂▅▅▆
wandb:      test perf ▁▁▁▁▁▁▁▂▁▂▂▂▃▃▃▄▄▄▄▅▆▆▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.8758
wandb:      test perf 1.0
wandb:     train loss 0.01069
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xrykvvsc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_093322-xrykvvsc/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_093926-xooz184s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xooz184s
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▄▅▅▅▅▆▇████████████████
wandb:        seconds █▆▇▆▅█▆▆▅▅▄▄▃▄▄▅▄▄▅▅▅▄▄▃▄▄▃▅▄▄▃▆▄▅▄▁▄▃▃▆
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▄▅▅▅▅▆▇████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.55432
wandb:      test perf 1.0
wandb:     train loss 0.01082
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/dqtlnh5e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_093501-dqtlnh5e/logs
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_094003-qikh211q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/qikh211q
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▄▄▅▅▅▅▅▇▇███████████████
wandb:        seconds ▃▅▁▃▃▄▅▃▃▂▂▃▃▁▂▅▅▃▃▄▆▄▅▃▄▅▆▅▄▅▄▄▆▃▃█▂▂▄▁
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▅▅▅▅▆▇▇███████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.32916
wandb:      test perf 1.0
wandb:     train loss 0.01032
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/kydbu5su
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_093500-kydbu5su/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_094008-3dchbycz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/3dchbycz
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▄▄▅▅▅▆▆▇█████████████████
wandb:        seconds ▂▃▅▂▄▃▂▃▅▅▃▁▂▄▃▄▃▃▃▂▃▃▇▇▆▇█▆█▇▅▆▄▅▇▇▇▆▄▅
wandb:      test perf ▁▁▁▁▁▁▁▁▂▁▁▁▁▃▃▄▄▅▅▅▆▆▇█████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.62015
wandb:      test perf 1.0
wandb:     train loss 0.01019
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/bjuiieao
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_093451-bjuiieao/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_094019-a0o0gz3h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/a0o0gz3h
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: - 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▄▄▄▄▅▆▆▇████████████████
wandb:        seconds ▂▁▃▇▅▂▅▆▄▅▄▃▅█▅█▇▆▅▆▆▄▅▄▁▁▄▂▄▂▄▂▂▃▃▃▄▄▄▃
wandb:      test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▄▄▄▄▅▆▆▇████████████████
wandb:     train loss █▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.4634
wandb:      test perf 1.0
wandb:     train loss 0.0104
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/qikh211q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_094003-qikh211q/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_094510-5jx1lur9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5jx1lur9
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▄▆▇███████████████████
wandb:        seconds ▂▄▆▅▇▅▇▇▅█▇▃▆▅▇▇▇█▆▇▇▇▆▃▃▅▁▃▂▁▄▂▃▃▂▇▅█▇▂
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▄▆▇███████████████████
wandb:     train loss █▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▃██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.38905
wandb:      test perf 1.0
wandb:     train loss 0.01108
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/3dchbycz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_094008-3dchbycz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_094518-227ik92r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/227ik92r
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▅▅▅▅▆██████████████████
wandb:        seconds ▅██▅▅▅▆▄▅▄▂▄▅▃▄▅▄▄▆▄▆▄▄▄▄▅▄▅▄▃▆▆▄▅▄▃▅▃▁▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▅▅▅▅▆██████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.7412
wandb:      test perf 1.0
wandb:     train loss 0.00994
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xooz184s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_093926-xooz184s/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_094530-ab0r66br
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ab0r66br
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▄▅▅▆▆▇████████████████
wandb:        seconds ▇▇█▇▆▆▇▇▄▆▅▆▅▆▅▅▄▆▄▇▇▆▅▄▆▅█▆▆▅▄▆▄▁▂▄▆▆▇▆
wandb:      test perf ▁▁▁▁▁▁▂▁▁▁▁▁▁▂▂▃▃▃▄▅▅▆▆▇████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.77847
wandb:      test perf 1.0
wandb:     train loss 0.01024
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/a0o0gz3h
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_094019-a0o0gz3h/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_094618-zcgjr6tx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/zcgjr6tx
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▆▇█████████████████
wandb:        seconds ▃▅▁▃▃▃▃▅▂█▃▃▄▅▄▃▅▂▄▅▄▄▅▂▃▅▂▃▂▂▃▄▄▃▆▆▂▄▅▃
wandb:      test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▆▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.44823
wandb:      test perf 1.0
wandb:     train loss 0.01095
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/5jx1lur9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_094510-5jx1lur9/logs
wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▄▅▆▆▆▇█████████████████
wandb:        seconds ▃▆▃▆▂▄▃▄▁▇▃▄▂▂▅▃▃▇▄▂▁▂▃▄▂▃▂▄▆▃█▄▄▆▄▅█▄▄▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▄▅▆▆▆▇█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.42657
wandb:      test perf 1.0
wandb:     train loss 0.01082
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/227ik92r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_094518-227ik92r/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_095020-7hwgi5i8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/7hwgi5i8
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_095025-lampi8bb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/lampi8bb
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▆▆▆▆██████████████████
wandb:        seconds ▅▅▃▄▂█▄▇▁█▆▆▅▆▄▄▅▅▆▃▇▆▄▆▇▆▆▆▇▃▆▁▇▄▅▄▇▅▃▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▅▆▆▆██████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.65424
wandb:      test perf 1.0
wandb:     train loss 0.00998
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ab0r66br
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_094530-ab0r66br/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_095144-rabwhu59
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/rabwhu59
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▅▅▆▇▇█████████████████
wandb:        seconds ▄▃▃▇▃▃▂▄▃▄▅█▄▄▄▄▂▃▅▆▃▄▂▃▄▄▃▁▂▃▂▄▂▂▃▅▁▂▅▂
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▅▅▆▇▇█████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.6362
wandb:      test perf 1.0
wandb:     train loss 0.01056
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/zcgjr6tx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_094618-zcgjr6tx/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_095210-i6t39rw3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/i6t39rw3
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▅▅▅▆▆█████████████████
wandb:        seconds ▅▂▄▄▄▄▄▅▃█▃▃▂▁▄█▆▆▆▄▂▄▄▅▄▄▄▆▅▆▁▆▆▃▅▆▄▆▇▆
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▅▅▅▆▆█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.48429
wandb:      test perf 1.0
wandb:     train loss 0.01152
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/7hwgi5i8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_095020-7hwgi5i8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▄▄▄▅▆▆▆█████████████████
wandb:        seconds ▃▇▅▆▆▆▅█▅▂▄▇▂▄▅▃▄▅▇▃█▃▄▇▄▅▃▃▂▅▃▁▇▃▇▄██▅▂
wandb:      test perf ▁▁▁▁▁▁▂▁▁▁▁▁▁▂▃▃▄▄▄▅▆▆▆█████████████████
wandb:     train loss █▅▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▄▇█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.35535
wandb:      test perf 1.0
wandb:     train loss 0.01061
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/lampi8bb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_095025-lampi8bb/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_095520-2n7pdao1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/2n7pdao1
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_095522-fkv3uuc2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/fkv3uuc2
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▅▆▆▆▆██████████████████
wandb:        seconds ▆▇▅▇██▆▅▅▇▆█▃▃▂▂▄▁▂▃▂▄▅▅▃▃▁▁▃▃▄▃▃▄▃▃▃▃▃▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▅▆▆▆▆██████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.43511
wandb:      test perf 1.0
wandb:     train loss 0.01093
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/rabwhu59
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_095144-rabwhu59/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_095658-9udruax4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/9udruax4
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▄▅▅▅▆▇▇█████████████████
wandb:        seconds ▆▅▇▇▅▄▅▂▅▅▄▆▅█▇▅▅▇▄▆▅▁▅▅▄▄▆▆▇▅▆▇▅▅▄▅▆▅▆▄
wandb:      test perf ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▅▅▆▆▇▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.63697
wandb:      test perf 1.0
wandb:     train loss 0.01043
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/i6t39rw3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_095210-i6t39rw3/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_095805-wwzg7d65
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/wwzg7d65
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▄▄▄▅▅▇▇█████████████████
wandb:        seconds ▆▅▆▅▆▆▃▄▁▂▂▄▄▁█▂▂▇▅▇▅▅▅▃▄▅▆▆▆▄▃▂▃▄▃▄▂▄▃▂
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▄▄▄▅▅▇▇█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆█▇████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.28617
wandb:      test perf 1.0
wandb:     train loss 0.01021
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/2n7pdao1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_095520-2n7pdao1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_100012-lpqru7q0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/lpqru7q0
wandb: 
wandb: Run history:
wandb: best test perf ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▄▅▅▅▆▆▆▇████████████████
wandb:        seconds ▆▄▆▃▇▅▂▄▃▁▁▂▄▂▅▂▇▇▁▃▂▂▃▄▅▄█▂▃▇▆▃▄▄▂▆▄▅▂▂
wandb:      test perf ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▄▅▅▅▆▆▆▇████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.34263
wandb:      test perf 1.0
wandb:     train loss 0.0102
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/fkv3uuc2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_095522-fkv3uuc2/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_100018-2zsdm4ut
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/2zsdm4ut
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▂▂▂▂▂▂▂▂▂▂▂▂▃▃▄▄▅▆▆▆▇█████████████████
wandb:        seconds ▄▅▁▄▆▆▇▃▆▅▄▃▄▂▁▄▃▅▃▂▅▃▅▅▆▅▄▆▁▄▃▆▅█▇▆█▆▅▅
wandb:      test perf ▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▄▄▅▆▆▆▇█████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.3822
wandb:      test perf 1.0
wandb:     train loss 0.00996
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/9udruax4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_095658-9udruax4/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_100140-bbdss89k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/bbdss89k
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▄▅▅▅▆▆▇████████████████
wandb:        seconds ▆▇█▅▆▃▅▅▄▃▂▃▅▇▁▂▅▂▄▄▅▃▅▂▅▁▂▅▂▆▃▁▂▁▃▅▂▄▃▆
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▄▅▅▅▆▆▇████████████████
wandb:     train loss █▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.75164
wandb:      test perf 1.0
wandb:     train loss 0.01059
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/wwzg7d65
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_095805-wwzg7d65/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_100348-jmu7qbwl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/jmu7qbwl
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▅▅▆▆▆█████████████████
wandb:        seconds ▆██▇▆▆▅▆▄▂▁▃▁▄▅▅▄▃▄▄▄▃▅▄▅▆▃▂▅▅▅▃▄▅▄▅▆▃▆▅
wandb:      test perf ▁▁▁▁▁▁▁▂▂▁▁▁▃▂▂▃▃▄▅▅▆▆▆█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.53914
wandb:      test perf 1.0
wandb:     train loss 0.01006
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/lpqru7q0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_100012-lpqru7q0/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_100527-k5mg0pp7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/k5mg0pp7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▄▅▆▆▇██████████████████
wandb:        seconds ▁▂▃▄▄▃▃▅▆▇█▆▆▆▇▆▇▆▇▅▅▄▄▅▇▇▆▅▄▃▅▆▅▃▅▆▄▅▄▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▄▅▆▆▇██████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.71984
wandb:      test perf 1.0
wandb:     train loss 0.01023
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/2zsdm4ut
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_100018-2zsdm4ut/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_100630-snt7p7gr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/snt7p7gr
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▄▅▆▆▆█████████████████
wandb:        seconds ▂▃▅▅█▄▂▄▁▃▃▆▄▁▃▄▂▄▅▇▅▅▅▂▂▆█▄▆▅▃▂▃▃▆▆▅▄▄▂
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▄▅▆▆▆█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.33938
wandb:      test perf 1.0
wandb:     train loss 0.01088
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/bbdss89k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_100140-bbdss89k/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_100640-73b0ng33
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/73b0ng33
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▄▄▄▆▆▇▇█████████████████
wandb:        seconds █▃▆█▂▂▅▄▄▅▆▃▃▅▃▅▄▂▅▆▄▂▄▁▃▂▄▁▄▃▁▅▅▂▄▆▃▂▂▆
wandb:      test perf ▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▄▄▄▆▆▇▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.6787
wandb:      test perf 1.0
wandb:     train loss 0.01094
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/jmu7qbwl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_100348-jmu7qbwl/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_100914-toyhvzkj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/toyhvzkj
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.034 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.034 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: - 0.034 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▅▆▇██████████████████
wandb:        seconds ▅▅▃█▆▂▄▄▂▁▃▆▂▁▂▄▁▅▃▄▅▅▁█▃▃▃▃▄▅▄▃▃▅▃▄▄▆▆▃
wandb:      test perf ▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▅▆▇██████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.44684
wandb:      test perf 1.0
wandb:     train loss 0.01079
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/k5mg0pp7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_100527-k5mg0pp7/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_101032-u15hbvo1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/u15hbvo1
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.013 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.013 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▅▅▅▆▆▇██████████████████
wandb:        seconds ▇▆█▅▁▄▃▅▃▄▂▁▂▂▃▄▄▃▅▅▃▇▄▇▃▃▄▁▅▁▃▇▃▃▅▇▆▅▁▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▅▅▅▆▆▇██████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.38918
wandb:      test perf 1.0
wandb:     train loss 0.0108
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/73b0ng33
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_100640-73b0ng33/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_101138-ly6t9obd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ly6t9obd
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▄▅▅▆▆█████████████████
wandb:        seconds ▂▃▅▃▃▄█▅▅▆▇▅▅▇▄▅▂▂▂▆▃▅▃▇▅▇▁▁▆▆▇▄▅▅▂▄▆▄▅▆
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▄▅▅▆▆█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.81029
wandb:      test perf 1.0
wandb:     train loss 0.0108
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/snt7p7gr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_100630-snt7p7gr/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_101234-wkv44yp0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/wkv44yp0
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▄▄▄▅▆▆▇▇█████████████████
wandb:        seconds ██▄▅▅▁▅▅▁▄▃▅▅▄▇▂▅▅▄▆▄▆▅▅▄▃▄█▄▇▅▅▅▅▆▄▆▃▅▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▄▄▄▅▆▆▇▇█████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.58203
wandb:      test perf 1.0
wandb:     train loss 0.01105
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/toyhvzkj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_100914-toyhvzkj/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_101450-zbl6o60u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/zbl6o60u
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▄▄▄▅▆▆▇▇█████████████████
wandb:        seconds ▆▄▅▆▇▆▅▄▄▅▄▄▅▇█▂▄█▆▆▃▅▇▇▅▆▄▅▆▄▄▄▁▂▃▁▅▇▃▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▄▄▄▅▆▆▇▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.45571
wandb:      test perf 1.0
wandb:     train loss 0.01095
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/u15hbvo1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_101032-u15hbvo1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_101546-fmkgtub2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/fmkgtub2
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▄▄▄▆▆▇█████████████████
wandb:        seconds ▃▆▃▅▇▄▁▁▄▄▄▅▃▃▆▇█▅▅▅▆▆▃▃▅▂▃▂▂▄▆▇▄▄▅▄▄▄▃▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▄▄▄▆▆▇█████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.47362
wandb:      test perf 1.0
wandb:     train loss 0.0095
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ly6t9obd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_101138-ly6t9obd/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_101640-m5srnjg0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/m5srnjg0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▄▄▅▅▅▆▆▆█████████████████
wandb:        seconds ▇▆▆▇▅▂▃▅▅▄█▅▆▅▁▆▅▆▅▇▇▃▅▇▅▇▃▃▅▅▅▆▆▆▂▅▇▆▅▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▄▄▅▅▅▆▆▆█████████████████
wandb:     train loss █▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆▆█████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.75327
wandb:      test perf 1.0
wandb:     train loss 0.01036
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/wkv44yp0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_101234-wkv44yp0/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_101840-iwd7tn4m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/iwd7tn4m
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▄▄▅▆▆▆█████████████████
wandb:        seconds ▃▂▄▆▄▆▃▅▇▄▆▃▃▂█▅▆▆▃▄▆▃▃▂▃▃▂▂▁▃▄▂▃▃▅▆▅▄▇▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▄▄▅▆▆▆█████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▃██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.53984
wandb:      test perf 1.0
wandb:     train loss 0.01029
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/zbl6o60u
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_101450-zbl6o60u/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_102008-1jpmqfyk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1jpmqfyk
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▄▄▄▅▆▆▆▆▇████████████████
wandb:        seconds ▅▂▅█▂▂▂▂▃▅▇▃▂▃▂▃▂▂▃▂▄▅▃▃▁▂▁▃▂▃▆▆▇▄▇▃▇▃▂▇
wandb:      test perf ▁▁▁▁▁▂▂▁▁▁▁▂▂▃▃▄▄▄▅▆▆▆▆▇████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.57963
wandb:      test perf 1.0
wandb:     train loss 0.00982
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/fmkgtub2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_101546-fmkgtub2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_102044-efm0i1ne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/efm0i1ne
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.013 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.013 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▄▄▄▅▆▆▇█████████████████
wandb:        seconds ▇▆█▅▄▁▁▃▃▅▂▄▂▄▃▄▁▂▅▆▃▃▂▃▆▇▄▂▄▄▇▇▆▄▄█▄▇▂▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▄▄▄▅▆▆▇█████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.36831
wandb:      test perf 1.0
wandb:     train loss 0.0107
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/m5srnjg0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_101640-m5srnjg0/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_102126-0dln99hz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0dln99hz
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▄▄▆▆▆▇█████████████████
wandb:        seconds ██▅▄▂▃▃▄▃▄▄▃▃▄▅▄▁▄▅▃▃▁▂▄▆▂▃▃▂▂▃▃▃▄▅▂▃▅▄▅
wandb:      test perf ▁▁▁▁▁▂▁▁▁▁▂▂▂▂▃▃▃▄▄▆▆▆▇█████████████████
wandb:     train loss █▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▅▅▇████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.60242
wandb:      test perf 1.0
wandb:     train loss 0.00952
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/iwd7tn4m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_101840-iwd7tn4m/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_102349-6imv11pp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6imv11pp
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▃▄▅▆▆▆█████████████████
wandb:        seconds ▃▂▆▇▅▆▇▄▇▃▆▇▁▂▃▄▃▃▃▃▂▅▅█▇▃▆▆▅▄▃▄█▆▅▁▅▆▇▇
wandb:      test perf ▁▁▁▁▁▂▁▁▁▁▁▁▁▂▂▂▃▃▄▅▆▆▆█████████████████
wandb:     train loss █▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.69946
wandb:      test perf 1.0
wandb:     train loss 0.01084
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/1jpmqfyk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_102008-1jpmqfyk/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_102536-3mg5wswx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/3mg5wswx
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.013 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.013 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▅▅▅▇▇█████████████████
wandb:        seconds ▅▅▅▇▃▁▆▇▇▃▄▅▄▇▃▃▇▅▄▅▅▅▆▅▆█▃▄█▄▅▄▆▅▅▄▆▃▃▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▅▅▆▆▇▇█████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.45057
wandb:      test perf 1.0
wandb:     train loss 0.01114
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/efm0i1ne
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_102044-efm0i1ne/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▄▄▄▅▅▆▆▆█████████████████
wandb:        seconds ▂▆▄▃▃▄▃▃▂▂▅▇▄▅▄▅▆█▅▂▄▆▄▅▂▃▃█▄▇▆▄▂▅▃▅▆▁▃▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▄▄▄▅▅▆▆▆█████████████████
wandb:     train loss █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.35711
wandb:      test perf 1.0
wandb:     train loss 0.01035
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/0dln99hz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_102126-0dln99hz/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.015 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.015 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▄▄▅▆▇▇█████████████████
wandb:        seconds ▅█▄▅▇▅██▆▇▅▆▃▄▂▂█▇▅▂▃▃▂▃▄▄▄▂▃▃▅▃▄▂▇▄▄▁▁▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▄▄▅▆▇▇█████████████████
wandb:     train loss █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.37336
wandb:      test perf 1.0
wandb:     train loss 0.01026
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6imv11pp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_102349-6imv11pp/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▅▅▆▆▇██████████████████
wandb:        seconds ▅▇▇▇█▃▂▂▄▄▇▂▃▅▄█▃▃▂▃▄▂▄▂▃▃▃▃▂▄▃▃▃▁▃▃▂▁▂▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▅▅▆▆▇██████████████████
wandb:     train loss █▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁▇██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.43624
wandb:      test perf 1.0
wandb:     train loss 0.01112
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/3mg5wswx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_102536-3mg5wswx/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103039-92ghdmti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/92ghdmti
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103039-99toze8i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/99toze8i
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103040-p60y4x4x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/p60y4x4x
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103040-4mp26fj3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/4mp26fj3
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▂▇▇▇▇▇███████████
wandb:        seconds █▂▂▃▃▃▄▂▂▂▅▃▂▄▃▂▆▁▂▂
wandb:      test perf ▁▁▁▂▇▄▃▄▅███████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.12854
wandb:      test perf 1.0
wandb:     train loss 0.00118
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/99toze8i
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103039-99toze8i/logs
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁█████████████
wandb:        seconds █▂▂▃▂▂▂▅▃▂▄▃▂▃▂▂▃▂▄▁
wandb:      test perf ▁▁▁▁▁▁▁█████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.02455
wandb:      test perf 1.0
wandb:     train loss 0.00091
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/p60y4x4x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103040-p60y4x4x/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁█████████████
wandb:        seconds █▂▃▃▄▄▄▃▄▄▅▅▅▅▄▄▄▅▅▁
wandb:      test perf ▁▁▁▁▁▁▁█████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.00887
wandb:      test perf 1.0
wandb:     train loss 0.00096
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/92ghdmti
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103039-92ghdmti/logs
wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▂▂███████████████
wandb:        seconds █▅▄▅▄▅▅▆▆▆▅▅▇▅▅▄▄▅▄▁
wandb:      test perf ▁▁▁▂▂███████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.82542
wandb:      test perf 1.0
wandb:     train loss 0.0013
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/4mp26fj3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103040-4mp26fj3/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103131-d3f1waro
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/d3f1waro
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103132-tjor7wnv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/tjor7wnv
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103133-8b6zm0ya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8b6zm0ya
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103134-iq10ssvi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/iq10ssvi
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▃███████████
wandb:        seconds ▁▂█▆▆▄▆▇▇▆▇▄█▂▅▇▆▆▃▃
wandb:      test perf ▁▁▁▁▁▁▁▁▃███████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.87919
wandb:      test perf 1.0
wandb:     train loss 0.00104
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/d3f1waro
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103131-d3f1waro/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▇▇▇██████████████
wandb:        seconds ▁▃▇▆▄▃▇▇█▄█▆▄▆▄▇▄▃▅█
wandb:      test perf ▁▁▁▇▆▆██████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.0554
wandb:      test perf 1.0
wandb:     train loss 0.00149
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/tjor7wnv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103132-tjor7wnv/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▆███████████
wandb:        seconds ▄▅▄▅▄▄▄▆▅▆▆▆▆▄▆█▅▆▄▁
wandb:      test perf ▁▁▁▁▁▁▁▁▆███████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.72306
wandb:      test perf 1.0
wandb:     train loss 0.0012
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/8b6zm0ya
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103133-8b6zm0ya/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▄▅▅▅▅▅███████████
wandb:        seconds ▅▆▅█▆▇██▅▆▆▆▆▇▆▇▅▅▁▁
wandb:      test perf ▁▁▁▄▅▅▃▃▅███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.48599
wandb:      test perf 1.0
wandb:     train loss 0.00111
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/iq10ssvi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103134-iq10ssvi/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103221-xmfcaksl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xmfcaksl
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103222-3oekbo0q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/3oekbo0q
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103222-wo0hf6qk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/wo0hf6qk
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103224-h1a2bxne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/h1a2bxne
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▃▃▃▃▃▃▃▇██████████
wandb:        seconds ▁▂▇▃█▅▆▆▆▄▄▆▄▇▅▆▆▅▄▆
wandb:      test perf ▁▁▃▁▁▁▁▁▃▇██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.92236
wandb:      test perf 1.0
wandb:     train loss 0.00117
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/3oekbo0q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103222-3oekbo0q/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:        seconds ▁▆▄▆▅▆▇▆▆▇▇█▇▆▇▄▅▅█▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.86882
wandb:      test perf 1.0
wandb:     train loss 0.00074
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xmfcaksl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103221-xmfcaksl/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▂▂▃▇███████████
wandb:        seconds ▄▅▆▇▄▄▅▁▃▄▅▅▆▅▆▇▅█▄▁
wandb:      test perf ▁▁▁▁▁▂▂▃▇███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.76533
wandb:      test perf 1.0
wandb:     train loss 0.00137
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/wo0hf6qk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103222-wo0hf6qk/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103309-7os3gxn2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/7os3gxn2
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▆▆▆██████████████
wandb:        seconds ▇▆▆▅▄▆▆▆▇▅██▆▇█▆▇▆▃▁
wandb:      test perf ▁▁▁▆▄▃██████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.57202
wandb:      test perf 1.0
wandb:     train loss 0.00117
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/h1a2bxne
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103224-h1a2bxne/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103310-6k881ia0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6k881ia0
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103311-qo2ohjva
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/qo2ohjva
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103313-f5bfsy34
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/f5bfsy34
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂███████████████
wandb:        seconds ▁▃▆▇███▄▇▅▆▆▅▄▅▄▆▄▂▃
wandb:      test perf ▁▁▁▁▂███████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.61154
wandb:      test perf 1.0
wandb:     train loss 0.00123
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/7os3gxn2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103309-7os3gxn2/logs
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▇███████████
wandb:        seconds ▁▃▇▆▇█▅▅▆▅▆▆▄▆▇▆▄▃▁▁
wandb:      test perf ▁▁▁▁▁▁▁▁▇███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.705
wandb:      test perf 1.0
wandb:     train loss 0.00109
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6k881ia0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103310-6k881ia0/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103355-30ta79jj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/30ta79jj
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:        seconds ▅█▅▄▇█▆▆▅▅▇▅▆▄▅▅▅▁▂█
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.16956
wandb:      test perf 1.0
wandb:     train loss 0.0015
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/qo2ohjva
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103311-qo2ohjva/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103357-5utj5son
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5utj5son
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▃▇▇▇▇▇████████████
wandb:        seconds ▅▆▅▅▇▆▆▄▆▅▄▂▃▄▆█▁▂▃▂
wandb:      test perf ▁▁▃▇▂▇▇▇████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.87411
wandb:      test perf 1.0
wandb:     train loss 0.00173
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/f5bfsy34
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103313-f5bfsy34/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103401-5cv81jlp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5cv81jlp
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103403-ag07bxet
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ag07bxet
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▃▃▇▇▇▇████████████
wandb:        seconds ▄▇▆▄▆▄▆█▃▂▁▂▁▁▂▂▂▃▁▂
wandb:      test perf ▁▁▃▂▇▄▁▁████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.66014
wandb:      test perf 1.0
wandb:     train loss 0.00125
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/30ta79jj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103355-30ta79jj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Waiting for W&B process to finish... (success).
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - Waiting for wandb.init()...wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103442-7a1h81rd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/7a1h81rd
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▄████████████
wandb:        seconds ▃▁▃▄▅▃▃▄▄▅▅▆▅▅▅▃▄▄█▄
wandb:      test perf ▁▁▁▁▁▁▁▄████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.13236
wandb:      test perf 1.0
wandb:     train loss 0.00135
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/5utj5son
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103357-5utj5son/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▃███████████
wandb:        seconds ▄▅▆▅▆▇▆▅▅█▅▅▃▁▄▄█▁▂▂
wandb:      test perf ▁▁▁▁▁▁▁▁▃███████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.7983
wandb:      test perf 1.0
wandb:     train loss 0.00104
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ag07bxet
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103403-ag07bxet/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:        seconds ▂▅▅▇▄▅▅▃▄▆▃▄▄▃▄▅█▄▂▁
wandb:      test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.82505
wandb:      test perf 1.0
wandb:     train loss 0.0012
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/5cv81jlp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103401-5cv81jlp/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103451-zb7v47n4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/zb7v47n4
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103456-h5g4zz33
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/h5g4zz33
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103457-f9nnhgrc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/f9nnhgrc
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▆██████████
wandb:        seconds ▁▁▃█▂▂▂▂▂▂▂▃▂▂▂▂▂▂▁▂
wandb:      test perf ▁▁▁▁▁▁▁▁▁▆██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.64007
wandb:      test perf 1.0
wandb:     train loss 0.00128
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/7a1h81rd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103442-7a1h81rd/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103530-n7239qgs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/n7239qgs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃▅█████████
wandb:        seconds █▁▃▄▃▄▆▅▄▅▆▄▄▄▃▃▅▄▃▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃▅█████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.04289
wandb:      test perf 1.0
wandb:     train loss 0.00103
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/zb7v47n4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103451-zb7v47n4/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:        seconds ▅▄▄▄▅▄▄▆▅▃▅▆▃▃█▁▃▃▁▁
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.79112
wandb:      test perf 1.0
wandb:     train loss 0.00136
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/h5g4zz33
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103456-h5g4zz33/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103542-vmtxczsb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/vmtxczsb
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▂████████████████
wandb:        seconds ▇▄▄▃██▄▅▅▇▅▄▁▃█▂▅▆▁▂
wandb:      test perf ▁▁▁▂█▆██████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.84422
wandb:      test perf 1.0
wandb:     train loss 0.00112
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/f9nnhgrc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103457-f9nnhgrc/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103545-j88gq5od
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/j88gq5od
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103548-vfrvft90
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/vfrvft90
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▆▆▆██████████████
wandb:        seconds ▃▆▆▃▃▃▁▆▇▆▄▅▆▆▁██▅▆▄
wandb:      test perf ▁▁▁▆▁▂██████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.60672
wandb:      test perf 1.0
wandb:     train loss 0.00132
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/n7239qgs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103530-n7239qgs/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103615-z99o1o0h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/z99o1o0h
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:        seconds ▆▆▂▄▅▅▆▅▅▆▆▃▃▃█▂▁▃▅▂
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.77995
wandb:      test perf 1.0
wandb:     train loss 0.00146
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/vmtxczsb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103542-vmtxczsb/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103630-p6743yqe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/p6743yqe
wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▃▅▆████████████
wandb:        seconds ▁▃█▅█▇▆▇█▇▃▃▇▇▄▄██▄▃
wandb:      test perf ▁▁▁▁▁▃▅▆████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.81299
wandb:      test perf 1.0
wandb:     train loss 0.00103
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/j88gq5od
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103545-j88gq5od/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▁▃█████████
wandb:        seconds ▆█▆▅▆▇▇▅▂▄█▆▃▅▇▆▆▂▁▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▁▃█████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.87139
wandb:      test perf 1.0
wandb:     train loss 0.00127
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/vfrvft90
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103548-vfrvft90/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103637-61tsz103
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/61tsz103
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103639-m9jfi3vl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/m9jfi3vl
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▇▇▇█████████████
wandb:        seconds ▃▃▃▂▂▂▃▁▁▅█▃▂▃▁▃▄▃▃▃
wandb:      test perf ▁▁▁▁▇▇▇█████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.81877
wandb:      test perf 1.0
wandb:     train loss 0.00114
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/z99o1o0h
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103615-z99o1o0h/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103702-bvnvb4hb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/bvnvb4hb
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▅████████████
wandb:        seconds ▄█▅▁▃▃▃▃▃▂▂▂▂▃▄▃▃▃▃▃
wandb:      test perf ▁▁▁▁▁▁▁▅████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.81767
wandb:      test perf 1.0
wandb:     train loss 0.00158
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/p6743yqe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103630-p6743yqe/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103719-gofh8v34
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/gofh8v34
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▆▆▇████████████
wandb:        seconds ▂▂▁▃▂▃▄▃▂▁▅▄▃▄▄▄▄▃▂█
wandb:      test perf ▁▁▁▁▁▆▆▇████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.35144
wandb:      test perf 1.0
wandb:     train loss 0.00177
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/61tsz103
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103637-61tsz103/logs
wandb: \ 0.013 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.013 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▇▇▇██████████████
wandb:        seconds ▄▃▃▄▄▃▂▃▁█▃▅▄▅▃▃▂▄▅▁
wandb:      test perf ▁▁▁▇▃▆██████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.72698
wandb:      test perf 1.0
wandb:     train loss 0.00137
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/m9jfi3vl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103639-m9jfi3vl/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103726-l42z4oiw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/l42z4oiw
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103728-wyuc2tpc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/wyuc2tpc
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▂█████████████
wandb:        seconds ▁▅▃▄▄▅▄▄▂▂██▄▃▄▇▅▆▅▄
wandb:      test perf ▁▁▁▁▁▁▂█████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.94103
wandb:      test perf 1.0
wandb:     train loss 0.00089
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/bvnvb4hb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103702-bvnvb4hb/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103751-742shdng
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/742shdng
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▆██████████
wandb:        seconds ▁▅▄▂▁▂▃▄▂▄▂▃▅█▂▂▅▄▃▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▆██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.27802
wandb:      test perf 1.0
wandb:     train loss 0.00119
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/gofh8v34
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103719-gofh8v34/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.010 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.010 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103812-f47a7x0i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/f47a7x0i
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▆▇██████████████
wandb:        seconds ▇▃▃▄▃▃▃▄█▄▂▃▂▂▂▂▁▁▁▅
wandb:      test perf ▂▁▁▁▆▇██████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.14402
wandb:      test perf 1.0
wandb:     train loss 0.00153
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/wyuc2tpc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103728-wyuc2tpc/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▂▆▆▆▇▇█████████████
wandb:        seconds ▄▄█▄▄▅▅▂▁▇█▃▅▅▄▂▄▄▅▄
wandb:      test perf ▁▂▆▃▁▇▇█████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.09019
wandb:      test perf 1.0
wandb:     train loss 0.00116
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/l42z4oiw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103726-l42z4oiw/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103820-iyppy7pj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/iyppy7pj
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103820-mgnbaasb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/mgnbaasb
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▃████████████
wandb:        seconds ▃▄▃▃▃▃▃▂▄▄▁▁▂█▇▂▃▄▆▅
wandb:      test perf ▁▁▁▁▁▁▁▃████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.92124
wandb:      test perf 1.0
wandb:     train loss 0.00119
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/742shdng
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103751-742shdng/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103839-5j8ti8y8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5j8ti8y8
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▆▆▆▆██████████████
wandb:        seconds ▂█▃▁▁▂▃▃▂▂▂▄▃▂▂▃▃▃▃▃
wandb:      test perf ▁▁▆▂▂▆██████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.96774
wandb:      test perf 1.0
wandb:     train loss 0.00092
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/f47a7x0i
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103812-f47a7x0i/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103900-a1dxlktd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/a1dxlktd
wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▂▆██████████
wandb:        seconds ▆▅▅▄▃▄▄█▂▃▃▂▃▁▄▄▁▂▄▅
wandb:      test perf ▁▁▁▁▁▁▁▁▂▆██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.98205
wandb:      test perf 1.0
wandb:     train loss 0.00145
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/mgnbaasb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103820-mgnbaasb/logs
wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:        seconds ▅▅▅▃▂▃▅█▁▂▁▃▃▄▃▁▁▂▄▂
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.78757
wandb:      test perf 1.0
wandb:     train loss 0.00115
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/iyppy7pj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103820-iyppy7pj/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103908-2v8h3koy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/2v8h3koy
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103910-ot6lzwuk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ot6lzwuk
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▅▆▆████████████
wandb:        seconds ▄▃▄▃▅▄▂▂▂▅▂▁▁▄█▅▃▄▅▅
wandb:      test perf ▁▁▁▁▂▅▆▆████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.86288
wandb:      test perf 1.0
wandb:     train loss 0.0011
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/5j8ti8y8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103839-5j8ti8y8/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103927-837cgzfy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/837cgzfy
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▇▇▇▇██████████████
wandb:        seconds ▂█▇▁▂▂▁▂▁▂▂▇▆▂▃▄▄▃▃▄
wandb:      test perf ▁▁▇▁▆▄██████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.91924
wandb:      test perf 1.0
wandb:     train loss 0.00128
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/a1dxlktd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103900-a1dxlktd/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103949-e58flacm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/e58flacm
wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:        seconds ▂▆▄▂▃▁▅█▂▂▂▄▁▄▆▄▂▃▅▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.00799
wandb:      test perf 1.0
wandb:     train loss 0.00129
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/2v8h3koy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103908-2v8h3koy/logs
wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:        seconds ▇▅▄▃▂▆█▁▄▄▄▅▅▅▃▃▄█▇▁
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.71574
wandb:      test perf 1.0
wandb:     train loss 0.00109
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ot6lzwuk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103910-ot6lzwuk/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_103958-qy8h3dt7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/qy8h3dt7
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104000-n25jd7ia
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/n25jd7ia
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▃▄▄▆██████████████
wandb:        seconds ▂▃▃▄▄▄▃▃▂▄▄▂▁▃█▅▄▂▃▃
wandb:      test perf ▁▁▃▄▂▆██████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.8385
wandb:      test perf 1.0
wandb:     train loss 0.0011
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/837cgzfy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103927-837cgzfy/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104015-o8073gyg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/o8073gyg
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃▃█████████
wandb:        seconds ▁▄█▄▂▂▃▃▃▃▅▅▂▄▄▅▃▃▃▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃▃█████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.83058
wandb:      test perf 1.0
wandb:     train loss 0.00146
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/e58flacm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103949-e58flacm/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104038-bxs6ig0t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/bxs6ig0t
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▂▂▂▂▂▂▃███████████
wandb:        seconds ▁▃▄▃▃██▅▂▅▃▅▄▆▃▄▂▄▄▄
wandb:      test perf ▁▁▂▁▁▁▁▁▃███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.93208
wandb:      test perf 1.0
wandb:     train loss 0.00143
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/qy8h3dt7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_103958-qy8h3dt7/logs
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▃███████████
wandb:        seconds ▃▅▃▂█▅▂▁▃▄▃▃▃▃▂▂▄▄▁▁
wandb:      test perf ▁▁▁▁▁▁▁▁▃███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.71588
wandb:      test perf 1.0
wandb:     train loss 0.00115
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/n25jd7ia
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104000-n25jd7ia/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104047-5uw86hrj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5uw86hrj
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104050-8isqrhfp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8isqrhfp
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▂▂▂▄▇█████████████
wandb:        seconds ▃▁▃▇▆▆▅▃▄▅▇▄▃▂▅▇▇▆▆█
wandb:      test perf ▁▁▂▁▁▄▇█████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.06004
wandb:      test perf 1.0
wandb:     train loss 0.00115
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/o8073gyg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104015-o8073gyg/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104106-a44yjto3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/a44yjto3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.013 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▇███████████
wandb:        seconds ▂▃▅▃▆▅▃▄▁▂▃█▅▁▄▆▄▆▅▄
wandb:      test perf ▁▁▁▁▁▁▁▁▇███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.90123
wandb:      test perf 1.0
wandb:     train loss 0.00148
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/bxs6ig0t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104038-bxs6ig0t/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104127-69zlwhep
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/69zlwhep
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▃████████████
wandb:        seconds ▄▅▂▂▂▂█▅▂▁▂▃▃▂▂▂▂▂▄▁
wandb:      test perf ▁▁▁▁▁▁▁▃████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.69178
wandb:      test perf 1.0
wandb:     train loss 0.00114
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/5uw86hrj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104047-5uw86hrj/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104136-nrvwdkcb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/nrvwdkcb
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▃██████████████
wandb:        seconds ▆▂▂▃█▄▂▄▃▁▃▃▃▁▃▃▁▁▂▅
wandb:      test perf ▁▁▁▁▁▃██████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.23869
wandb:      test perf 1.0
wandb:     train loss 0.00134
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/8isqrhfp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104050-8isqrhfp/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104144-vwei9bst
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/vwei9bst
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▂▄▆▇█████████████
wandb:        seconds ▇▅▅▅▅▅▅▃▄▆▄▃▄▅▇▁▁▃█▆
wandb:      test perf ▁▁▁▂▄▆▇█████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.86793
wandb:      test perf 1.0
wandb:     train loss 0.00141
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/a44yjto3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104106-a44yjto3/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104154-x06xvpol
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/x06xvpol
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▄███████████
wandb:        seconds ▃▅▆▁▂▅█▄▃▃▆▇▃▄▃▄▄▄▄▆
wandb:      test perf ▁▁▁▁▁▁▁▁▄███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.10279
wandb:      test perf 1.0
wandb:     train loss 0.00126
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/69zlwhep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104127-69zlwhep/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104216-nj3pyrkw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/nj3pyrkw
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▃▃▇███████████
wandb:        seconds ▄█▂▁▂▃▆▂▂▃▄▄▄▃▂▂▁▂▅▂
wandb:      test perf ▁▁▁▁▁▁▃▃▇███████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.82577
wandb:      test perf 1.0
wandb:     train loss 0.00111
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/nrvwdkcb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104136-nrvwdkcb/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104227-6f1mtu0l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6f1mtu0l
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁███████████████
wandb:        seconds ▃▅█▄▆▆▅▅▃▃▁▃▃▃▆▃▂▁▄▇
wandb:      test perf ▁▁▁▁▁███████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.11692
wandb:      test perf 1.0
wandb:     train loss 0.00132
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/vwei9bst
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104144-vwei9bst/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104234-wa33ki90
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/wa33ki90
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▇██████████
wandb:        seconds ▄▄▅▄▂▃▂▃▄▃▃▃▁▃▂▆▅▂▂█
wandb:      test perf ▁▁▁▁▁▁▁▁▁▇██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.26354
wandb:      test perf 1.0
wandb:     train loss 0.00123
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/x06xvpol
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104154-x06xvpol/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104243-gggaqz04
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/gggaqz04
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:        seconds ▄▆█▆▁▃▄▃▃▃▆▆▇▄▄▃▅▅▆▇
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.11059
wandb:      test perf 1.0
wandb:     train loss 0.00153
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/nj3pyrkw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104216-nj3pyrkw/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104306-t5gpe58a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/t5gpe58a
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▅█████████████
wandb:        seconds █▃▁▂▆▆▄▁▃▄▄▄▃▄▂▃▄▅▅▃
wandb:      test perf ▁▁▁▁▁▁▅█████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.8435
wandb:      test perf 1.0
wandb:     train loss 0.00084
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6f1mtu0l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104227-6f1mtu0l/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104318-nmk7b74s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/nmk7b74s
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▇▇▇██████████████
wandb:        seconds ▃█▆▁▃▅▃▃▄▅▄▂▁▆▂▁▃▂▂█
wandb:      test perf ▁▁▁▇▇▆██████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.2361
wandb:      test perf 1.0
wandb:     train loss 0.00127
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/wa33ki90
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104234-wa33ki90/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104324-q36c9f2t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/q36c9f2t
wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:        seconds ▄▃▂▃▃▄▃▁▃▆▇▃▂▃▃█▆▂▁▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.89407
wandb:      test perf 1.0
wandb:     train loss 0.00109
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/gggaqz04
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104243-gggaqz04/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104334-kg23vf5q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/kg23vf5q
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:        seconds ▁▂▄█▃▁▄▅▂▃▂▇█▁▂▄▆▆▄▄
wandb:      test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.90227
wandb:      test perf 1.0
wandb:     train loss 0.00149
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/t5gpe58a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104306-t5gpe58a/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104355-upkbl2no
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/upkbl2no
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:        seconds ▅▃▁▁▆█▆▄▄▆▅▃▃▃▃▂▅▆▃▃
wandb:      test perf ▁▁▁▁▁▁▁▁▁▄██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.80314
wandb:      test perf 1.0
wandb:     train loss 0.00122
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/nmk7b74s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104318-nmk7b74s/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▅██████████
wandb:        seconds ▁▃██▃▅▅▅▅▄▂▂▁▃▆▂▄▃▂▅
wandb:      test perf ▁▁▁▁▁▁▁▁▁▅██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.91864
wandb:      test perf 1.0
wandb:     train loss 0.00124
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/q36c9f2t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104324-q36c9f2t/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104408-dtqg70oo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/dtqg70oo
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104412-0g1n6oxt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0g1n6oxt
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:        seconds ▆▄▄▂▃▃▄▁▁▃▄▂▂▅▃▄██▁▂
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.62931
wandb:      test perf 1.0
wandb:     train loss 0.00097
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/kg23vf5q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104334-kg23vf5q/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104422-n2yr1bvc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/n2yr1bvc
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁████████████
wandb:        seconds ▃▂▂▅▆▁▅▄▂▃██▃▄▄▃▄▄▆▆
wandb:      test perf ▁▁▁▁▁▁▁▁████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.1338
wandb:      test perf 1.0
wandb:     train loss 0.00136
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/upkbl2no
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104355-upkbl2no/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104445-3gntunf5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/3gntunf5
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▄▆▆▇████████████
wandb:        seconds ▇▁▂▅▇▃▃▄▅▃▄▃▃▁▁▅█▂▃▃
wandb:      test perf ▁▁▁▁▄▆▅▇████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.94028
wandb:      test perf 1.0
wandb:     train loss 0.00142
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/dtqg70oo
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104408-dtqg70oo/logs
wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:        seconds █▇▇▆▆▆▅▅▂▁▃▃▂▃▃▃▃▂▂▁
wandb:      test perf ▁▁▁▁▁▁▁▁▁▃██████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.67385
wandb:      test perf 1.0
wandb:     train loss 0.00117
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/0g1n6oxt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104412-0g1n6oxt/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104500-0g07zgjr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0g07zgjr
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▂▂▂▃▅███████████
wandb:        seconds ▃▅▃▃▂▃▅▃▂▂█▄▃▂▄▂▂▁▁▇
wandb:      test perf ▁▁▁▁▂▂▂▃▅███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.92317
wandb:      test perf 1.0
wandb:     train loss 0.00104
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/n2yr1bvc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104422-n2yr1bvc/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104501-y5ghf9kc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/y5ghf9kc
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104508-g1bazbkr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/g1bazbkr
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▇████████████
wandb:        seconds █▆▁▂▆▅▁▁▇▆▃▃▄▃▄▄▃▄▃▃
wandb:      test perf ▁▁▁▁▁▁▁▇████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.86696
wandb:      test perf 1.0
wandb:     train loss 0.00138
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/3gntunf5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104445-3gntunf5/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104534-5w5tb0ia
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/5w5tb0ia
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▃███████████
wandb:        seconds ▃█▃▂▄▄▃▃▃▃▄▂▃▂▂▃▂▁▂▁
wandb:      test perf ▁▁▁▁▁▁▁▁▃███████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.67896
wandb:      test perf 1.0
wandb:     train loss 0.00101
wandb:     train perf 1.0
wandb: 
wandb: Waiting for W&B process to finish... (success).
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/0g07zgjr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104500-0g07zgjr/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁██████████████
wandb:        seconds █▇▂▂▅▄▃▃▃▄▃▃▃▂▂▃▁▃▃▁
wandb:      test perf ▁▁▁▁▁▁██▇███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.72515
wandb:      test perf 1.0
wandb:     train loss 0.00127
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/y5ghf9kc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104501-y5ghf9kc/logs
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▃▃▃██████████████
wandb:        seconds █▆▆▆▇▄▄▄▂▁▂▂▃▁▁▄▃▂▁▂
wandb:      test perf ▁▁▁▃▁▁██▇███████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.66619
wandb:      test perf 1.0
wandb:     train loss 0.00156
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/g1bazbkr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104508-g1bazbkr/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104549-8cmmi73k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8cmmi73k
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104549-c29qvqeu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/c29qvqeu
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104552-do7sta1b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/do7sta1b
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁████████████
wandb:        seconds ▅▄▃▂▃█▁▂▂▃▄█▅▅▄▃▅▄▄▆
wandb:      test perf ▁▁▁▁▁▁▁▁████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 2.00063
wandb:      test perf 1.0
wandb:     train loss 0.00143
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/5w5tb0ia
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104534-5w5tb0ia/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104624-sk51zavm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/sk51zavm
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.013 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: | 0.013 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▃▇████████████
wandb:        seconds ▄▄▅▅▆▃▆█▄▆▄▃▁▂▃█▃▂▂▄
wandb:      test perf ▁▁▁▁▁▁▃▇████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.95034
wandb:      test perf 1.0
wandb:     train loss 0.00118
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/c29qvqeu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104549-c29qvqeu/logs
wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁████████████
wandb:        seconds ▇▃▅▄▅▇▅▃▅▄▄▁▁▁█▇▃▄▅▃
wandb:      test perf ▁▁▁▁▁▁▁▁████████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.72896
wandb:      test perf 1.0
wandb:     train loss 0.00124
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/do7sta1b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104552-do7sta1b/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▄▇██████████████
wandb:        seconds ▁▃▅▄▃▃▄▆▄▃▃▂▂▁▁█▅▂▅▄
wandb:      test perf ▁▁▁▁▄▇██████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.97886
wandb:      test perf 1.0
wandb:     train loss 0.00111
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/8cmmi73k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104549-8cmmi73k/logs
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104637-twv309p8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/twv309p8
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104638-dkk1qevz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/dkk1qevz
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▆████████████
wandb:        seconds ▆▄▁▁▂▅▁▁▆▅▅▃▄▅██▆▅▇▃
wandb:      test perf ▁▁▁▁▁▁▁▆████████████
wandb:     train loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.73901
wandb:      test perf 1.0
wandb:     train loss 0.00136
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/sk51zavm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104624-sk51zavm/logs
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▇███████████
wandb:        seconds █▅▇▆▅█▆▇▅▄▃▂▃▂▁▃▃▂▂▁
wandb:      test perf ▁▁▁▁▁▁▁▁▇███████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.59659
wandb:      test perf 1.0
wandb:     train loss 0.00099
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/dkk1qevz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104638-dkk1qevz/logs
wandb: 
wandb: Run history:
wandb: best test perf ▁▁▁▁▁▁▁▁▃▇██████████
wandb:        seconds ▃▇▇▆█▇▇▆▆▆▆▆▅▂▁▂▄▁▂▂
wandb:      test perf ▁▁▁▁▁▁▁▁▃▇██████████
wandb:     train loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train perf ▁███████████████████
wandb: 
wandb: Run summary:
wandb: best test perf 1.0
wandb:        seconds 1.6591
wandb:      test perf 1.0
wandb:     train loss 0.00139
wandb:     train perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/twv309p8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104637-twv309p8/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104729-vw7lbz7m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/vw7lbz7m
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104729-snoavth8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/snoavth8
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104730-2kdt97y5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/2kdt97y5
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104729-3mt3dx1b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/3mt3dx1b
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇█
wandb: train loss ▇█▇▅▇▆▇▆▆▇▆▆▅▅▅▅▅▆▆▄▅▅▅▅▄▄▄▄▃▃▃▃▂▂▃▂▃▁▁▂
wandb: train perf ▁▂▂▅▄▄▂▃▂▃▃▃▄▅▄▃▂▄▁▅▄▃▄▄▄▄▅▅▅▇▅▆█▆▄▇▄█▇▅
wandb: valid perf ▁▂▃▃▃▃▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▅▅▅▆▆▆▅▅▆▆▆▆▆▆▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 1.46248
wandb: train perf 0.46667
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/2kdt97y5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104730-2kdt97y5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104929-nbagwe3a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/nbagwe3a
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.016 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▄▅▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb: train loss ▇▇▅█▅▄▄▇▆▃▅▆▆▆▄▅▅▃▃▄▃▃▃▂▃▂▂▂▂▂▂▁▁▃▁▂▂▂▂▁
wandb: train perf ▁▃▅▁▅█▅▂▃█▃▃▂▃▃▃▃▅▅▅▆▆▆▇▆███▅▇███▆█▆▇▅▆█
wandb: valid perf ▃▁▁▁▂▁▁▁▁▁▂▃▃▄▃▄▄▄▄▅▆▅▇▇▇▇▆▆▆▇▇▇▇█▇▇▇▇██
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.71041
wandb: train perf 0.86667
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/snoavth8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104729-snoavth8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_104953-17ig57wh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/17ig57wh
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▁▁▂▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb: train loss █▇▆▆▆█▆▆▇▅▅▄▅▆▅▆▅▅▅▅▄▃▃▃▃▂▂▁▃▄▁▂▂▁▁▁▁▂▁▁
wandb: train perf ▁▂▄▃▄▁▄▅▂▄▅▇▃▄▃▃▃▅▄▄▅▆▅▆▅▆▆█▆▄▇▄█▇▇▇█▆▇▆
wandb: valid perf ▂▂▂▁▁▂▃▆▇▇▇▇▇▇▆▅▆▇▇▇▇▇▆▅▅▇▇▆▆▆█▇▆▇▇▇▇█▇█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.73993
wandb: train perf 0.73333
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/3mt3dx1b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104729-3mt3dx1b/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_105024-2muqvuyd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/2muqvuyd
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.013 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: | 0.013 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▂▂▂▂▂▂▂▂▂▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇█
wandb: train loss ██▇█▆▇▇▆▅▅▅▄▆▄▄▃▃▄▄▄▄▃▃▃▂▃▂▂▂▁▂▂▁▃▂▁▂▃▁▁
wandb: train perf ▂▁▁▁▃▂▃▃▅▅▄▆▃▄▆▇▇▆▅▄▅▇▄▇█▅▇▇▇▇▇▇█▅▇▇▇▆▇▇
wandb: valid perf ▁▁▃▃▂▂▂▂▃▃▃▄▅▄▃▄▄▄▄▄▄▃▄▅▅▅▅▆▅▆▇▇▆▆▆▆▇▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.54561
wandb: train perf 0.86667
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/vw7lbz7m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104729-vw7lbz7m/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_105137-wk274sih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/wk274sih
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▂▃▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇████
wandb: train loss █▇▇██▆▇▇▆█▇▆▆▆▅▄▄▅▅▄▅▃▅▃▄▃▄▃▃▂▂▃▃▂▁▃▁▁▂▁
wandb: train perf ▁▃▂▁▂▃▂▂▃▂▃▄▃▃▅▅▅▄▄▅▂█▃▇▅▆▅▆▅▇▇▇▅▇█▅█▇▆█
wandb: valid perf ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▃▄▄▄▅▅▄▅▅▄▅▄▅▅▆▆▆▆▆▇▇▇█▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.54061
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/17ig57wh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104953-17ig57wh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_105242-s0pmr972
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/s0pmr972
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▂▃▃▃▄▄▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█
wandb: train loss ▇██▇█▇▆▇▇▅▅▅▅▄▄▃▄▄▃▃▃▃▃▃▃▂▃▂▃▂▁▁▂▂▁▁▁▂▁▁
wandb: train perf ▂▂▁▂▂▂▃▂▃▅▃▄▄▆▆█▅▅▆▅▇▆▅▆▆▇▅▇▆▇██▆▇███▇██
wandb: valid perf ▁▁▂▃▂▃▃▃▅▄▄▆▄▄▄▅▅▅▅▆▅▅▅▆▆▅▆▆▆▆▆▆▆▆▆▇▆▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.42749
wandb: train perf 0.93333
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/nbagwe3a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_104929-nbagwe3a/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_105333-6m9yqdkv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6m9yqdkv
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.026 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.026 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▂▂▂▃▃▃▃▃▃▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb: train loss ▇█▇▅▆▆▇▇▆▅▆▇▆▅▆▅▅▄▅▄▄▄▃▃▃▂▃▂▂▂▃▂▂▃▁▂▁▁▂▁
wandb: train perf ▂▂▂▅▂▃▂▁▃▃▄▂▃▄▃▅▃▄▂▆▅▅▅▆▅█▅▇▇▇▄▇▇▅▇▅▇█▅▆
wandb: valid perf ▁▁▂▂▂▃▂▂▂▁▂▅▅▄▄▄▃▃▂▃▅▅▅▆▆▆▇▅▇▅▅▅▅▅▇▅▇▅▆█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.62778
wandb: train perf 0.73333
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/2muqvuyd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_105024-2muqvuyd/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_105345-mfc4fudf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/mfc4fudf
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▂▂▂▂▂▂▂▂▃▃▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇█
wandb: train loss ▇▇▇▆▅▅▃██▆▅▇▆▅▅▃▅▃▅▆▃▃▂▄▄▄▄▂▄▄▃▂▂▂▂▃▂▁▂▁
wandb: train perf ▂▁▁▃▅▅█▂▂▂▅▁▃▅▄▅▄█▃▃▅▆▇▄▅▅▅▇▃▄▅▆▇▆▇▄▆▇▅█
wandb: valid perf ▁▁▂▁▂▂▂▂▂▂▃▂▄▅▅▅▅▄▅▅▆▅▄▄▄▄▄▃▃▅▅▄▆▆▆▇▆▅▆█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.95534
wandb: train perf 0.86667
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/wk274sih
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_105137-wk274sih/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_105358-97ejlavb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/97ejlavb
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.026 MB uploaded (0.000 MB deduped)wandb: | 0.010 MB of 0.026 MB uploaded (0.000 MB deduped)wandb: / 0.010 MB of 0.026 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▂▂▂▂▂▃▃▃▃▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb: train loss ██▇▅▅▇▇▆▇▆▅▆▆▅▅▅▄▄▅▄▃▄▃▃▃▃▂▂▂▂▁▁▂▂▁▁▁▁▁▁
wandb: train perf ▁▂▃▄▆▂▄▅▂▄▅▃▄▅▃▂▅▅▄▃▆▅▇▆▆▅▇█▆▇▇█▇▇██▇█▇▇
wandb: valid perf ▁▂▂▂▂▂▂▃▃▃▃▅▆▆▆▆▅▆▇▅▅▄▆▇▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.71484
wandb: train perf 0.73333
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/s0pmr972
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_105242-s0pmr972/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_105549-453isn5k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/453isn5k
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▇▇▇█
wandb: train loss ████▇█▆▇▆▅▆▅▄▄▄▄▅▅▄▄▃▃▃▄▃▃▃▃▂▄▁▂▁▂▃▂▃▂▁▁
wandb: train perf ▁▁▁▂▂▂▃▃▅▄▃▅▆▅▅▄▃▃▆▄▆▅▅▅▇▆▅▅▆▆█▇█▇▆▆▆▆▇█
wandb: valid perf ▂▁▂▂▂▃▄▄▃▃▂▃▃▃▄▄▃▅▃▃▃▅▅▄▄▄▄▄▅▄▄▄▄▅▅▆▇▇▆█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.5633
wandb: train perf 0.93333
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6m9yqdkv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_105333-6m9yqdkv/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_105653-xosz0nuj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/xosz0nuj
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▃▅▇▇▇▇▇█████████████████
wandb: train loss ██▇▇▆▆▆▅▆▇▅▅▅▆▄▅▅▃▄▄▄▃▃▄▃▄▃▂▃▂▂▂▂▂▂▂▂▂▁▁
wandb: train perf ▁▁▁▁▅▃▃▅▃▂▅▆▅▃▆▃▅▇▅▆▅▆▇▅▆▅▆▇▆███▇█▆█▇▆██
wandb: valid perf ▁▂▁▃▂▃▃▃▂▃▂▃▂▃▃▃▄▅▆▆▆▇▇██▇▆▆▆▆▆▇▆▇██▇▇██
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.65643
wandb: train perf 0.86667
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/97ejlavb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_105358-97ejlavb/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_105801-1pcebumu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1pcebumu
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▂▂▂▂▂▂▂▂▂▂▃▃▄▇▇▇▇▇▇▇▇▇▇▇▇█████████████
wandb: train loss ██▇▇▇▇▇▆▅▇▅▅▄▄▄▄▃▄▄▃▃▂▃▂▂▂▂▂▁▂▁▂▁▁▁▂▁▁▂▂
wandb: train perf ▁▂▂▂▂▃▃▅▇▁▅▄▆▅▅▆▆▆▆▇▆▇▇▇▇█▇▆█▆█▇▇██▆▆█▅▆
wandb: valid perf ▂▂▂▂▂▂▂▁▂▂▃▂▄▄▄▇▇▇▆▅▆▅▄▅▅▇▆▇▆▇█▇▇▇▅▅▇█▇█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.30837
wandb: train perf 1.0
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/mfc4fudf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_105345-mfc4fudf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_105808-7wdwdkq7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TransformerConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/7wdwdkq7
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▁▁▁▂▃▃▃▃▃▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████
wandb: train loss █▇██▇▇▆▆▆▅▅▆▅▄▄▄▃▃▄▃▄▅▃▃▃▃▂▂▂▂▂▁▁▂▂▄▁▂▂▁
wandb: train perf ▂▂▁▁▂▂▅▄▃▅▅▂▂▅▆▅▆▇▄▇▄▄▆▅▆▅▇▆▇▇▆█▇█▆▅▇▇▆▇
wandb: valid perf ▁▁▁▁▁▃▃▂▃▃▄▄▅▅▅▆▅▅▅▅▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇██▆▇█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.48562
wandb: train perf 0.86667
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/453isn5k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_105549-453isn5k/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.021 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.021 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▃▃▃▃▃▃▃▃▃▃▄▅▆▆▆▇▇▇▇▇▇▇▇███████████████
wandb: train loss ██▇▇▇▇▇▆█▇▅▆▆▇▇▄▅▅▅▄▇▅▄▅▃▃▂▃▄▂▃▃▂▃▂▂▃▃▁▂
wandb: train perf ▁▃▄▂▃▃▂▃▂▃▆▃▄▃▄▆▄▆▄▆▂▄▄▄▇▆▇▆▃██▅▇█▇█▇▅█▇
wandb: valid perf ▁▂▂▂▂▂▂▂▂▃▂▃▄▅▆▆▆▇▆▆▅▅▅▆▇███▇▇▇▇▇▆▆▇▇▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 1.34993
wandb: train perf 0.66667
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run ResGatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/1pcebumu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_105801-1pcebumu/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.026 MB of 0.026 MB uploaded (0.000 MB deduped)wandb: / 0.026 MB of 0.026 MB uploaded (0.000 MB deduped)wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▁▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███████
wandb: train loss ███▆▆█▆▅█▆▅▅▇▄▆▆▆▅▅▅▅▄▄▄▄▃▃▂▃▄▃▂▃▂▂▂▂▁▁▁
wandb: train perf ▂▂▁▃▄▁▂▄▂▃▄▃▁▄▃▂▂▃▄▄▃▇▅▄▄█▆█▅▄▄▇▆▆▇▇▇██▇
wandb: valid perf ▁▁▄▃▂▂▃▄▅▄▅▃▄▃▄▄▅▄▄▅▅▅▅▆▆▆▇▇▅▇▇▇▇▇███▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.84262
wandb: train perf 0.73333
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run TransformerConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/7wdwdkq7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_105808-7wdwdkq7/logs
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.033 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.033 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▂▂▂▂▄▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█
wandb: train loss ███▆▆▆▆▆▅▅▃▅▅▄▄▃▃▄▃▂▃▃▂▃▂▂▂▂▂▂▁▂▁▁▂▁▂▂▁▁
wandb: train perf ▁▂▂▃▄▃▄▃▄▅▆▅▃▅▅▅▆▄▆▇▇▅▇▆▆▇██▆▇▇▇█▇▇▇▅▆▇▇
wandb: valid perf ▂▁▂▂▂▃▄▄▄▄▆▆▆▆▄▅▅▄▅▄▄▆▆▆▇▆▇▆▅▄▇▇▆▆▆▆▆▆▇█
wandb: 
wandb: Run summary:
wandb:  test perf 1.0
wandb: train loss 0.33728
wandb: train perf 0.86667
wandb: valid perf 1.0
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/xosz0nuj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_105653-xosz0nuj/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_110113-8yjaf4tu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8yjaf4tu
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_110113-7li6682f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/7li6682f
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_110113-qne94jjj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GATConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/qne94jjj
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_110113-yrhefk4e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/yrhefk4e
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.107 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.107 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▅▆▅▇▅▅▅▆▆▆▆▆▆██████████████████████████
wandb: train loss █▆▄▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▄▆▆▇▇██▇███████████████████████████████
wandb: valid perf ▁▁▄▆▆▄▆▆▇▅▆▅▇█▆▇▄▄█▅▅▄▇▆▆▄▆▅▇▇▆▅▆▇▆█▅▆▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.45
wandb: train loss 0.00101
wandb: train perf 1.0
wandb: valid perf 0.47368
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/8yjaf4tu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_110113-8yjaf4tu/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.107 MB of 0.107 MB uploaded (0.000 MB deduped)wandb: / 0.107 MB of 0.107 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▂▁▃▃▆▆▅▄█▆▆▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▆▆▆▅▅▅▆▆▆▄▄▅▄▅
wandb: train loss █▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂
wandb: train perf ▁▂▅▆▇███████████████████████████████████
wandb: valid perf ▁▃▃▃▂▆▆▆▆▆▆█▇▆▇▇▆▆▆▇▆▄▆▆▆▆▆▆▆▇▆▇▆▆▇▇▇▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 0.35
wandb: train loss 0.02426
wandb: train perf 0.98246
wandb: valid perf 0.52632
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/yrhefk4e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_110113-yrhefk4e/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.107 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.107 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▂▁▃▇▇▇▇▇▇▇▆▅▅▅▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb: train loss █▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▄▆█▇███████████████████████████████████
wandb: valid perf ▁▄▅▅▆▆▇▆▇▆█▆▇▇▇▇▆▆▇▆▇▆▆▆▇▆▆▆▆▆▆▆▆▇▆▇▆▅▆▅
wandb: 
wandb: Run summary:
wandb:  test perf 0.7
wandb: train loss 0.00165
wandb: train perf 1.0
wandb: valid perf 0.68421
wandb: 
wandb: 🚀 View run GATConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/qne94jjj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_110113-qne94jjj/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂██████████████████████████████████████
wandb: train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁███████████████████████████████████████
wandb: valid perf ▁▅▇█▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb: 
wandb: Run summary:
wandb:  test perf 0.5
wandb: train loss 9e-05
wandb: train perf 1.0
wandb: valid perf 0.42105
wandb: 
wandb: 🚀 View run GatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/7li6682f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_110113-7li6682f/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_115220-wv6nmq32
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/wv6nmq32
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.018 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 🚀 View run GatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/wv6nmq32
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_115220-wv6nmq32/logs
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 57, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 85, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 338, in forward
    x = gnn(x, edge_index, e)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/gnn.py", line 31, in forward
    x = layer(x, edge_index, edge_attr)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/pyg_gnn_wrapper.py", line 84, in forward
    return self.layer(x, edge_index)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/nn/conv/gated_graph_conv.py", line 81, in forward
    x = self.rnn(m, x)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/rnn.py", line 1279, in forward
    ret = _VF.gru_cell(
RuntimeError: CUDA out of memory. Tried to allocate 158.00 MiB (GPU 3; 23.70 GiB total capacity; 22.45 GiB already allocated; 135.69 MiB free; 22.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_115253-20k45vrf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/20k45vrf
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_115418-6f8jn7r6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6f8jn7r6
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_115459-hhirb9rc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GATConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/hhirb9rc
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_124052-y47veqce
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/y47veqce
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.018 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 🚀 View run GatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/y47veqce
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_124052-y47veqce/logs
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 57, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 85, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 338, in forward
    x = gnn(x, edge_index, e)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/gnn.py", line 31, in forward
    x = layer(x, edge_index, edge_attr)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/pyg_gnn_wrapper.py", line 84, in forward
    return self.layer(x, edge_index)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/nn/conv/gated_graph_conv.py", line 81, in forward
    x = self.rnn(m, x)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/rnn.py", line 1279, in forward
    ret = _VF.gru_cell(
RuntimeError: CUDA out of memory. Tried to allocate 158.00 MiB (GPU 3; 23.70 GiB total capacity; 22.46 GiB already allocated; 115.69 MiB free; 22.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_124944-we9kica2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/we9kica2
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_125457-ivntnlst
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ivntnlst
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_135538-8v3c7w9l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GATConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/8v3c7w9l
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_142033-eokiwjn9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/eokiwjn9
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: 🚀 View run GatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/eokiwjn9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_142033-eokiwjn9/logs
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 57, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 85, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 338, in forward
    x = gnn(x, edge_index, e)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/gnn.py", line 31, in forward
    x = layer(x, edge_index, edge_attr)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/pyg_gnn_wrapper.py", line 84, in forward
    return self.layer(x, edge_index)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/nn/conv/gated_graph_conv.py", line 81, in forward
    x = self.rnn(m, x)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/rnn.py", line 1279, in forward
    ret = _VF.gru_cell(
RuntimeError: CUDA out of memory. Tried to allocate 158.00 MiB (GPU 3; 23.70 GiB total capacity; 22.47 GiB already allocated; 115.69 MiB free; 22.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_143812-6ang25g1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/6ang25g1
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_143908-vhn9uemm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GATConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/vhn9uemm
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_144602-qnhasudb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/qnhasudb
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_164311-mcl6b7k2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GATConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/mcl6b7k2
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_165305-c4hzdyph
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/c4hzdyph
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_165413-ju9rd7bm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/ju9rd7bm
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_172706-zrd6otmy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/zrd6otmy
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: 🚀 View run GatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/zrd6otmy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_172706-zrd6otmy/logs
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 57, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 85, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 338, in forward
    x = gnn(x, edge_index, e)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/gnn.py", line 31, in forward
    x = layer(x, edge_index, edge_attr)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/pyg_gnn_wrapper.py", line 84, in forward
    return self.layer(x, edge_index)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/nn/conv/gated_graph_conv.py", line 81, in forward
    x = self.rnn(m, x)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/rnn.py", line 1279, in forward
    ret = _VF.gru_cell(
RuntimeError: CUDA out of memory. Tried to allocate 158.00 MiB (GPU 3; 23.70 GiB total capacity; 22.48 GiB already allocated; 93.69 MiB free; 22.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████
wandb: train loss █▇▆▄▃▃▂▂▂▂▂▁▂▁▂▁▁▁▁▂▁▃▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂
wandb: train perf ▁▂▃▄▅▆▇▇▇▇▇█▇█▇████▇█▅██▇████▇███▇█████▇
wandb: valid perf ▁▅▇██▇▇▇█▇▇▇█▇█▇▇█▇█▇█▇▇█▇▇▇▇█▇▇▇█▇▇▇▇▇█
wandb: 
wandb: Run summary:
wandb:  test perf 0.11875
wandb: train loss 0.09673
wandb: train perf 0.97065
wandb: valid perf 0.11355
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/20k45vrf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_115253-20k45vrf/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▃▇████████████▇▇▇██████████████████████
wandb: train loss █▇▆▅▄▃▂▂▂▂▂▂▁▁▁▂▂▁▂▁▁▂▁▁▂▁▁▂▁▁▇▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▄▅▆▆▇▇▇▇▇███▇▇█▇██▇██▇██▇▇█▂█████▇███
wandb: valid perf ▁▄▇▇▇█▇▇▇▇▇▇▇▇██▇███████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.17875
wandb: train loss 0.73204
wandb: train perf 0.76025
wandb: valid perf 0.18168
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6f8jn7r6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_115418-6f8jn7r6/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_205249-s9cvb8g3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/s9cvb8g3
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_205738-1uy7gkgi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GATConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/1uy7gkgi
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: 🚀 View run GATConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/1uy7gkgi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_205738-1uy7gkgi/logs
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 57, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 85, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 338, in forward
    x = gnn(x, edge_index, e)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/gnn.py", line 31, in forward
    x = layer(x, edge_index, edge_attr)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/pyg_gnn_wrapper.py", line 72, in forward
    return self.layer(x, edge_index, edge_attr)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 225, in forward
    edge_index, edge_attr = add_self_loops(
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/utils/loop.py", line 207, in add_self_loops
    edge_attr = torch.cat([edge_attr, loop_attr], dim=0)
RuntimeError: CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 23.70 GiB total capacity; 3.33 GiB already allocated; 63.69 MiB free; 3.89 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_210456-b3998ojf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/b3998ojf
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: / 0.018 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 🚀 View run GatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/b3998ojf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_210456-b3998ojf/logs
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 57, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 85, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 338, in forward
    x = gnn(x, edge_index, e)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/gnn.py", line 31, in forward
    x = layer(x, edge_index, edge_attr)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/pyg_gnn_wrapper.py", line 84, in forward
    return self.layer(x, edge_index)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/nn/conv/gated_graph_conv.py", line 81, in forward
    x = self.rnn(m, x)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/rnn.py", line 1279, in forward
    ret = _VF.gru_cell(
RuntimeError: CUDA out of memory. Tried to allocate 158.00 MiB (GPU 3; 23.70 GiB total capacity; 22.49 GiB already allocated; 93.69 MiB free; 22.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_210616-z6c3jiy7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/z6c3jiy7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▇▇▇████████████████████████████████████
wandb: train loss █▇▆▅▄▃▂▂▂▂▂▂▂▂▁▁▂▂▁▇▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▂▁▁
wandb: train perf ▁▂▃▄▅▆▆▇▇▇▇▇▇▇██▇▇█▂▇███▇███▇█████▇██▇██
wandb: valid perf ▁▆██████████████████████████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.17207
wandb: train loss 0.00129
wandb: train perf 1.0
wandb: valid perf 0.16547
wandb: 
wandb: 🚀 View run GATConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/hhirb9rc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_115459-hhirb9rc/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆█████████████████████████
wandb: train loss █▇▆▅▃▃▂▂▂▂▂▂▂▁▁▅▂▁▁▁▂▁▁▇▂▁▁▁▂▁▁▁▆▁▁▁▆▁▁▁
wandb: train perf ▁▂▃▄▅▆▇▇▇▇▇▇▇██▄▇███▇██▂▇███▇███▃███▃▇██
wandb: valid perf ▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.14234
wandb: train loss 0.00083
wandb: train perf 1.0
wandb: valid perf 0.13086
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/we9kica2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_124944-we9kica2/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▇▇▇▇▇▇▇▇▇▇▇████████████████████████████
wandb: train loss █▇▆▅▃▂▂▂▂▂▁▁▂▁▁▁▄▁▁▃▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▂▃▄▆▆▇▇▇▇██▇▇██▅██▆██████▄███▇█████████
wandb: valid perf ▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇▇▇█▇▇▇█▇▇▇▇▇▇▇▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.11516
wandb: train loss 0.31928
wandb: train perf 0.8956
wandb: valid perf 0.10773
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/ivntnlst
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_125457-ivntnlst/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_222655-nyfw5l4z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GATConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/nyfw5l4z
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_223522-3wepanb6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GINEConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/3wepanb6
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_223953-18yt5bvf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GCNConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/18yt5bvf
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.14.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230314_225936-h74j2fif
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/h74j2fif
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 🚀 View run GatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/h74j2fif
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_225936-h74j2fif/logs
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 57, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 85, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 338, in forward
    x = gnn(x, edge_index, e)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/gnn.py", line 31, in forward
    x = layer(x, edge_index, edge_attr)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/pyg_gnn_wrapper.py", line 84, in forward
    return self.layer(x, edge_index)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/nn/conv/gated_graph_conv.py", line 81, in forward
    x = self.rnn(m, x)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/rnn.py", line 1279, in forward
    ret = _VF.gru_cell(
RuntimeError: CUDA out of memory. Tried to allocate 158.00 MiB (GPU 3; 23.70 GiB total capacity; 22.49 GiB already allocated; 73.69 MiB free; 22.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▄▇▇▇▇▇▇▇▇▇▇▇███████████████████████████
wandb: train loss █▇▆▄▃▂▂▂▂▁▁▁▁▆▂▂▂▁▁▂▁▁▁▁▇▁▂▁▁▁▃▁▂▁▁▁▁▁▇▁
wandb: train perf ▁▂▃▅▆▇▇▇▇▇███▃▇▇▇██▇▇███▂▇▇███▆█▇█▇███▂█
wandb: valid perf ▁▄██▇▇▇▇▇▇▇█████████▇███████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.21004
wandb: train loss 0.04542
wandb: train perf 0.98755
wandb: valid perf 0.20391
wandb: 
wandb: 🚀 View run GATConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/8v3c7w9l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_135538-8v3c7w9l/logs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  test perf ▁▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████████████████
wandb: train loss █▇▆▅▄▃▂▂▂▂▂▂▂▂▁▄▂▁▁▂▁▁█▁▁▁▁▄▁▁▁▁▁▁▁▃▁▁▁▁
wandb: train perf ▁▂▂▄▅▆▇▇▇▇▇▇▇▇█▅▇██▇██▂████▅███▇███▆████
wandb: valid perf ▁▆▆▆▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇██▇▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.135
wandb: train loss 0.06693
wandb: train perf 0.98159
wandb: valid perf 0.12484
wandb: 
wandb: 🚀 View run GCNConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/qnhasudb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_144602-qnhasudb/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.14.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230315_000352-0mh7ts2u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/0mh7ts2u
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.010 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 🚀 View run GatedGraphConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/0mh7ts2u
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230315_000352-0mh7ts2u/logs
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 57, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 85, in run
    train_perf, train_loss = train(
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 22, in train
    out = model(data)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model.py", line 338, in forward
    x = gnn(x, edge_index, e)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/gnn.py", line 31, in forward
    x = layer(x, edge_index, edge_attr)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/graph-MLPMixer/core/model_utils/pyg_gnn_wrapper.py", line 84, in forward
    return self.layer(x, edge_index)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch_geometric/nn/conv/gated_graph_conv.py", line 81, in forward
    x = self.rnn(m, x)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/site-packages/torch/nn/modules/rnn.py", line 1279, in forward
    ret = _VF.gru_cell(
RuntimeError: CUDA out of memory. Tried to allocate 158.00 MiB (GPU 3; 23.70 GiB total capacity; 22.45 GiB already allocated; 135.69 MiB free; 22.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/shpark/.conda/envs/graph_mlpmixer/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/shpark/graph-MLPMixer/train/tree_neighbour.py", line 57, in <module>
    run(cfg, create_dataset, create_model, train, test)
  File "/home/shpark/graph-MLPMixer/core/train_helper.py", line 35, in run
    train_dataset, val_dataset, test_dataset = create_dataset(cfg)
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 146, in create_dataset
    train_dataset = [transform_train(x) for x in train_dataset]
  File "/home/shpark/graph-MLPMixer/core/get_data.py", line 146, in <listcomp>
    train_dataset = [transform_train(x) for x in train_dataset]
  File "/home/shpark/graph-MLPMixer/core/transform.py", line 131, in __call__
    data.coarsen_adj = random_walk(coarsen_adj)
  File "/home/shpark/graph-MLPMixer/core/transform.py", line 15, in random_walk
    M_power = torch.matmul(M_power, M)
KeyboardInterrupt
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.108 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.108 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.108 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▃▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████
wandb: train loss ██▆▅▃▂▂▂▁▁▁▁█▄▂▁▁▁▄▂▁▁▁▁▁▇▁▁▁▁▇▁▁▁▁▁▁▁▁▁
wandb: train perf ▁▁▂▄▆▇▇▇▇███▁▅▇███▄▇█████▂████▂█████████
wandb: valid perf ▁▃▅▅▅▅▅▅▅▅▅▅▃▆▇▆▆▆▇▇▇▇▇▇▇▆▇▇▇▇█▇▇▇▇▇▇█▇▇
wandb: 
wandb: Run summary:
wandb:  test perf 0.1791
wandb: train loss 0.00033
wandb: train perf 1.0
wandb: valid perf 0.16074
wandb: 
wandb: 🚀 View run GINEConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/6ang25g1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_143812-6ang25g1/logs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  test perf ▁▂▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████
wandb: train loss █▇▅▄▃▂▂▂▁▁▁▁▅▂▁▁▁▁▁▁▅▁▂▁▁▁▁▅▁▁▁▁▁▁▄▁▁▁▁▁
wandb: train perf ▁▁▃▅▆▆▇▇▇███▃▇▇█████▄█▇████▄██████▅▇████
wandb: valid perf ▁▂▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█████████████████
wandb: 
wandb: Run summary:
wandb:  test perf 0.31137
wandb: train loss 8e-05
wandb: train perf 1.0
wandb: valid perf 0.30996
wandb: 
wandb: 🚀 View run GATConv_onlyChannelMixer at: https://wandb.ai/eddy26/graph-MLPMixer/runs/vhn9uemm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230314_143908-vhn9uemm/logs
wandb: Currently logged in as: eddy26. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.14.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.11
wandb: Run data is saved locally in /home/shpark/graph-MLPMixer/wandb/run-20230315_012041-4c9bjvab
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ResGatedGraphConv_onlyChannelMixer
wandb: ⭐️ View project at https://wandb.ai/eddy26/graph-MLPMixer
wandb: 🚀 View run at https://wandb.ai/eddy26/graph-MLPMixer/runs/4c9bjvab
